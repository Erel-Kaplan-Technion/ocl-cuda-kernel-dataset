{"kernel_name": "backprop", "parallel_api": "cuda", "code": {"backprop_cuda.cu": "\n\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <cuda.h>\n#include <sys/time.h>\n\n#include \"backprop_cuda_kernel.cu\"\n#include \"backprop.h\"\n\nextern \"C\"\nvoid bpnn_layerforward(float *l1, float *l2, float **conn, int n1, int n2);\n\nextern \"C\"\nvoid bpnn_output_error(float *delta, float *target, float *output, int nj, float *err);\n\nextern \"C\"\nvoid bpnn_hidden_error(float *delta_h, int nh, float *delta_o, int no, float **who, float *hidden, float *err);\n\nextern \"C\" \nvoid bpnn_adjust_weights(float *delta, int ndelta, float *ly, int nly, float **w, float **oldw);\n\n\nextern \"C\"\nint setup(int argc, char** argv);\n\nextern \"C\"\nfloat **alloc_2d_dbl(int m, int n);\n\nextern \"C\"\nfloat squash(float x);\n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nunsigned int num_threads = 0;\nunsigned int num_blocks = 0;\n\nint\nmain( int argc, char** argv) \n{\n\tsetup(argc, argv);\n}\n\n\nextern \"C\"\nvoid bpnn_train_cuda(BPNN *net, float *eo, float *eh)\n{\n  int in, hid, out;\n  float out_err, hid_err;\n  \n  in = net->input_n;\n  hid = net->hidden_n;\n  out = net->output_n;   \n   \n#ifdef GPU  \n  int m = 0;\n  float *input_hidden_cuda;\n  float *input_cuda;\n  float *output_hidden_cuda;\n  float *partial_sum;\n  float *hidden_partial_sum;\n  float *hidden_delta_cuda;\n  float *input_prev_weights_cuda;\n  float sum;\n  float *input_weights_one_dim;\n  float *input_weights_prev_one_dim;\n  num_blocks = in / 16;  \n  dim3  grid( 1 , num_blocks);\n  dim3  threads(16 , 16);\n  \n  input_weights_one_dim = (float *) malloc((in + 1)* (hid + 1) * sizeof(float));\n  input_weights_prev_one_dim = (float *) malloc((in + 1)* (hid + 1) * sizeof(float));\n  partial_sum = (float *) malloc(num_blocks * WIDTH * sizeof(float));\n \n  for (int k = 0; k <= in; k++) {\t\n   for (int j = 0; j <= hid; j++) {\n\t  input_weights_one_dim[m] = net->input_weights[k][j];\n\t  input_weights_prev_one_dim[m] = net-> input_prev_weights[k][j];\n\t  m++;\n    }\n  }\n  \n  cudaMalloc((void**) &input_cuda, (in + 1) * sizeof(float));\n  cudaMalloc((void**) &output_hidden_cuda, (hid + 1) * sizeof(float));\n  cudaMalloc((void**) &input_hidden_cuda, (in + 1) * (hid + 1) * sizeof(float));\n  cudaMalloc((void**) &hidden_partial_sum, num_blocks * WIDTH * sizeof(float));\n  \n  \n#endif\n\n#ifdef CPU\n\n  printf(\"Performing CPU computation\\n\");\n  bpnn_layerforward(net->input_units, net->hidden_units,net->input_weights, in, hid);\n\n#endif\n\n#ifdef GPU\n \n  printf(\"Performing GPU computation\\n\");\n  \n  cudaMemcpy(input_cuda, net->input_units, (in + 1) * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(input_hidden_cuda, input_weights_one_dim, (in + 1) * (hid + 1) * sizeof(float), cudaMemcpyHostToDevice);\n\n  \n  \n  bpnn_layerforward_CUDA<<< grid, threads >>>(input_cuda,\n\t                                          output_hidden_cuda,\n\t\t\t\t\t\t\t\t\t\t\t  input_hidden_cuda,\n\t\t\t\t\t\t\t\t\t\t\t  hidden_partial_sum,\n\t\t\t\t\t\t\t\t\t\t\t  in,\n\t\t\t\t\t\t\t\t\t\t\t  hid);\n \n  cudaThreadSynchronize();\n  \n  cudaError_t error = cudaGetLastError();\n\tif (error != cudaSuccess) {\n\t\tprintf(\"bpnn kernel error: %s\\n\", cudaGetErrorString(error));\n\t\texit(EXIT_FAILURE);\n\t}\n  \n  cudaMemcpy(partial_sum, hidden_partial_sum, num_blocks * WIDTH * sizeof(float), cudaMemcpyDeviceToHost);\n     \n  for (int j = 1; j <= hid; j++) {\n    sum = 0.0;\n    for (int k = 0; k < num_blocks; k++) {\t\n      sum += partial_sum[k * hid + j-1] ;\n    }\n\tsum += net->input_weights[0][j];\n\tnet-> hidden_units[j] = float(1.0 / (1.0 + exp(-sum)));\n  }\n  #endif\n\n  bpnn_layerforward(net->hidden_units, net->output_units, net->hidden_weights, hid, out);\n  bpnn_output_error(net->output_delta, net->target, net->output_units, out, &out_err);\n  bpnn_hidden_error(net->hidden_delta, hid, net->output_delta, out, net->hidden_weights, net->hidden_units, &hid_err);  \n  bpnn_adjust_weights(net->output_delta, out, net->hidden_units, hid, net->hidden_weights, net->hidden_prev_weights);\n\n#ifdef CPU\n\n  bpnn_adjust_weights(net->hidden_delta, hid, net->input_units, in, net->input_weights, net->input_prev_weights);\n\n#endif  \n\n\n#ifdef GPU\n\n  cudaMalloc((void**) &hidden_delta_cuda, (hid + 1) * sizeof(float));\n  cudaMalloc((void**) &input_prev_weights_cuda, (in + 1) * (hid + 1) * sizeof(float));\n\n  cudaMemcpy(hidden_delta_cuda, net->hidden_delta, (hid + 1) * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(input_prev_weights_cuda, input_weights_prev_one_dim, (in + 1) * (hid + 1) * sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(input_hidden_cuda, input_weights_one_dim, (in + 1) * (hid + 1) * sizeof(float), cudaMemcpyHostToDevice);\n\n\n  bpnn_adjust_weights_cuda<<< grid, threads >>>(hidden_delta_cuda,  \n\t\t\t\t\t\t\t\t\t\t\t\thid, \n\t\t\t\t\t\t\t\t\t\t\t\tinput_cuda, \n\t\t\t\t\t\t\t\t\t\t\t\tin,\n\t\t\t\t\t\t\t\t\t\t\t\tinput_hidden_cuda, \n\t\t\t\t\t\t\t\t\t\t\t\tinput_prev_weights_cuda\n\t\t\t\t\t\t\t\t\t\t\t\t);\n\n  cudaMemcpy(net->input_units, input_cuda, (in + 1) * sizeof(float), cudaMemcpyDeviceToHost);\n  cudaMemcpy(input_weights_one_dim, input_hidden_cuda, (in + 1) * (hid + 1) * sizeof(float), cudaMemcpyDeviceToHost);\n    \n  cudaFree(input_cuda);\n  cudaFree(output_hidden_cuda);\n  cudaFree(input_hidden_cuda);\n  cudaFree(hidden_partial_sum);\n  cudaFree(input_prev_weights_cuda);\n  cudaFree(hidden_delta_cuda);\n  \n  free(partial_sum);\n  free(input_weights_one_dim);\n  free(input_weights_prev_one_dim);\n\n#endif   \n  \n}\n", "backprop_cuda_kernel.cu": "#ifndef _BACKPROP_CUDA_KERNEL_H_\n#define _BACKPROP_CUDA_KERNEL_H_\n\n#include <stdio.h>\n#include \"backprop.h\"\n#include \"math.h\"\n#include \"cuda.h\"\n\n\n__global__ void\nbpnn_layerforward_CUDA(float *input_cuda,\n\t                   float *output_hidden_cuda,\n\t\t\t\t\t   float *input_hidden_cuda,\n\t\t\t\t\t   float *hidden_partial_sum,\n\t\t\t\t\t   int in,\n\t\t\t\t\t   int hid) \n{\n   int by = blockIdx.y;\n   int tx = threadIdx.x;\n   int ty = threadIdx.y;\n\n   int index =  ( hid + 1 ) * HEIGHT * by + ( hid + 1 ) * ty + tx + 1 + ( hid + 1 ) ;  \n\n   int index_in = HEIGHT * by + ty + 1;\n   \n   __shared__ float input_node[HEIGHT];\n   __shared__ float weight_matrix[HEIGHT][WIDTH];\n\n\n   if ( tx == 0 )\n   input_node[ty] = input_cuda[index_in] ;\n   \n   __syncthreads();\n\n   weight_matrix[ty][tx] = input_hidden_cuda[index];\n\n   __syncthreads();\n   \n   weight_matrix[ty][tx] = weight_matrix[ty][tx] * input_node[ty];\n\n   __syncthreads();   \n   \n   for ( int i = 1 ; i <= __log2f(HEIGHT) ; i++){\n \n\t   int power_two = __powf(2, i);\n\n\t   if( ty % power_two == 0 )\n\t   weight_matrix[ty][tx] = weight_matrix[ty][tx] + weight_matrix[ty + power_two/2][tx];\n\n\t   __syncthreads();\n\n   }\n   \n   input_hidden_cuda[index] = weight_matrix[ty][tx];\n   \n\n   __syncthreads();\n\n   if ( tx == 0 ) {\n\t   hidden_partial_sum[by * hid + ty] = weight_matrix[tx][ty];\n   }\n\n}\n\n\n__global__ void bpnn_adjust_weights_cuda(float * delta,   \n\t\t\t\t\t\t\t\t\t\t int hid,         \n\t\t\t\t\t\t\t\t\t\t float * ly,      \n\t\t\t\t\t\t\t\t\t\t int in,          \n\t\t\t\t\t\t\t\t\t\t float * w,       \n\t\t\t\t\t\t\t\t\t\t float * oldw)  \t\t\t\t\t\t\t\t\t\n{\n  \n  \n   int by = blockIdx.y;\n\n   int tx = threadIdx.x;\n   int ty = threadIdx.y;\n\t\n   int index =  ( hid + 1 ) * HEIGHT * by + ( hid + 1 ) * ty + tx + 1 + ( hid + 1 ) ;  \n   int index_y = HEIGHT * by + ty + 1;\n   int index_x = tx + 1;\n\n\n   w[index] += ((ETA * delta[index_x] * ly[index_y]) + (MOMENTUM * oldw[index]));\n   oldw[index] = ((ETA * delta[index_x] * ly[index_y]) + (MOMENTUM * oldw[index]));\n\n\n   __syncthreads();\n\n   if (ty == 0 && by ==0){\n   w[index_x] += ((ETA * delta[index_x]) + (MOMENTUM * oldw[index_x]));\n   oldw[index_x] = ((ETA * delta[index_x]) + (MOMENTUM * oldw[index_x]));\n   }\n\n\n}\n#endif \n"}, "code_dirs": {"backprop_cuda.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/backprop", "backprop_cuda_kernel.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/backprop"}}
{"kernel_name": "backprop", "parallel_api": "ocl", "code": {"backprop_ocl.cpp": "// includes, system\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <sys/time.h>\n#include \"backprop.h\"\n\n#ifdef NV\n\t#include <oclUtils.h>\n#else\n\t#include <CL/cl.h>\n#endif\n\n#ifdef TIMING\n    #include \"timing.h\"\n#endif\n\nstatic cl_context\t    context;\nstatic cl_command_queue cmd_queue;\nstatic cl_device_id   * device_list;\nstatic cl_uint          num_devices;\n\n// OCL config\nint platform_id_inuse = 0;            // platform id in use (default: 0)\nint device_id_inuse = 0;              //device id in use (default : 0)\ncl_device_type device_type = CL_DEVICE_TYPE_GPU;\n\n#ifdef TIMING\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_init_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nstatic int initialize(void)\n{\n\tcl_int result;\n\tsize_t size;\n    cl_uint num_platforms;\n\n    // get OpenCL platforms\n\tif (clGetPlatformIDs(0, NULL, &num_platforms) != CL_SUCCESS) { printf(\"ERROR: clGetPlatformIDs(0,0,*) failed\\n\"); return -1; }\n\tcl_platform_id all_platform_id[num_platforms];\n\tif (clGetPlatformIDs(num_platforms, all_platform_id, NULL) != CL_SUCCESS) { printf(\"ERROR: clGetPlatformIDs(*,*,0) failed\\n\"); return -1; }\n    cl_platform_id platform_id = all_platform_id[platform_id_inuse];\n\n    // get device\n    if (clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_ALL, 0, NULL, &num_devices) != CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\tprintf(\"num_devices = %d\\n\", num_devices);\n    if(device_id_inuse > num_devices) {\n        printf(\"Invalid Device Number\\n\");\n        return -1;\n    }\n\tdevice_list = new cl_device_id[num_devices];\n\t//device_list = (cl_device_id *)malloc(sizeof(cl_device_id)*num_devices);\n\tif( !device_list ) { printf(\"ERROR: new cl_device_id[] failed\\n\"); return -1; }\n    if (clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_ALL, num_devices, device_list, NULL) != CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\n    // get device type\n    if (clGetDeviceInfo(device_list[device_id_inuse], CL_DEVICE_TYPE, sizeof(device_type), (void *)&device_type, NULL)!= CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\n\t// create OpenCL context\n\tcl_context_properties ctxprop[] = { CL_CONTEXT_PLATFORM, (cl_context_properties)platform_id, 0};\n\tcontext = clCreateContextFromType( ctxprop, device_type, NULL, NULL, NULL );\n\tif( !context ) { printf(\"ERROR: clCreateContextFromType(%s) failed\\n\", device_type == CL_DEVICE_TYPE_GPU ? \"GPU\" : \"CPU\"); return -1; }\n\n\t// create command queue for the specific device\n#ifdef TIMING\n\tcmd_queue = clCreateCommandQueue( context, device_list[device_id_inuse], CL_QUEUE_PROFILING_ENABLE, NULL );\n#else\n\tcmd_queue = clCreateCommandQueue( context, device_list[device_id_inuse], 0, NULL );\n#endif\n\tif( !cmd_queue ) { printf(\"ERROR: clCreateCommandQueue() failed\\n\"); return -1; }\n\treturn 0;\n}\n\nstatic int shutdown()\n{\n\t// release resources\n\tif( cmd_queue ) clReleaseCommandQueue( cmd_queue );\n\tif( context ) clReleaseContext( context );\n\tif( device_list ) delete[] device_list;\n\n\t// reset all variables\n\tcmd_queue = 0;\n\tcontext = 0;\n\tdevice_list = 0;\n\tnum_devices = 0;\n\tdevice_type = CL_DEVICE_TYPE_GPU;\n\n\treturn 0;\n}\n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nunsigned int num_threads = 0;\nunsigned int num_blocks = 0;\n\nint\nmain( int argc, char** argv)\n{\n\tsetup(argc, argv);\n}\n\n\nint bpnn_train_kernel(BPNN *net, float *eo, float *eh)\n{\n\tint in, hid, out;\n\tfloat out_err, hid_err;\n\n\tin = net->input_n;\n\thid = net->hidden_n;\n\tout = net->output_n;\n\n\tint sourcesize = 1024*1024;\n\tchar * source = (char *)calloc(sourcesize, sizeof(char));\n\tif(!source) { printf(\"ERROR: calloc(%d) failed\\n\", sourcesize); return -1; }\n\n\tconst char * kernel_bp1  = \"bpnn_layerforward_ocl\";\n\tconst char * kernel_bp2  = \"bpnn_adjust_weights_ocl\";\n\tconst char * tempchar = \"./backprop_kernel.cl\";\n\tFILE * fp = fopen(tempchar, \"rb\");\n\tif(!fp) { printf(\"ERROR: unable to open '%s'\\n\", tempchar); return -1; }\n\tfread(source + strlen(source), sourcesize, 1, fp);\n\tfclose(fp);\n\n#ifdef  TIMING\n    gettimeofday(&tv_total_start, NULL);\n#endif\n\tif(initialize()) return -1;\n\n\t// compile kernel\n\tcl_int err = 0;\n\tconst char * slist[2] = { source, 0 };\n\tcl_program prog = clCreateProgramWithSource(context, 1, slist, NULL, &err);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateProgramWithSource() => %d\\n\", err); return -1; }\n\terr = clBuildProgram(prog, 0, NULL, NULL, NULL, NULL);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clBuildProgram() => %d\\n\", err); return -1; }\n\n\tcl_kernel kernel1;\n\tcl_kernel kernel2;\n\tkernel1 = clCreateKernel(prog, kernel_bp1, &err);\n\tkernel2 = clCreateKernel(prog, kernel_bp2, &err);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateKernel() 0 => %d\\n\", err); return -1; }\n\tclReleaseProgram(prog);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_init_end, NULL);\n\ttvsub(&tv_init_end, &tv_total_start, &tv);\n\tinit_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\n\tfloat *input_weights_one_dim;\n    float *input_weights_prev_one_dim;\n\tfloat * partial_sum;\n\tfloat sum;\n\tfloat num_blocks = in / BLOCK_SIZE;\n\n\tinput_weights_one_dim = (float *) malloc((in + 1)* (hid + 1) * sizeof(float));\n\tinput_weights_prev_one_dim = (float *) malloc((in + 1)* (hid + 1) * sizeof(float));\n\tpartial_sum = (float *) malloc(num_blocks * WIDTH * sizeof(float));\n\n\tsize_t global_work[3] = { BLOCK_SIZE, BLOCK_SIZE * num_blocks, 1 };\n\tsize_t local_work[3] = { BLOCK_SIZE, BLOCK_SIZE, 1 };\n\n\tint m = 0;\n\tfor (int k = 0; k <= in; k++) {\n\t\tfor (int j = 0; j <= hid; j++) {\n\t\tinput_weights_one_dim[m] = net->input_weights[k][j];\n\t\tinput_weights_prev_one_dim[m] = net-> input_prev_weights[k][j];\n\t    m++;\n\t\t}\n\t}\n\n\tcl_mem input_hidden_ocl;\n\tcl_mem input_ocl;\n\tcl_mem output_hidden_ocl;\n\tcl_mem hidden_partial_sum;\n\tcl_mem hidden_delta_ocl;\n\tcl_mem input_prev_weights_ocl;\n\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_start, NULL);\n#endif\n\tinput_ocl = clCreateBuffer(context, CL_MEM_READ_WRITE, (in + 1) * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer input_ocl\\n\"); return -1;}\n\tinput_hidden_ocl = clCreateBuffer(context, CL_MEM_READ_WRITE, (in + 1) * (hid + 1) * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer input_hidden_ocl\\n\"); return -1;}\n\toutput_hidden_ocl = clCreateBuffer(context, CL_MEM_READ_WRITE, (hid + 1) * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer output_hidden_ocl\\n\"); return -1;}\n\thidden_partial_sum = clCreateBuffer(context, CL_MEM_READ_WRITE, num_blocks * WIDTH * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer hidden_partial_sum\\n\"); return -1;}\n\thidden_delta_ocl = clCreateBuffer(context, CL_MEM_READ_WRITE, (hid + 1) * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer hidden_delta_ocl\\n\"); return -1;}\n\tinput_prev_weights_ocl = clCreateBuffer(context, CL_MEM_READ_WRITE, (in + 1) * (hid + 1) * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer input_prev_weights_ocl\\n\"); return -1;}\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_mem_alloc_start, &tv);\n    mem_alloc_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tprintf(\"Performing %s computation\\n\", device_type == CL_DEVICE_TYPE_GPU ? \"GPU\" : \"CPU\");\n    cl_event event;\n    cl_event write_event[3];\n\n\terr = clEnqueueWriteBuffer(cmd_queue, input_ocl, 1, 0, (in + 1) * sizeof(float), net->input_units, 0, 0, &write_event[0]);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer input_ocl\\n\"); return -1; }\n\n\terr = clEnqueueWriteBuffer(cmd_queue, input_hidden_ocl, 1, 0, (in + 1) * (hid + 1) * sizeof(float), input_weights_one_dim, 0, 0, &write_event[1]);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer input_hidden_ocl\\n\"); return -1; }\n#ifdef TIMING\n    h2d_time += probe_event_time(write_event[0],cmd_queue);\n    h2d_time += probe_event_time(write_event[1],cmd_queue);\n#endif\n    clReleaseEvent(write_event[0]);\n    clReleaseEvent(write_event[1]);\n\n\tclSetKernelArg(kernel1, 0, sizeof(void *), (void*) &input_ocl);\n\tclSetKernelArg(kernel1, 1, sizeof(void *), (void*) &output_hidden_ocl);\n\tclSetKernelArg(kernel1, 2, sizeof(void *), (void*) &input_hidden_ocl);\n\tclSetKernelArg(kernel1, 3, sizeof(void *), (void*) &hidden_partial_sum );\n\tclSetKernelArg(kernel1, 4, sizeof(float) *  HEIGHT, (void*)NULL );\n\tclSetKernelArg(kernel1, 5, sizeof(float ) *  HEIGHT * WIDTH, (void*)NULL );\n\tclSetKernelArg(kernel1, 6, sizeof(cl_int), (void*) &in);\n\tclSetKernelArg(kernel1, 7, sizeof(cl_int), (void*) &hid);\n\n\terr = clEnqueueNDRangeKernel(cmd_queue, kernel1, 2, NULL, global_work, local_work, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: 1  clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\n#ifdef TIMING\n    kernel_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\terr = clEnqueueReadBuffer(cmd_queue, hidden_partial_sum, 1, 0, num_blocks * WIDTH * sizeof(float), partial_sum, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: 1  clEnqueueReadBuffer: partial sum\\n\"); return -1; }\n#ifdef TIMING\n    d2h_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\tfor (int j = 1; j <= hid; j++) {\n\t\tsum = 0.0;\n\t\tfor (int k = 0; k < num_blocks; k++) {\n\t\tsum += partial_sum[k * hid + j-1] ;\n    }\n\t\tsum += net->input_weights[0][j];\n\t\tnet-> hidden_units[j] = float(1.0 / (1.0 + exp(-sum)));\n\t}\n\n\n\tbpnn_layerforward(net->hidden_units, net->output_units, net->hidden_weights, hid, out);\n\tbpnn_output_error(net->output_delta, net->target, net->output_units, out, &out_err);\n\tbpnn_hidden_error(net->hidden_delta, hid, net->output_delta, out, net->hidden_weights, net->hidden_units, &hid_err);\n\tbpnn_adjust_weights(net->output_delta, out, net->hidden_units, hid, net->hidden_weights, net->hidden_prev_weights);\n\n\terr = clEnqueueWriteBuffer(cmd_queue, hidden_delta_ocl,       1, 0, (hid + 1) * sizeof(float), net->hidden_delta, 0, 0, &write_event[0]);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer hidden_delta_ocl\\n\"); return -1; }\n\n\terr = clEnqueueWriteBuffer(cmd_queue, input_prev_weights_ocl, 1, 0, (in + 1) * (hid + 1) * sizeof(float), input_weights_prev_one_dim, 0, 0, &write_event[1]);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer input_prev_weights_ocl\\n\"); return -1; }\n\n\terr = clEnqueueWriteBuffer(cmd_queue, input_hidden_ocl,       1, 0, (in + 1) * (hid + 1) * sizeof(float), input_weights_one_dim, 0, 0, &write_event[2]);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer input_hidden_ocl\\n\"); return -1; }\n#ifdef TIMING\n    h2d_time += probe_event_time(write_event[0],cmd_queue);\n    h2d_time += probe_event_time(write_event[1],cmd_queue);\n    h2d_time += probe_event_time(write_event[2],cmd_queue);\n#endif\n    clReleaseEvent(write_event[0]);\n    clReleaseEvent(write_event[1]);\n    clReleaseEvent(write_event[2]);\n\n\tclSetKernelArg(kernel2, 0, sizeof(void *), (void*) &hidden_delta_ocl);\n\tclSetKernelArg(kernel2, 1, sizeof(cl_int), (void*) &hid);\n\tclSetKernelArg(kernel2, 2, sizeof(void *), (void*) &input_ocl);\n\tclSetKernelArg(kernel2, 3, sizeof(cl_int), (void*) &in);\n\tclSetKernelArg(kernel2, 4, sizeof(void *), (void*) &input_hidden_ocl);\n\tclSetKernelArg(kernel2, 5, sizeof(void *), (void*) &input_prev_weights_ocl );\n\n\terr = clEnqueueNDRangeKernel(cmd_queue, kernel2, 2, NULL, global_work, local_work, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: 1  clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\n#ifdef TIMING\n    kernel_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\terr = clEnqueueReadBuffer(cmd_queue, input_ocl, 1, 0, (in + 1) * sizeof(float), net->input_units, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: 1  clEnqueueReadBuffer: input_ocl\\n\"); return -1; }\n#ifdef TIMING\n    d2h_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\terr = clEnqueueReadBuffer(cmd_queue, input_hidden_ocl, 1, 0, (in + 1) * (hid + 1) * sizeof(float), input_weights_one_dim, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: 1  clEnqueueReadBuffer: input_hidden_ocl\\n\"); return -1; }\n#ifdef TIMING\n    d2h_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n\n\tclReleaseMemObject(input_ocl);\n\tclReleaseMemObject(output_hidden_ocl);\n\tclReleaseMemObject(input_hidden_ocl);\n\tclReleaseMemObject(hidden_partial_sum);\n\tclReleaseMemObject(input_prev_weights_ocl);\n\n\tfree(input_weights_prev_one_dim);\n\tfree(partial_sum);\n\tfree(input_weights_one_dim);\n\n    shutdown();\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\ttvsub(&tv_close_end, &tv_total_start, &tv);\n\ttotal_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n\tprintf(\"Init: %f\\n\", init_time);\n\tprintf(\"MemAlloc: %f\\n\", mem_alloc_time);\n\tprintf(\"HtoD: %f\\n\", h2d_time);\n\tprintf(\"Exec: %f\\n\", kernel_time);\n\tprintf(\"DtoH: %f\\n\", d2h_time);\n\tprintf(\"Close: %f\\n\", close_time);\n\tprintf(\"Total: %f\\n\", total_time);\n#endif\n}\n", "backprop_kernel.cl": "#define THREADS 256\n#define WIDTH 16  \n#define HEIGHT 16 \n#define ETA 0.3f       \n#define MOMENTUM 0.3f  \n\n#ifndef _BACKPROP_CUDA_KERNEL_H_\n#define _BACKPROP_CUDA_KERNEL_H_\n#define WM(i, j)   weight_matrix[(j) + (i) * WIDTH]\n\n__kernel void \nbpnn_layerforward_ocl(__global float *input_cuda,\n\t                  __global float *output_hidden_cuda,\n\t\t\t\t\t  __global float *input_hidden_cuda,\n\t\t\t\t\t  __global float *hidden_partial_sum,\n\t\t\t\t\t  __local float *input_node,\n\t\t\t\t\t  __local float *weight_matrix,\n\t\t\t\t\t  int in,\n\t\t\t\t\t  int hid) \n{\n\n   int by = get_group_id(1);\n   int tx = get_local_id(0);\n   int ty = get_local_id(1);\n\n   int index =  ( hid + 1 ) * HEIGHT * by + ( hid + 1 ) * ty + tx + 1 + ( hid + 1 ) ;  \n\n   int index_in = HEIGHT * by + ty + 1;\n   \n\tif ( tx == 0 )\n\t\tinput_node[ty] = input_cuda[index_in] ;\n\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\t\tweight_matrix[ty * WIDTH + tx] =  input_hidden_cuda[index];\n\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n   \n\t\tweight_matrix[ty * WIDTH + tx]= weight_matrix[ty * WIDTH + tx] * input_node[ty];\n\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n   \n\t\tfor ( int i = 1 ; i <= HEIGHT ; i=i*2){\n      int power_two = i; \n\n\t    if( ty % power_two == 0 )\n\t\t  weight_matrix[ty * WIDTH + tx]= weight_matrix[ty * WIDTH + tx] + weight_matrix[(ty + power_two/2)* WIDTH + tx];\n\t\t  \n\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n    }\n   \n    input_hidden_cuda[index] =  weight_matrix[ty * WIDTH + tx];\n   \n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n    if ( tx == 0 ) {\n\t  hidden_partial_sum[by * hid + ty] = weight_matrix[tx* WIDTH + ty];\n    }\n\n}\n\n\n__kernel void  bpnn_adjust_weights_ocl( __global float * delta,   \n\t\t\t\t\t\t\t\t\t\t int hid,         \n\t\t\t\t\t\t\t\t\t\t__global float * ly,      \n\t\t\t\t\t\t\t\t\t\t int in,          \n\t\t\t\t\t\t\t\t\t\t__global float * w,       \n\t\t\t\t\t\t\t\t\t\t__global float * oldw)  \t\t\t\t\t\t\t\t\t\n{\n   \n   int by = get_group_id(1);\n   int tx = get_local_id(0);\n   int ty = get_local_id(1);\n\t\n   int index =  ( hid + 1 ) * HEIGHT * by + ( hid + 1 ) * ty + tx + 1 + ( hid + 1 ) ;  \n   int index_y = HEIGHT * by + ty + 1;\n   int index_x = tx + 1;\n\n   w[index] += ((ETA * delta[index_x] * ly[index_y]) + (MOMENTUM * oldw[index]));\n   oldw[index] = ((ETA * delta[index_x] * ly[index_y]) + (MOMENTUM * oldw[index]));\n\n   barrier(CLK_LOCAL_MEM_FENCE);\n\n   if (ty == 0 && by ==0){\n\tw[index_x] += ((ETA * delta[index_x]) + (MOMENTUM * oldw[index_x]));\n\toldw[index_x] = ((ETA * delta[index_x]) + (MOMENTUM * oldw[index_x]));\n   }\n\n}\n#endif \n"}, "code_dirs": {"backprop_ocl.cpp": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/backprop", "backprop_kernel.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/backprop"}}
{"kernel_name": "bfs", "parallel_api": "cuda", "code": {"bfs.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <cuda.h>\n\n#ifdef TIMING\n#include \"timing.h\"\n#endif\n\n#define MAX_THREADS_PER_BLOCK 512\n\nint no_of_nodes;\nint edge_list_size;\nFILE *fp;\n\n#ifdef TIMING\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nstruct Node\n{\n\tint starting;\n\tint no_of_edges;\n};\n\n#include \"kernel.cu\"\n#include \"kernel2.cu\"\n\nvoid BFSGraph(int argc, char** argv);\n\nint main( int argc, char** argv) \n{\n\tno_of_nodes=0;\n\tedge_list_size=0;\n\tBFSGraph( argc, argv);\n}\n\nvoid Usage(int argc, char**argv){\n\nfprintf(stderr,\"Usage: %s <input_file>\\n\", argv[0]);\n\n}\n\nvoid BFSGraph( int argc, char** argv) \n{\n\n    char *input_f;\n\tif(argc!=2){\n\tUsage(argc, argv);\n\texit(0);\n\t}\n\n\tinput_f = argv[1];\n\tprintf(\"Reading File\\n\");\n\tfp = fopen(input_f,\"r\");\n\tif(!fp)\n\t{\n\t\tprintf(\"Error Reading graph file\\n\");\n\t\treturn;\n\t}\n\n\tint source = 0;\n\n\tfscanf(fp,\"%d\",&no_of_nodes);\n\n\tint num_of_blocks = 1;\n\tint num_of_threads_per_block = no_of_nodes;\n\n\tif(no_of_nodes>MAX_THREADS_PER_BLOCK)\n\t{\n\t\tnum_of_blocks = (int)ceil(no_of_nodes/(double)MAX_THREADS_PER_BLOCK); \n\t\tnum_of_threads_per_block = MAX_THREADS_PER_BLOCK; \n\t}\n\n\tNode* h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n\tbool *h_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_updating_graph_mask = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\tbool *h_graph_visited = (bool*) malloc(sizeof(bool)*no_of_nodes);\n\n\tint start, edgeno;   \n\tfor( unsigned int i = 0; i < no_of_nodes; i++) \n\t{\n\t\tfscanf(fp,\"%d %d\",&start,&edgeno);\n\t\th_graph_nodes[i].starting = start;\n\t\th_graph_nodes[i].no_of_edges = edgeno;\n\t\th_graph_mask[i]=false;\n\t\th_updating_graph_mask[i]=false;\n\t\th_graph_visited[i]=false;\n\t}\n\n\tfscanf(fp,\"%d\",&source);\n\tsource=0;\n\n\th_graph_mask[source]=true;\n\th_graph_visited[source]=true;\n\n\tfscanf(fp,\"%d\",&edge_list_size);\n\n\tint id,cost;\n\tint* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n\tfor(int i=0; i < edge_list_size ; i++)\n\t{\n\t\tfscanf(fp,\"%d\",&id);\n\t\tfscanf(fp,\"%d\",&cost);\n\t\th_graph_edges[i] = id;\n\t}\n\n\tif(fp)\n\t\tfclose(fp);    \n\n\tprintf(\"Read File\\n\");\n\n#ifdef  TIMING\n    gettimeofday(&tv_total_start, NULL);\n#endif\n\tNode* d_graph_nodes;\n\tcudaMalloc( (void**) &d_graph_nodes, sizeof(Node)*no_of_nodes) ;\n\tcudaMemcpy( d_graph_nodes, h_graph_nodes, sizeof(Node)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n\tint* d_graph_edges;\n\tcudaMalloc( (void**) &d_graph_edges, sizeof(int)*edge_list_size) ;\n\tcudaMemcpy( d_graph_edges, h_graph_edges, sizeof(int)*edge_list_size, cudaMemcpyHostToDevice) ;\n\n\tbool* d_graph_mask;\n\tcudaMalloc( (void**) &d_graph_mask, sizeof(bool)*no_of_nodes) ;\n\tcudaMemcpy( d_graph_mask, h_graph_mask, sizeof(bool)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n\tbool* d_updating_graph_mask;\n\tcudaMalloc( (void**) &d_updating_graph_mask, sizeof(bool)*no_of_nodes) ;\n\tcudaMemcpy( d_updating_graph_mask, h_updating_graph_mask, sizeof(bool)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n\tbool* d_graph_visited;\n\tcudaMalloc( (void**) &d_graph_visited, sizeof(bool)*no_of_nodes) ;\n\tcudaMemcpy( d_graph_visited, h_graph_visited, sizeof(bool)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n\tint* h_cost = (int*) malloc( sizeof(int)*no_of_nodes);\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\th_cost[i]=-1;\n\th_cost[source]=0;\n\t\n\tint* d_cost;\n\tcudaMalloc( (void**) &d_cost, sizeof(int)*no_of_nodes);\n\tcudaMemcpy( d_cost, h_cost, sizeof(int)*no_of_nodes, cudaMemcpyHostToDevice) ;\n\n\tbool *d_over;\n\tcudaMalloc( (void**) &d_over, sizeof(bool));\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_total_start, &tv);\n    h2d_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tprintf(\"Copied Everything to GPU memory\\n\");\n\n\tdim3  grid( num_of_blocks, 1, 1);\n\tdim3  threads( num_of_threads_per_block, 1, 1);\n\n\tint k=0;\n\tprintf(\"Start traversing the tree\\n\");\n\tbool stop;\n\tdo\n\t{\n\t\tstop=false;\n#ifdef  TIMING\n\t\tgettimeofday(&tv_h2d_start, NULL);\n#endif\n\t\tcudaMemcpy( d_over, &stop, sizeof(bool), cudaMemcpyHostToDevice) ;\n#ifdef  TIMING\n\t\tgettimeofday(&tv_h2d_end, NULL);\n\t\ttvsub(&tv_h2d_end, &tv_h2d_start, &tv);\n\t\th2d_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\t\tKernel<<< grid, threads, 0 >>>( d_graph_nodes, d_graph_edges, d_graph_mask, d_updating_graph_mask, d_graph_visited, d_cost, no_of_nodes);\n\t\t// check if kernel execution generated and error\n\n\t\tKernel2<<< grid, threads, 0 >>>( d_graph_mask, d_updating_graph_mask, d_graph_visited, d_over, no_of_nodes);\n\t\t// check if kernel execution generated and error\n\n#ifdef  TIMING\n\t\tcudaDeviceSynchronize();\n\t\tgettimeofday(&tv_kernel_end, NULL);\n\t\ttvsub(&tv_kernel_end, &tv_h2d_end, &tv);\n\t\tkernel_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\t\tcudaMemcpy( &stop, d_over, sizeof(bool), cudaMemcpyDeviceToHost) ;\n#ifdef  TIMING\n\t\tgettimeofday(&tv_d2h_end, NULL);\n\t\ttvsub(&tv_d2h_end, &tv_kernel_end, &tv);\n\t\td2h_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\t\tk++;\n\t}\n\twhile(stop);\n\n\n\tprintf(\"Kernel Executed %d times\\n\",k);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_d2h_start, NULL);\n#endif\n\tcudaMemcpy( h_cost, d_cost, sizeof(int)*no_of_nodes, cudaMemcpyDeviceToHost) ;\n#ifdef  TIMING\n\tgettimeofday(&tv_d2h_end, NULL);\n\ttvsub(&tv_d2h_end, &tv_d2h_start, &tv);\n\td2h_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tFILE *fpo = fopen(\"result.txt\",\"w\");\n\tfor(int i=0;i<no_of_nodes;i++)\n\t\tfprintf(fpo,\"%d) cost:%d\\n\",i,h_cost[i]);\n\tfclose(fpo);\n\tprintf(\"Result stored in result.txt\\n\");\n\n\n\tfree( h_graph_nodes);\n\tfree( h_graph_edges);\n\tfree( h_graph_mask);\n\tfree( h_updating_graph_mask);\n\tfree( h_graph_visited);\n\tfree( h_cost);\n#ifdef  TIMING\n    gettimeofday(&tv_close_start, NULL);\n#endif\n\tcudaFree(d_graph_nodes);\n\tcudaFree(d_graph_edges);\n\tcudaFree(d_graph_mask);\n\tcudaFree(d_updating_graph_mask);\n\tcudaFree(d_graph_visited);\n\tcudaFree(d_cost);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\ttvsub(&tv_close_end, &tv_total_start, &tv);\n\ttotal_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n\tprintf(\"Init: %f\\n\", init_time);\n\tprintf(\"MemAlloc: %f\\n\", mem_alloc_time);\n\tprintf(\"HtoD: %f\\n\", h2d_time);\n\tprintf(\"Exec: %f\\n\", kernel_time);\n\tprintf(\"DtoH: %f\\n\", d2h_time);\n\tprintf(\"Close: %f\\n\", close_time);\n\tprintf(\"Total: %f\\n\", total_time);\n#endif\n}\n", "kernel.cu": "#ifndef _KERNEL_H_\n#define _KERNEL_H_\n\n__global__ void\nKernel( Node* g_graph_nodes, int* g_graph_edges, bool* g_graph_mask, bool* g_updating_graph_mask, bool *g_graph_visited, int* g_cost, int no_of_nodes) \n{\n\tint tid = blockIdx.x*MAX_THREADS_PER_BLOCK + threadIdx.x;\n\tif( tid<no_of_nodes && g_graph_mask[tid])\n\t{\n\t\tg_graph_mask[tid]=false;\n\t\tfor(int i=g_graph_nodes[tid].starting; i<(g_graph_nodes[tid].no_of_edges + g_graph_nodes[tid].starting); i++)\n\t\t\t{\n\t\t\tint id = g_graph_edges[i];\n\t\t\tif(!g_graph_visited[id])\n\t\t\t\t{\n\t\t\t\tg_cost[id]=g_cost[tid]+1;\n\t\t\t\tg_updating_graph_mask[id]=true;\n\t\t\t\t}\n\t\t\t}\n\t}\n}\n\n#endif \n", "kernel2.cu": "#ifndef _KERNEL2_H_\n#define _KERNEL2_H_\n\n__global__ void\nKernel2( bool* g_graph_mask, bool *g_updating_graph_mask, bool* g_graph_visited, bool *g_over, int no_of_nodes)\n{\n\tint tid = blockIdx.x*MAX_THREADS_PER_BLOCK + threadIdx.x;\n\tif( tid<no_of_nodes && g_updating_graph_mask[tid])\n\t{\n\n\t\tg_graph_mask[tid]=true;\n\t\tg_graph_visited[tid]=true;\n\t\t*g_over=true;\n\t\tg_updating_graph_mask[tid]=false;\n\t}\n}\n\n#endif\n\n"}, "code_dirs": {"bfs.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/bfs", "kernel.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/bfs", "kernel2.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/bfs"}}
{"kernel_name": "bfs", "parallel_api": "ocl", "code": {"bfs.cpp": "//--by Jianbin Fang\n\n#define __CL_ENABLE_EXCEPTIONS\n#include <cstdlib>\n#include <iostream>\n#include <string>\n#include <cstring>\n\n#ifdef  PROFILING\n#include \"timer.h\"\n#endif\n\n#ifdef TIMING\n#include \"timing.h\"\n#endif\n\n#include \"CLHelper.h\"\n#include \"util.h\"\n\n#define MAX_THREADS_PER_BLOCK 256\n\n//Structure to hold a node information\nstruct Node {\n    int starting;\n    int no_of_edges;\n};\n\n//Primitives for timing\n#ifdef TIMING\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time= 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nvoid run_bfs_cpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size, \\\n                 int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask, \\\n                 char *h_graph_visited, int *h_cost_ref)\n{\n    char stop;\n    int k = 0;\n    do {\n        stop=false;\n        for(int tid = 0; tid < no_of_nodes; tid++ ) {\n            if (h_graph_mask[tid] == true) {\n                h_graph_mask[tid]=false;\n                for(int i=h_graph_nodes[tid].starting; i<(h_graph_nodes[tid].no_of_edges + h_graph_nodes[tid].starting); i++) {\n                    int id = h_graph_edges[i];\t//--cambine: node id is connected with node tid\n                    if(!h_graph_visited[id]) {\t//--cambine: if node id has not been visited, enter the body below\n                        h_cost_ref[id]=h_cost_ref[tid]+1;\n                        h_updating_graph_mask[id]=true;\n                    }\n                }\n            }\n        }\n\n        for(int tid=0; tid< no_of_nodes ; tid++ ) {\n            if (h_updating_graph_mask[tid] == true) {\n                h_graph_mask[tid]=true;\n                h_graph_visited[tid]=true;\n                stop=true;\n                h_updating_graph_mask[tid]=false;\n            }\n        }\n        k++;\n    } while(stop);\n}\n\nvoid run_bfs_gpu(int no_of_nodes, Node *h_graph_nodes, int edge_list_size, \\\n                 int *h_graph_edges, char *h_graph_mask, char *h_updating_graph_mask, \\\n                 char *h_graph_visited, int *h_cost)\nthrow(std::string)\n{\n\n    //int number_elements = height*width;\n    char h_over;\n    cl_mem d_graph_nodes, d_graph_edges, d_graph_mask, d_updating_graph_mask, \\\n    d_graph_visited, d_cost, d_over;\n    try {\n#ifdef  TIMING\n        gettimeofday(&tv_total_start, NULL);\n#endif\n\n        _clInit();\n\n#ifdef  TIMING\n        gettimeofday(&tv_mem_alloc_start, NULL);\n        tvsub(&tv_mem_alloc_start, &tv_total_start, &tv);\n        init_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n        //--1 transfer data from host to device\n        d_graph_nodes = _clMalloc(no_of_nodes*sizeof(Node), h_graph_nodes);\n        d_graph_edges = _clMalloc(edge_list_size*sizeof(int), h_graph_edges);\n        d_graph_mask = _clMallocRW(no_of_nodes*sizeof(char), h_graph_mask);\n        d_updating_graph_mask = _clMallocRW(no_of_nodes*sizeof(char), h_updating_graph_mask);\n        d_graph_visited = _clMallocRW(no_of_nodes*sizeof(char), h_graph_visited);\n\n        d_cost = _clMallocRW(no_of_nodes*sizeof(int), h_cost);\n        d_over = _clMallocRW(sizeof(char), &h_over);\n\n#ifdef  TIMING\n        gettimeofday(&tv_mem_alloc_end, NULL);\n        tvsub(&tv_mem_alloc_end, &tv_mem_alloc_start, &tv);\n        mem_alloc_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n        _clMemcpyH2D(d_graph_nodes, no_of_nodes*sizeof(Node), h_graph_nodes);\n        _clMemcpyH2D(d_graph_edges, edge_list_size*sizeof(int), h_graph_edges);\n        _clMemcpyH2D(d_graph_mask, no_of_nodes*sizeof(char), h_graph_mask);\n        _clMemcpyH2D(d_updating_graph_mask, no_of_nodes*sizeof(char), h_updating_graph_mask);\n        _clMemcpyH2D(d_graph_visited, no_of_nodes*sizeof(char), h_graph_visited);\n        _clMemcpyH2D(d_cost, no_of_nodes*sizeof(int), h_cost);\n\n        //--2 invoke kernel\n#ifdef\tPROFILING\n        timer kernel_timer;\n        double kernel_time = 0.0;\n        kernel_timer.reset();\n        kernel_timer.start();\n#endif\n        do {\n            h_over = false;\n            _clMemcpyH2D(d_over, sizeof(char), &h_over);\n\n            //--kernel 0\n            int kernel_id = 0;\n            int kernel_idx = 0;\n            _clSetArgs(kernel_id, kernel_idx++, d_graph_nodes);\n            _clSetArgs(kernel_id, kernel_idx++, d_graph_edges);\n            _clSetArgs(kernel_id, kernel_idx++, d_graph_mask);\n            _clSetArgs(kernel_id, kernel_idx++, d_updating_graph_mask);\n            _clSetArgs(kernel_id, kernel_idx++, d_graph_visited);\n            _clSetArgs(kernel_id, kernel_idx++, d_cost);\n            _clSetArgs(kernel_id, kernel_idx++, &no_of_nodes, sizeof(int));\n\n            //int work_items = no_of_nodes;\n            _clInvokeKernel(kernel_id, no_of_nodes, work_group_size);\n\n            //--kernel 1\n            kernel_id = 1;\n            kernel_idx = 0;\n            _clSetArgs(kernel_id, kernel_idx++, d_graph_mask);\n            _clSetArgs(kernel_id, kernel_idx++, d_updating_graph_mask);\n            _clSetArgs(kernel_id, kernel_idx++, d_graph_visited);\n            _clSetArgs(kernel_id, kernel_idx++, d_over);\n            _clSetArgs(kernel_id, kernel_idx++, &no_of_nodes, sizeof(int));\n\n            //work_items = no_of_nodes;\n            _clInvokeKernel(kernel_id, no_of_nodes, work_group_size);\n\n            _clMemcpyD2H(d_over,sizeof(char), &h_over);\n        } while(h_over);\n\n        _clFinish();\n#ifdef\tPROFILING\n        kernel_timer.stop();\n        kernel_time = kernel_timer.getTimeInSeconds();\n#endif\n\n        //--3 transfer data from device to host\n        _clMemcpyD2H(d_cost,no_of_nodes*sizeof(int), h_cost);\n\n#ifdef  TIMING\n        gettimeofday(&tv_close_start, NULL);\n#endif\n        //--statistics\n#ifdef\tPROFILING\n        std::cout<<\"kernel time(s):\"<<kernel_time<<std::endl;\n#endif\n        //--4 release cl resources.\n        _clFree(d_graph_nodes);\n        _clFree(d_graph_edges);\n        _clFree(d_graph_mask);\n        _clFree(d_updating_graph_mask);\n        _clFree(d_graph_visited);\n        _clFree(d_cost);\n        _clFree(d_over);\n        _clRelease();\n    } catch(std::string msg) {\n        _clFree(d_graph_nodes);\n        _clFree(d_graph_edges);\n        _clFree(d_graph_mask);\n        _clFree(d_updating_graph_mask);\n        _clFree(d_graph_visited);\n        _clFree(d_cost);\n        _clFree(d_over);\n        _clRelease();\n        std::string e_str = \"in run_transpose_gpu -> \";\n        e_str += msg;\n        throw(e_str);\n    }\n#ifdef  TIMING\n        gettimeofday(&tv_close_end, NULL);\n        tvsub(&tv_close_end, &tv_close_start, &tv);\n        close_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n        tvsub(&tv_close_end, &tv_total_start, &tv);\n        total_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n        printf(\"Init: %f\\n\", init_time);\n        printf(\"MemAlloc: %f\\n\", mem_alloc_time);\n        printf(\"HtoD: %f\\n\", h2d_time);\n        printf(\"Exec: %f\\n\", kernel_time);\n        printf(\"DtoH: %f\\n\", d2h_time);\n        printf(\"Close: %f\\n\", close_time);\n        printf(\"Total: %f\\n\", total_time);\n#endif\n\n    return ;\n}\nvoid Usage(int argc, char**argv)\n{\n\n    fprintf(stderr,\"Usage: %s <input_file> [-p platform] [-d device] [-t gpu(0)/cpu(1)]\\n\", argv[0]);\n\n}\n\nint main(int argc, char * argv[])\n{\n    int no_of_nodes;\n    int edge_list_size;\n    FILE *fp;\n    Node* h_graph_nodes;\n    char *h_graph_mask, *h_updating_graph_mask, *h_graph_visited;\n    try {\n        char *input_f;\n        if(argc < 2) {\n            Usage(argc, argv);\n            exit(0);\n        }\n\n        _clCmdParams(argc, argv);\n        input_f = argv[1];\n        printf(\"Reading File\\n\");\n        //Read in Graph from a file\n        fp = fopen(input_f,\"r\");\n        if(!fp) {\n            printf(\"Error Reading graph file\\n\");\n            return 0;\n        }\n\n        int source = 0;\n\n        fscanf(fp,\"%d\",&no_of_nodes);\n\n        int num_of_blocks = 1;\n        int num_of_threads_per_block = no_of_nodes;\n\n        if(no_of_nodes>MAX_THREADS_PER_BLOCK) {\n            num_of_blocks = (int)ceil(no_of_nodes/(double)MAX_THREADS_PER_BLOCK);\n            num_of_threads_per_block = MAX_THREADS_PER_BLOCK;\n        }\n        work_group_size = num_of_threads_per_block;\n\n        h_graph_nodes = (Node*) malloc(sizeof(Node)*no_of_nodes);\n        h_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n        h_updating_graph_mask = (char*) malloc(sizeof(char)*no_of_nodes);\n        h_graph_visited = (char*) malloc(sizeof(char)*no_of_nodes);\n\n        int start, edgeno;\n        for(int i = 0; i < no_of_nodes; i++) {\n            fscanf(fp,\"%d %d\",&start,&edgeno);\n            h_graph_nodes[i].starting = start;\n            h_graph_nodes[i].no_of_edges = edgeno;\n            h_graph_mask[i]=false;\n            h_updating_graph_mask[i]=false;\n            h_graph_visited[i]=false;\n        }\n\n        fscanf(fp,\"%d\",&source);\n        source=0;\n\n        h_graph_mask[source]=true;\n        h_graph_visited[source]=true;\n        fscanf(fp,\"%d\",&edge_list_size);\n        int id,cost;\n        int* h_graph_edges = (int*) malloc(sizeof(int)*edge_list_size);\n        for(int i=0; i < edge_list_size ; i++) {\n            fscanf(fp,\"%d\",&id);\n            fscanf(fp,\"%d\",&cost);\n            h_graph_edges[i] = id;\n        }\n\n        if(fp)\n            fclose(fp);\n        // allocate mem for the result on host side\n        int\t*h_cost = (int*) malloc(sizeof(int)*no_of_nodes);\n        int *h_cost_ref = (int*)malloc(sizeof(int)*no_of_nodes);\n        for(int i=0; i<no_of_nodes; i++) {\n            h_cost[i]=-1;\n            h_cost_ref[i] = -1;\n        }\n        h_cost[source]=0;\n        h_cost_ref[source]=0;\n        run_bfs_gpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost);\n        for(int i = 0; i < no_of_nodes; i++) {\n            h_graph_mask[i]=false;\n            h_updating_graph_mask[i]=false;\n            h_graph_visited[i]=false;\n        }\n        source=0;\n        h_graph_mask[source]=true;\n        h_graph_visited[source]=true;\n        run_bfs_cpu(no_of_nodes,h_graph_nodes,edge_list_size,h_graph_edges, h_graph_mask, h_updating_graph_mask, h_graph_visited, h_cost_ref);\n        compare_results<int>(h_cost_ref, h_cost, no_of_nodes);\n        free(h_graph_nodes);\n        free(h_graph_mask);\n        free(h_updating_graph_mask);\n        free(h_graph_visited);\n\n    } catch(std::string msg) {\n        std::cout<<\"--cambine: exception in main ->\"<<msg<<std::endl;\n        free(h_graph_nodes);\n        free(h_graph_mask);\n        free(h_updating_graph_mask);\n        free(h_graph_visited);\n    }\n\n    return 0;\n}\n", "Kernels.cl": "#pragma OPENCL EXTENSION cl_khr_byte_addressable_store: enable\ntypedef struct{\n\tint starting;\n\tint no_of_edges;\n} Node;\n__kernel void BFS_1( const __global Node* g_graph_nodes,\n\t\t\t\t\tconst __global int* g_graph_edges, \n\t\t\t\t\t__global char* g_graph_mask, \n\t\t\t\t\t__global char* g_updating_graph_mask, \n\t\t\t\t\t__global char* g_graph_visited, \n\t\t\t\t\t__global int* g_cost, \n\t\t\t\t\tconst  int no_of_nodes){\n\tint tid = get_global_id(0);\n\tif( tid<no_of_nodes && g_graph_mask[tid]){\n\t\tg_graph_mask[tid]=false;\n\t\tfor(int i=g_graph_nodes[tid].starting; i<(g_graph_nodes[tid].no_of_edges + g_graph_nodes[tid].starting); i++){\n\t\t\tint id = g_graph_edges[i];\n\t\t\tif(!g_graph_visited[id]){\n\t\t\t\tg_cost[id]=g_cost[tid]+1;\n\t\t\t\tg_updating_graph_mask[id]=true;\n\t\t\t\t}\n\t\t\t}\n\t}\t\n}\n\n__kernel void BFS_2(__global char* g_graph_mask, \n\t\t\t\t\t__global char* g_updating_graph_mask, \n\t\t\t\t\t__global char* g_graph_visited, \n\t\t\t\t\t__global char* g_over,\n\t\t\t\t\tconst  int no_of_nodes\n\t\t\t\t\t) {\n\tint tid = get_global_id(0);\n\tif( tid<no_of_nodes && g_updating_graph_mask[tid]){\n\n\t\tg_graph_mask[tid]=true;\n\t\tg_graph_visited[tid]=true;\n\t\t*g_over=true;\n\t\tg_updating_graph_mask[tid]=false;\n\t}\n}\n\n\n"}, "code_dirs": {"bfs.cpp": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/bfs", "Kernels.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/bfs"}}
{"kernel_name": "cfd", "parallel_api": "cuda", "code": {"euler3d.cu": "\n#include <helper_cuda.h>\n#include <helper_timer.h>\n#include <iostream>\n#include <fstream>\n\n \n \n\n#define GAMMA 1.4f\n#define iterations 2000\n\n\n#define NDIM 3\n#define NNB 4\n\n#define RK 3\n#define ff_mach 1.2f\n#define deg_angle_of_attack 0.0f\n\n\n\n#ifdef RD_WG_SIZE_0_0\n\t#define BLOCK_SIZE_0 RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n\t#define BLOCK_SIZE_0 RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n\t#define BLOCK_SIZE_0 RD_WG_SIZE\n#else\n\t#define BLOCK_SIZE_0 192\n#endif\n\n#ifdef RD_WG_SIZE_1_0\n\t#define BLOCK_SIZE_1 RD_WG_SIZE_1_0\n#elif defined(RD_WG_SIZE_1)\n\t#define BLOCK_SIZE_1 RD_WG_SIZE_1\n#elif defined(RD_WG_SIZE)\n\t#define BLOCK_SIZE_1 RD_WG_SIZE\n#else\n\t#define BLOCK_SIZE_1 192\n#endif\n\n#ifdef RD_WG_SIZE_2_0\n\t#define BLOCK_SIZE_2 RD_WG_SIZE_2_0\n#elif defined(RD_WG_SIZE_1)\n\t#define BLOCK_SIZE_2 RD_WG_SIZE_2\n#elif defined(RD_WG_SIZE)\n\t#define BLOCK_SIZE_2 RD_WG_SIZE\n#else\n\t#define BLOCK_SIZE_2 192\n#endif\n\n#ifdef RD_WG_SIZE_3_0\n\t#define BLOCK_SIZE_3 RD_WG_SIZE_3_0\n#elif defined(RD_WG_SIZE_3)\n\t#define BLOCK_SIZE_3 RD_WG_SIZE_3\n#elif defined(RD_WG_SIZE)\n\t#define BLOCK_SIZE_3 RD_WG_SIZE\n#else\n\t#define BLOCK_SIZE_3 192\n#endif\n\n#ifdef RD_WG_SIZE_4_0\n\t#define BLOCK_SIZE_4 RD_WG_SIZE_4_0\n#elif defined(RD_WG_SIZE_4)\n\t#define BLOCK_SIZE_4 RD_WG_SIZE_4\n#elif defined(RD_WG_SIZE)\n\t#define BLOCK_SIZE_4 RD_WG_SIZE\n#else\n\t#define BLOCK_SIZE_4 192\n#endif\n\n\n\n// #if block_length > 128\n// #warning \"the kernels may fail too launch on some systems if the block length is too large\"\n// #endif\n\n\n#define VAR_DENSITY 0\n#define VAR_MOMENTUM  1\n#define VAR_DENSITY_ENERGY (VAR_MOMENTUM+NDIM)\n#define NVAR (VAR_DENSITY_ENERGY+1)\n\n\n\ntemplate <typename T>\nT* alloc(int N)\n{\n\tT* t;\n\tcheckCudaErrors(cudaMalloc((void**)&t, sizeof(T)*N));\n\treturn t;\n}\n\ntemplate <typename T>\nvoid dealloc(T* array)\n{\n\tcheckCudaErrors(cudaFree((void*)array));\n}\n\ntemplate <typename T>\nvoid copy(T* dst, T* src, int N)\n{\n\tcheckCudaErrors(cudaMemcpy((void*)dst, (void*)src, N*sizeof(T), cudaMemcpyDeviceToDevice));\n}\n\ntemplate <typename T>\nvoid upload(T* dst, T* src, int N)\n{\n\tcheckCudaErrors(cudaMemcpy((void*)dst, (void*)src, N*sizeof(T), cudaMemcpyHostToDevice));\n}\n\ntemplate <typename T>\nvoid download(T* dst, T* src, int N)\n{\n\tcheckCudaErrors(cudaMemcpy((void*)dst, (void*)src, N*sizeof(T), cudaMemcpyDeviceToHost));\n}\n\nvoid dump(float* variables, int nel, int nelr)\n{\n\tfloat* h_variables = new float[nelr*NVAR];\n\tdownload(h_variables, variables, nelr*NVAR);\n\n\t{\n\t\tstd::ofstream file(\"density\");\n\t\tfile << nel << \" \" << nelr << std::endl;\n\t\tfor(int i = 0; i < nel; i++) file << h_variables[i + VAR_DENSITY*nelr] << std::endl;\n\t}\n\n\n\t{\n\t\tstd::ofstream file(\"momentum\");\n\t\tfile << nel << \" \" << nelr << std::endl;\n\t\tfor(int i = 0; i < nel; i++)\n\t\t{\n\t\t\tfor(int j = 0; j != NDIM; j++)\n\t\t\t\tfile << h_variables[i + (VAR_MOMENTUM+j)*nelr] << \" \";\n\t\t\tfile << std::endl;\n\t\t}\n\t}\n\t\n\t{\n\t\tstd::ofstream file(\"density_energy\");\n\t\tfile << nel << \" \" << nelr << std::endl;\n\t\tfor(int i = 0; i < nel; i++) file << h_variables[i + VAR_DENSITY_ENERGY*nelr] << std::endl;\n\t}\n\tdelete[] h_variables;\n}\n\n\n__constant__ float ff_variable[NVAR];\n__constant__ float3 ff_flux_contribution_momentum_x[1];\n__constant__ float3 ff_flux_contribution_momentum_y[1];\n__constant__ float3 ff_flux_contribution_momentum_z[1];\n__constant__ float3 ff_flux_contribution_density_energy[1];\n\n__global__ void cuda_initialize_variables(int nelr, float* variables)\n{\n\tconst int i = (blockDim.x*blockIdx.x + threadIdx.x);\n\tfor(int j = 0; j < NVAR; j++)\n\t\tvariables[i + j*nelr] = ff_variable[j];\n}\nvoid initialize_variables(int nelr, float* variables)\n{\n\tdim3 Dg(nelr / BLOCK_SIZE_1), Db(BLOCK_SIZE_1);\n\tcuda_initialize_variables<<<Dg, Db>>>(nelr, variables);\n\tgetLastCudaError(\"initialize_variables failed\");\n}\n\n__device__ __host__ inline void compute_flux_contribution(float& density, float3& momentum, float& density_energy, float& pressure, float3& velocity, float3& fc_momentum_x, float3& fc_momentum_y, float3& fc_momentum_z, float3& fc_density_energy)\n{\n\tfc_momentum_x.x = velocity.x*momentum.x + pressure;\n\tfc_momentum_x.y = velocity.x*momentum.y;\n\tfc_momentum_x.z = velocity.x*momentum.z;\n\t\n\t\n\tfc_momentum_y.x = fc_momentum_x.y;\n\tfc_momentum_y.y = velocity.y*momentum.y + pressure;\n\tfc_momentum_y.z = velocity.y*momentum.z;\n\n\tfc_momentum_z.x = fc_momentum_x.z;\n\tfc_momentum_z.y = fc_momentum_y.z;\n\tfc_momentum_z.z = velocity.z*momentum.z + pressure;\n\n\tfloat de_p = density_energy+pressure;\n\tfc_density_energy.x = velocity.x*de_p;\n\tfc_density_energy.y = velocity.y*de_p;\n\tfc_density_energy.z = velocity.z*de_p;\n}\n\n__device__ inline void compute_velocity(float& density, float3& momentum, float3& velocity)\n{\n\tvelocity.x = momentum.x / density;\n\tvelocity.y = momentum.y / density;\n\tvelocity.z = momentum.z / density;\n}\n\t\n__device__ inline float compute_speed_sqd(float3& velocity)\n{\n\treturn velocity.x*velocity.x + velocity.y*velocity.y + velocity.z*velocity.z;\n}\n\n__device__ inline float compute_pressure(float& density, float& density_energy, float& speed_sqd)\n{\n\treturn (float(GAMMA)-float(1.0f))*(density_energy - float(0.5f)*density*speed_sqd);\n}\n\n__device__ inline float compute_speed_of_sound(float& density, float& pressure)\n{\n\treturn sqrtf(float(GAMMA)*pressure/density);\n}\n\n__global__ void cuda_compute_step_factor(int nelr, float* variables, float* areas, float* step_factors)\n{\n\tconst int i = (blockDim.x*blockIdx.x + threadIdx.x);\n\n\tfloat density = variables[i + VAR_DENSITY*nelr];\n\tfloat3 momentum;\n\tmomentum.x = variables[i + (VAR_MOMENTUM+0)*nelr];\n\tmomentum.y = variables[i + (VAR_MOMENTUM+1)*nelr];\n\tmomentum.z = variables[i + (VAR_MOMENTUM+2)*nelr];\n\t\n\tfloat density_energy = variables[i + VAR_DENSITY_ENERGY*nelr];\n\t\n\tfloat3 velocity;       compute_velocity(density, momentum, velocity);\n\tfloat speed_sqd      = compute_speed_sqd(velocity);\n\tfloat pressure       = compute_pressure(density, density_energy, speed_sqd);\n\tfloat speed_of_sound = compute_speed_of_sound(density, pressure);\n\n\tstep_factors[i] = float(0.5f) / (sqrtf(areas[i]) * (sqrtf(speed_sqd) + speed_of_sound));\n}\nvoid compute_step_factor(int nelr, float* variables, float* areas, float* step_factors)\n{\n\tdim3 Dg(nelr / BLOCK_SIZE_2), Db(BLOCK_SIZE_2);\n\tcuda_compute_step_factor<<<Dg, Db>>>(nelr, variables, areas, step_factors);\t\t\n\tgetLastCudaError(\"compute_step_factor failed\");\n}\n\n\n__global__ void cuda_compute_flux(int nelr, int* elements_surrounding_elements, float* normals, float* variables, float* fluxes)\n{\n\tconst float smoothing_coefficient = float(0.2f);\n\tconst int i = (blockDim.x*blockIdx.x + threadIdx.x);\n\t\n\tint j, nb;\n\tfloat3 normal; float normal_len;\n\tfloat factor;\n\t\n\tfloat density_i = variables[i + VAR_DENSITY*nelr];\n\tfloat3 momentum_i;\n\tmomentum_i.x = variables[i + (VAR_MOMENTUM+0)*nelr];\n\tmomentum_i.y = variables[i + (VAR_MOMENTUM+1)*nelr];\n\tmomentum_i.z = variables[i + (VAR_MOMENTUM+2)*nelr];\n\n\tfloat density_energy_i = variables[i + VAR_DENSITY_ENERGY*nelr];\n\n\tfloat3 velocity_i;             \t\t\t\tcompute_velocity(density_i, momentum_i, velocity_i);\n\tfloat speed_sqd_i                          = compute_speed_sqd(velocity_i);\n\tfloat speed_i                              = sqrtf(speed_sqd_i);\n\tfloat pressure_i                           = compute_pressure(density_i, density_energy_i, speed_sqd_i);\n\tfloat speed_of_sound_i                     = compute_speed_of_sound(density_i, pressure_i);\n\tfloat3 flux_contribution_i_momentum_x, flux_contribution_i_momentum_y, flux_contribution_i_momentum_z;\n\tfloat3 flux_contribution_i_density_energy;\t\n\tcompute_flux_contribution(density_i, momentum_i, density_energy_i, pressure_i, velocity_i, flux_contribution_i_momentum_x, flux_contribution_i_momentum_y, flux_contribution_i_momentum_z, flux_contribution_i_density_energy);\n\t\n\tfloat flux_i_density = float(0.0f);\n\tfloat3 flux_i_momentum;\n\tflux_i_momentum.x = float(0.0f);\n\tflux_i_momentum.y = float(0.0f);\n\tflux_i_momentum.z = float(0.0f);\n\tfloat flux_i_density_energy = float(0.0f);\n\t\t\n\tfloat3 velocity_nb;\n\tfloat density_nb, density_energy_nb;\n\tfloat3 momentum_nb;\n\tfloat3 flux_contribution_nb_momentum_x, flux_contribution_nb_momentum_y, flux_contribution_nb_momentum_z;\n\tfloat3 flux_contribution_nb_density_energy;\t\n\tfloat speed_sqd_nb, speed_of_sound_nb, pressure_nb;\n\t\n\t#pragma unroll\n\tfor(j = 0; j < NNB; j++)\n\t{\n\t\tnb = elements_surrounding_elements[i + j*nelr];\n\t\tnormal.x = normals[i + (j + 0*NNB)*nelr];\n\t\tnormal.y = normals[i + (j + 1*NNB)*nelr];\n\t\tnormal.z = normals[i + (j + 2*NNB)*nelr];\n\t\tnormal_len = sqrtf(normal.x*normal.x + normal.y*normal.y + normal.z*normal.z);\n\t\t\n\t\tif(nb >= 0) \t// a legitimate neighbor\n\t\t{\n\t\t\tdensity_nb = variables[nb + VAR_DENSITY*nelr];\n\t\t\tmomentum_nb.x = variables[nb + (VAR_MOMENTUM+0)*nelr];\n\t\t\tmomentum_nb.y = variables[nb + (VAR_MOMENTUM+1)*nelr];\n\t\t\tmomentum_nb.z = variables[nb + (VAR_MOMENTUM+2)*nelr];\n\t\t\tdensity_energy_nb = variables[nb + VAR_DENSITY_ENERGY*nelr];\n\t\t\t\t\t\t\t\t\t\t\t\tcompute_velocity(density_nb, momentum_nb, velocity_nb);\n\t\t\tspeed_sqd_nb                      = compute_speed_sqd(velocity_nb);\n\t\t\tpressure_nb                       = compute_pressure(density_nb, density_energy_nb, speed_sqd_nb);\n\t\t\tspeed_of_sound_nb                 = compute_speed_of_sound(density_nb, pressure_nb);\n\t\t\t                                    compute_flux_contribution(density_nb, momentum_nb, density_energy_nb, pressure_nb, velocity_nb, flux_contribution_nb_momentum_x, flux_contribution_nb_momentum_y, flux_contribution_nb_momentum_z, flux_contribution_nb_density_energy);\n\t\t\t\n\t\t\tfactor = -normal_len*smoothing_coefficient*float(0.5f)*(speed_i + sqrtf(speed_sqd_nb) + speed_of_sound_i + speed_of_sound_nb);\n\t\t\tflux_i_density += factor*(density_i-density_nb);\n\t\t\tflux_i_density_energy += factor*(density_energy_i-density_energy_nb);\n\t\t\tflux_i_momentum.x += factor*(momentum_i.x-momentum_nb.x);\n\t\t\tflux_i_momentum.y += factor*(momentum_i.y-momentum_nb.y);\n\t\t\tflux_i_momentum.z += factor*(momentum_i.z-momentum_nb.z);\n\n\t\t\tfactor = float(0.5f)*normal.x;\n\t\t\tflux_i_density += factor*(momentum_nb.x+momentum_i.x);\n\t\t\tflux_i_density_energy += factor*(flux_contribution_nb_density_energy.x+flux_contribution_i_density_energy.x);\n\t\t\tflux_i_momentum.x += factor*(flux_contribution_nb_momentum_x.x+flux_contribution_i_momentum_x.x);\n\t\t\tflux_i_momentum.y += factor*(flux_contribution_nb_momentum_y.x+flux_contribution_i_momentum_y.x);\n\t\t\tflux_i_momentum.z += factor*(flux_contribution_nb_momentum_z.x+flux_contribution_i_momentum_z.x);\n\t\t\t\n\t\t\tfactor = float(0.5f)*normal.y;\n\t\t\tflux_i_density += factor*(momentum_nb.y+momentum_i.y);\n\t\t\tflux_i_density_energy += factor*(flux_contribution_nb_density_energy.y+flux_contribution_i_density_energy.y);\n\t\t\tflux_i_momentum.x += factor*(flux_contribution_nb_momentum_x.y+flux_contribution_i_momentum_x.y);\n\t\t\tflux_i_momentum.y += factor*(flux_contribution_nb_momentum_y.y+flux_contribution_i_momentum_y.y);\n\t\t\tflux_i_momentum.z += factor*(flux_contribution_nb_momentum_z.y+flux_contribution_i_momentum_z.y);\n\t\t\t\n\t\t\tfactor = float(0.5f)*normal.z;\n\t\t\tflux_i_density += factor*(momentum_nb.z+momentum_i.z);\n\t\t\tflux_i_density_energy += factor*(flux_contribution_nb_density_energy.z+flux_contribution_i_density_energy.z);\n\t\t\tflux_i_momentum.x += factor*(flux_contribution_nb_momentum_x.z+flux_contribution_i_momentum_x.z);\n\t\t\tflux_i_momentum.y += factor*(flux_contribution_nb_momentum_y.z+flux_contribution_i_momentum_y.z);\n\t\t\tflux_i_momentum.z += factor*(flux_contribution_nb_momentum_z.z+flux_contribution_i_momentum_z.z);\n\t\t}\n\t\telse if(nb == -1)\t// a wing boundary\n\t\t{\n\t\t\tflux_i_momentum.x += normal.x*pressure_i;\n\t\t\tflux_i_momentum.y += normal.y*pressure_i;\n\t\t\tflux_i_momentum.z += normal.z*pressure_i;\n\t\t}\n\t\telse if(nb == -2) // a far field boundary\n\t\t{\n\t\t\tfactor = float(0.5f)*normal.x;\n\t\t\tflux_i_density += factor*(ff_variable[VAR_MOMENTUM+0]+momentum_i.x);\n\t\t\tflux_i_density_energy += factor*(ff_flux_contribution_density_energy[0].x+flux_contribution_i_density_energy.x);\n\t\t\tflux_i_momentum.x += factor*(ff_flux_contribution_momentum_x[0].x + flux_contribution_i_momentum_x.x);\n\t\t\tflux_i_momentum.y += factor*(ff_flux_contribution_momentum_y[0].x + flux_contribution_i_momentum_y.x);\n\t\t\tflux_i_momentum.z += factor*(ff_flux_contribution_momentum_z[0].x + flux_contribution_i_momentum_z.x);\n\t\t\t\n\t\t\tfactor = float(0.5f)*normal.y;\n\t\t\tflux_i_density += factor*(ff_variable[VAR_MOMENTUM+1]+momentum_i.y);\n\t\t\tflux_i_density_energy += factor*(ff_flux_contribution_density_energy[0].y+flux_contribution_i_density_energy.y);\n\t\t\tflux_i_momentum.x += factor*(ff_flux_contribution_momentum_x[0].y + flux_contribution_i_momentum_x.y);\n\t\t\tflux_i_momentum.y += factor*(ff_flux_contribution_momentum_y[0].y + flux_contribution_i_momentum_y.y);\n\t\t\tflux_i_momentum.z += factor*(ff_flux_contribution_momentum_z[0].y + flux_contribution_i_momentum_z.y);\n\n\t\t\tfactor = float(0.5f)*normal.z;\n\t\t\tflux_i_density += factor*(ff_variable[VAR_MOMENTUM+2]+momentum_i.z);\n\t\t\tflux_i_density_energy += factor*(ff_flux_contribution_density_energy[0].z+flux_contribution_i_density_energy.z);\n\t\t\tflux_i_momentum.x += factor*(ff_flux_contribution_momentum_x[0].z + flux_contribution_i_momentum_x.z);\n\t\t\tflux_i_momentum.y += factor*(ff_flux_contribution_momentum_y[0].z + flux_contribution_i_momentum_y.z);\n\t\t\tflux_i_momentum.z += factor*(ff_flux_contribution_momentum_z[0].z + flux_contribution_i_momentum_z.z);\n\n\t\t}\n\t}\n\n\tfluxes[i + VAR_DENSITY*nelr] = flux_i_density;\n\tfluxes[i + (VAR_MOMENTUM+0)*nelr] = flux_i_momentum.x;\n\tfluxes[i + (VAR_MOMENTUM+1)*nelr] = flux_i_momentum.y;\n\tfluxes[i + (VAR_MOMENTUM+2)*nelr] = flux_i_momentum.z;\n\tfluxes[i + VAR_DENSITY_ENERGY*nelr] = flux_i_density_energy;\n}\nvoid compute_flux(int nelr, int* elements_surrounding_elements, float* normals, float* variables, float* fluxes)\n{\n\tdim3 Dg(nelr / BLOCK_SIZE_3), Db(BLOCK_SIZE_3);\n\tcuda_compute_flux<<<Dg,Db>>>(nelr, elements_surrounding_elements, normals, variables, fluxes);\n\tgetLastCudaError(\"compute_flux failed\");\n}\n\n__global__ void cuda_time_step(int j, int nelr, float* old_variables, float* variables, float* step_factors, float* fluxes)\n{\n\tconst int i = (blockDim.x*blockIdx.x + threadIdx.x);\n\n\tfloat factor = step_factors[i]/float(RK+1-j);\n\n\tvariables[i + VAR_DENSITY*nelr] = old_variables[i + VAR_DENSITY*nelr] + factor*fluxes[i + VAR_DENSITY*nelr];\n\tvariables[i + VAR_DENSITY_ENERGY*nelr] = old_variables[i + VAR_DENSITY_ENERGY*nelr] + factor*fluxes[i + VAR_DENSITY_ENERGY*nelr];\n\tvariables[i + (VAR_MOMENTUM+0)*nelr] = old_variables[i + (VAR_MOMENTUM+0)*nelr] + factor*fluxes[i + (VAR_MOMENTUM+0)*nelr];\n\tvariables[i + (VAR_MOMENTUM+1)*nelr] = old_variables[i + (VAR_MOMENTUM+1)*nelr] + factor*fluxes[i + (VAR_MOMENTUM+1)*nelr];\t\n\tvariables[i + (VAR_MOMENTUM+2)*nelr] = old_variables[i + (VAR_MOMENTUM+2)*nelr] + factor*fluxes[i + (VAR_MOMENTUM+2)*nelr];\t\n}\nvoid time_step(int j, int nelr, float* old_variables, float* variables, float* step_factors, float* fluxes)\n{\n\tdim3 Dg(nelr / BLOCK_SIZE_4), Db(BLOCK_SIZE_4);\n\tcuda_time_step<<<Dg,Db>>>(j, nelr, old_variables, variables, step_factors, fluxes);\n\tgetLastCudaError(\"update failed\");\n}\n\nint main(int argc, char** argv)\n{\n  printf(\"WG size of kernel:initialize = %d, WG size of kernel:compute_step_factor = %d, WG size of kernel:compute_flux = %d, WG size of kernel:time_step = %d\\n\", BLOCK_SIZE_1, BLOCK_SIZE_2, BLOCK_SIZE_3, BLOCK_SIZE_4);\n\n\tif (argc < 2)\n\t{\n\t\tstd::cout << \"specify data file name\" << std::endl;\n\t\treturn 0;\n\t}\n\tconst char* data_file_name = argv[1];\n\t\n\tcudaDeviceProp prop;\n\tint dev;\n\t\n\tcheckCudaErrors(cudaSetDevice(0));\n\tcheckCudaErrors(cudaGetDevice(&dev));\n\tcheckCudaErrors(cudaGetDeviceProperties(&prop, dev));\n\t\n\tprintf(\"Name:                     %s\\n\", prop.name);\n\n\t{\n\t\tfloat h_ff_variable[NVAR];\n\t\tconst float angle_of_attack = float(3.1415926535897931 / 180.0f) * float(deg_angle_of_attack);\n\t\t\n\t\th_ff_variable[VAR_DENSITY] = float(1.4);\n\t\t\n\t\tfloat ff_pressure = float(1.0f);\n\t\tfloat ff_speed_of_sound = sqrt(GAMMA*ff_pressure / h_ff_variable[VAR_DENSITY]);\n\t\tfloat ff_speed = float(ff_mach)*ff_speed_of_sound;\n\t\t\n\t\tfloat3 ff_velocity;\n\t\tff_velocity.x = ff_speed*float(cos((float)angle_of_attack));\n\t\tff_velocity.y = ff_speed*float(sin((float)angle_of_attack));\n\t\tff_velocity.z = 0.0f;\n\t\t\n\t\th_ff_variable[VAR_MOMENTUM+0] = h_ff_variable[VAR_DENSITY] * ff_velocity.x;\n\t\th_ff_variable[VAR_MOMENTUM+1] = h_ff_variable[VAR_DENSITY] * ff_velocity.y;\n\t\th_ff_variable[VAR_MOMENTUM+2] = h_ff_variable[VAR_DENSITY] * ff_velocity.z;\n\t\t\t\t\n\t\th_ff_variable[VAR_DENSITY_ENERGY] = h_ff_variable[VAR_DENSITY]*(float(0.5f)*(ff_speed*ff_speed)) + (ff_pressure / float(GAMMA-1.0f));\n\n\t\tfloat3 h_ff_momentum;\n\t\th_ff_momentum.x = *(h_ff_variable+VAR_MOMENTUM+0);\n\t\th_ff_momentum.y = *(h_ff_variable+VAR_MOMENTUM+1);\n\t\th_ff_momentum.z = *(h_ff_variable+VAR_MOMENTUM+2);\n\t\tfloat3 h_ff_flux_contribution_momentum_x;\n\t\tfloat3 h_ff_flux_contribution_momentum_y;\n\t\tfloat3 h_ff_flux_contribution_momentum_z;\n\t\tfloat3 h_ff_flux_contribution_density_energy;\n\t\tcompute_flux_contribution(h_ff_variable[VAR_DENSITY], h_ff_momentum, h_ff_variable[VAR_DENSITY_ENERGY], ff_pressure, ff_velocity, h_ff_flux_contribution_momentum_x, h_ff_flux_contribution_momentum_y, h_ff_flux_contribution_momentum_z, h_ff_flux_contribution_density_energy);\n\n\t\tcheckCudaErrors( cudaMemcpyToSymbol(ff_variable,          h_ff_variable,          NVAR*sizeof(float)) );\n\t\tcheckCudaErrors( cudaMemcpyToSymbol(ff_flux_contribution_momentum_x, &h_ff_flux_contribution_momentum_x, sizeof(float3)) );\n\t\tcheckCudaErrors( cudaMemcpyToSymbol(ff_flux_contribution_momentum_y, &h_ff_flux_contribution_momentum_y, sizeof(float3)) );\n\t\tcheckCudaErrors( cudaMemcpyToSymbol(ff_flux_contribution_momentum_z, &h_ff_flux_contribution_momentum_z, sizeof(float3)) );\n\t\t\n\t\tcheckCudaErrors( cudaMemcpyToSymbol(ff_flux_contribution_density_energy, &h_ff_flux_contribution_density_energy, sizeof(float3)) );\t\t\n\t}\n\tint nel;\n\tint nelr;\n\t\n\tfloat* areas;\n\tint* elements_surrounding_elements;\n\tfloat* normals;\n\t{\n\t\tstd::ifstream file(data_file_name);\n\t\n\t\tfile >> nel;\n\t\tnelr = BLOCK_SIZE_0*((nel / BLOCK_SIZE_0 )+ std::min(1, nel % BLOCK_SIZE_0));\n\n\t\tfloat* h_areas = new float[nelr];\n\t\tint* h_elements_surrounding_elements = new int[nelr*NNB];\n\t\tfloat* h_normals = new float[nelr*NDIM*NNB];\n\n\t\t\t\t\n\t\tfor(int i = 0; i < nel; i++)\n\t\t{\n\t\t\tfile >> h_areas[i];\n\t\t\tfor(int j = 0; j < NNB; j++)\n\t\t\t{\n\t\t\t\tfile >> h_elements_surrounding_elements[i + j*nelr];\n\t\t\t\tif(h_elements_surrounding_elements[i+j*nelr] < 0) h_elements_surrounding_elements[i+j*nelr] = -1;\n\t\t\t\th_elements_surrounding_elements[i + j*nelr]--; //it's coming in with Fortran numbering\t\t\t\t\n\t\t\t\t\n\t\t\t\tfor(int k = 0; k < NDIM; k++)\n\t\t\t\t{\n\t\t\t\t\tfile >> h_normals[i + (j + k*NNB)*nelr];\n\t\t\t\t\th_normals[i + (j + k*NNB)*nelr] = -h_normals[i + (j + k*NNB)*nelr];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tint last = nel-1;\n\t\tfor(int i = nel; i < nelr; i++)\n\t\t{\n\t\t\th_areas[i] = h_areas[last];\n\t\t\tfor(int j = 0; j < NNB; j++)\n\t\t\t{\n\t\t\t\th_elements_surrounding_elements[i + j*nelr] = h_elements_surrounding_elements[last + j*nelr];\t\n\t\t\t\tfor(int k = 0; k < NDIM; k++) h_normals[last + (j + k*NNB)*nelr] = h_normals[last + (j + k*NNB)*nelr];\n\t\t\t}\n\t\t}\n\t\t\n\t\tareas = alloc<float>(nelr);\n\t\tupload<float>(areas, h_areas, nelr);\n\n\t\telements_surrounding_elements = alloc<int>(nelr*NNB);\n\t\tupload<int>(elements_surrounding_elements, h_elements_surrounding_elements, nelr*NNB);\n\n\t\tnormals = alloc<float>(nelr*NDIM*NNB);\n\t\tupload<float>(normals, h_normals, nelr*NDIM*NNB);\n\t\t\t\t\n\t\tdelete[] h_areas;\n\t\tdelete[] h_elements_surrounding_elements;\n\t\tdelete[] h_normals;\n\t}\n\n\tfloat* variables = alloc<float>(nelr*NVAR);\n\tinitialize_variables(nelr, variables);\n\n\tfloat* old_variables = alloc<float>(nelr*NVAR);   \t\n\tfloat* fluxes = alloc<float>(nelr*NVAR);\n\tfloat* step_factors = alloc<float>(nelr); \n\n\tinitialize_variables(nelr, old_variables);\n\tinitialize_variables(nelr, fluxes);\n\tcudaMemset( (void*) step_factors, 0, sizeof(float)*nelr );\n\tcudaThreadSynchronize();\n\n\tstd::cout << \"Starting...\" << std::endl;\n\n\tStopWatchInterface *timer = 0;\n\tsdkCreateTimer(&timer); \n\tsdkStartTimer(&timer); \n\tfor(int i = 0; i < iterations; i++)\n\t{\n\t\tcopy<float>(old_variables, variables, nelr*NVAR);\n\t\t\n\t\tcompute_step_factor(nelr, variables, areas, step_factors);\n\t\tgetLastCudaError(\"compute_step_factor failed\");\n\t\t\n\t\tfor(int j = 0; j < RK; j++)\n\t\t{\n\t\t\tcompute_flux(nelr, elements_surrounding_elements, normals, variables, fluxes);\n\t\t\tgetLastCudaError(\"compute_flux failed\");\t\t\t\n\t\t\ttime_step(j, nelr, old_variables, variables, step_factors, fluxes);\n\t\t\tgetLastCudaError(\"time_step failed\");\t\t\t\n\t\t}\n\t}\n\n\tcudaThreadSynchronize();\n\tsdkStopTimer(&timer); \n\n\tstd::cout  << (sdkGetAverageTimerValue(&timer)/1000.0)  / iterations << \" seconds per iteration\" << std::endl;\n\n\tstd::cout << \"Saving solution...\" << std::endl;\n\tdump(variables, nel, nelr);\n\tstd::cout << \"Saved solution...\" << std::endl;\n\n\t\n\tstd::cout << \"Cleaning up...\" << std::endl;\n\tdealloc<float>(areas);\n\tdealloc<int>(elements_surrounding_elements);\n\tdealloc<float>(normals);\n\t\n\tdealloc<float>(variables);\n\tdealloc<float>(old_variables);\n\tdealloc<float>(fluxes);\n\tdealloc<float>(step_factors);\n\n\tstd::cout << \"Done...\" << std::endl;\n\n\treturn 0;\n}\n"}, "code_dirs": {"euler3d.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/cfd"}}
{"kernel_name": "cfd", "parallel_api": "ocl", "code": {"euler3d.cpp": "#include <iostream>\n#include <fstream>\n#include <math.h>\n#include \"CLHelper.h\" \n \n#define GAMMA 1.4f\n#define iterations 2000\n#ifndef block_length\n\t#define block_length 192\n#endif\n\n#define NDIM 3\n#define NNB 4\n\n#define RK 3\n#define ff_mach 1.2f\n#define deg_angle_of_attack 0.0f\n\n#if block_length > 128\n#warning \"the kernels may fail too launch on some systems if the block length is too large\"\n#endif\n\n\n#define VAR_DENSITY 0\n#define VAR_MOMENTUM  1\n#define VAR_DENSITY_ENERGY (VAR_MOMENTUM+NDIM)\n#define NVAR (VAR_DENSITY_ENERGY+1)\n\ntypedef struct{\n\tfloat x;\n\tfloat y;\n\tfloat z;\n} float3;\n\ntemplate <typename T>\ncl_mem alloc(int N){\n\tcl_mem mem_d = _clMalloc(sizeof(T)*N);\n\treturn mem_d;\n}\n\ntemplate <typename T>\nvoid dealloc(cl_mem array){\n\t_clFree(array);\n}\n\ntemplate <typename T>\nvoid copy(cl_mem dst, cl_mem src, int N){\n\t_clMemcpyD2D(dst, src, N*sizeof(T));\n}\n\ntemplate <typename T>\nvoid upload(cl_mem dst, T* src, int N){\n\t_clMemcpyH2D(dst, src, N*sizeof(T));\n}\n\ntemplate <typename T>\nvoid download(T* dst, cl_mem src, int N){\n\t_clMemcpyD2H(dst, src, N*sizeof(T));\n}\n\nvoid dump(cl_mem variables, int nel, int nelr){\n\tfloat* h_variables = new float[nelr*NVAR];\n\tdownload(h_variables, variables, nelr*NVAR);\n\n\t{\n\t\tstd::ofstream file(\"density.txt\");\n\t\tfile << nel << \" \" << nelr << std::endl;\n\t\tfor(int i = 0; i < nel; i++) file << h_variables[i + VAR_DENSITY*nelr] << std::endl;\n\t}\n\n\n\t{\n\t\tstd::ofstream file(\"momentum.txt\");\n\t\tfile << nel << \" \" << nelr << std::endl;\n\t\tfor(int i = 0; i < nel; i++)\n\t\t{\n\t\t\tfor(int j = 0; j != NDIM; j++)\n\t\t\t\tfile << h_variables[i + (VAR_MOMENTUM+j)*nelr] << \" \";\n\t\t\tfile << std::endl;\n\t\t}\n\t}\n\t\n\t{\n\t\tstd::ofstream file(\"density_energy.txt\");\n\t\tfile << nel << \" \" << nelr << std::endl;\n\t\tfor(int i = 0; i < nel; i++) file << h_variables[i + VAR_DENSITY_ENERGY*nelr] << std::endl;\n\t}\n\tdelete[] h_variables;\n}\n\nvoid initialize_variables(int nelr, cl_mem variables, cl_mem ff_variable) throw(string){\n\n\tint work_items = nelr;\n\tint work_group_size = BLOCK_SIZE_1;\n\tint kernel_id = 1;\n\tint arg_idx = 0;\t\n\t_clSetArgs(kernel_id, arg_idx++, variables);\n\t_clSetArgs(kernel_id, arg_idx++, ff_variable);\n\t_clSetArgs(kernel_id, arg_idx++, &nelr, sizeof(int));\n\t_clInvokeKernel(kernel_id, work_items, work_group_size);\n}\n\nvoid compute_step_factor(int nelr, cl_mem variables, cl_mem areas, cl_mem step_factors){\n\n\tint work_items = nelr;\n\tint work_group_size = BLOCK_SIZE_2;\n\tint kernel_id = 2;\n\tint arg_idx = 0;\n\t_clSetArgs(kernel_id, arg_idx++, variables);\n\t_clSetArgs(kernel_id, arg_idx++, areas);\n\t_clSetArgs(kernel_id, arg_idx++, step_factors);\n\t_clSetArgs(kernel_id, arg_idx++, &nelr, sizeof(int));\n\t_clInvokeKernel(kernel_id, work_items, work_group_size);\n}\n\nvoid compute_flux(int nelr, cl_mem elements_surrounding_elements, cl_mem normals, cl_mem variables, cl_mem ff_variable, \\\n\t\t\tcl_mem fluxes, cl_mem ff_flux_contribution_density_energy,\n\t\t\tcl_mem ff_flux_contribution_momentum_x,\n\t\t\tcl_mem ff_flux_contribution_momentum_y,\n\t\t\tcl_mem ff_flux_contribution_momentum_z){\n\n\tint work_items = nelr;\n\tint work_group_size = BLOCK_SIZE_3;\n\tint kernel_id = 3;\n\tint arg_idx = 0;\n\t_clSetArgs(kernel_id, arg_idx++, elements_surrounding_elements);\n\t_clSetArgs(kernel_id, arg_idx++, normals);\n\t_clSetArgs(kernel_id, arg_idx++, variables);\n\t_clSetArgs(kernel_id, arg_idx++, ff_variable);\n\t_clSetArgs(kernel_id, arg_idx++, fluxes);\n\t_clSetArgs(kernel_id, arg_idx++, ff_flux_contribution_density_energy);\n\t_clSetArgs(kernel_id, arg_idx++, ff_flux_contribution_momentum_x);\n\t_clSetArgs(kernel_id, arg_idx++, ff_flux_contribution_momentum_y);\n\t_clSetArgs(kernel_id, arg_idx++, ff_flux_contribution_momentum_z);\n\t_clSetArgs(kernel_id, arg_idx++, &nelr, sizeof(int));\n\t_clInvokeKernel(kernel_id, work_items, work_group_size);\n}\n\nvoid time_step(int j, int nelr, cl_mem old_variables, cl_mem variables, cl_mem step_factors, cl_mem fluxes){\n\n\tint work_items = nelr;\n\tint work_group_size = BLOCK_SIZE_4;\n\tint kernel_id = 4;\n\tint arg_idx = 0;\n\t_clSetArgs(kernel_id, arg_idx++, &j, sizeof(int));\n\t_clSetArgs(kernel_id, arg_idx++, &nelr, sizeof(int));\n\t_clSetArgs(kernel_id, arg_idx++, old_variables);\n\t_clSetArgs(kernel_id, arg_idx++, variables);\n\t_clSetArgs(kernel_id, arg_idx++, step_factors);\n\t_clSetArgs(kernel_id, arg_idx++, fluxes);\n\t\n\t_clInvokeKernel(kernel_id, work_items, work_group_size);\n}\ninline void compute_flux_contribution(float& density, float3& momentum, float& density_energy, float& pressure, float3& velocity, float3& fc_momentum_x, float3& fc_momentum_y, float3& fc_momentum_z, float3& fc_density_energy)\n{\n\tfc_momentum_x.x = velocity.x*momentum.x + pressure;\n\tfc_momentum_x.y = velocity.x*momentum.y;\n\tfc_momentum_x.z = velocity.x*momentum.z;\n\t\n\t\n\tfc_momentum_y.x = fc_momentum_x.y;\n\tfc_momentum_y.y = velocity.y*momentum.y + pressure;\n\tfc_momentum_y.z = velocity.y*momentum.z;\n\n\tfc_momentum_z.x = fc_momentum_x.z;\n\tfc_momentum_z.y = fc_momentum_y.z;\n\tfc_momentum_z.z = velocity.z*momentum.z + pressure;\n\n\tfloat de_p = density_energy+pressure;\n\tfc_density_energy.x = velocity.x*de_p;\n\tfc_density_energy.y = velocity.y*de_p;\n\tfc_density_energy.z = velocity.z*de_p;\n}\n\nint main(int argc, char** argv){\n  printf(\"WG size of kernel:initialize = %d, WG size of kernel:compute_step_factor = %d, WG size of kernel:compute_flux = %d, WG size of kernel:time_step = %d\\n\", BLOCK_SIZE_1, BLOCK_SIZE_2, BLOCK_SIZE_3, BLOCK_SIZE_4);\n\n\tif (argc < 2){\n\t\tstd::cout << \"specify data file name and [device type] [device id]\" << std::endl;\n\t\treturn 0;\n\t}\n\tconst char* data_file_name = argv[1];\n\t_clCmdParams(argc, argv);\n\tcl_mem ff_variable, ff_flux_contribution_momentum_x, ff_flux_contribution_momentum_y,ff_flux_contribution_momentum_z,  ff_flux_contribution_density_energy;\n\tcl_mem areas, elements_surrounding_elements, normals;\n\tcl_mem variables, old_variables, fluxes, step_factors;\n\tfloat h_ff_variable[NVAR];\n\n\ttry{\t\t\n\t\t_clInit(device_type, device_id);\t\t\n\t\t{\n\t\t\tconst float angle_of_attack = float(3.1415926535897931 / 180.0f) * float(deg_angle_of_attack);\n\t\t\t\n\t\t\th_ff_variable[VAR_DENSITY] = float(1.4);\n\t\t\t\n\t\t\tfloat ff_pressure = float(1.0f);\n\t\t\tfloat ff_speed_of_sound = sqrt(GAMMA*ff_pressure / h_ff_variable[VAR_DENSITY]);\n\t\t\tfloat ff_speed = float(ff_mach)*ff_speed_of_sound;\n\t\t\t\n\t\t\tfloat3 ff_velocity;\n\t\t\tff_velocity.x = ff_speed*float(cos((float)angle_of_attack));\n\t\t\tff_velocity.y = ff_speed*float(sin((float)angle_of_attack));\n\t\t\tff_velocity.z = 0.0f;\n\t\t\t\n\t\t\th_ff_variable[VAR_MOMENTUM+0] = h_ff_variable[VAR_DENSITY] * ff_velocity.x;\n\t\t\th_ff_variable[VAR_MOMENTUM+1] = h_ff_variable[VAR_DENSITY] * ff_velocity.y;\n\t\t\th_ff_variable[VAR_MOMENTUM+2] = h_ff_variable[VAR_DENSITY] * ff_velocity.z;\n\t\t\t\t\t\n\t\t\th_ff_variable[VAR_DENSITY_ENERGY] = h_ff_variable[VAR_DENSITY]*(float(0.5f)*(ff_speed*ff_speed)) + (ff_pressure / float(GAMMA-1.0f));\n\n\t\t\tfloat3 h_ff_momentum;\n\t\t\th_ff_momentum.x = *(h_ff_variable+VAR_MOMENTUM+0);\n\t\t\th_ff_momentum.y = *(h_ff_variable+VAR_MOMENTUM+1);\n\t\t\th_ff_momentum.z = *(h_ff_variable+VAR_MOMENTUM+2);\n\t\t\tfloat3 h_ff_flux_contribution_momentum_x;\n\t\t\tfloat3 h_ff_flux_contribution_momentum_y;\n\t\t\tfloat3 h_ff_flux_contribution_momentum_z;\n\t\t\tfloat3 h_ff_flux_contribution_density_energy;\n\t\t\tcompute_flux_contribution(h_ff_variable[VAR_DENSITY], h_ff_momentum, h_ff_variable[VAR_DENSITY_ENERGY], ff_pressure, ff_velocity, h_ff_flux_contribution_momentum_x, h_ff_flux_contribution_momentum_y, h_ff_flux_contribution_momentum_z, h_ff_flux_contribution_density_energy);\n\n\t\t\tff_variable = _clMalloc(NVAR*sizeof(float));\n\t\t\tff_flux_contribution_momentum_x = _clMalloc(sizeof(float3));\n\t\t\tff_flux_contribution_momentum_y = _clMalloc(sizeof(float3));\n\t\t\tff_flux_contribution_momentum_z = _clMalloc(sizeof(float3));\n\t\t\tff_flux_contribution_density_energy = _clMalloc(sizeof(float3));\n\t\t\t_clMemcpyH2D(ff_variable,          h_ff_variable,          NVAR*sizeof(float));\n\t\t\t_clMemcpyH2D(ff_flux_contribution_momentum_x, &h_ff_flux_contribution_momentum_x, sizeof(float3));\n\t\t\t_clMemcpyH2D(ff_flux_contribution_momentum_y, &h_ff_flux_contribution_momentum_y, sizeof(float3));\n\t\t\t_clMemcpyH2D(ff_flux_contribution_momentum_z, &h_ff_flux_contribution_momentum_z, sizeof(float3));\t\t\n\t\t\t_clMemcpyH2D(ff_flux_contribution_density_energy, &h_ff_flux_contribution_density_energy, sizeof(float3));\n\t\t\t_clFinish();\n\t\t\n\t\t}\n\t\tint nel;\n\t\tint nelr;\n\t\t{\n\t\t\tstd::ifstream file(data_file_name);\n\t\t\tif(file==NULL){\n\t\t\t\tthrow(string(\"can not find/open file!\"));\n\t\t\t}\n\t\t\tfile >> nel;\n\t\t\tnelr = block_length*((nel / block_length )+ std::min(1, nel % block_length));\n\t\t\tstd::cout<<\"--cambine: nel=\"<<nel<<\", nelr=\"<<nelr<<std::endl;\n\t\t\tfloat* h_areas = new float[nelr];\n\t\t\tint* h_elements_surrounding_elements = new int[nelr*NNB];\n\t\t\tfloat* h_normals = new float[nelr*NDIM*NNB];\n\n\t\t\t\t\t\n\t\t\tfor(int i = 0; i < nel; i++)\n\t\t\t{\n\t\t\t\tfile >> h_areas[i];\n\t\t\t\tfor(int j = 0; j < NNB; j++)\n\t\t\t\t{\n\t\t\t\t\tfile >> h_elements_surrounding_elements[i + j*nelr];\n\t\t\t\t\tif(h_elements_surrounding_elements[i+j*nelr] < 0) h_elements_surrounding_elements[i+j*nelr] = -1;\n\t\t\t\t\th_elements_surrounding_elements[i + j*nelr]--; //it's coming in with Fortran numbering\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tfor(int k = 0; k < NDIM; k++)\n\t\t\t\t\t{\n\t\t\t\t\t\tfile >> h_normals[i + (j + k*NNB)*nelr];\n\t\t\t\t\t\th_normals[i + (j + k*NNB)*nelr] = -h_normals[i + (j + k*NNB)*nelr];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tint last = nel-1;\n\t\t\tfor(int i = nel; i < nelr; i++)\n\t\t\t{\n\t\t\t\th_areas[i] = h_areas[last];\n\t\t\t\tfor(int j = 0; j < NNB; j++)\n\t\t\t\t{\n\t\t\t\t\th_elements_surrounding_elements[i + j*nelr] = h_elements_surrounding_elements[last + j*nelr];\t\n\t\t\t\t\tfor(int k = 0; k < NDIM; k++) h_normals[last + (j + k*NNB)*nelr] = h_normals[last + (j + k*NNB)*nelr];\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tareas = alloc<float>(nelr);\n\t\t\tupload<float>(areas, h_areas, nelr);\n\n\t\t\telements_surrounding_elements = alloc<int>(nelr*NNB);\n\t\t\tupload<int>(elements_surrounding_elements, h_elements_surrounding_elements, nelr*NNB);\n\n\t\t\tnormals = alloc<float>(nelr*NDIM*NNB);\n\t\t\tupload<float>(normals, h_normals, nelr*NDIM*NNB);\n\t\t\t\t\t\n\t\t\tdelete[] h_areas;\n\t\t\tdelete[] h_elements_surrounding_elements;\n\t\t\tdelete[] h_normals;\n\t\t}\n\t\t\n\t\tvariables = alloc<float>(nelr*NVAR);\t\t\t\t\n\t\tint tp = 0;\n\t\tinitialize_variables(nelr, variables, ff_variable);\t\t\t\n\t\told_variables = alloc<float>(nelr*NVAR);   \t\n\t\tfluxes = alloc<float>(nelr*NVAR);\n\t\tstep_factors = alloc<float>(nelr); \n\t\tinitialize_variables(nelr, old_variables, ff_variable);\t\n\t\tinitialize_variables(nelr, fluxes, ff_variable);\t\t\n\t\t_clMemset(step_factors, 0, sizeof(float)*nelr);\t\n\t\t_clFinish();\n\t\tstd::cout << \"Starting...\" << std::endl;\n\n\t\tfor(int i = 0; i < iterations; i++){\n\t\t\tcopy<float>(old_variables, variables, nelr*NVAR);\n\t\t\tcompute_step_factor(nelr, variables, areas, step_factors);\n\t\t\tfor(int j = 0; j < RK; j++){\n\t\t\t\tcompute_flux(nelr, elements_surrounding_elements, normals, variables, ff_variable, fluxes, ff_flux_contribution_density_energy, \\\n\t\t\t\tff_flux_contribution_momentum_x, ff_flux_contribution_momentum_y, ff_flux_contribution_momentum_z);\n\t\t\t\n\t\t\t\ttime_step(j, nelr, old_variables, variables, step_factors, fluxes);\n\t\t\t}\n\t\t}\n\t\t_clFinish();\n\t\tstd::cout << \"Saving solution...\" << std::endl;\n\t\tdump(variables, nel, nelr);\n\t\tstd::cout << \"Saved solution...\" << std::endl;\n\t\t_clStatistics();\n\t\tstd::cout << \"Cleaning up...\" << std::endl;\n\t\t\n\t\t_clFree(ff_variable);\n\t\t_clFree(ff_flux_contribution_momentum_x);\n\t\t_clFree(ff_flux_contribution_momentum_y);\n\t\t_clFree(ff_flux_contribution_momentum_z);\n\t\t_clFree(ff_flux_contribution_density_energy);\n\t\t_clFree(areas);\n\t\t_clFree(elements_surrounding_elements);\n\t\t_clFree(normals);\n\t\t_clFree(variables);\n\t\t_clFree(old_variables);\n\t\t_clFree(fluxes);\n\t\t_clFree(step_factors);\n\t\t_clRelease();\n\t\tstd::cout << \"Done...\" << std::endl;\n\t\t_clPrintTiming();\n\t}\n\tcatch(string msg){\n\t\tstd::cout<<\"--cambine:( an exception catched in main body ->\"<<msg<<std::endl;\t\t\n\t\t_clFree(ff_variable);\n\t\t_clFree(ff_flux_contribution_momentum_x);\n\t\t_clFree(ff_flux_contribution_momentum_y);\n\t\t_clFree(ff_flux_contribution_momentum_z);\n\t\t_clFree(ff_flux_contribution_density_energy);\n\t\t_clFree(areas);\n\t\t_clFree(elements_surrounding_elements);\n\t\t_clFree(normals);\n\t\t_clFree(variables);\n\t\t_clFree(old_variables);\n\t\t_clFree(fluxes);\n\t\t_clFree(step_factors);\n\t\t_clRelease();\t\t\n\t}\n\tcatch(...){\n\t\tstd::cout<<\"--cambine:( unknow exceptions in main body...\"<<std::endl;\t\t\n\t\t_clFree(ff_variable);\n\t\t_clFree(ff_flux_contribution_momentum_x);\n\t\t_clFree(ff_flux_contribution_momentum_y);\n\t\t_clFree(ff_flux_contribution_momentum_z);\n\t\t_clFree(ff_flux_contribution_density_energy);\n\t\t_clFree(areas);\n\t\t_clFree(elements_surrounding_elements);\n\t\t_clFree(normals);\n\t\t_clFree(variables);\n\t\t_clFree(old_variables);\n\t\t_clFree(fluxes);\n\t\t_clFree(step_factors);\n\t\t_clRelease();\t\t\n\t}\n\t\t\n\treturn 0;\n}\n", "Kernels.cl": "#ifndef _KERNEL_\n#define _KERNEL_\n\n#define GAMMA (1.4f)\n\n\n#define NDIM 3\n#define NNB 4\n\n#define RK 3\t\n#define ff_mach 1.2f\n#define deg_angle_of_attack 0.0f\n\n#define VAR_DENSITY 0\n#define VAR_MOMENTUM  1\n#define VAR_DENSITY_ENERGY (VAR_MOMENTUM+NDIM)\n#define NVAR (VAR_DENSITY_ENERGY+1)\n\n\n\ntypedef struct{\n\tfloat x;\n\tfloat y;\n\tfloat z;\n} FLOAT3;\n__kernel void memset_kernel(__global char * mem_d, short val, int ct){\n\tconst int thread_id = get_global_id(0);\n\tif( thread_id >= ct) return;\n\tmem_d[thread_id] = val;\n}\n\ninline void compute_velocity(float  density, FLOAT3 momentum, FLOAT3* velocity){\n\tvelocity->x = momentum.x / density;\n\tvelocity->y = momentum.y / density;\n\tvelocity->z = momentum.z / density;\n}\n\t\ninline float compute_speed_sqd(FLOAT3 velocity){\n\treturn velocity.x*velocity.x + velocity.y*velocity.y + velocity.z*velocity.z;\n}\n\ninline float compute_pressure(float density, float density_energy, float speed_sqd){\n\treturn ((float)(GAMMA) - (float)(1.0f))*(density_energy - (float)(0.5f)*density*speed_sqd);\n}\ninline float compute_speed_of_sound(float density, float pressure){\n\t//return sqrtf(float(GAMMA)*pressure/density);\n\treturn sqrt((float)(GAMMA)*pressure/density);\n}\ninline void compute_flux_contribution(float density, FLOAT3 momentum, float density_energy, float pressure, FLOAT3 velocity, FLOAT3* fc_momentum_x, FLOAT3* fc_momentum_y, FLOAT3* fc_momentum_z, FLOAT3* fc_density_energy)\n{\n\tfc_momentum_x->x = velocity.x*momentum.x + pressure;\n\tfc_momentum_x->y = velocity.x*momentum.y;\n\tfc_momentum_x->z = velocity.x*momentum.z;\n\t\n\t\n\tfc_momentum_y->x = fc_momentum_x->y;\n\tfc_momentum_y->y = velocity.y*momentum.y + pressure;\n\tfc_momentum_y->z = velocity.y*momentum.z;\n\n\tfc_momentum_z->x = fc_momentum_x->z;\n\tfc_momentum_z->y = fc_momentum_y->z;\n\tfc_momentum_z->z = velocity.z*momentum.z + pressure;\n\n\tfloat de_p = density_energy+pressure;\n\tfc_density_energy->x = velocity.x*de_p;\n\tfc_density_energy->y = velocity.y*de_p;\n\tfc_density_energy->z = velocity.z*de_p;\n}\n__kernel void initialize_variables(__global float* variables, __constant float* ff_variable, int nelr){\n\t//const int i = (blockDim.x*blockIdx.x + threadIdx.x);\n\tconst int i = get_global_id(0);\n\tif( i >= nelr) return;\n\tfor(int j = 0; j < NVAR; j++)\n\t\tvariables[i + j*nelr] = ff_variable[j];\n\t\n}\n\n__kernel void compute_step_factor(__global float* variables, \n\t\t\t\t\t\t\t__global float* areas, \n\t\t\t\t\t\t\t__global float* step_factors,\n\t\t\t\t\t\t\tint nelr){\n\t//const int i = (blockDim.x*blockIdx.x + threadIdx.x);\n\tconst int i = get_global_id(0);\n\tif( i >= nelr) return;\n\n\tfloat density = variables[i + VAR_DENSITY*nelr];\n\tFLOAT3 momentum;\n\tmomentum.x = variables[i + (VAR_MOMENTUM+0)*nelr];\n\tmomentum.y = variables[i + (VAR_MOMENTUM+1)*nelr];\n\tmomentum.z = variables[i + (VAR_MOMENTUM+2)*nelr];\n\t\n\tfloat density_energy = variables[i + VAR_DENSITY_ENERGY*nelr];\n\t\n\tFLOAT3 velocity;       compute_velocity(density, momentum, &velocity);\n\tfloat speed_sqd      = compute_speed_sqd(velocity);\n\tfloat pressure       = compute_pressure(density, density_energy, speed_sqd);\n\tfloat speed_of_sound = compute_speed_of_sound(density, pressure);\n\n\tstep_factors[i] = (float)(0.5f) / (sqrt(areas[i]) * (sqrt(speed_sqd) + speed_of_sound));\n}\n\n__kernel void compute_flux(\n\t\t\t\t\t__global int* elements_surrounding_elements, \n\t\t\t\t\t__global float* normals, \n\t\t\t\t\t__global float* variables, \n\t\t\t\t\t__constant float* ff_variable,\n\t\t\t\t\t__global float* fluxes,\n\t\t\t\t\t__constant FLOAT3* ff_flux_contribution_density_energy,\n\t\t\t\t\t__constant FLOAT3* ff_flux_contribution_momentum_x,\n\t\t\t\t\t__constant FLOAT3* ff_flux_contribution_momentum_y,\n\t\t\t\t\t__constant FLOAT3* ff_flux_contribution_momentum_z,\n\t\t\t\t\tint nelr){\n\tconst float smoothing_coefficient = (float)(0.2f);\n\tconst int i = get_global_id(0);\n\tif( i >= nelr) return;\n\tint j, nb;\n\tFLOAT3 normal; float normal_len;\n\tfloat factor;\n\t\n\tfloat density_i = variables[i + VAR_DENSITY*nelr];\n\tFLOAT3 momentum_i;\n\tmomentum_i.x = variables[i + (VAR_MOMENTUM+0)*nelr];\n\tmomentum_i.y = variables[i + (VAR_MOMENTUM+1)*nelr];\n\tmomentum_i.z = variables[i + (VAR_MOMENTUM+2)*nelr];\n\n\tfloat density_energy_i = variables[i + VAR_DENSITY_ENERGY*nelr];\n\n\tFLOAT3 velocity_i;             \t\t\t\tcompute_velocity(density_i, momentum_i, &velocity_i);\n\tfloat speed_sqd_i                          = compute_speed_sqd(velocity_i);\n\tfloat speed_i                              = sqrt(speed_sqd_i);\n\tfloat pressure_i                           = compute_pressure(density_i, density_energy_i, speed_sqd_i);\n\tfloat speed_of_sound_i                     = compute_speed_of_sound(density_i, pressure_i);\n\tFLOAT3 flux_contribution_i_momentum_x, flux_contribution_i_momentum_y, flux_contribution_i_momentum_z;\n\tFLOAT3 flux_contribution_i_density_energy;\t\n\tcompute_flux_contribution(density_i, momentum_i, density_energy_i, pressure_i, velocity_i, &flux_contribution_i_momentum_x, &flux_contribution_i_momentum_y, &flux_contribution_i_momentum_z, &flux_contribution_i_density_energy);\n\t\n\tfloat flux_i_density = (float)(0.0f);\n\tFLOAT3 flux_i_momentum;\n\tflux_i_momentum.x = (float)(0.0f);\n\tflux_i_momentum.y = (float)(0.0f);\n\tflux_i_momentum.z = (float)(0.0f);\n\tfloat flux_i_density_energy = (float)(0.0f);\n\t\t\n\tFLOAT3 velocity_nb;\n\tfloat density_nb, density_energy_nb;\n\tFLOAT3 momentum_nb;\n\tFLOAT3 flux_contribution_nb_momentum_x, flux_contribution_nb_momentum_y, flux_contribution_nb_momentum_z;\n\tFLOAT3 flux_contribution_nb_density_energy;\t\n\tfloat speed_sqd_nb, speed_of_sound_nb, pressure_nb;\n\t\n\t#pragma unroll\n\tfor(j = 0; j < NNB; j++)\n\t{\n\t\tnb = elements_surrounding_elements[i + j*nelr];\n\t\tnormal.x = normals[i + (j + 0*NNB)*nelr];\n\t\tnormal.y = normals[i + (j + 1*NNB)*nelr];\n\t\tnormal.z = normals[i + (j + 2*NNB)*nelr];\n\t\t//normal_len = sqrtf(normal.x*normal.x + normal.y*normal.y + normal.z*normal.z);\n\t\tnormal_len = sqrt(normal.x*normal.x + normal.y*normal.y + normal.z*normal.z);\n\t\t\n\t\tif(nb >= 0) \t// a legitimate neighbor\n\t\t{\n\t\t\tdensity_nb = variables[nb + VAR_DENSITY*nelr];\n\t\t\tmomentum_nb.x = variables[nb + (VAR_MOMENTUM+0)*nelr];\n\t\t\tmomentum_nb.y = variables[nb + (VAR_MOMENTUM+1)*nelr];\n\t\t\tmomentum_nb.z = variables[nb + (VAR_MOMENTUM+2)*nelr];\n\t\t\tdensity_energy_nb = variables[nb + VAR_DENSITY_ENERGY*nelr];\n\t\t\t\t\t\t\t\t\t\t\t\tcompute_velocity(density_nb, momentum_nb, &velocity_nb);\n\t\t\tspeed_sqd_nb                      = compute_speed_sqd(velocity_nb);\n\t\t\tpressure_nb                       = compute_pressure(density_nb, density_energy_nb, speed_sqd_nb);\n\t\t\tspeed_of_sound_nb                 = compute_speed_of_sound(density_nb, pressure_nb);\n\t\t\t                                    compute_flux_contribution(density_nb, momentum_nb, density_energy_nb, pressure_nb, velocity_nb, &flux_contribution_nb_momentum_x, &flux_contribution_nb_momentum_y, &flux_contribution_nb_momentum_z, &flux_contribution_nb_density_energy);\n\t\t\t\n\t\t\tfactor = -normal_len*smoothing_coefficient*(float)(0.5f)*(speed_i + sqrt(speed_sqd_nb) + speed_of_sound_i + speed_of_sound_nb);\n\t\t\tflux_i_density += factor*(density_i-density_nb);\n\t\t\tflux_i_density_energy += factor*(density_energy_i-density_energy_nb);\n\t\t\tflux_i_momentum.x += factor*(momentum_i.x-momentum_nb.x);\n\t\t\tflux_i_momentum.y += factor*(momentum_i.y-momentum_nb.y);\n\t\t\tflux_i_momentum.z += factor*(momentum_i.z-momentum_nb.z);\n\n\t\t\tfactor = (float)(0.5f)*normal.x;\n\t\t\tflux_i_density += factor*(momentum_nb.x+momentum_i.x);\n\t\t\tflux_i_density_energy += factor*(flux_contribution_nb_density_energy.x+flux_contribution_i_density_energy.x);\n\t\t\tflux_i_momentum.x += factor*(flux_contribution_nb_momentum_x.x+flux_contribution_i_momentum_x.x);\n\t\t\tflux_i_momentum.y += factor*(flux_contribution_nb_momentum_y.x+flux_contribution_i_momentum_y.x);\n\t\t\tflux_i_momentum.z += factor*(flux_contribution_nb_momentum_z.x+flux_contribution_i_momentum_z.x);\n\t\t\t\n\t\t\tfactor = (float)(0.5f)*normal.y;\n\t\t\tflux_i_density += factor*(momentum_nb.y+momentum_i.y);\n\t\t\tflux_i_density_energy += factor*(flux_contribution_nb_density_energy.y+flux_contribution_i_density_energy.y);\n\t\t\tflux_i_momentum.x += factor*(flux_contribution_nb_momentum_x.y+flux_contribution_i_momentum_x.y);\n\t\t\tflux_i_momentum.y += factor*(flux_contribution_nb_momentum_y.y+flux_contribution_i_momentum_y.y);\n\t\t\tflux_i_momentum.z += factor*(flux_contribution_nb_momentum_z.y+flux_contribution_i_momentum_z.y);\n\t\t\t\n\t\t\tfactor = (float)(0.5f)*normal.z;\n\t\t\tflux_i_density += factor*(momentum_nb.z+momentum_i.z);\n\t\t\tflux_i_density_energy += factor*(flux_contribution_nb_density_energy.z+flux_contribution_i_density_energy.z);\n\t\t\tflux_i_momentum.x += factor*(flux_contribution_nb_momentum_x.z+flux_contribution_i_momentum_x.z);\n\t\t\tflux_i_momentum.y += factor*(flux_contribution_nb_momentum_y.z+flux_contribution_i_momentum_y.z);\n\t\t\tflux_i_momentum.z += factor*(flux_contribution_nb_momentum_z.z+flux_contribution_i_momentum_z.z);\n\t\t}\n\t\telse if(nb == -1)\t\n\t\t{\n\t\t\tflux_i_momentum.x += normal.x*pressure_i;\n\t\t\tflux_i_momentum.y += normal.y*pressure_i;\n\t\t\tflux_i_momentum.z += normal.z*pressure_i;\n\t\t}\n\t\telse if(nb == -2) \n\t\t{\n\t\t\tfactor = (float)(0.5f)*normal.x;\n\t\t\tflux_i_density += factor*(ff_variable[VAR_MOMENTUM+0]+momentum_i.x);\n\t\t\tflux_i_density_energy += factor*(ff_flux_contribution_density_energy[0].x+flux_contribution_i_density_energy.x);\n\t\t\tflux_i_momentum.x += factor*(ff_flux_contribution_momentum_x[0].x + flux_contribution_i_momentum_x.x);\n\t\t\tflux_i_momentum.y += factor*(ff_flux_contribution_momentum_y[0].x + flux_contribution_i_momentum_y.x);\n\t\t\tflux_i_momentum.z += factor*(ff_flux_contribution_momentum_z[0].x + flux_contribution_i_momentum_z.x);\n\t\t\t\n\t\t\tfactor = (float)(0.5f)*normal.y;\n\t\t\tflux_i_density += factor*(ff_variable[VAR_MOMENTUM+1]+momentum_i.y);\n\t\t\tflux_i_density_energy += factor*(ff_flux_contribution_density_energy[0].y+flux_contribution_i_density_energy.y);\n\t\t\tflux_i_momentum.x += factor*(ff_flux_contribution_momentum_x[0].y + flux_contribution_i_momentum_x.y);\n\t\t\tflux_i_momentum.y += factor*(ff_flux_contribution_momentum_y[0].y + flux_contribution_i_momentum_y.y);\n\t\t\tflux_i_momentum.z += factor*(ff_flux_contribution_momentum_z[0].y + flux_contribution_i_momentum_z.y);\n\n\t\t\tfactor = (float)(0.5f)*normal.z;\n\t\t\tflux_i_density += factor*(ff_variable[VAR_MOMENTUM+2]+momentum_i.z);\n\t\t\tflux_i_density_energy += factor*(ff_flux_contribution_density_energy[0].z+flux_contribution_i_density_energy.z);\n\t\t\tflux_i_momentum.x += factor*(ff_flux_contribution_momentum_x[0].z + flux_contribution_i_momentum_x.z);\n\t\t\tflux_i_momentum.y += factor*(ff_flux_contribution_momentum_y[0].z + flux_contribution_i_momentum_y.z);\n\t\t\tflux_i_momentum.z += factor*(ff_flux_contribution_momentum_z[0].z + flux_contribution_i_momentum_z.z);\n\n\t\t}\n\t}\n\n\tfluxes[i + VAR_DENSITY*nelr] = flux_i_density;\n\tfluxes[i + (VAR_MOMENTUM+0)*nelr] = flux_i_momentum.x;\n\tfluxes[i + (VAR_MOMENTUM+1)*nelr] = flux_i_momentum.y;\n\tfluxes[i + (VAR_MOMENTUM+2)*nelr] = flux_i_momentum.z;\n\tfluxes[i + VAR_DENSITY_ENERGY*nelr] = flux_i_density_energy;\n}\n\n__kernel void time_step(int j, int nelr, \n\t\t\t\t__global float* old_variables, \n\t\t\t\t__global float* variables, \n\t\t\t\t__global float* step_factors, \n\t\t\t\t__global float* fluxes){\n\t//const int i = (blockDim.x*blockIdx.x + threadIdx.x);\n\tconst int i = get_global_id(0);\n\tif( i >= nelr) return;\n\n\tfloat factor = step_factors[i]/(float)(RK+1-j);\n\n\tvariables[i + VAR_DENSITY*nelr] = old_variables[i + VAR_DENSITY*nelr] + factor*fluxes[i + VAR_DENSITY*nelr];\n\tvariables[i + VAR_DENSITY_ENERGY*nelr] = old_variables[i + VAR_DENSITY_ENERGY*nelr] + factor*fluxes[i + VAR_DENSITY_ENERGY*nelr];\n\tvariables[i + (VAR_MOMENTUM+0)*nelr] = old_variables[i + (VAR_MOMENTUM+0)*nelr] + factor*fluxes[i + (VAR_MOMENTUM+0)*nelr];\n\tvariables[i + (VAR_MOMENTUM+1)*nelr] = old_variables[i + (VAR_MOMENTUM+1)*nelr] + factor*fluxes[i + (VAR_MOMENTUM+1)*nelr];\t\n\tvariables[i + (VAR_MOMENTUM+2)*nelr] = old_variables[i + (VAR_MOMENTUM+2)*nelr] + factor*fluxes[i + (VAR_MOMENTUM+2)*nelr];\t\n\t\n}\n\n#endif\n"}, "code_dirs": {"euler3d.cpp": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/cfd", "Kernels.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/cfd"}}
{"kernel_name": "gaussian", "parallel_api": "cuda", "code": {"gaussian.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <sys/time.h>\n#include \"cuda.h\"\n#include <string.h>\n#include <math.h>\n\n#ifdef TIMING\n#include \"timing.h\"\n#endif\n\n#ifdef RD_WG_SIZE_0_0\n        #define MAXBLOCKSIZE RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n        #define MAXBLOCKSIZE RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n        #define MAXBLOCKSIZE RD_WG_SIZE\n#else\n        #define MAXBLOCKSIZE 512\n#endif\n\n#ifdef RD_WG_SIZE_1_0\n        #define BLOCK_SIZE_XY RD_WG_SIZE_1_0\n#elif defined(RD_WG_SIZE_1)\n        #define BLOCK_SIZE_XY RD_WG_SIZE_1\n#elif defined(RD_WG_SIZE)\n        #define BLOCK_SIZE_XY RD_WG_SIZE\n#else\n        #define BLOCK_SIZE_XY 4\n#endif\n\n#ifdef TIMING\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nint Size;\nfloat *a, *b, *finalVec;\nfloat *m;\n\nFILE *fp;\n\nvoid InitProblemOnce(char *filename);\nvoid InitPerRun();\nvoid ForwardSub();\nvoid BackSub();\n__global__ void Fan1(float *m, float *a, int Size, int t);\n__global__ void Fan2(float *m, float *a, float *b,int Size, int j1, int t);\nvoid InitMat(float *ary, int nrow, int ncol);\nvoid InitAry(float *ary, int ary_size);\nvoid PrintMat(float *ary, int nrow, int ncolumn);\nvoid PrintAry(float *ary, int ary_size);\nvoid PrintDeviceProperties();\nvoid checkCUDAError(const char *msg);\n\nunsigned int totalKernelTime = 0;\n\nvoid\ncreate_matrix(float *m, int size){\n  int i,j;\n  float lamda = -0.01;\n  float coe[2*size-1];\n  float coe_i =0.0;\n\n  for (i=0; i < size; i++)\n    {\n      coe_i = 10*exp(lamda*i); \n      j=size-1+i;     \n      coe[j]=coe_i;\n      j=size-1-i;     \n      coe[j]=coe_i;\n    }\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n\tm[i*size+j]=coe[size-1-i+j];\n      }\n  }\n}\n\nint main(int argc, char *argv[])\n{\n  printf(\"WG size of kernel 1 = %d, WG size of kernel 2= %d X %d\\n\", MAXBLOCKSIZE, BLOCK_SIZE_XY, BLOCK_SIZE_XY);\n    int verbose = 0;\n    int i, j;\n    char flag;\n    if (argc < 2) {\n        printf(\"Usage: gaussian -f filename / -s size [-q]\\n\\n\");\n        exit(0);\n    }\n    \n    PrintDeviceProperties();\n    for(i=1;i<argc;i++) {\n      if (argv[i][0]=='-') {\n        flag = argv[i][1];\n          switch (flag) {\n            case 's':\n              i++;\n              Size = atoi(argv[i]);\n\t      printf(\"Create matrix internally in parse, size = %d \\n\", Size);\n\t      a = (float *) malloc(Size * Size * sizeof(float));\n\t      create_matrix(a, Size);\n\t      b = (float *) malloc(Size * sizeof(float));\n\t      for (j =0; j< Size; j++)\n\t    \tb[j]=1.0;\n\t      m = (float *) malloc(Size * Size * sizeof(float));\n              break;\n            case 'f':\n              i++;\n\t      printf(\"Read file from %s \\n\", argv[i]);\n\t      InitProblemOnce(argv[i]);\n              break;\n            case 'q':\n\t      verbose = 0;\n              break;\n\t  }\n      }\n    }\n    InitPerRun();\n    struct timeval time_start;\n    gettimeofday(&time_start, NULL);\t\n    ForwardSub();\n    struct timeval time_end;\n    gettimeofday(&time_end, NULL);\n    unsigned int time_total = (time_end.tv_sec * 1000000 + time_end.tv_usec) - (time_start.tv_sec * 1000000 + time_start.tv_usec);\n    if (verbose) {\n        printf(\"Matrix m is: \\n\");\n        PrintMat(m, Size, Size);\n        printf(\"Matrix a is: \\n\");\n        PrintMat(a, Size, Size);\n        printf(\"Array b is: \\n\");\n        PrintAry(b, Size);\n    }\n    BackSub();\n    if (verbose) {\n        printf(\"The final solution is: \\n\");\n        PrintAry(finalVec,Size);\n    }\n    printf(\"\\nTime total (including memory transfers)\\t%f sec\\n\", time_total * 1e-6);\n    printf(\"Time for CUDA kernels:\\t%f sec\\n\",totalKernelTime * 1e-6);\n    \n    free(m);\n    free(a);\n    free(b);\n\n#ifdef  TIMING\n\tprintf(\"Exec: %f\\n\", kernel_time);\n#endif\n}\n\nvoid PrintDeviceProperties(){\n\tcudaDeviceProp deviceProp;  \n\tint nDevCount = 0;  \n\t\n\tcudaGetDeviceCount( &nDevCount );  \n\tprintf( \"Total Device found: %d\", nDevCount );  \n\tfor (int nDeviceIdx = 0; nDeviceIdx < nDevCount; ++nDeviceIdx )  \n\t{  \n\t    memset( &deviceProp, 0, sizeof(deviceProp));  \n\t    if( cudaSuccess == cudaGetDeviceProperties(&deviceProp, nDeviceIdx))  \n\t        {\n\t\t\t\tprintf( \"\\nDevice Name \\t\\t - %s \", deviceProp.name );  \n\t\t\t    printf( \"\\n**************************************\");  \n\t\t\t    printf( \"\\nTotal Global Memory\\t\\t\\t - %lu KB\", deviceProp.totalGlobalMem/1024 );  \n\t\t\t    printf( \"\\nShared memory available per block \\t - %lu KB\", deviceProp.sharedMemPerBlock/1024 );  \n\t\t\t    printf( \"\\nNumber of registers per thread block \\t - %d\", deviceProp.regsPerBlock );  \n\t\t\t    printf( \"\\nWarp size in threads \\t\\t\\t - %d\", deviceProp.warpSize );  \n\t\t\t    printf( \"\\nMemory Pitch \\t\\t\\t\\t - %zu bytes\", deviceProp.memPitch );  \n\t\t\t    printf( \"\\nMaximum threads per block \\t\\t - %d\", deviceProp.maxThreadsPerBlock );  \n\t\t\t    printf( \"\\nMaximum Thread Dimension (block) \\t - %d %d %d\", deviceProp.maxThreadsDim[0], deviceProp.maxThreadsDim[1], deviceProp.maxThreadsDim[2] );  \n\t\t\t    printf( \"\\nMaximum Thread Dimension (grid) \\t - %d %d %d\", deviceProp.maxGridSize[0], deviceProp.maxGridSize[1], deviceProp.maxGridSize[2] );  \n\t\t\t    printf( \"\\nTotal constant memory \\t\\t\\t - %zu bytes\", deviceProp.totalConstMem );  \n\t\t\t    printf( \"\\nCUDA ver \\t\\t\\t\\t - %d.%d\", deviceProp.major, deviceProp.minor );  \n\t\t\t    printf( \"\\nClock rate \\t\\t\\t\\t - %d KHz\", deviceProp.clockRate );  \n\t\t\t    printf( \"\\nTexture Alignment \\t\\t\\t - %zu bytes\", deviceProp.textureAlignment );  \n\t\t\t    printf( \"\\nDevice Overlap \\t\\t\\t\\t - %s\", deviceProp. deviceOverlap?\"Allowed\":\"Not Allowed\" );  \n\t\t\t    printf( \"\\nNumber of Multi processors \\t\\t - %d\\n\\n\", deviceProp.multiProcessorCount );  \n\t\t\t}  \n\t    else  \n\t        printf( \"\\n%s\", cudaGetErrorString(cudaGetLastError()));  \n\t}  \n}\n \n \n\nvoid InitProblemOnce(char *filename)\n{\n\tfp = fopen(filename, \"r\");\n\t\n\tfscanf(fp, \"%d\", &Size);\t\n\t \n\ta = (float *) malloc(Size * Size * sizeof(float));\n\t \n\tInitMat(a, Size, Size);\n\tb = (float *) malloc(Size * sizeof(float));\n\t\n\tInitAry(b, Size);\n\t\t\n\t m = (float *) malloc(Size * Size * sizeof(float));\n}\n\n\nvoid InitPerRun() \n{\n\tint i;\n\tfor (i=0; i<Size*Size; i++)\n\t\t\t*(m+i) = 0.0;\n}\n\n\n__global__ void Fan1(float *m_cuda, float *a_cuda, int Size, int t)\n{   \n\tif(threadIdx.x + blockIdx.x * blockDim.x >= Size-1-t) return;\n\t*(m_cuda+Size*(blockDim.x*blockIdx.x+threadIdx.x+t+1)+t) = *(a_cuda+Size*(blockDim.x*blockIdx.x+threadIdx.x+t+1)+t) / *(a_cuda+Size*t+t);\n}\n\n\n\n__global__ void Fan2(float *m_cuda, float *a_cuda, float *b_cuda,int Size, int j1, int t)\n{\n\tif(threadIdx.x + blockIdx.x * blockDim.x >= Size-1-t) return;\n\tif(threadIdx.y + blockIdx.y * blockDim.y >= Size-t) return;\n\t\n\tint xidx = blockIdx.x * blockDim.x + threadIdx.x;\n\tint yidx = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\ta_cuda[Size*(xidx+1+t)+(yidx+t)] -= m_cuda[Size*(xidx+1+t)+t] * a_cuda[Size*t+(yidx+t)];\n\tif(yidx == 0){\n\t\tb_cuda[xidx+1+t] -= m_cuda[Size*(xidx+1+t)+(yidx+t)] * b_cuda[t];\n\t}\n}\n\n\nvoid ForwardSub()\n{\n\tint t;\n    float *m_cuda,*a_cuda,*b_cuda;\n\t\n\tcudaMalloc((void **) &m_cuda, Size * Size * sizeof(float));\n\t \n\tcudaMalloc((void **) &a_cuda, Size * Size * sizeof(float));\n\t\n\tcudaMalloc((void **) &b_cuda, Size * sizeof(float));\t\n\n\tcudaMemcpy(m_cuda, m, Size * Size * sizeof(float),cudaMemcpyHostToDevice );\n\tcudaMemcpy(a_cuda, a, Size * Size * sizeof(float),cudaMemcpyHostToDevice );\n\tcudaMemcpy(b_cuda, b, Size * sizeof(float),cudaMemcpyHostToDevice );\n\t\n\tint block_size,grid_size;\n\t\n\tblock_size = MAXBLOCKSIZE;\n\tgrid_size = (Size/block_size) + (!(Size%block_size)? 0:1);\n\n\tdim3 dimBlock(block_size);\n\tdim3 dimGrid(grid_size);\n\t\n\tint blockSize2d, gridSize2d;\n\tblockSize2d = BLOCK_SIZE_XY;\n\tgridSize2d = (Size/blockSize2d) + (!(Size%blockSize2d?0:1)); \n\t\n\tdim3 dimBlockXY(blockSize2d,blockSize2d);\n\tdim3 dimGridXY(gridSize2d,gridSize2d);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_kernel_start, NULL);\n#endif\n\n    struct timeval time_start;\n    gettimeofday(&time_start, NULL);\n\tfor (t=0; t<(Size-1); t++) {\n\t\tFan1<<<dimGrid,dimBlock>>>(m_cuda,a_cuda,Size,t);\n\t\tcudaThreadSynchronize();\n\t\tFan2<<<dimGridXY,dimBlockXY>>>(m_cuda,a_cuda,b_cuda,Size,Size-t,t);\n\t\tcudaThreadSynchronize();\n\t\tcheckCUDAError(\"Fan2\");\n\t}\n\tstruct timeval time_end;\n    gettimeofday(&time_end, NULL);\n    totalKernelTime = (time_end.tv_sec * 1000000 + time_end.tv_usec) - (time_start.tv_sec * 1000000 + time_start.tv_usec);\n\t\n#ifdef  TIMING\n\ttvsub(&time_end, &tv_kernel_start, &tv);\n\tkernel_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tcudaMemcpy(m, m_cuda, Size * Size * sizeof(float),cudaMemcpyDeviceToHost );\n\tcudaMemcpy(a, a_cuda, Size * Size * sizeof(float),cudaMemcpyDeviceToHost );\n\tcudaMemcpy(b, b_cuda, Size * sizeof(float),cudaMemcpyDeviceToHost );\n\tcudaFree(m_cuda);\n\tcudaFree(a_cuda);\n\tcudaFree(b_cuda);\n}\n\n\n\nvoid BackSub()\n{\n\tfinalVec = (float *) malloc(Size * sizeof(float));\n\tint i,j;\n\tfor(i=0;i<Size;i++){\n\t\tfinalVec[Size-i-1]=b[Size-i-1];\n\t\tfor(j=0;j<i;j++)\n\t\t{\n\t\t\tfinalVec[Size-i-1]-=*(a+Size*(Size-i-1)+(Size-j-1)) * finalVec[Size-j-1];\n\t\t}\n\t\tfinalVec[Size-i-1]=finalVec[Size-i-1]/ *(a+Size*(Size-i-1)+(Size-i-1));\n\t}\n}\n\nvoid InitMat(float *ary, int nrow, int ncol)\n{\n\tint i, j;\n\t\n\tfor (i=0; i<nrow; i++) {\n\t\tfor (j=0; j<ncol; j++) {\n\t\t\tfscanf(fp, \"%f\",  ary+Size*i+j);\n\t\t}\n\t}  \n}\n\nvoid PrintMat(float *ary, int nrow, int ncol)\n{\n\tint i, j;\n\t\n\tfor (i=0; i<nrow; i++) {\n\t\tfor (j=0; j<ncol; j++) {\n\t\t\tprintf(\"%8.2f \", *(ary+Size*i+j));\n\t\t}\n\t\tprintf(\"\\n\");\n\t}\n\tprintf(\"\\n\");\n}\n\nvoid InitAry(float *ary, int ary_size)\n{\n\tint i;\n\t\n\tfor (i=0; i<ary_size; i++) {\n\t\tfscanf(fp, \"%f\",  &ary[i]);\n\t}\n}  \n\nvoid PrintAry(float *ary, int ary_size)\n{\n\tint i;\n\tfor (i=0; i<ary_size; i++) {\n\t\tprintf(\"%.2f \", ary[i]);\n\t}\n\tprintf(\"\\n\\n\");\n}\nvoid checkCUDAError(const char *msg)\n{\n    cudaError_t err = cudaGetLastError();\n    if( cudaSuccess != err) \n    {\n        fprintf(stderr, \"Cuda error: %s: %s.\\n\", msg, \n                                  cudaGetErrorString( err) );\n        exit(EXIT_FAILURE);\n    }                         \n}\n\n"}, "code_dirs": {"gaussian.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/gaussian"}}
{"kernel_name": "gaussian", "parallel_api": "ocl", "code": {"gaussianElim.cpp": "#ifndef __GAUSSIAN_ELIMINATION__\n#define __GAUSSIAN_ELIMINATION__\n\n#include \"gaussianElim.h\"\n#include <math.h>\n\n#include \"timing.h\"\n\n#ifdef RD_WG_SIZE_0_0\n        #define BLOCK_SIZE_0 RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n        #define BLOCK_SIZE_0 RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n        #define BLOCK_SIZE_0 RD_WG_SIZE\n#else\n        #define BLOCK_SIZE_0 0\n#endif\n\n//2D defines. Go from specific to general\n#ifdef RD_WG_SIZE_1_0\n        #define BLOCK_SIZE_1_X RD_WG_SIZE_1_0\n#elif defined(RD_WG_SIZE_1)\n        #define BLOCK_SIZE_1_X RD_WG_SIZE_1\n#elif defined(RD_WG_SIZE)\n        #define BLOCK_SIZE_1_X RD_WG_SIZE\n#else\n        #define BLOCK_SIZE_1_X 0\n#endif\n\n#ifdef RD_WG_SIZE_1_1\n        #define BLOCK_SIZE_1_Y RD_WG_SIZE_1_1\n#elif defined(RD_WG_SIZE_1)\n        #define BLOCK_SIZE_1_Y RD_WG_SIZE_1\n#elif defined(RD_WG_SIZE)\n        #define BLOCK_SIZE_1_Y RD_WG_SIZE\n#else\n        #define BLOCK_SIZE_1_Y 0\n#endif\n\n#ifdef TIMING\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_init_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time= 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\ncl_context context=NULL;\n\nvoid\ncreate_matrix(float *m, int size){\n  int i,j;\n  float lamda = -0.01;\n  float coe[2*size-1];\n  float coe_i =0.0;\n\n  for (i=0; i < size; i++)\n    {\n      coe_i = 10*exp(lamda*i); \n      j=size-1+i;     \n      coe[j]=coe_i;\n      j=size-1-i;     \n      coe[j]=coe_i;\n    }\n\n\n  for (i=0; i < size; i++) {\n      for (j=0; j < size; j++) {\n\tm[i*size+j]=coe[size-1-i+j];\n      }\n  }\n\n\n}\n\n\nint main(int argc, char *argv[]) {\n\n  printf(\"WG size of kernel 1 = %d, WG size of kernel 2= %d X %d\\n\", BLOCK_SIZE_0, BLOCK_SIZE_1_X, BLOCK_SIZE_1_Y);\n    float *a=NULL, *b=NULL, *finalVec=NULL;\n    float *m=NULL;\n    int size = -1;\n    \n    FILE *fp;\n    \n    char filename[200];\n    int show_data=0,quiet=0,timing=0,platform=0,device=0;\n    \n    if (parseCommandline(argc, argv, filename,\n\t\t\t &quiet, &show_data, &timing, &platform, &device, &size)) {\n    printUsage();\n    return 0;\n    }\n\n#ifdef  TIMING\n    gettimeofday(&tv_total_start, NULL);\n#endif\n    context = cl_init_context(platform,device,quiet);\n#ifdef  TIMING\n\tgettimeofday(&tv_init_end, NULL);\n\ttvsub(&tv_init_end, &tv_total_start, &tv);\n\tinit_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n    if(size < 1)\n    {\n\tfp = fopen(filename, \"r\");\n\tfscanf(fp, \"%d\", &size);\n\n\ta = (float *) malloc(size * size * sizeof(float));\n\tInitMat(fp,size, a, size, size);\n\n\tb = (float *) malloc(size * sizeof(float));\n\tInitAry(fp, b, size);\n\n\tfclose(fp);\n\n      }\n    else\n      {\n\tprintf(\"create input internally before create, size = %d \\n\", size);\n\n\ta = (float *) malloc(size * size * sizeof(float));\n\tcreate_matrix(a, size);\n\n\tb = (float *) malloc(size * sizeof(float));\n\tfor (int i =0; i< size; i++)\n\t  b[i]=1.0;\n\n      }\n\n    if (!quiet && show_data) {\n      printf(\"The input matrix a is:\\n\");\n      PrintMat(a, size, size, size);\n\n      printf(\"The input array b is:\\n\");\n      PrintAry(b, size);\n    }\n \n    m = (float *) malloc(size * size * sizeof(float));\n\t \n\n    finalVec = (float *) malloc(size * sizeof(float));\n    \n    InitPerRun(size,m);\n\n\tForwardSub(context,a,b,m,size,timing);\n\n    if (!quiet && show_data) {\n        printf(\"The result of matrix m is: \\n\");\n\n        PrintMat(m, size, size, size);\n        printf(\"The result of matrix a is: \\n\");\n        PrintMat(a, size, size, size);\n        printf(\"The result of array b is: \\n\");\n        PrintAry(b, size);\n\n        BackSub(a,b,finalVec,size);\n        printf(\"The final solution is: \\n\");\n        PrintAry(finalVec,size);\n    }\n\n    free(m);\n    free(a);\n    free(b);\n    free(finalVec);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n\n    cl_cleanup();\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\ttvsub(&tv_close_end, &tv_total_start, &tv);\n\ttotal_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n\tprintf(\"Init: %f\\n\", init_time);\n\tprintf(\"MemAlloc: %f\\n\", mem_alloc_time);\n\tprintf(\"HtoD: %f\\n\", h2d_time);\n\tprintf(\"Exec: %f\\n\", kernel_time);\n\tprintf(\"DtoH: %f\\n\", d2h_time);\n\tprintf(\"Close: %f\\n\", close_time);\n\tprintf(\"Total: %f\\n\", total_time);\n#endif\n\n  return 0;\n}\n\nvoid ForwardSub(cl_context context, float *a, float *b, float *m, int size,int timing){    \n    cl_kernel fan1_kernel,fan2_kernel;\n    cl_int status=0;\n    cl_program gaussianElim_program;\n    cl_event writeEvent,kernelEvent,readEvent;\n    float writeMB=0,readMB=0;\n\n    gaussianElim_program = cl_compileProgram(\n        (char *)\"gaussianElim_kernels.cl\",NULL);\n\n    fan1_kernel = clCreateKernel(\n        gaussianElim_program, \"Fan1\", &status);\n    status = cl_errChk(status, (char *)\"Error Creating Fan1 kernel\",true);\n    if(status)exit(1);\n   \n    fan2_kernel = clCreateKernel(\n        gaussianElim_program, \"Fan2\", &status);\n    status = cl_errChk(status, (char *)\"Error Creating Fan2 kernel\",true);\n    if(status)exit(1);\n    \n    cl_mem a_dev, b_dev, m_dev;\n\n    cl_int error=0;\n\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_start, NULL);\n#endif\n    a_dev = clCreateBuffer(context, CL_MEM_READ_WRITE,\n        sizeof(float)*size*size, NULL, &error);\n    b_dev = clCreateBuffer(context, CL_MEM_READ_WRITE,\n        sizeof(float)*size, NULL, &error);\n    m_dev = clCreateBuffer(context, CL_MEM_READ_WRITE,\n        sizeof(float) * size * size, NULL, &error);\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_mem_alloc_start, &tv);\n    mem_alloc_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n    cl_command_queue command_queue = cl_getCommandQueue();\n\n    error = clEnqueueWriteBuffer(command_queue,\n               a_dev,\n               1,\n               0,\n               sizeof(float)*size*size,\n               a,\n               0,\n               NULL,\n               &writeEvent);\n#ifdef TIMING\n    h2d_time += eventTime(writeEvent,command_queue);\n#endif\n    clReleaseEvent(writeEvent);\n\n    error = clEnqueueWriteBuffer(command_queue,\n               b_dev,\n               1,\n               0,\n               sizeof(float)*size,\n               b,\n               0,\n               NULL,\n               &writeEvent);\n#ifdef TIMING\n    h2d_time += eventTime(writeEvent,command_queue);\n#endif\n    clReleaseEvent(writeEvent);\n\n    error = clEnqueueWriteBuffer(command_queue,\n               m_dev,\n               1,\n               0,\n               sizeof(float)*size*size,\n               m,\n               0,\n               NULL,\n               &writeEvent);\n#ifdef TIMING\n    h2d_time += eventTime(writeEvent,command_queue);\n#endif\n    clReleaseEvent(writeEvent);\n\n    writeMB = (float)(sizeof(float) * size * (size + size + 1) / 1e6);\n\n    size_t globalWorksizeFan1[1];\n    size_t globalWorksizeFan2[2];\n    size_t localWorksizeFan1Buf[1]={BLOCK_SIZE_0};\n    size_t localWorksizeFan2Buf[2]={BLOCK_SIZE_1_X, BLOCK_SIZE_1_Y};\n    size_t *localWorksizeFan1=NULL;\n    size_t *localWorksizeFan2=NULL;\n\n        globalWorksizeFan1[0] = size;\n        globalWorksizeFan2[0] = size;\n        globalWorksizeFan2[1] = size;\n\n        if(localWorksizeFan1Buf[0]){\n                localWorksizeFan1=localWorksizeFan1Buf;\n                globalWorksizeFan1[0]=(int)ceil(globalWorksizeFan1[0]/(double)localWorks\\\nizeFan1Buf[0])*localWorksizeFan1Buf[0];\n        }\n        if(localWorksizeFan2Buf[0]){\n                localWorksizeFan2=localWorksizeFan2Buf;\n                globalWorksizeFan2[0]=(int)ceil(globalWorksizeFan2[0]/(double)localWorks\\\nizeFan2Buf[0])*localWorksizeFan2Buf[0];\n                globalWorksizeFan2[1]=(int)ceil(globalWorksizeFan2[1]/(double)localWorks\\\nizeFan2Buf[1])*localWorksizeFan2Buf[1];\n        }\n\n\tint t;\n\tfor (t=0; t<(size-1); t++) {\n        cl_int argchk;\n        argchk  = clSetKernelArg(fan1_kernel, 0, sizeof(cl_mem), (void *)&m_dev);\n        argchk |= clSetKernelArg(fan1_kernel, 1, sizeof(cl_mem), (void *)&a_dev);\n        argchk |= clSetKernelArg(fan1_kernel, 2, sizeof(cl_mem), (void *)&b_dev);\n        argchk |= clSetKernelArg(fan1_kernel, 3, sizeof(int), (void *)&size);\n        argchk |= clSetKernelArg(fan1_kernel, 4, sizeof(int), (void *)&t);\n    \n        cl_errChk(argchk,\"ERROR in Setting Fan1 kernel args\",true);\n\n        error = clEnqueueNDRangeKernel(\n                  command_queue,  fan1_kernel, 1, 0,\n                  globalWorksizeFan1,localWorksizeFan1,\n                  0, NULL, &kernelEvent);\n\n        cl_errChk(error,\"ERROR in Executing Fan1 Kernel\",true);\n#ifdef TIMING\n        kernel_time += eventTime(kernelEvent,command_queue);\n#endif\n        clReleaseEvent(kernelEvent);\n\n\t\targchk  = clSetKernelArg(fan2_kernel, 0, sizeof(cl_mem), (void *)&m_dev);\n        argchk |= clSetKernelArg(fan2_kernel, 1, sizeof(cl_mem), (void *)&a_dev);\n        argchk |= clSetKernelArg(fan2_kernel, 2, sizeof(cl_mem), (void *)&b_dev);\n        argchk |= clSetKernelArg(fan2_kernel, 3, sizeof(int), (void *)&size);\n        argchk |= clSetKernelArg(fan2_kernel, 4, sizeof(int), (void *)&t);\n\n        cl_errChk(argchk,\"ERROR in Setting Fan2 kernel args\",true);\n\n        error = clEnqueueNDRangeKernel(\n                  command_queue,  fan2_kernel, 2, 0,\n                  globalWorksizeFan2,NULL,\n                  0, NULL, &kernelEvent);\n\n        cl_errChk(error,\"ERROR in Executing Fan1 Kernel\",true);\n#ifdef TIMING\n        kernel_time+=eventTime(kernelEvent,command_queue);\n#endif\n        clReleaseEvent(kernelEvent);\n\t}\n\n    error = clEnqueueReadBuffer(command_queue,\n        a_dev,\n        1,\n        0,\n        sizeof(float) * size * size,\n        a,\n        0,\n        NULL,\n        &readEvent);\n\n    cl_errChk(error,\"ERROR with clEnqueueReadBuffer\",true);\n#ifdef TIMING\n    d2h_time +=eventTime(readEvent,command_queue);\n#endif\n    clReleaseEvent(readEvent);\n\n    error = clEnqueueReadBuffer(command_queue,\n        b_dev,\n        1,\n        0,\n        sizeof(float) * size,\n        b,\n        0,\n        NULL,\n        &readEvent);\n    cl_errChk(error,\"ERROR with clEnqueueReadBuffer\",true);\n#ifdef TIMING\n    d2h_time +=eventTime(readEvent,command_queue);\n#endif\n    clReleaseEvent(readEvent);\n\n    error = clEnqueueReadBuffer(command_queue,\n        m_dev,\n        1,\n        0,\n        sizeof(float) * size * size,\n        m,\n        0,\n        NULL,\n        &readEvent);\n\n    cl_errChk(error,\"ERROR with clEnqueueReadBuffer\",true);\n#ifdef TIMING\n    d2h_time +=eventTime(readEvent,command_queue);\n#endif\n    clReleaseEvent(readEvent);\n\n    readMB = (float)(sizeof(float) * size * (size + size + 1) / 1e6);\nclFinish(command_queue);\n\n#ifdef TIMING\n    printf(\"Matrix Size\\tWrite(s) [size]\\t\\tKernel(s)\\tRead(s)  [size]\\t\\tTotal(s)\\n\");\n    printf(\"%dx%d      \\t\",size,size);\n    printf(\"%f [%.2fMB]\\t\",h2d_time,writeMB);\n    printf(\"%f\\t\",kernel_time);\n    printf(\"%f [%.2fMB]\\t\",d2h_time,readMB);\n    printf(\"%f\\n\\n\",h2d_time+kernel_time+d2h_time);\n#endif\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n    clReleaseMemObject(a_dev);\n    clReleaseMemObject(b_dev);\n    clReleaseMemObject(m_dev);\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n}\n\nfloat eventTime(cl_event event,cl_command_queue command_queue){\n    cl_int error=0;\n    cl_ulong eventStart,eventEnd;\n    clFinish(command_queue);\n    error = clGetEventProfilingInfo(event,CL_PROFILING_COMMAND_START,\n                                    sizeof(cl_ulong),&eventStart,NULL);\n    cl_errChk(error,\"ERROR in Event Profiling.\",true); \n    error = clGetEventProfilingInfo(event,CL_PROFILING_COMMAND_END,\n                                    sizeof(cl_ulong),&eventEnd,NULL);\n    cl_errChk(error,\"ERROR in Event Profiling.\",true);\n\n    return (float)((eventEnd-eventStart)/1000000.0);\n}\n\nint parseCommandline(int argc, char *argv[], char* filename,\n                     int *q, int *v, int *t, int *p, int *d, int *size){\n    int i;\n    if (argc < 2) return 1;\n    char flag;\n\n    for(i=1;i<argc;i++) {\n      if (argv[i][0]=='-') {\n        flag = argv[i][1];\n          switch (flag) {\n            case 's':\n              i++;\n              *size = atoi(argv[i]);\n\t      printf(\"Create matrix internally in parse, size = %d \\n\", *size);\n              break;\n            case 'f':\n              i++;\n\t      strncpy(filename,argv[i],100);\n\t      printf(\"Read file from %s \\n\", filename);\n              break;\n            case 'h':\n              return 1;\n              break;\n            case 'q':\n              *q = 1;\n              break;\n\t\t\tcase 'v':\n\t\t\t  *v = 1;\n\t\t\t  break;\n            case 't':\n              *t = 1;\n              break;\n            case 'p':\n              i++;\n              *p = atoi(argv[i]);\n              break;\n            case 'd':\n              i++;\n              *d = atoi(argv[i]);\n              break;\n        }\n      }\n    }\n    if ((*d >= 0 && *p<0) || (*p>=0 && *d<0))\n      return 1;\n    return 0;\n}\n\nvoid printUsage(){\n  printf(\"Gaussian Elimination Usage\\n\");\n  printf(\"\\n\");\n  printf(\"gaussianElimination [filename] [-hqt] [-p [int] -d [int]]\\n\");\n  printf(\"\\n\");\n  printf(\"example:\\n\");\n  printf(\"$ ./gaussianElimination matrix4.txt\\n\");\n  printf(\"\\n\");\n  printf(\"filename     the filename that holds the matrix data\\n\");\n  printf(\"\\n\");\n  printf(\"-h           Display the help file\\n\");\n  printf(\"-q           Quiet mode. Suppress all text output.\\n\");\n  printf(\"-t           Print timing information.\\n\");\n  printf(\"\\n\");\n  printf(\"-p [int]     Choose the platform (must choose both platform and device)\\n\");\n  printf(\"-d [int]     Choose the device (must choose both platform and device)\\n\");\n  printf(\"\\n\");\n  printf(\"\\n\");\n  printf(\"Notes: 1. The filename is required as the first parameter.\\n\");\n  printf(\"       2. If you declare either the device or the platform,\\n\");\n  printf(\"          you must declare both.\\n\\n\");\n}\n\n\nvoid InitPerRun(int size,float *m) \n{\n\tint i;\n\tfor (i=0; i<size*size; i++)\n\t\t\t*(m+i) = 0.0;\n}\nvoid BackSub(float *a, float *b, float *finalVec, int size)\n{\n\tint i,j;\n\tfor(i=0;i<size;i++){\n\t\tfinalVec[size-i-1]=b[size-i-1];\n\t\tfor(j=0;j<i;j++)\n\t\t{\n\t\t\tfinalVec[size-i-1]-=*(a+size*(size-i-1)+(size-j-1)) * finalVec[size-j-1];\n\t\t}\n\t\tfinalVec[size-i-1]=finalVec[size-i-1]/ *(a+size*(size-i-1)+(size-i-1));\n\t}\n}\nvoid InitMat(FILE *fp, int size, float *ary, int nrow, int ncol)\n{\n\tint i, j;\n\t\n\tfor (i=0; i<nrow; i++) {\n\t\tfor (j=0; j<ncol; j++) {\n\t\t\tfscanf(fp, \"%f\",  ary+size*i+j);\n\t\t}\n\t}  \n}\n\nvoid InitAry(FILE *fp, float *ary, int ary_size)\n{\n\tint i;\n\t\n\tfor (i=0; i<ary_size; i++) {\n\t\tfscanf(fp, \"%f\",  &ary[i]);\n\t}\n}  \n\nvoid PrintMat(float *ary, int size, int nrow, int ncol)\n{\n\tint i, j;\n\t\n\tfor (i=0; i<nrow; i++) {\n\t\tfor (j=0; j<ncol; j++) {\n\t\t\tprintf(\"%8.2e \", *(ary+size*i+j));\n\t\t}\n\t\tprintf(\"\\n\");\n\t}\n\tprintf(\"\\n\");\n}\n\nvoid PrintAry(float *ary, int ary_size)\n{\n\tint i;\n\tfor (i=0; i<ary_size; i++) {\n\t\tprintf(\"%.2e \", ary[i]);\n\t}\n\tprintf(\"\\n\\n\");\n}\n#endif\n\n", "gaussianElim_kernels.cl": "//#pragma OPENCL EXTENSION cl_khr_byte_addressable_store : enable\n\ntypedef struct latLong\n    {\n        float lat;\n        float lng;\n    } LatLong;\n\n__kernel void Fan1(__global float *m_dev,\n                  __global float *a_dev,\n                  __global float *b_dev,\n                  const int size,\n                  const int t) {\n    int globalId = get_global_id(0);\n                              \n    if (globalId < size-1-t) {\n         *(m_dev + size * (globalId + t + 1)+t) = *(a_dev + size * (globalId + t + 1) + t) / *(a_dev + size * t + t);    \n    }\n}\n\n\n__kernel void Fan2(__global float *m_dev,\n                  __global float *a_dev,\n                  __global float *b_dev,\n                  const int size,\n                  const int t) {\n\t int globalId = get_global_id(0);\n\t \n\t int globalIdx = get_global_id(0);\n\t int globalIdy = get_global_id(1);\n      if (globalIdx < size-1-t && globalIdy < size-t) {\n         a_dev[size*(globalIdx+1+t)+(globalIdy+t)] -= m_dev[size*(globalIdx+1+t)+t] * a_dev[size*t+(globalIdy+t)];\n \t \n \t    if(globalIdy == 0){\n \t\t   b_dev[globalIdx+1+t] -= m_dev[size*(globalIdx+1+t)+(globalIdy+t)] * b_dev[t];\n \t    }\n \t }\n    \n}\n"}, "code_dirs": {"gaussianElim.cpp": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/gaussian", "gaussianElim_kernels.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/gaussian"}}
{"kernel_name": "hotspot", "parallel_api": "cuda", "code": {"hotspot.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#ifdef RD_WG_SIZE_0_0                                                            \n        #define BLOCK_SIZE RD_WG_SIZE_0_0                                        \n#elif defined(RD_WG_SIZE_0)                                                      \n        #define BLOCK_SIZE RD_WG_SIZE_0                                          \n#elif defined(RD_WG_SIZE)                                                        \n        #define BLOCK_SIZE RD_WG_SIZE                                            \n#else                                                                                    \n        #define BLOCK_SIZE 16                                                            \n#endif                                                                                   \n\n#define STR_SIZE 256\n\n#define MAX_PD\t(3.0e6)\n#define PRECISION\t0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP\t0.5\n\nfloat t_chip = 0.0005;\nfloat chip_height = 0.016;\nfloat chip_width = 0.016;\nfloat amb_temp = 80.0;\n\nvoid run(int argc, char** argv);\n\n#define pin_stats_reset()   startCycle()\n#define pin_stats_pause(cycles)   stopCycle(cycles)\n#define pin_stats_dump(cycles)    printf(\"timer: %Lu\\n\", cycles)\n\n\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \"error: %s\\n\", s);\n\n}\n\nvoid writeoutput(float *vect, int grid_rows, int grid_cols, char *file){\n\n\tint i,j, index=0;\n\tFILE *fp;\n\tchar str[STR_SIZE];\n\n\tif( (fp = fopen(file, \"w\" )) == 0 )\n          printf( \"The file was not opened\\n\" );\n\n\n\tfor (i=0; i < grid_rows; i++) \n\t for (j=0; j < grid_cols; j++)\n\t {\n\n\t\t sprintf(str, \"%d\\t%g\\n\", index, vect[i*grid_cols+j]);\n\t\t fputs(str,fp);\n\t\t index++;\n\t }\n\t\t\n      fclose(fp);\t\n}\n\n\nvoid readinput(float *vect, int grid_rows, int grid_cols, char *file){\n\n  \tint i,j;\n\tFILE *fp;\n\tchar str[STR_SIZE];\n\tfloat val;\n\n\tif( (fp  = fopen(file, \"r\" )) ==0 )\n            printf( \"The file was not opened\\n\" );\n\n\n\tfor (i=0; i <= grid_rows-1; i++) \n\t for (j=0; j <= grid_cols-1; j++)\n\t {\n\t\tfgets(str, STR_SIZE, fp);\n\t\tif (feof(fp))\n\t\t\tfatal(\"not enough lines in file\");\n\t\t//if ((sscanf(str, \"%d%f\", &index, &val) != 2) || (index != ((i-1)*(grid_cols-2)+j-1)))\n\t\tif ((sscanf(str, \"%f\", &val) != 1))\n\t\t\tfatal(\"invalid file format\");\n\t\tvect[i*grid_cols+j] = val;\n\t}\n\n\tfclose(fp);\t\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\n__global__ void calculate_temp(int iteration,  //number of iteration\n                               float *power,   //power input\n                               float *temp_src,    //temperature input/output\n                               float *temp_dst,    //temperature input/output\n                               int grid_cols,  //Col of grid\n                               int grid_rows,  //Row of grid\n\t\t\t\t\t\t\t   int border_cols,  // border offset \n\t\t\t\t\t\t\t   int border_rows,  // border offset\n                               float Cap,      //Capacitance\n                               float Rx, \n                               float Ry, \n                               float Rz, \n                               float step, \n                               float time_elapsed){\n\t\n        __shared__ float temp_on_cuda[BLOCK_SIZE][BLOCK_SIZE];\n        __shared__ float power_on_cuda[BLOCK_SIZE][BLOCK_SIZE];\n        __shared__ float temp_t[BLOCK_SIZE][BLOCK_SIZE]; // saving temparary temperature result\n\n\tfloat amb_temp = 80.0;\n        float step_div_Cap;\n        float Rx_1,Ry_1,Rz_1;\n        \n\tint bx = blockIdx.x;\n        int by = blockIdx.y;\n\n\tint tx=threadIdx.x;\n\tint ty=threadIdx.y;\n\t\n\tstep_div_Cap=step/Cap;\n\t\n\tRx_1=1/Rx;\n\tRy_1=1/Ry;\n\tRz_1=1/Rz;\n\t\n\tint small_block_rows = BLOCK_SIZE-iteration*2;//EXPAND_RATE\n\tint small_block_cols = BLOCK_SIZE-iteration*2;//EXPAND_RATE\n\n        int blkY = small_block_rows*by-border_rows;\n        int blkX = small_block_cols*bx-border_cols;\n        int blkYmax = blkY+BLOCK_SIZE-1;\n        int blkXmax = blkX+BLOCK_SIZE-1;\n\n\tint yidx = blkY+ty;\n\tint xidx = blkX+tx;\n\n\tint loadYidx=yidx, loadXidx=xidx;\n        int index = grid_cols*loadYidx+loadXidx;\n       \n\tif(IN_RANGE(loadYidx, 0, grid_rows-1) && IN_RANGE(loadXidx, 0, grid_cols-1)){\n            temp_on_cuda[ty][tx] = temp_src[index];  // Load the temperature data from global memory to shared memory\n            power_on_cuda[ty][tx] = power[index];// Load the power data from global memory to shared memory\n\t}\n\t__syncthreads();\n\n        int validYmin = (blkY < 0) ? -blkY : 0;\n        int validYmax = (blkYmax > grid_rows-1) ? BLOCK_SIZE-1-(blkYmax-grid_rows+1) : BLOCK_SIZE-1;\n        int validXmin = (blkX < 0) ? -blkX : 0;\n        int validXmax = (blkXmax > grid_cols-1) ? BLOCK_SIZE-1-(blkXmax-grid_cols+1) : BLOCK_SIZE-1;\n\n        int N = ty-1;\n        int S = ty+1;\n        int W = tx-1;\n        int E = tx+1;\n        \n        N = (N < validYmin) ? validYmin : N;\n        S = (S > validYmax) ? validYmax : S;\n        W = (W < validXmin) ? validXmin : W;\n        E = (E > validXmax) ? validXmax : E;\n\n        bool computed;\n        for (int i=0; i<iteration ; i++){ \n            computed = false;\n            if( IN_RANGE(tx, i+1, BLOCK_SIZE-i-2) &&  \\\n                  IN_RANGE(ty, i+1, BLOCK_SIZE-i-2) &&  \\\n                  IN_RANGE(tx, validXmin, validXmax) && \\\n                  IN_RANGE(ty, validYmin, validYmax) ) {\n                  computed = true;\n                  temp_t[ty][tx] =   temp_on_cuda[ty][tx] + step_div_Cap * (power_on_cuda[ty][tx] + \n\t       \t         (temp_on_cuda[S][tx] + temp_on_cuda[N][tx] - 2.0*temp_on_cuda[ty][tx]) * Ry_1 + \n\t\t             (temp_on_cuda[ty][E] + temp_on_cuda[ty][W] - 2.0*temp_on_cuda[ty][tx]) * Rx_1 + \n\t\t             (amb_temp - temp_on_cuda[ty][tx]) * Rz_1);\n\t\n            }\n            __syncthreads();\n            if(i==iteration-1)\n                break;\n            if(computed)\t //Assign the computation range\n                temp_on_cuda[ty][tx]= temp_t[ty][tx];\n            __syncthreads();\n          }\n\n      if (computed){\n          temp_dst[index]= temp_t[ty][tx];\t\t\n      }\n}\n\nint compute_tran_temp(float *MatrixPower,float *MatrixTemp[2], int col, int row, \\\n\t\tint total_iterations, int num_iterations, int blockCols, int blockRows, int borderCols, int borderRows) \n{\n        dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n        dim3 dimGrid(blockCols, blockRows);  \n\t\n\tfloat grid_height = chip_height / row;\n\tfloat grid_width = chip_width / col;\n\n\tfloat Cap = FACTOR_CHIP * SPEC_HEAT_SI * t_chip * grid_width * grid_height;\n\tfloat Rx = grid_width / (2.0 * K_SI * t_chip * grid_height);\n\tfloat Ry = grid_height / (2.0 * K_SI * t_chip * grid_width);\n\tfloat Rz = t_chip / (K_SI * grid_height * grid_width);\n\n\tfloat max_slope = MAX_PD / (FACTOR_CHIP * t_chip * SPEC_HEAT_SI);\n\tfloat step = PRECISION / max_slope;\n\tfloat t;\n        float time_elapsed;\n\ttime_elapsed=0.001;\n\n        int src = 1, dst = 0;\n\t\n\tfor (t = 0; t < total_iterations; t+=num_iterations) {\n            int temp = src;\n            src = dst;\n            dst = temp;\n            calculate_temp<<<dimGrid, dimBlock>>>(MIN(num_iterations, total_iterations-t), MatrixPower,MatrixTemp[src],MatrixTemp[dst],\\\n\t\tcol,row,borderCols, borderRows, Cap,Rx,Ry,Rz,step,time_elapsed);\n\t}\n        return dst;\n}\n\nvoid usage(int argc, char **argv)\n{\n\tfprintf(stderr, \"Usage: %s <grid_rows/grid_cols> <pyramid_height> <sim_time> <temp_file> <power_file> <output_file>\\n\", argv[0]);\n\tfprintf(stderr, \"\\t<grid_rows/grid_cols>  - number of rows/cols in the grid (positive integer)\\n\");\n\tfprintf(stderr, \"\\t<pyramid_height> - pyramid heigh(positive integer)\\n\");\n\tfprintf(stderr, \"\\t<sim_time>   - number of iterations\\n\");\n\tfprintf(stderr, \"\\t<temp_file>  - name of the file containing the initial temperature values of each cell\\n\");\n\tfprintf(stderr, \"\\t<power_file> - name of the file containing the dissipated power values of each cell\\n\");\n\tfprintf(stderr, \"\\t<output_file> - name of the output file\\n\");\n\texit(1);\n}\n\nint main(int argc, char** argv)\n{\n  printf(\"WG size of kernel = %d X %d\\n\", BLOCK_SIZE, BLOCK_SIZE);\n\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    int size;\n    int grid_rows,grid_cols;\n    float *FilesavingTemp,*FilesavingPower,*MatrixOut; \n    char *tfile, *pfile, *ofile;\n    \n    int total_iterations = 60;\n    int pyramid_height = 1; // number of iterations\n\t\n\tif (argc != 7)\n\t\tusage(argc, argv);\n\tif((grid_rows = atoi(argv[1]))<=0||\n\t   (grid_cols = atoi(argv[1]))<=0||\n       (pyramid_height = atoi(argv[2]))<=0||\n       (total_iterations = atoi(argv[3]))<=0)\n\t\tusage(argc, argv);\n\t\t\n\ttfile=argv[4];\n    pfile=argv[5];\n    ofile=argv[6];\n\t\n    size=grid_rows*grid_cols;\n\n    # define EXPAND_RATE 2\n    int borderCols = (pyramid_height)*EXPAND_RATE/2;\n    int borderRows = (pyramid_height)*EXPAND_RATE/2;\n    int smallBlockCol = BLOCK_SIZE-(pyramid_height)*EXPAND_RATE;\n    int smallBlockRow = BLOCK_SIZE-(pyramid_height)*EXPAND_RATE;\n    int blockCols = grid_cols/smallBlockCol+((grid_cols%smallBlockCol==0)?0:1);\n    int blockRows = grid_rows/smallBlockRow+((grid_rows%smallBlockRow==0)?0:1);\n\n    FilesavingTemp = (float *) malloc(size*sizeof(float));\n    FilesavingPower = (float *) malloc(size*sizeof(float));\n    MatrixOut = (float *) calloc (size, sizeof(float));\n\n    if( !FilesavingPower || !FilesavingTemp || !MatrixOut)\n        fatal(\"unable to allocate memory\");\n\n    printf(\"pyramidHeight: %d\\ngridSize: [%d, %d]\\nborder:[%d, %d]\\nblockGrid:[%d, %d]\\ntargetBlock:[%d, %d]\\n\",\\\n\tpyramid_height, grid_cols, grid_rows, borderCols, borderRows, blockCols, blockRows, smallBlockCol, smallBlockRow);\n\t\n    readinput(FilesavingTemp, grid_rows, grid_cols, tfile);\n    readinput(FilesavingPower, grid_rows, grid_cols, pfile);\n\n    float *MatrixTemp[2], *MatrixPower;\n    cudaMalloc((void**)&MatrixTemp[0], sizeof(float)*size);\n    cudaMalloc((void**)&MatrixTemp[1], sizeof(float)*size);\n    cudaMemcpy(MatrixTemp[0], FilesavingTemp, sizeof(float)*size, cudaMemcpyHostToDevice);\n\n    cudaMalloc((void**)&MatrixPower, sizeof(float)*size);\n    cudaMemcpy(MatrixPower, FilesavingPower, sizeof(float)*size, cudaMemcpyHostToDevice);\n    printf(\"Start computing the transient temperature\\n\");\n    int ret = compute_tran_temp(MatrixPower,MatrixTemp,grid_cols,grid_rows, \\\n\t total_iterations,pyramid_height, blockCols, blockRows, borderCols, borderRows);\n\tprintf(\"Ending simulation\\n\");\n    cudaMemcpy(MatrixOut, MatrixTemp[ret], sizeof(float)*size, cudaMemcpyDeviceToHost);\n\n    writeoutput(MatrixOut,grid_rows, grid_cols, ofile);\n\n    cudaFree(MatrixPower);\n    cudaFree(MatrixTemp[0]);\n    cudaFree(MatrixTemp[1]);\n    free(MatrixOut);\n}\n"}, "code_dirs": {"hotspot.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/hotspot"}}
{"kernel_name": "hotspot", "parallel_api": "ocl", "code": {"hotspot.c": "#include \"hotspot.h\"\n\n#ifdef TIMING\n#include \"timing.h\"\n\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_init_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nvoid writeoutput(float *vect, int grid_rows, int grid_cols, char *file) {\n\n\tint i,j, index=0;\n\tFILE *fp;\n\tchar str[STR_SIZE];\n\n\tif( (fp = fopen(file, \"w\" )) == 0 )\n          printf( \"The file was not opened\\n\" );\n\n\n\tfor (i=0; i < grid_rows; i++) \n\t for (j=0; j < grid_cols; j++)\n\t {\n\n\t\t sprintf(str, \"%d\\t%g\\n\", index, vect[i*grid_cols+j]);\n\t\t fputs(str,fp);\n\t\t index++;\n\t }\n\t\t\n      fclose(fp);\t\n}\n\n\nvoid readinput(float *vect, int grid_rows, int grid_cols, char *file) {\n\n  \tint i,j;\n\tFILE *fp;\n\tchar str[STR_SIZE];\n\tfloat val;\n\n\tif( (fp  = fopen(file, \"r\" )) ==0 )\n            fatal( \"The file was not opened\" );\n\n\n\tfor (i=0; i <= grid_rows-1; i++) \n\t for (j=0; j <= grid_cols-1; j++)\n\t {\n\t\tif (fgets(str, STR_SIZE, fp) == NULL) fatal(\"Error reading file\\n\");\n\t\tif (feof(fp))\n\t\t\tfatal(\"not enough lines in file\");\n\t\tif ((sscanf(str, \"%f\", &val) != 1))\n\t\t\tfatal(\"invalid file format\");\n\t\tvect[i*grid_cols+j] = val;\n\t}\n\n\tfclose(fp);\t\n\n}\n\n\nint compute_tran_temp(cl_mem MatrixPower, cl_mem MatrixTemp[2], int col, int row, \\\n\t\tint total_iterations, int num_iterations, int blockCols, int blockRows, int borderCols, int borderRows,\n\t\tfloat *TempCPU, float *PowerCPU) \n{ \n\t\n\tfloat grid_height = chip_height / row;\n\tfloat grid_width = chip_width / col;\n\n\tfloat Cap = FACTOR_CHIP * SPEC_HEAT_SI * t_chip * grid_width * grid_height;\n\tfloat Rx = grid_width / (2.0 * K_SI * t_chip * grid_height);\n\tfloat Ry = grid_height / (2.0 * K_SI * t_chip * grid_width);\n\tfloat Rz = t_chip / (K_SI * grid_height * grid_width);\n\n\tfloat max_slope = MAX_PD / (FACTOR_CHIP * t_chip * SPEC_HEAT_SI);\n\tfloat step = PRECISION / max_slope;\n\tint t, itr;\n\n\tint src = 0, dst = 1;\n\t\n\tcl_int error;\n\tcl_event events[total_iterations/num_iterations + 1];\n\t\n\tsize_t global_work_size[2];\n\tglobal_work_size[0] = BLOCK_SIZE * blockCols;\n\tglobal_work_size[1] = BLOCK_SIZE * blockRows;\n\tsize_t local_work_size[2];\n\tlocal_work_size[0] = BLOCK_SIZE;\n\tlocal_work_size[1] = BLOCK_SIZE;\n\t\n\tfor (t = 0, itr = 0; t < total_iterations; t += num_iterations, itr++) {\n\t\t\n\t\tint iter = MIN(num_iterations, total_iterations - t);\n\t\tclSetKernelArg(kernel, 0, sizeof(int), (void *) &iter);\n\t\tclSetKernelArg(kernel, 1, sizeof(cl_mem), (void *) &MatrixPower);\n\t\tclSetKernelArg(kernel, 2, sizeof(cl_mem), (void *) &MatrixTemp[src]);\n\t\tclSetKernelArg(kernel, 3, sizeof(cl_mem), (void *) &MatrixTemp[dst]);\n\t\tclSetKernelArg(kernel, 4, sizeof(int), (void *) &col);\n\t\tclSetKernelArg(kernel, 5, sizeof(int), (void *) &row);\n\t\tclSetKernelArg(kernel, 6, sizeof(int), (void *) &borderCols);\n\t\tclSetKernelArg(kernel, 7, sizeof(int), (void *) &borderRows);\n\t\tclSetKernelArg(kernel, 8, sizeof(float), (void *) &Cap);\n\t\tclSetKernelArg(kernel, 9, sizeof(float), (void *) &Rx);\n\t\tclSetKernelArg(kernel, 10, sizeof(float), (void *) &Ry);\n\t\tclSetKernelArg(kernel, 11, sizeof(float), (void *) &Rz);\n\t\tclSetKernelArg(kernel, 12, sizeof(float), (void *) &step);\n\n\t\terror = clEnqueueNDRangeKernel(command_queue, kernel, 2, NULL, global_work_size, local_work_size, 0, NULL, &events[itr]);\n\t\tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\n\t\terror = clFlush(command_queue);\n\t\tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\n\t\tsrc = 1 - src;\n\t\tdst = 1 - dst;\n\t}\n\n\tfor (t = 0, itr = 0; t < total_iterations; t += num_iterations, itr++) {\n#ifdef TIMING\n\t    kernel_time += probe_event_time(events[itr], command_queue);\n#endif\n\t    clReleaseEvent(events[itr]);\n\t}\n\n\treturn src;\n}\n\nvoid usage(int argc, char **argv) {\n\tfprintf(stderr, \"Usage: %s <grid_rows/grid_cols> <pyramid_height> <sim_time> <temp_file> <power_file> <output_file> [-p platform_id] [-d device_id]\\n\", argv[0]);\n\tfprintf(stderr, \"\\t<grid_rows/grid_cols>  - number of rows/cols in the grid (positive integer)\\n\");\n\tfprintf(stderr, \"\\t<pyramid_height> - pyramid heigh(positive integer)\\n\");\n\tfprintf(stderr, \"\\t<sim_time>   - number of iterations\\n\");\n\tfprintf(stderr, \"\\t<temp_file>  - name of the file containing the initial temperature values of each cell\\n\");\n\tfprintf(stderr, \"\\t<power_file> - name of the file containing the dissipated power values of each cell\\n\");\n\tfprintf(stderr, \"\\t<output_file> - name of the output file\\n\");\n\texit(1);\n}\n\nint main(int argc, char** argv) {\n\n    printf(\"WG size of kernel = %d X %d\\n\", BLOCK_SIZE, BLOCK_SIZE);\n\n    int size;\n    int grid_rows,grid_cols = 0;\n    float *FilesavingTemp,*FilesavingPower;\n    char *tfile, *pfile, *ofile;\n\n    int total_iterations = 60;\n    int pyramid_height = 1;\n\n\tif (argc < 7)\n\t\tusage(argc, argv);\n\tif((grid_rows = atoi(argv[1]))<=0||\n\t   (grid_cols = atoi(argv[1]))<=0||\n       (pyramid_height = atoi(argv[2]))<=0||\n       (total_iterations = atoi(argv[3]))<=0)\n\t\tusage(argc, argv);\n\n\ttfile=argv[4];\n    pfile=argv[5];\n    ofile=argv[6];\n    size=grid_rows*grid_cols;\n\n    int platform_id_inuse = 0;\n    int device_id_inuse = 0;\n    cl_device_type device_type = CL_DEVICE_TYPE_GPU;\n\n    int cur_arg;\n\tfor (cur_arg = 1; cur_arg<argc; cur_arg++) {\n        if (strcmp(argv[cur_arg], \"-h\") == 0) \n\t\t    usage(argc, argv);\n        else if (strcmp(argv[cur_arg], \"-p\") == 0) {\n            if (argc >= cur_arg + 1) {\n                platform_id_inuse = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n        else if (strcmp(argv[cur_arg], \"-d\") == 0) {\n            if (argc >= cur_arg + 1) {\n                device_id_inuse = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n    }\n\n    int borderCols = (pyramid_height)*EXPAND_RATE/2;\n    int borderRows = (pyramid_height)*EXPAND_RATE/2;\n    int smallBlockCol = BLOCK_SIZE-(pyramid_height)*EXPAND_RATE;\n    int smallBlockRow = BLOCK_SIZE-(pyramid_height)*EXPAND_RATE;\n    int blockCols = grid_cols/smallBlockCol+((grid_cols%smallBlockCol==0)?0:1);\n    int blockRows = grid_rows/smallBlockRow+((grid_rows%smallBlockRow==0)?0:1);\n\n    FilesavingTemp = (float *) malloc(size*sizeof(float));\n    FilesavingPower = (float *) malloc(size*sizeof(float));\n\n    if( !FilesavingPower || !FilesavingTemp)\n        fatal(\"unable to allocate memory\");\n\n    readinput(FilesavingTemp, grid_rows, grid_cols, tfile);\n    readinput(FilesavingPower, grid_rows, grid_cols, pfile);\n\n#ifdef  TIMING\n    gettimeofday(&tv_total_start, NULL);\n#endif\n\n\tcl_int error;\n\tcl_uint num_platforms;\n\t\n\terror = clGetPlatformIDs(0, NULL, &num_platforms);\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\t\n\tcl_platform_id* platforms = (cl_platform_id *) malloc(sizeof(cl_platform_id) * num_platforms);\n\terror = clGetPlatformIDs(num_platforms, platforms, NULL);\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\t\n\tcl_platform_id platform = platforms[platform_id_inuse];\n\tchar pbuf[100];\n\terror = clGetPlatformInfo(platform, CL_PLATFORM_VENDOR, sizeof(pbuf), pbuf, NULL);\n\tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\tprintf(\"Platform: %s\\n\", pbuf);\n\n\tcl_uint devices_size;\n\terror = clGetDeviceIDs(platform, CL_DEVICE_TYPE_ALL, 0, NULL, &devices_size);\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\tprintf(\"num_devices = %d\\n\", devices_size);\n    if (device_id_inuse > devices_size) {\n        printf(\"Invalid Device Number\\n\");\n    \tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n    }\n\tcl_device_id *devices = (cl_device_id *)malloc(sizeof(cl_device_id)*devices_size);\n    error = clGetDeviceIDs(platform, CL_DEVICE_TYPE_ALL, devices_size, devices, NULL);\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\n\tdevice = devices[device_id_inuse];\n\terror = clGetDeviceInfo(device, CL_DEVICE_NAME, sizeof(pbuf), pbuf, NULL);\n\tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\tprintf(\"Device: %s\\n\", pbuf);\n\n\terror = clGetDeviceInfo(device, CL_DEVICE_TYPE, sizeof(device_type), (void *)&device_type, NULL);\n\tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\tif (device_type == CL_DEVICE_TYPE_GPU)\n        printf(\"Use GPU device\\n\");\n    else if (device_type == CL_DEVICE_TYPE_CPU)\n        printf(\"Use CPU device\\n\");\n\n\tcl_context_properties context_properties[3] = { CL_CONTEXT_PLATFORM, (cl_context_properties) platform, 0};\n    context = clCreateContextFromType(context_properties, device_type, NULL, NULL, &error);\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\n#ifdef TIMING\n\tcommand_queue = clCreateCommandQueue(context, device, CL_QUEUE_PROFILING_ENABLE, &error);\n#else\n\tcommand_queue = clCreateCommandQueue(context, device, 0, &error);\n#endif\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\n\tconst char *source = load_kernel_source(\"hotspot_kernel.cl\");\n\tsize_t sourceSize = strlen(source);\n\n    cl_program program = clCreateProgramWithSource(context, 1, &source, &sourceSize, &error);\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\t\n\tchar clOptions[110];\n\tsprintf(clOptions,\" \");\n#ifdef BLOCK_SIZE\n\tsprintf(clOptions + strlen(clOptions), \" -DBLOCK_SIZE=%d\", BLOCK_SIZE);\n#endif\n\n\terror = clBuildProgram(program, 1, &device, clOptions, NULL, NULL);\n\tstatic char log[65536]; memset(log, 0, sizeof(log));\n\tclGetProgramBuildInfo(program, device, CL_PROGRAM_BUILD_LOG, sizeof(log)-1, log, NULL);\n\tif (strstr(log,\"warning:\") || strstr(log, \"error:\")) printf(\"<<<<\\n%s\\n>>>>\\n\", log);\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n    kernel = clCreateKernel(program, \"hotspot\", &error);\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\n\tcl_mem MatrixTemp[2];\n\n#ifdef  TIMING\n\tgettimeofday(&tv_init_end, NULL);\n\ttvsub(&tv_init_end, &tv_total_start, &tv);\n\tinit_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n    MatrixTemp[1] = clCreateBuffer(context, CL_MEM_READ_WRITE , sizeof(float) * size, NULL, &error);\n    if (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_init_end, &tv);\n    mem_alloc_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tMatrixTemp[0] = clCreateBuffer(context, CL_MEM_READ_WRITE | CL_MEM_USE_HOST_PTR, sizeof(float) * size, FilesavingTemp, &error);\n\tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\tcl_mem MatrixPower = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_USE_HOST_PTR, sizeof(float) * size, FilesavingPower, &error);\n\tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\n#ifdef  TIMING\n    gettimeofday(&tv_h2d_end, NULL);\n    tvsub(&tv_h2d_end, &tv_mem_alloc_end, &tv);\n    h2d_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tint ret = compute_tran_temp(MatrixPower, MatrixTemp, grid_cols, grid_rows, total_iterations, pyramid_height,\n\t\t\t\t\t\t\t\tblockCols, blockRows, borderCols, borderRows, FilesavingTemp, FilesavingPower);\n\t\n\tcl_event event;\n\tcl_float *MatrixOut = (cl_float *) clEnqueueMapBuffer(command_queue, MatrixTemp[ret], CL_TRUE, CL_MAP_READ, 0, sizeof(float) * size, 0, NULL, &event, &error);\n\tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n#ifdef TIMING\n    d2h_time += probe_event_time(event, command_queue);\n#endif\n    clReleaseEvent(event);\n\n    writeoutput(MatrixOut, grid_rows, grid_cols, ofile);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n\terror = clEnqueueUnmapMemObject(command_queue, MatrixTemp[ret], (void *) MatrixOut, 0, NULL, NULL);\n\tif (error != CL_SUCCESS) fatal_CL(error, __LINE__);\n\n\tclReleaseMemObject(MatrixTemp[0]);\n\tclReleaseMemObject(MatrixTemp[1]);\n\tclReleaseMemObject(MatrixPower);\n\n    clReleaseContext(context);\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\ttvsub(&tv_close_end, &tv_total_start, &tv);\n\ttotal_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n\tprintf(\"Init: %f\\n\", init_time);\n\tprintf(\"MemAlloc: %f\\n\", mem_alloc_time);\n\tprintf(\"HtoD: %f\\n\", h2d_time);\n\tprintf(\"Exec: %f\\n\", kernel_time);\n\tprintf(\"DtoH: %f\\n\", d2h_time);\n\tprintf(\"Close: %f\\n\", close_time);\n\tprintf(\"Total: %f\\n\", total_time);\n#endif\n\n\treturn 0;\n}\n", "hotspot_kernel.cl": "#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n\n__kernel void hotspot(  int iteration,  //number of iteration\n                               global float *power,   //power input\n                               global float *temp_src,    //temperature input/output\n                               global float *temp_dst,    //temperature input/output\n                               int grid_cols,  //Col of grid\n                               int grid_rows,  //Row of grid\n\t\t\t\t\t\t\t   int border_cols,  // border offset \n\t\t\t\t\t\t\t   int border_rows,  // border offset\n                               float Cap,      //Capacitance\n                               float Rx, \n                               float Ry, \n                               float Rz, \n                               float step) {\n\t\n\tlocal float temp_on_cuda[BLOCK_SIZE][BLOCK_SIZE];\n\tlocal float power_on_cuda[BLOCK_SIZE][BLOCK_SIZE];\n\tlocal float temp_t[BLOCK_SIZE][BLOCK_SIZE]; // saving temporary temperature result\n\n\tfloat amb_temp = 80.0f;\n\tfloat step_div_Cap;\n\tfloat Rx_1,Ry_1,Rz_1;\n\n\tint bx = get_group_id(0);\n\tint by = get_group_id(1);\n\n\tint tx = get_local_id(0);\n\tint ty = get_local_id(1);\n\n\tstep_div_Cap=step/Cap;\n\n\tRx_1=1/Rx;\n\tRy_1=1/Ry;\n\tRz_1=1/Rz;\n\n\tint small_block_rows = BLOCK_SIZE-iteration*2;//EXPAND_RATE\n\tint small_block_cols = BLOCK_SIZE-iteration*2;//EXPAND_RATE\n\n\tint blkY = small_block_rows*by-border_rows;\n\tint blkX = small_block_cols*bx-border_cols;\n\tint blkYmax = blkY+BLOCK_SIZE-1;\n\tint blkXmax = blkX+BLOCK_SIZE-1;\n\n\tint yidx = blkY+ty;\n\tint xidx = blkX+tx;\n\n\tint loadYidx=yidx, loadXidx=xidx;\n\tint index = grid_cols*loadYidx+loadXidx;\n       \n\tif(IN_RANGE(loadYidx, 0, grid_rows-1) && IN_RANGE(loadXidx, 0, grid_cols-1)){\n            temp_on_cuda[ty][tx] = temp_src[index];  // Load the temperature data from global memory to shared memory\n            power_on_cuda[ty][tx] = power[index];// Load the power data from global memory to shared memory\n\t}\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\tint validYmin = (blkY < 0) ? -blkY : 0;\n\tint validYmax = (blkYmax > grid_rows-1) ? BLOCK_SIZE-1-(blkYmax-grid_rows+1) : BLOCK_SIZE-1;\n\tint validXmin = (blkX < 0) ? -blkX : 0;\n\tint validXmax = (blkXmax > grid_cols-1) ? BLOCK_SIZE-1-(blkXmax-grid_cols+1) : BLOCK_SIZE-1;\n\n\tint N = ty-1;\n\tint S = ty+1;\n\tint W = tx-1;\n\tint E = tx+1;\n\n\tN = (N < validYmin) ? validYmin : N;\n\tS = (S > validYmax) ? validYmax : S;\n\tW = (W < validXmin) ? validXmin : W;\n\tE = (E > validXmax) ? validXmax : E;\n\n\tbool computed;\n\tfor (int i=0; i<iteration ; i++){ \n\t\tcomputed = false;\n\t\tif( IN_RANGE(tx, i+1, BLOCK_SIZE-i-2) &&  \\\n\t\tIN_RANGE(ty, i+1, BLOCK_SIZE-i-2) &&  \\\n\t\tIN_RANGE(tx, validXmin, validXmax) && \\\n\t\tIN_RANGE(ty, validYmin, validYmax) ) {\n\t\t\tcomputed = true;\n\t\t\ttemp_t[ty][tx] =   temp_on_cuda[ty][tx] + step_div_Cap * (power_on_cuda[ty][tx] + \n\t\t\t(temp_on_cuda[S][tx] + temp_on_cuda[N][tx] - 2.0f * temp_on_cuda[ty][tx]) * Ry_1 + \n\t\t\t(temp_on_cuda[ty][E] + temp_on_cuda[ty][W] - 2.0f * temp_on_cuda[ty][tx]) * Rx_1 + \n\t\t\t(amb_temp - temp_on_cuda[ty][tx]) * Rz_1);\n\n\t\t}\n\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n\t\t\n\t\tif(i==iteration-1)\n\t\t\tbreak;\n\t\tif(computed)\t //Assign the computation range\n\t\t\ttemp_on_cuda[ty][tx]= temp_t[ty][tx];\n\t\t\t\n\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n\t}\n\n\tif (computed){\n\t  temp_dst[index]= temp_t[ty][tx];\t\t\n\t}\n}\n"}, "code_dirs": {"hotspot.c": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/hotspot", "hotspot_kernel.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/hotspot"}}
{"kernel_name": "kmeans", "parallel_api": "cuda", "code": {"kmeans_cuda.cu": "#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include <assert.h>\n\n#include <omp.h>\n\n#include <cuda.h>\n\n#define THREADS_PER_DIM 16\n#define BLOCKS_PER_DIM 16\n#define THREADS_PER_BLOCK THREADS_PER_DIM*THREADS_PER_DIM\n\n#include \"kmeans_cuda_kernel.cu\"\n\n\n#define CPU_DELTA_REDUCE\n#define CPU_CENTER_REDUCE\n\nextern \"C\"\nint setup(int argc, char** argv);\t\t\t\t\t\t\t\t\t/* function prototype */\n\nunsigned int num_threads_perdim = THREADS_PER_DIM;\t\t\t\t\t/* sqrt(256) -- see references for this choice */\nunsigned int num_blocks_perdim = BLOCKS_PER_DIM;\t\t\t\t\t/* temporary */\nunsigned int num_threads = num_threads_perdim*num_threads_perdim;\t/* number of threads */\nunsigned int num_blocks = num_blocks_perdim*num_blocks_perdim;\t\t/* number of blocks */\n\nint    *membership_new;\t\t\t\t\t\t\t\t\t\t\t\t/* newly assignment membership */\nfloat  *feature_d;\t\t\t\t\t\t\t\t\t\t\t\t\t/* inverted data array */\nfloat  *feature_flipped_d;\t\t\t\t\t\t\t\t\t\t\t/* original (not inverted) data array */\nint    *membership_d;\t\t\t\t\t\t\t\t\t\t\t\t/* membership on the device */\nfloat  *block_new_centers;\t\t\t\t\t\t\t\t\t\t\t/* sum of points in a cluster (per block) */\nfloat  *clusters_d;\t\t\t\t\t\t\t\t\t\t\t\t\t/* cluster centers on the device */\nfloat  *block_clusters_d;\t\t\t\t\t\t\t\t\t\t\t/* per block calculation of cluster centers */\nint    *block_deltas_d;\t\t\t\t\t\t\t\t\t\t\t\t/* per block calculation of deltas */\n\n\nextern \"C\"\nvoid allocateMemory(int npoints, int nfeatures, int nclusters, float **features)\n{\t\n\tnum_blocks = npoints / num_threads;\n\tif (npoints % num_threads > 0)\n\t\tnum_blocks++;\n\n\tnum_blocks_perdim = sqrt((double) num_blocks);\n\twhile (num_blocks_perdim * num_blocks_perdim < num_blocks)\n\t\tnum_blocks_perdim++;\n\n\tnum_blocks = num_blocks_perdim*num_blocks_perdim;\n\n\tmembership_new = (int*) malloc(npoints * sizeof(int));\n\tfor(int i=0;i<npoints;i++) {\n\t\tmembership_new[i] = -1;\n\t}\n\n\tblock_new_centers = (float *) malloc(nclusters*nfeatures*sizeof(float));\n\t\n\tcudaMalloc((void**) &feature_flipped_d, npoints*nfeatures*sizeof(float));\n\tcudaMemcpy(feature_flipped_d, features[0], npoints*nfeatures*sizeof(float), cudaMemcpyHostToDevice);\n\tcudaMalloc((void**) &feature_d, npoints*nfeatures*sizeof(float));\n\t\t\n\tinvert_mapping<<<num_blocks,num_threads>>>(feature_flipped_d,feature_d,npoints,nfeatures);\n\t\t\n\tcudaMalloc((void**) &membership_d, npoints*sizeof(int));\n\tcudaMalloc((void**) &clusters_d, nclusters*nfeatures*sizeof(float));\n\n\t\n#ifdef BLOCK_DELTA_REDUCE\n\tcudaMalloc((void**) &block_deltas_d, num_blocks_perdim * num_blocks_perdim * sizeof(int));\n#endif\n\n#ifdef BLOCK_CENTER_REDUCE\n\tcudaMalloc((void**) &block_clusters_d, \n        num_blocks_perdim * num_blocks_perdim * \n        nclusters * nfeatures * sizeof(float));\n#endif\n\n}\n\nextern \"C\"\nvoid deallocateMemory()\n{\n\tfree(membership_new);\n\tfree(block_new_centers);\n\tcudaFree(feature_d);\n\tcudaFree(feature_flipped_d);\n\tcudaFree(membership_d);\n\n\tcudaFree(clusters_d);\n#ifdef BLOCK_CENTER_REDUCE\n    cudaFree(block_clusters_d);\n#endif\n#ifdef BLOCK_DELTA_REDUCE\n    cudaFree(block_deltas_d);\n#endif\n}\n\nint\nmain( int argc, char** argv) \n{\n    cudaSetDevice(1);\n\tsetup(argc, argv);    \n}\n\nextern \"C\"\nint\nkmeansCuda(float  **feature,\n           int      nfeatures,\n           int      npoints,\n           int      nclusters,\n           int     *membership,\n\t\t   float  **clusters,\n\t\t   int     *new_centers_len,\n           float  **new_centers\n\t\t   )\n{\n\tint delta = 0;\t\t\t/* if point has moved */\n\tint i,j;\t\t\t\t/* counters */\n\n\n\tcudaSetDevice(1);\n\n\tcudaMemcpy(membership_d, membership_new, npoints*sizeof(int), cudaMemcpyHostToDevice);\n\n\tcudaMemcpy(clusters_d, clusters[0], nclusters*nfeatures*sizeof(float), cudaMemcpyHostToDevice);\n\n    cudaChannelFormatDesc chDesc0 = cudaCreateChannelDesc<float>();\n    t_features.filterMode = cudaFilterModePoint;   \n    t_features.normalized = false;\n    t_features.channelDesc = chDesc0;\n\n\tif(cudaBindTexture(NULL, &t_features, feature_d, &chDesc0, npoints*nfeatures*sizeof(float)) != CUDA_SUCCESS)\n        printf(\"Couldn't bind features array to texture!\\n\");\n\n\tcudaChannelFormatDesc chDesc1 = cudaCreateChannelDesc<float>();\n    t_features_flipped.filterMode = cudaFilterModePoint;   \n    t_features_flipped.normalized = false;\n    t_features_flipped.channelDesc = chDesc1;\n\n\tif(cudaBindTexture(NULL, &t_features_flipped, feature_flipped_d, &chDesc1, npoints*nfeatures*sizeof(float)) != CUDA_SUCCESS)\n        printf(\"Couldn't bind features_flipped array to texture!\\n\");\n\n\tcudaChannelFormatDesc chDesc2 = cudaCreateChannelDesc<float>();\n    t_clusters.filterMode = cudaFilterModePoint;   \n    t_clusters.normalized = false;\n    t_clusters.channelDesc = chDesc2;\n\n\tif(cudaBindTexture(NULL, &t_clusters, clusters_d, &chDesc2, nclusters*nfeatures*sizeof(float)) != CUDA_SUCCESS)\n        printf(\"Couldn't bind clusters array to texture!\\n\");\n\n\tcudaMemcpyToSymbol(\"c_clusters\",clusters[0],nclusters*nfeatures*sizeof(float),0,cudaMemcpyHostToDevice);\n\n\n    dim3  grid( num_blocks_perdim, num_blocks_perdim );\n    dim3  threads( num_threads_perdim*num_threads_perdim );\n    \n    kmeansPoint<<< grid, threads >>>( feature_d,\n                                      nfeatures,\n                                      npoints,\n                                      nclusters,\n                                      membership_d,\n                                      clusters_d,\n\t\t\t\t\t\t\t\t\t  block_clusters_d,\n\t\t\t\t\t\t\t\t\t  block_deltas_d);\n\n\tcudaThreadSynchronize();\n\n\tcudaMemcpy(membership_new, membership_d, npoints*sizeof(int), cudaMemcpyDeviceToHost);\t\n\n#ifdef BLOCK_CENTER_REDUCE\n    float * block_clusters_h = (float *) malloc(\n        num_blocks_perdim * num_blocks_perdim * \n        nclusters * nfeatures * sizeof(float));\n        \n\tcudaMemcpy(block_clusters_h, block_clusters_d, \n        num_blocks_perdim * num_blocks_perdim * \n        nclusters * nfeatures * sizeof(float), \n        cudaMemcpyDeviceToHost);\n#endif\n#ifdef BLOCK_DELTA_REDUCE\n    int * block_deltas_h = (int *) malloc(\n        num_blocks_perdim * num_blocks_perdim * sizeof(int));\n        \n\tcudaMemcpy(block_deltas_h, block_deltas_d, \n        num_blocks_perdim * num_blocks_perdim * sizeof(int), \n        cudaMemcpyDeviceToHost);\n#endif\n    \n\tdelta = 0;\n\tfor (i = 0; i < npoints; i++)\n\t{\t\t\n\t\tint cluster_id = membership_new[i];\n\t\tnew_centers_len[cluster_id]++;\n\t\tif (membership_new[i] != membership[i])\n\t\t{\n#ifdef CPU_DELTA_REDUCE\n\t\t\tdelta++;\n#endif\n\t\t\tmembership[i] = membership_new[i];\n\t\t}\n#ifdef CPU_CENTER_REDUCE\n\t\tfor (j = 0; j < nfeatures; j++)\n\t\t{\t\t\t\n\t\t\tnew_centers[cluster_id][j] += feature[i][j];\n\t\t}\n#endif\n\t}\n\t\n\n#ifdef BLOCK_DELTA_REDUCE\t\n    for(i = 0; i < num_blocks_perdim * num_blocks_perdim; i++) {\n        delta += block_deltas_h[i];\n    }\n        \n#endif\n#ifdef BLOCK_CENTER_REDUCE\t\n\t\n\tfor(int j = 0; j < nclusters;j++) {\n\t\tfor(int k = 0; k < nfeatures;k++) {\n\t\t\tblock_new_centers[j*nfeatures + k] = 0.f;\n\t\t}\n\t}\n\n    for(i = 0; i < num_blocks_perdim * num_blocks_perdim; i++) {\n\t\tfor(int j = 0; j < nclusters;j++) {\n\t\t\tfor(int k = 0; k < nfeatures;k++) {\n\t\t\t\tblock_new_centers[j*nfeatures + k] += block_clusters_h[i * nclusters*nfeatures + j * nfeatures + k];\n\t\t\t}\n\t\t}\n    }\n\t\n\n#ifdef CPU_CENTER_REDUCE\n#endif\n\n#ifdef BLOCK_CENTER_REDUCE\n\tfor(int j = 0; j < nclusters;j++) {\n\t\tfor(int k = 0; k < nfeatures;k++)\n\t\t\tnew_centers[j][k]= block_new_centers[j*nfeatures + k];\t\t\n\t}\n#endif\n\n#endif\n\n\treturn delta;\n\t\n}\n\n\n"}, "code_dirs": {"kmeans_cuda.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/kmeans"}}
{"kernel_name": "kmeans", "parallel_api": "ocl", "code": {"kmeans.cpp": "#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <math.h>\n#include <iostream>\n#include <string>\n#include \"kmeans.h\"\n\n#ifdef WIN\n\t#include <windows.h>\n#else\n\t#include <pthread.h>\n\t#include <sys/time.h>\n\tdouble gettime() {\n\t\tstruct timeval t;\n\t\tgettimeofday(&t,NULL);\n\t\treturn t.tv_sec+t.tv_usec*1e-6;\n\t}\n#endif\n\n\n#ifdef NV \n\t#include <oclUtils.h>\n#else\n\t#include <CL/cl.h>\n#endif\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\n#ifdef RD_WG_SIZE_0_0\n        #define BLOCK_SIZE RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n        #define BLOCK_SIZE RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n        #define BLOCK_SIZE RD_WG_SIZE\n#else\n        #define BLOCK_SIZE 256\n#endif\n\n#ifdef RD_WG_SIZE_1_0\n     #define BLOCK_SIZE2 RD_WG_SIZE_1_0\n#elif defined(RD_WG_SIZE_1)\n     #define BLOCK_SIZE2 RD_WG_SIZE_1\n#elif defined(RD_WG_SIZE)\n     #define BLOCK_SIZE2 RD_WG_SIZE\n#else\n     #define BLOCK_SIZE2 256\n#endif\n\n#ifdef TIMING\n#include \"timing.h\"\n\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_init_start, tv_init_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nint platform_id_inuse = 0;\nint device_id_inuse = 0;\n\nstatic cl_context\t    context;\nstatic cl_command_queue cmd_queue;\nstatic cl_device_type   device_type;\nstatic cl_device_id   * device_list;\nstatic cl_uint          num_devices;\n\nstatic int initialize()\n{\n\tcl_int result;\n\tsize_t size;\n\tcl_uint num_platforms;\n\n    if (clGetPlatformIDs(0, NULL, &num_platforms) != CL_SUCCESS) { printf(\"ERROR: clGetPlatformIDs(0,0,*) failed\\n\"); return -1; }\n\tcl_platform_id all_platform_id[num_platforms];\n\tif (clGetPlatformIDs(num_platforms, all_platform_id, NULL) != CL_SUCCESS) { printf(\"ERROR: clGetPlatformIDs(*,*,0) failed\\n\"); return -1; }\n    cl_platform_id platform_id = all_platform_id[platform_id_inuse];\n\n    if (clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_ALL, 0, NULL, &num_devices) != CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\tprintf(\"num_devices = %d\\n\", num_devices);\n    if (device_id_inuse > num_devices) {\n        printf(\"Invalid Device Number\\n\");\n        return -1;\n    }\n\tdevice_list = new cl_device_id[num_devices];\n\tif( !device_list ) { printf(\"ERROR: new cl_device_id[] failed\\n\"); return -1; }\n    if (clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_ALL, num_devices, device_list, NULL) != CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\n    if (clGetDeviceInfo(device_list[device_id_inuse], CL_DEVICE_TYPE, sizeof(device_type), (void *)&device_type, NULL)!= CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\n\tcl_context_properties ctxprop[] = { CL_CONTEXT_PLATFORM, (cl_context_properties)platform_id, 0};\n\tcontext = clCreateContextFromType( ctxprop, device_type, NULL, NULL, NULL );\n\tif( !context ) { printf(\"ERROR: clCreateContextFromType(%s) failed\\n\", device_type == CL_DEVICE_TYPE_GPU ? \"GPU\" : \"CPU\"); return -1; }\n\n#ifdef TIMING\n\tcmd_queue = clCreateCommandQueue( context, device_list[device_id_inuse], CL_QUEUE_PROFILING_ENABLE, NULL );\n#else\n\tcmd_queue = clCreateCommandQueue( context, device_list[device_id_inuse], 0, NULL );\n#endif\n\tif( !cmd_queue ) { printf(\"ERROR: clCreateCommandQueue() failed\\n\"); return -1; }\n\n\treturn 0;\n}\n\nstatic int shutdown()\n{\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n\tif( cmd_queue ) clReleaseCommandQueue( cmd_queue );\n\tif( context ) clReleaseContext( context );\n\tif( device_list ) delete device_list;\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tcmd_queue = 0;\n\tcontext = 0;\n\tdevice_list = 0;\n\tnum_devices = 0;\n\tdevice_type = 0;\n\n\treturn 0;\n}\n\ncl_mem d_feature;\ncl_mem d_feature_swap;\ncl_mem d_cluster;\ncl_mem d_membership;\n\ncl_kernel kernel;\ncl_kernel kernel_s;\ncl_kernel kernel2;\n\nint   *membership_OCL;\nint   *membership_d;\nfloat *feature_d;\nfloat *clusters_d;\nfloat *center_d;\n\nint allocate(int n_points, int n_features, int n_clusters, float **feature)\n{\n\n\tint sourcesize = 1024*1024;\n\tchar * source = (char *)calloc(sourcesize, sizeof(char)); \n\tif(!source) { printf(\"ERROR: calloc(%d) failed\\n\", sourcesize); return -1; }\n\n\tconst char * tempchar = \"./kmeans.cl\";\n\tFILE * fp = fopen(tempchar, \"rb\"); \n\tif(!fp) { printf(\"ERROR: unable to open '%s'\\n\", tempchar); return -1; }\n\tfread(source + strlen(source), sourcesize, 1, fp);\n\tfclose(fp);\n\n#ifdef  TIMING\n    gettimeofday(&tv_init_start, NULL);\n#endif\n\tif(initialize()) return -1;\n\n\tcl_int err = 0;\n\tconst char * slist[2] = { source, 0 };\n\tcl_program prog = clCreateProgramWithSource(context, 1, slist, NULL, &err);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateProgramWithSource() => %d\\n\", err); return -1; }\n\terr = clBuildProgram(prog, 0, NULL, NULL, NULL, NULL);\n\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clBuildProgram() => %d\\n\", err); return -1; }\n\t\n\tconst char * kernel_kmeans_c  = \"kmeans_kernel_c\";\n\tconst char * kernel_swap  = \"kmeans_swap\";\t\n\t\t\n\tkernel_s = clCreateKernel(prog, kernel_kmeans_c, &err);  \n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateKernel() 0 => %d\\n\", err); return -1; }\n\tkernel2 = clCreateKernel(prog, kernel_swap, &err);  \n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateKernel() 0 => %d\\n\", err); return -1; }\n\t\t\n\tclReleaseProgram(prog);\t\n#ifdef  TIMING\n\tgettimeofday(&tv_init_end, NULL);\n\ttvsub(&tv_init_end, &tv_init_start, &tv);\n\tinit_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\t\n\td_feature = clCreateBuffer(context, CL_MEM_READ_WRITE, n_points * n_features * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer d_feature (size:%d) => %d\\n\", n_points * n_features, err); return -1;}\n\td_feature_swap = clCreateBuffer(context, CL_MEM_READ_WRITE, n_points * n_features * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer d_feature_swap (size:%d) => %d\\n\", n_points * n_features, err); return -1;}\n\td_cluster = clCreateBuffer(context, CL_MEM_READ_WRITE, n_clusters * n_features  * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer d_cluster (size:%d) => %d\\n\", n_clusters * n_features, err); return -1;}\n\td_membership = clCreateBuffer(context, CL_MEM_READ_WRITE, n_points * sizeof(int), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer d_membership (size:%d) => %d\\n\", n_points, err); return -1;}\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_init_end, &tv);\n    mem_alloc_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\t\t\n\tcl_event event;\n\terr = clEnqueueWriteBuffer(cmd_queue, d_feature, 1, 0, n_points * n_features * sizeof(float), feature[0], 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer d_feature (size:%d) => %d\\n\", n_points * n_features, err); return -1; }\n#ifdef TIMING\n    h2d_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\tclSetKernelArg(kernel2, 0, sizeof(void *), (void*) &d_feature);\n\tclSetKernelArg(kernel2, 1, sizeof(void *), (void*) &d_feature_swap);\n\tclSetKernelArg(kernel2, 2, sizeof(cl_int), (void*) &n_points);\n\tclSetKernelArg(kernel2, 3, sizeof(cl_int), (void*) &n_features);\n\t\n\tsize_t global_work[3] = { n_points, 1, 1 };\n\tsize_t local_work_size= BLOCK_SIZE;\n\tif(global_work[0]%local_work_size !=0)\n\t  global_work[0]=(global_work[0]/local_work_size+1)*local_work_size;\n\n\terr = clEnqueueNDRangeKernel(cmd_queue, kernel2, 1, NULL, global_work, &local_work_size, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\n#ifdef TIMING\n    kernel_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\tmembership_OCL = (int*) malloc(n_points * sizeof(int));\n}\n\nvoid deallocateMemory()\n{\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n\tclReleaseMemObject(d_feature);\n\tclReleaseMemObject(d_feature_swap);\n\tclReleaseMemObject(d_cluster);\n\tclReleaseMemObject(d_membership);\n\tfree(membership_OCL);\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n}\n\n\nint main( int argc, char** argv) \n{\n\tprintf(\"WG size of kernel_swap = %d, WG size of kernel_kmeans = %d \\n\", BLOCK_SIZE, BLOCK_SIZE2);\n#ifdef  TIMING\n\tgettimeofday(&tv_total_start, NULL);\n#endif\n\n\tsetup(argc, argv);\n\tshutdown();\n\n#ifdef  TIMING\n\tgettimeofday(&tv_total_end, NULL);\n\ttvsub(&tv_close_end, &tv_total_start, &tv);\n\ttotal_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n\tprintf(\"Init: %f\\n\", init_time);\n\tprintf(\"MemAlloc: %f\\n\", mem_alloc_time);\n\tprintf(\"HtoD: %f\\n\", h2d_time);\n\tprintf(\"Exec: %f\\n\", kernel_time);\n\tprintf(\"DtoH: %f\\n\", d2h_time);\n\tprintf(\"Close: %f\\n\", close_time);\n\tprintf(\"Total: %f\\n\", total_time);\n#endif\n}\n\nint\tkmeansOCL(float **feature,    /* in: [npoints][nfeatures] */\n           int     n_features,\n           int     n_points,\n           int     n_clusters,\n           int    *membership,\n\t\t   float **clusters,\n\t\t   int     *new_centers_len,\n           float  **new_centers)\t\n{\n  \n\tint delta = 0;\n\tint i, j, k;\n\tcl_int err = 0;\n\tcl_event event;\n\t\n\tsize_t global_work[3] = { n_points, 1, 1 }; \n\n\tsize_t local_work_size=BLOCK_SIZE2;\n\tif(global_work[0]%local_work_size !=0)\n\t  global_work[0]=(global_work[0]/local_work_size+1)*local_work_size;\n\t\n\terr = clEnqueueWriteBuffer(cmd_queue, d_cluster, 1, 0, n_clusters * n_features * sizeof(float), clusters[0], 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer d_cluster (size:%d) => %d\\n\", n_points, err); return -1; }\n#ifdef TIMING\n    h2d_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\tint size = 0; int offset = 0;\n\t\t\t\t\t\n\tclSetKernelArg(kernel_s, 0, sizeof(void *), (void*) &d_feature_swap);\n\tclSetKernelArg(kernel_s, 1, sizeof(void *), (void*) &d_cluster);\n\tclSetKernelArg(kernel_s, 2, sizeof(void *), (void*) &d_membership);\n\tclSetKernelArg(kernel_s, 3, sizeof(cl_int), (void*) &n_points);\n\tclSetKernelArg(kernel_s, 4, sizeof(cl_int), (void*) &n_clusters);\n\tclSetKernelArg(kernel_s, 5, sizeof(cl_int), (void*) &n_features);\n\tclSetKernelArg(kernel_s, 6, sizeof(cl_int), (void*) &offset);\n\tclSetKernelArg(kernel_s, 7, sizeof(cl_int), (void*) &size);\n\n\terr = clEnqueueNDRangeKernel(cmd_queue, kernel_s, 1, NULL, global_work, &local_work_size, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\n#ifdef TIMING\n    h2d_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\tclFinish(cmd_queue);\n\terr = clEnqueueReadBuffer(cmd_queue, d_membership, 1, 0, n_points * sizeof(int), membership_OCL, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: Memcopy Out\\n\"); return -1; }\n#ifdef TIMING\n    d2h_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\t\n\tdelta = 0;\n\tfor (i = 0; i < n_points; i++)\n\t{\n\t\tint cluster_id = membership_OCL[i];\n\t\tnew_centers_len[cluster_id]++;\n\t\tif (membership_OCL[i] != membership[i])\n\t\t{\n\t\t\tdelta++;\n\t\t\tmembership[i] = membership_OCL[i];\n\t\t}\n\t\tfor (j = 0; j < n_features; j++)\n\t\t{\n\t\t\tnew_centers[cluster_id][j] += feature[i][j];\n\t\t}\n\t}\n\n\treturn delta;\n}\n", "kmeans.cl": "#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\n__kernel void\nkmeans_kernel_c(__global float  *feature,   \n\t\t\t  __global float  *clusters,\n\t\t\t  __global int    *membership,\n\t\t\t    int     npoints,\n\t\t\t\tint     nclusters,\n\t\t\t\tint     nfeatures,\n\t\t\t\tint\t\toffset,\n\t\t\t\tint\t\tsize\n\t\t\t  ) \n{\n\tunsigned int point_id = get_global_id(0);\n    int index = 0;\n\t\tif (point_id < npoints)\n\t\t{\n\t\t\tfloat min_dist=FLT_MAX;\n\t\t\tfor (int i=0; i < nclusters; i++) {\n\t\t\t\t\n\t\t\t\tfloat dist = 0;\n\t\t\t\tfloat ans  = 0;\n\t\t\t\tfor (int l=0; l<nfeatures; l++){\n\t\t\t\t\t\tans += (feature[l * npoints + point_id]-clusters[i*nfeatures+l])* \n\t\t\t\t\t\t\t   (feature[l * npoints + point_id]-clusters[i*nfeatures+l]);\n\t\t\t\t}\n\n\t\t\t\tdist = ans;\n\t\t\t\tif (dist < min_dist) {\n\t\t\t\t\tmin_dist = dist;\n\t\t\t\t\tindex    = i;\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t  membership[point_id] = index;\n\t\t}\t\n\t\n\treturn;\n}\n\n__kernel void\nkmeans_swap(__global float  *feature,   \n\t\t\t__global float  *feature_swap,\n\t\t\tint     npoints,\n\t\t\tint     nfeatures\n){\n\n\tunsigned int tid = get_global_id(0);\n    if (tid < npoints){\n\t    for(int i = 0; i <  nfeatures; i++)\n\t\t    feature_swap[i * npoints + tid] = feature[tid * nfeatures + i];\n    }\n} \n"}, "code_dirs": {"kmeans.cpp": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/kmeans", "kmeans.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/kmeans"}}
{"kernel_name": "hotspot3D", "parallel_api": "cuda", "code": {"3D.cu": "#include <stdio.h>\n#include <time.h>\n#include <assert.h>\n#include <stdlib.h> \n#include <math.h> \n#include <sys/time.h>\n\n#define BLOCK_SIZE 16\n#define STR_SIZE 256\n\n#define block_x_ 128 \n#define block_y_ 2\n#define block_z_ 1\n#define MAX_PD\t(3.0e6)\n#define PRECISION\t0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI 100\n#define FACTOR_CHIP\t0.5\n\n#include \"opt1.cu\"\n\nfloat t_chip = 0.0005;\nfloat chip_height = 0.016; float chip_width = 0.016;\nfloat amb_temp = 80.0;\n\nvoid fatal(const char *s)\n{\n    fprintf(stderr, \"Error: %s\\n\", s);\n}\n\nvoid readinput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n    int i,j,k;\n    FILE *fp;\n    char str[STR_SIZE];\n    float val;\n\n    if( (fp  = fopen(file, \"r\" )) ==0 )\n      fatal( \"The file was not opened\" );\n\n\n    for (i=0; i <= grid_rows-1; i++) \n      for (j=0; j <= grid_cols-1; j++)\n        for (k=0; k <= layers-1; k++)\n          {\n            if (fgets(str, STR_SIZE, fp) == NULL) fatal(\"Error reading file\\n\");\n            if (feof(fp))\n              fatal(\"not enough lines in file\");\n            if ((sscanf(str, \"%f\", &val) != 1))\n              fatal(\"invalid file format\");\n            vect[i*grid_cols+j+k*grid_rows*grid_cols] = val;\n          }\n\n    fclose(fp);\t\n\n}\n\n\nvoid writeoutput(float *vect, int grid_rows, int grid_cols, int layers, char *file) {\n\n    int i,j,k, index=0;\n    FILE *fp;\n    char str[STR_SIZE];\n\n    if( (fp = fopen(file, \"w\" )) == 0 )\n      printf( \"The file was not opened\\n\" );\n\n    for (i=0; i < grid_rows; i++) \n      for (j=0; j < grid_cols; j++)\n        for (k=0; k < layers; k++)\n          {\n            sprintf(str, \"%d\\t%g\\n\", index, vect[i*grid_cols+j+k*grid_rows*grid_cols]);\n            fputs(str,fp);\n            index++;\n          }\n\n    fclose(fp);\t\n}\n\nvoid computeTempCPU(float *pIn, float* tIn, float *tOut, \n        int nx, int ny, int nz, float Cap, \n        float Rx, float Ry, float Rz, \n        float dt, int numiter) \n{   float ce, cw, cn, cs, ct, cb, cc;\n    float stepDivCap = dt / Cap;\n    ce = cw =stepDivCap/ Rx;\n    cn = cs =stepDivCap/ Ry;\n    ct = cb =stepDivCap/ Rz;\n\n    cc = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n    int c,w,e,n,s,b,t;\n    int x,y,z;\n    int i = 0;\n    do{\n        for(z = 0; z < nz; z++)\n            for(y = 0; y < ny; y++)\n                for(x = 0; x < nx; x++)\n                {\n                    c = x + y * nx + z * nx * ny;\n\n                    w = (x == 0) ? c      : c - 1;\n                    e = (x == nx - 1) ? c : c + 1;\n                    n = (y == 0) ? c      : c - nx;\n                    s = (y == ny - 1) ? c : c + nx;\n                    b = (z == 0) ? c      : c - nx * ny;\n                    t = (z == nz - 1) ? c : c + nx * ny;\n\n                    tOut[c] = tIn[c]*cc + tIn[n]*cn + tIn[s]*cs + tIn[e]*ce + tIn[w]*cw + tIn[t]*ct + tIn[b]*cb + (dt/Cap) * pIn[c] + ct*amb_temp;\n                }\n        float *temp = tIn;\n        tIn = tOut;\n        tOut = temp; \n        i++;\n    }\n    while(i < numiter);\n\n}\n\nfloat accuracy(float *arr1, float *arr2, int len)\n{\n    float err = 0.0; \n    int i;\n    for(i = 0; i < len; i++)\n    {\n        err += (arr1[i]-arr2[i]) * (arr1[i]-arr2[i]);\n    }\n\n    return (float)sqrt(err/len);\n}\n \n\nvoid usage(int argc, char **argv)\n{\n    fprintf(stderr, \"Usage: %s <rows/cols> <layers> <iterations> <powerFile> <tempFile> <outputFile>\\n\", argv[0]);\n    fprintf(stderr, \"\\t<rows/cols>  - number of rows/cols in the grid (positive integer)\\n\");\n    fprintf(stderr, \"\\t<layers>  - number of layers in the grid (positive integer)\\n\");\n\n    fprintf(stderr, \"\\t<iteration> - number of iterations\\n\");\n    fprintf(stderr, \"\\t<powerFile>  - name of the file containing the initial power values of each cell\\n\");\n    fprintf(stderr, \"\\t<tempFile>  - name of the file containing the initial temperature values of each cell\\n\");\n    fprintf(stderr, \"\\t<outputFile - output file\\n\");\n    exit(1);\n}\n\nint main(int argc, char** argv)\n{\n    if (argc != 7)\n    {\n        usage(argc,argv);\n    }\n\n    char *pfile, *tfile, *ofile;\n    int iterations = atoi(argv[3]);\n\n    pfile = argv[4];\n    tfile = argv[5];\n    ofile = argv[6];\n    int numCols = atoi(argv[1]);\n    int numRows = atoi(argv[1]);\n    int layers = atoi(argv[2]);\n\n    /* calculating parameters*/\n\n    float dx = chip_height/numRows;\n    float dy = chip_width/numCols;\n    float dz = t_chip/layers;\n\n    float Cap = FACTOR_CHIP * SPEC_HEAT_SI * t_chip * dx * dy;\n    float Rx = dy / (2.0 * K_SI * t_chip * dx);\n    float Ry = dx / (2.0 * K_SI * t_chip * dy);\n    float Rz = dz / (K_SI * dx * dy);\n\n    float max_slope = MAX_PD / (FACTOR_CHIP * t_chip * SPEC_HEAT_SI);\n    float dt = PRECISION / max_slope;\n\n\n    float *powerIn, *tempOut, *tempIn, *tempCopy;\n    int size = numCols * numRows * layers;\n\n    powerIn = (float*)calloc(size, sizeof(float));\n    tempCopy = (float*)malloc(size * sizeof(float));\n    tempIn = (float*)calloc(size,sizeof(float));\n    tempOut = (float*)calloc(size, sizeof(float));\n    float* answer = (float*)calloc(size, sizeof(float));\n\n    readinput(powerIn,numRows, numCols, layers,pfile);\n    readinput(tempIn, numRows, numCols, layers, tfile);\n\n    memcpy(tempCopy,tempIn, size * sizeof(float));\n\n    hotspot_opt1(powerIn, tempIn, tempOut, numCols, numRows, layers, Cap, Rx, Ry, Rz, dt,iterations);\n\n    computeTempCPU(powerIn, tempCopy, answer, numCols, numRows, layers, Cap, Rx, Ry, Rz, dt,iterations);\n\n    float acc = accuracy(tempOut,answer,numRows*numCols*layers);\n    printf(\"Accuracy: %e\\n\",acc);\n    writeoutput(tempOut,numRows, numCols, layers, ofile);\n    free(tempIn);\n    free(tempOut); free(powerIn);\n    return 0;\n}\t"}, "code_dirs": {"3D.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/hotspot3D"}}
{"kernel_name": "hotspot3D", "parallel_api": "ocl", "code": {"3D.c": "#include <stdio.h>\n#include <stdlib.h>\n#include <sys/types.h>\n#include <CL/cl.h>\n#include \"CL_helper.h\"\n#include \"timing.h\"\n\n#ifndef DEVICE\n#define DEVICE CL_DEVICE_TYPE_DEFAULT\n#endif\n\n#define TOL      (0.001)\n#define STR_SIZE (256)\n#define MAX_PD   (3.0e6)\n\n#define PRECISION    0.001\n#define SPEC_HEAT_SI 1.75e6\n#define K_SI         100\n\n#define FACTOR_CHIP\t0.5\n\n#define WG_SIZE_X (64)\n#define WG_SIZE_Y (4)\nfloat t_chip      = 0.0005;\nfloat chip_height = 0.016;\nfloat chip_width  = 0.016;\nfloat amb_temp    = 80.0;\n\nvoid usage(int argc, char **argv)\n{\n  fprintf(stderr, \"Usage: %s <-n rows/cols> <-l layers> <-i iterations> <-f powerFile tempFile outputFile> [-p platform] [-d device]\\n\", argv[0]);\n  fprintf(stderr, \"\\t<rows/cols>  - number of rows/cols in the grid (positive integer)\\n\");\n  fprintf(stderr, \"\\t<layers>  - number of layers in the grid (positive integer)\\n\");\n\n  fprintf(stderr, \"\\t<iteration> - number of iterations\\n\");\n  fprintf(stderr, \"\\t<powerFile>  - name of the file containing the initial power values of each cell\\n\");\n  fprintf(stderr, \"\\t<tempFile>  - name of the file containing the initial temperature values of each cell\\n\");\n  fprintf(stderr, \"\\t<outputFile - output file\\n\");\n  exit(1);\n}\n\n\nint main(int argc, char** argv)\n{\n    char *pfile = NULL, *tfile = NULL, *ofile = NULL;\n    int iterations = 0;\n    int numCols    = 0;\n    int numRows    = 0;\n    int layers     = 0;\n\n    int platform_id_inuse = 0;\n    int device_id_inuse = 0;\n\n    int cur_arg;\n\tfor (cur_arg = 1; cur_arg<argc; cur_arg++) {\n        if (strcmp(argv[cur_arg], \"-h\") == 0) {\n\t\t\tusage(argc, argv);\n        }\n        else if (strcmp(argv[cur_arg], \"-n\") == 0) {\n            if (argc >= cur_arg + 1) {\n                numCols = numRows = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n        else if (strcmp(argv[cur_arg], \"-l\") == 0) {\n            if (argc >= cur_arg + 1) {\n                layers = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n        else if (strcmp(argv[cur_arg], \"-i\") == 0) {\n            if (argc >= cur_arg + 1) {\n                iterations = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n        else if (strcmp(argv[cur_arg], \"-f\") == 0) {\n            if (argc >= cur_arg + 3) {\n                pfile = argv[cur_arg+1];\n                tfile = argv[cur_arg+2];\n                ofile = argv[cur_arg+3];\n                cur_arg += 3;\n            }\n        }\n        else if (strcmp(argv[cur_arg], \"-p\") == 0) {\n            if (argc >= cur_arg + 1) {\n                platform_id_inuse = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n        else if (strcmp(argv[cur_arg], \"-d\") == 0) {\n            if (argc >= cur_arg + 1) {\n                device_id_inuse = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n    }\n\n\tif (numCols == 0 || layers == 0 || iterations == 0 || pfile == NULL) {\n\t\tusage(argc, argv);\n\t}\n\n  float dx         = chip_height/numRows;\n  float dy         = chip_width/numCols;\n  float dz         = t_chip/layers;\n\n  float Cap        = FACTOR_CHIP * SPEC_HEAT_SI * t_chip * dx * dy;\n  float Rx         = dy / (2.0 * K_SI * t_chip * dx);\n  float Ry         = dx / (2.0 * K_SI * t_chip * dy);\n  float Rz         = dz / (K_SI * dx * dy);\n\n  float max_slope  = MAX_PD / (FACTOR_CHIP * t_chip * SPEC_HEAT_SI);\n  float dt         = PRECISION / max_slope;\n\n  float ce, cw, cn, cs, ct, cb, cc;\n  float stepDivCap = dt / Cap;\n  ce               = cw                                              = stepDivCap/ Rx;\n  cn               = cs                                              = stepDivCap/ Ry;\n  ct               = cb                                              = stepDivCap/ Rz;\n\n  cc               = 1.0 - (2.0*ce + 2.0*cn + 3.0*ct);\n\n\n  int          err;           \n  int size = numCols * numRows * layers;\n  float*        tIn      = (float*) calloc(size,sizeof(float));\n  float*        pIn      = (float*) calloc(size,sizeof(float));\n  float*        tempCopy = (float*)malloc(size * sizeof(float));\n  float*        tempOut  = (float*) calloc(size,sizeof(float));\n  int i                 = 0;\n  int count = size;\n  readinput(tIn,numRows, numCols, layers, tfile);\n  readinput(pIn,numRows, numCols, layers, pfile);\n\n  size_t global[2];                   \n  size_t local[2];\n  memcpy(tempCopy,tIn, size * sizeof(float));\n\n  cl_device_id     device_id;     \n  cl_context       context;       \n  cl_command_queue commands;      \n  cl_program       program;       \n  cl_kernel        ko_vadd;       \n\n  cl_mem d_a;                     \n  cl_mem d_b;                     \n  cl_mem d_c;                     \n  const char *KernelSource = load_kernel_source(\"hotspotKernel.cl\"); \n  cl_uint numPlatforms;\n\n#ifdef TIMING\n  struct timeval tv;\n  struct timeval tv_total_start, tv_total_end;\n  struct timeval tv_init_end;\n  struct timeval tv_h2d_start, tv_h2d_end;\n  struct timeval tv_d2h_start, tv_d2h_end;\n  struct timeval tv_kernel_start, tv_kernel_end;\n  struct timeval tv_mem_alloc_start, tv_mem_alloc_end;\n  struct timeval tv_close_start, tv_close_end;\n  float init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n              d2h_time = 0, close_time = 0, total_time = 0;\n\n  gettimeofday(&tv_total_start, NULL);\n#endif\n\n  err = clGetPlatformIDs(0, NULL, &numPlatforms);\n  if (err != CL_SUCCESS || numPlatforms <= 0)\n    {\n      printf(\"Error: Failed to find a platform!\\n%s\\n\",err_code(err));\n      return EXIT_FAILURE;\n    }\n\n  cl_platform_id Platform[numPlatforms];\n  err = clGetPlatformIDs(numPlatforms, Platform, NULL);\n  if (err != CL_SUCCESS || numPlatforms <= 0)\n    {\n      printf(\"Error: Failed to get the platform!\\n%s\\n\",err_code(err));\n      return EXIT_FAILURE;\n    }\n\n    cl_uint num_devices;\n    err = clGetDeviceIDs(Platform[platform_id_inuse], CL_DEVICE_TYPE_ALL, 0,\n            NULL, &num_devices);\n    if (err != CL_SUCCESS) {\n        printf(\"ERROR: clGetDeviceIDs failed\\n\");\n        return EXIT_FAILURE;\n    };\n\tprintf(\"num_devices = %d\\n\", num_devices);\n    if (device_id_inuse > num_devices) {\n        printf(\"Invalid Device Number\\n\");\n        return EXIT_FAILURE;\n    }\n\tcl_device_id *device_list = (cl_device_id *)malloc(sizeof(cl_device_id)*num_devices);\n\tif ( !device_list ) {\n        printf(\"ERROR: new cl_device_id[] failed\\n\");\n        return EXIT_FAILURE;\n    }\n    err = clGetDeviceIDs(Platform[platform_id_inuse], CL_DEVICE_TYPE_ALL, num_devices,\n            device_list, NULL);\n    if (err != CL_SUCCESS) {\n        printf(\"ERROR: clGetDeviceIDs failed\\n\");\n        return EXIT_FAILURE;\n    };\n    device_id = device_list[device_id_inuse];\n    free(device_list);\n  err = output_device_info(device_id);\n\n  context = clCreateContext(0, 1, &device_id, NULL, NULL, &err);\n  if (!context)\n    {\n      printf(\"Error: Failed to create a compute context!\\n%s\\n\", err_code(err));\n      return EXIT_FAILURE;\n    }\n\n#ifdef TIMING\n  commands = clCreateCommandQueue(context, device_id, CL_QUEUE_PROFILING_ENABLE, &err);\n#else\n  commands = clCreateCommandQueue(context, device_id, 0, &err);\n#endif\n  if (!commands)\n    {\n      printf(\"Error: Failed to create a command commands!\\n%s\\n\", err_code(err));\n      return EXIT_FAILURE;\n    }\n\n  program = clCreateProgramWithSource(context, 1, (const char **) & KernelSource, NULL, &err);\n  if (!program)\n    {\n      printf(\"Error: Failed to create compute program!\\n%s\\n\", err_code(err));\n      return EXIT_FAILURE;\n    }\n\n  err = clBuildProgram(program, 0, NULL, NULL, NULL, NULL);\n  if (err != CL_SUCCESS)\n    {\n      size_t len;\n      char buffer[2048];\n\n      printf(\"Error: Failed to build program executable!\\n%s\\n\", err_code(err));\n      clGetProgramBuildInfo(program, device_id, CL_PROGRAM_BUILD_LOG, sizeof(buffer), buffer, &len);\n      printf(\"%s\\n\", buffer);\n      return EXIT_FAILURE;\n    }\n\n  ko_vadd = clCreateKernel(program, \"hotspotOpt1\", &err);\n  if (!ko_vadd || err != CL_SUCCESS)\n    {\n      printf(\"Error: Failed to create compute kernel!\\n%s\\n\", err_code(err));\n      return EXIT_FAILURE;\n    }\n#ifdef  TIMING\n  gettimeofday(&tv_init_end, NULL);\n  tvsub(&tv_init_end, &tv_total_start, &tv);\n  init_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n  d_a  = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * count, NULL, NULL);\n  d_b  = clCreateBuffer(context, CL_MEM_READ_ONLY , sizeof(float) * count, NULL, NULL);\n  d_c  = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * count, NULL, NULL);\n#ifdef  TIMING\n  gettimeofday(&tv_mem_alloc_end, NULL);\n  tvsub(&tv_mem_alloc_end, &tv_init_end, &tv);\n  mem_alloc_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n  if (!d_a || !d_b || !d_c) \n    {\n      printf(\"Error: Failed to allocate device memory!\\n\");\n      exit(1);\n    }    \n\n  cl_event event;\n  err = clEnqueueWriteBuffer(commands, d_a, CL_TRUE, 0, sizeof(float) * count, tIn, 0, NULL, &event);\n  if (err != CL_SUCCESS)\n    {\n      printf(\"Error: Failed to write tIn to source array!\\n%s\\n\", err_code(err));\n      exit(1);\n    }\n#ifdef TIMING\n  h2d_time += probe_event_time(event, commands);\n#endif\n  clReleaseEvent(event);\n\n  err = clEnqueueWriteBuffer(commands, d_b, CL_TRUE, 0, sizeof(float) * count, pIn, 0, NULL, &event);\n  if (err != CL_SUCCESS)\n    {\n      printf(\"Error: Failed to write pIn to source array!\\n%s\\n\", err_code(err));\n      exit(1);\n    }\n#ifdef TIMING\n    h2d_time += probe_event_time(event, commands);\n#endif\n    clReleaseEvent(event);\n\n  err = clEnqueueWriteBuffer(commands, d_c, CL_TRUE, 0, sizeof(float) * count, tempOut, 0, NULL, &event);\n  if (err != CL_SUCCESS)\n    {\n      printf(\"Error: Failed to write tempOut to source array!\\n%s\\n\", err_code(err));\n      exit(1);\n    }\n#ifdef TIMING\n    h2d_time += probe_event_time(event, commands);\n#endif\n    clReleaseEvent(event);\n\n  int j;\n  for(j = 0; j < iterations; j++)\n    {\n      err  = clSetKernelArg(ko_vadd, 0, sizeof(cl_mem), &d_b);\n      err |= clSetKernelArg(ko_vadd, 1, sizeof(cl_mem), &d_a);\n      err |= clSetKernelArg(ko_vadd, 2, sizeof(cl_mem), &d_c);\n      err |= clSetKernelArg(ko_vadd, 3, sizeof(float), &stepDivCap);\n      err |= clSetKernelArg(ko_vadd, 4, sizeof(int), &numCols);\n      err |= clSetKernelArg(ko_vadd, 5, sizeof(int), &numRows);\n      err |= clSetKernelArg(ko_vadd, 6, sizeof(int), &layers);\n      err |= clSetKernelArg(ko_vadd, 7, sizeof(float), &ce);\n      err |= clSetKernelArg(ko_vadd, 8, sizeof(float), &cw);\n      err |= clSetKernelArg(ko_vadd, 9, sizeof(float), &cn);\n      err |= clSetKernelArg(ko_vadd, 10, sizeof(float), &cs);\n      err |= clSetKernelArg(ko_vadd, 11, sizeof(float), &ct);\n      err |= clSetKernelArg(ko_vadd, 12, sizeof(float), &cb);      \n      err |= clSetKernelArg(ko_vadd, 13, sizeof(float), &cc);\n      if (err != CL_SUCCESS)\n        {\n          printf(\"Error: Failed to set kernel arguments!\\n\");\n          exit(1);\n        }\n\n      global[0] = numCols;\n      global[1] = numRows;\n\n      local[0] = WG_SIZE_X;\n      local[1] = WG_SIZE_Y;\n\n      err = clEnqueueNDRangeKernel(commands, ko_vadd, 2, NULL, global, local, 0, NULL, &event);\n      if (err)\n        {\n          printf(\"Error: Failed to execute kernel!\\n%s\\n\", err_code(err));\n          return EXIT_FAILURE;\n        }\n\n      cl_mem temp = d_a;\n      d_a         = d_c;\n      d_c         = temp;\n\n#ifdef TIMING\n      kernel_time += probe_event_time(event, commands);\n#endif\n      clReleaseEvent(event);\n    }\n\n  clFinish(commands);\n  err = clEnqueueReadBuffer( commands, d_c, CL_TRUE, 0, sizeof(float) * count, tempOut, 0, NULL, &event);  \n  if (err != CL_SUCCESS)\n    {\n      printf(\"Error: Failed to read output array!\\n%s\\n\", err_code(err));\n      exit(1);\n    }\n#ifdef TIMING\n  d2h_time += probe_event_time(event, commands);\n#endif\n  clReleaseEvent(event);\n\n#ifdef  TIMING\n  gettimeofday(&tv_close_start, NULL);\n#endif\n  clReleaseMemObject(d_a);\n  clReleaseMemObject(d_b);\n  clReleaseMemObject(d_c);\n  clReleaseProgram(program);\n  clReleaseKernel(ko_vadd);\n  clReleaseCommandQueue(commands);\n  clReleaseContext(context);\n#ifdef  TIMING\n  gettimeofday(&tv_close_end, NULL);\n  tvsub(&tv_close_end, &tv_close_start, &tv);\n  close_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n  tvsub(&tv_close_end, &tv_total_start, &tv);\n  total_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n  printf(\"Init: %f\\n\", init_time);\n  printf(\"MemAlloc: %f\\n\", mem_alloc_time);\n  printf(\"HtoD: %f\\n\", h2d_time);\n  printf(\"Exec: %f\\n\", kernel_time);\n  printf(\"DtoH: %f\\n\", d2h_time);\n  printf(\"Close: %f\\n\", close_time);\n  printf(\"Total: %f\\n\", total_time);\n#endif\n\n  float* answer = (float*)calloc(size, sizeof(float));\n  computeTempCPU(pIn, tempCopy, answer, numCols, numRows, layers, Cap, Rx, Ry, Rz, dt, amb_temp, iterations);\n  float acc = accuracy(tempOut,answer,numRows*numCols*layers);\n  printf(\"Accuracy: %e\\n\",acc);\n\n  writeoutput(tempOut,numRows,numCols,layers,ofile);\n\n  return 0;\n}\n\n", "hotspotKernel.cl": "__kernel void hotspotOpt1(__global float *p, __global float* tIn, __global float *tOut, float sdc,\n                            int nx, int ny, int nz,\n                            float ce, float cw, \n                            float cn, float cs,\n                            float ct, float cb, \n                            float cc) \n{\n  float amb_temp = 80.0;\n\n  int i = get_global_id(0);\n  int j = get_global_id(1);\n  int c = i + j * nx;\n  int xy = nx * ny;\n\n  int W = (i == 0)        ? c : c - 1;\n  int E = (i == nx-1)     ? c : c + 1;\n  int N = (j == 0)        ? c : c - nx;\n  int S = (j == ny-1)     ? c : c + nx;\n\n  float temp1, temp2, temp3;\n  temp1 = temp2 = tIn[c];\n  temp3 = tIn[c+xy];\n  tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n    + cn * tIn[N] + cb * temp1 + ct * temp3 + sdc * p[c] + ct * amb_temp;\n  c += xy;\n  W += xy;\n  E += xy;\n  N += xy;\n  S += xy;\n\n  for (int k = 1; k < nz-1; ++k) {\n      temp1 = temp2;\n      temp2 = temp3;\n      temp3 = tIn[c+xy];\n      tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n        + cn * tIn[N] + cb * temp1 + ct * temp3 + sdc * p[c] + ct * amb_temp;\n      c += xy;\n      W += xy;\n      E += xy;\n      N += xy;\n      S += xy;\n  }\n  temp1 = temp2;\n  temp2 = temp3;\n  tOut[c] = cc * temp2 + cw * tIn[W] + ce * tIn[E] + cs * tIn[S]\n    + cn * tIn[N] + cb * temp1 + ct * temp3 + sdc * p[c] + ct * amb_temp;\n  return;\n}\n\n\n"}, "code_dirs": {"3D.c": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/hotspot3D", "hotspotKernel.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/hotspot3D"}}
{"kernel_name": "lud", "parallel_api": "cuda", "code": {"lud.cu": "#include <cuda.h>\n#include <stdio.h>\n#include <unistd.h>\n#include <getopt.h>\n#include <stdlib.h>\n#include <assert.h>\n\n#include \"common.h\"\n\n#ifdef TIMING\n#include \"timing.h\"\n#endif\n\n#ifdef RD_WG_SIZE_0_0\n        #define BLOCK_SIZE RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n        #define BLOCK_SIZE RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n        #define BLOCK_SIZE RD_WG_SIZE\n#else\n        #define BLOCK_SIZE 16\n#endif\n\nstatic int do_verify = 0;\n\nstatic struct option long_options[] = {\n  {\"input\", 1, NULL, 'i'},\n  {\"size\", 1, NULL, 's'},\n  {\"verify\", 0, NULL, 'v'},\n  {0,0,0,0}\n};\n\nextern void\nlud_cuda(float *d_m, int matrix_dim);\n\n#ifdef TIMING\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nint\nmain ( int argc, char *argv[] )\n{\n  printf(\"WG size of kernel = %d X %d\\n\", BLOCK_SIZE, BLOCK_SIZE);\n\n  int matrix_dim = 32; /* default matrix_dim */\n  int opt, option_index=0;\n  func_ret_t ret;\n  const char *input_file = NULL;\n  float *m, *d_m, *mm;\n  stopwatch sw;\n\n  while ((opt = getopt_long(argc, argv, \"::vs:i:\", \n                            long_options, &option_index)) != -1 ) {\n    switch(opt){\n    case 'i':\n      input_file = optarg;\n      break;\n    case 'v':\n      do_verify = 1;\n      break;\n    case 's':\n      matrix_dim = atoi(optarg);\n      printf(\"Generate input matrix internally, size =%d\\n\", matrix_dim);\n      break;\n    case '?':\n      fprintf(stderr, \"invalid option\\n\");\n      break;\n    case ':':\n      fprintf(stderr, \"missing argument\\n\");\n      break;\n    default:\n      fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\",\n\t      argv[0]);\n      exit(EXIT_FAILURE);\n    }\n  }\n  \n  if ( (optind < argc) || (optind == 1)) {\n    fprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\", argv[0]);\n    exit(EXIT_FAILURE);\n  }\n\n  if (input_file) {\n    printf(\"Reading matrix from file %s\\n\", input_file);\n    ret = create_matrix_from_file(&m, input_file, &matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix from file %s\\n\", input_file);\n      exit(EXIT_FAILURE);\n    }\n  } \n  else if (matrix_dim) {\n    printf(\"Creating matrix internally size=%d\\n\", matrix_dim);\n    ret = create_matrix(&m, matrix_dim);\n    if (ret != RET_SUCCESS) {\n      m = NULL;\n      fprintf(stderr, \"error create matrix internally size=%d\\n\", matrix_dim);\n      exit(EXIT_FAILURE);\n    }\n  }\n\n\n  else {\n    printf(\"No input file specified!\\n\");\n    exit(EXIT_FAILURE);\n  }\n\n  if (do_verify){\n    printf(\"Before LUD\\n\");\n    matrix_duplicate(m, &mm, matrix_dim);\n  }\n\n  cudaMalloc((void**)&d_m, \n             matrix_dim*matrix_dim*sizeof(float));\n\n  stopwatch_start(&sw);\n  cudaMemcpy(d_m, m, matrix_dim*matrix_dim*sizeof(float), \n\t     cudaMemcpyHostToDevice);\n\n#ifdef  TIMING\n  gettimeofday(&tv_kernel_start, NULL);\n#endif\n\n  lud_cuda(d_m, matrix_dim);\n\n#ifdef  TIMING\n  gettimeofday(&tv_kernel_end, NULL);\n  tvsub(&tv_kernel_end, &tv_kernel_start, &tv);\n  kernel_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n  cudaMemcpy(m, d_m, matrix_dim*matrix_dim*sizeof(float), \n\t     cudaMemcpyDeviceToHost);\n\n  stopwatch_stop(&sw);\n  printf(\"Time consumed(ms): %lf\\n\", 1000*get_interval_by_sec(&sw));\n\n  cudaFree(d_m);\n\n\n  if (do_verify){\n    printf(\"After LUD\\n\");\n    printf(\">>>Verify<<<<\\n\");\n    lud_verify(mm, m, matrix_dim); \n    free(mm);\n  }\n\n  free(m);\n\n#ifdef  TIMING\n  printf(\"Exec: %f\\n\", kernel_time);\n#endif\n\n  return EXIT_SUCCESS;\n}\t\t\t\t/* ----------  end of function main  ---------- */\n", "lud_kernel.cu": "#include <cuda.h>\n#include <stdio.h>\n\n#ifdef RD_WG_SIZE_0_0\n        #define BLOCK_SIZE RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n        #define BLOCK_SIZE RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n        #define BLOCK_SIZE RD_WG_SIZE\n#else\n        #define BLOCK_SIZE 16\n#endif\n\n\n__global__ void \nlud_diagonal(float *m, int matrix_dim, int offset)\n{\n  int i,j;\n  __shared__ float shadow[BLOCK_SIZE][BLOCK_SIZE];\n\n  int array_offset = offset*matrix_dim+offset;\n  for(i=0; i < BLOCK_SIZE; i++){\n    shadow[i][threadIdx.x]=m[array_offset+threadIdx.x];\n    array_offset += matrix_dim;\n  }\n  __syncthreads();\n  for(i=0; i < BLOCK_SIZE-1; i++) {\n\n    if (threadIdx.x>i){\n      for(j=0; j < i; j++)\n        shadow[threadIdx.x][i] -= shadow[threadIdx.x][j]*shadow[j][i];\n      shadow[threadIdx.x][i] /= shadow[i][i];\n    }\n\n    __syncthreads();\n    if (threadIdx.x>i){\n\n      for(j=0; j < i+1; j++)\n        shadow[i+1][threadIdx.x] -= shadow[i+1][j]*shadow[j][threadIdx.x];\n    }\n    __syncthreads();\n  }\n\n\n  array_offset = (offset+1)*matrix_dim+offset;\n  for(i=1; i < BLOCK_SIZE; i++){\n    m[array_offset+threadIdx.x]=shadow[i][threadIdx.x];\n    array_offset += matrix_dim;\n  }\n}\n\n__global__ void\nlud_perimeter(float *m, int matrix_dim, int offset)\n{\n  __shared__ float dia[BLOCK_SIZE][BLOCK_SIZE];\n  __shared__ float peri_row[BLOCK_SIZE][BLOCK_SIZE];\n  __shared__ float peri_col[BLOCK_SIZE][BLOCK_SIZE];\n\n  int i,j, array_offset;\n  int idx;\n\n  if (threadIdx.x < BLOCK_SIZE) {\n    idx = threadIdx.x;\n    \n    array_offset = offset*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE/2; i++){\n      dia[i][idx]=m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n    \n    array_offset = offset*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE; i++) {\n      peri_row[i][idx]=m[array_offset+(blockIdx.x+1)*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n\n  } else {\n    idx = threadIdx.x-BLOCK_SIZE;\n    \n    array_offset = (offset+BLOCK_SIZE/2)*matrix_dim+offset;\n    for (i=BLOCK_SIZE/2; i < BLOCK_SIZE; i++){\n      dia[i][idx]=m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n    \n    array_offset = (offset+(blockIdx.x+1)*BLOCK_SIZE)*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE; i++) {\n      peri_col[i][idx] = m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n  \n  }\n  __syncthreads();\n\n  if (threadIdx.x < BLOCK_SIZE) { //peri-row\n    idx=threadIdx.x;\n    for(i=1; i < BLOCK_SIZE; i++){\n      for (j=0; j < i; j++)\n        peri_row[i][idx]-=dia[i][j]*peri_row[j][idx];\n    }\n\n    \n    array_offset = (offset+1)*matrix_dim+offset;\n    for(i=1; i < BLOCK_SIZE; i++){\n      m[array_offset+(blockIdx.x+1)*BLOCK_SIZE+idx] = peri_row[i][idx];\n      array_offset += matrix_dim;\n    }\n  } else { //peri-col\n    idx=threadIdx.x - BLOCK_SIZE;\n    for(i=0; i < BLOCK_SIZE; i++){\n      for(j=0; j < i; j++)\n        peri_col[idx][i]-=peri_col[idx][j]*dia[j][i];\n      peri_col[idx][i] /= dia[i][i];\n    }\n\n    __syncthreads();\n    \n    array_offset = (offset+(blockIdx.x+1)*BLOCK_SIZE)*matrix_dim+offset;\n    for(i=0; i < BLOCK_SIZE; i++){\n      m[array_offset+idx] =  peri_col[i][idx];\n      array_offset += matrix_dim;\n    }\n  }\n\n  if (threadIdx.x < BLOCK_SIZE) { //peri-row\n    idx=threadIdx.x;\n    for(i=1; i < BLOCK_SIZE; i++){\n      for (j=0; j < i; j++)\n        peri_row[i][idx]-=dia[i][j]*peri_row[j][idx];\n    }\n  } else { //peri-col\n    idx=threadIdx.x - BLOCK_SIZE;\n    for(i=0; i < BLOCK_SIZE; i++){\n      for(j=0; j < i; j++)\n        peri_col[idx][i]-=peri_col[idx][j]*dia[j][i];\n      peri_col[idx][i] /= dia[i][i];\n    }\n  }\n\n  __syncthreads();\n    \n  if (threadIdx.x < BLOCK_SIZE) { //peri-row\n    idx=threadIdx.x;\n    array_offset = (offset+1)*matrix_dim+offset;\n    for(i=1; i < BLOCK_SIZE; i++){\n      m[array_offset+(blockIdx.x+1)*BLOCK_SIZE+idx] = peri_row[i][idx];\n      array_offset += matrix_dim;\n    }\n  } else { //peri-col\n    idx=threadIdx.x - BLOCK_SIZE;\n    array_offset = (offset+(blockIdx.x+1)*BLOCK_SIZE)*matrix_dim+offset;\n    for(i=0; i < BLOCK_SIZE; i++){\n      m[array_offset+idx] =  peri_col[i][idx];\n      array_offset += matrix_dim;\n    }\n  }\n\n}\n\n__global__ void\nlud_internal(float *m, int matrix_dim, int offset)\n{\n  __shared__ float peri_row[BLOCK_SIZE][BLOCK_SIZE];\n  __shared__ float peri_col[BLOCK_SIZE][BLOCK_SIZE];\n\n  int i;\n  float sum;\n\n  int global_row_id = offset + (blockIdx.y+1)*BLOCK_SIZE;\n  int global_col_id = offset + (blockIdx.x+1)*BLOCK_SIZE;\n\n  peri_row[threadIdx.y][threadIdx.x] = m[(offset+threadIdx.y)*matrix_dim+global_col_id+threadIdx.x];\n  peri_col[threadIdx.y][threadIdx.x] = m[(global_row_id+threadIdx.y)*matrix_dim+offset+threadIdx.x];\n\n  __syncthreads();\n\n  sum = 0;\n  for (i=0; i < BLOCK_SIZE; i++)\n    sum += peri_col[threadIdx.y][i] * peri_row[i][threadIdx.x];\n  m[(global_row_id+threadIdx.y)*matrix_dim+global_col_id+threadIdx.x] -= sum;\n\n\n}\n\n\nvoid lud_cuda(float *m, int matrix_dim)\n{\n  int i=0;\n  dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n  float *m_debug = (float*)malloc(matrix_dim*matrix_dim*sizeof(float));\n\n  for (i=0; i < matrix_dim-BLOCK_SIZE; i += BLOCK_SIZE) {\n      lud_diagonal<<<1, BLOCK_SIZE>>>(m, matrix_dim, i);\n      lud_perimeter<<<(matrix_dim-i)/BLOCK_SIZE-1, BLOCK_SIZE*2>>>(m, matrix_dim, i);\n      dim3 dimGrid((matrix_dim-i)/BLOCK_SIZE-1, (matrix_dim-i)/BLOCK_SIZE-1);\n      lud_internal<<<dimGrid, dimBlock>>>(m, matrix_dim, i); \n  }\n  lud_diagonal<<<1,BLOCK_SIZE>>>(m, matrix_dim, i);\n}\n\n"}, "code_dirs": {"lud.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/lud/cuda", "lud_kernel.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/lud/cuda"}}
{"kernel_name": "lud", "parallel_api": "ocl", "code": {"lud.cpp": "#include <stdio.h>\n#include <unistd.h>\n#include <getopt.h>\n#include <stdlib.h>\n#include <assert.h>\n\n#include \"common.h\"\n#include <sys/time.h>\n#include <CL/cl.h>\n#include \"timing.h\"\n\n#include <string.h>\n#include <string>\n#ifdef RD_WG_SIZE_0_0\n        #define BLOCK_SIZE RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n        #define BLOCK_SIZE RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n        #define BLOCK_SIZE RD_WG_SIZE\n#else\n        #define BLOCK_SIZE 16\n#endif\n\nstatic cl_context\t    context;\nstatic cl_command_queue cmd_queue;\nstatic cl_device_type   device_type;\nstatic cl_device_id   * device_list;\nstatic cl_uint          num_devices;\nstatic cl_uint          num_platforms;\n\nstatic int initialize(int platform_id_inuse, int device_id_inuse)\n{\n\tif (clGetPlatformIDs(0, NULL, &num_platforms) != CL_SUCCESS) { printf(\"ERROR: clGetPlatformIDs(0,0,*) failed\\n\"); return -1; }\n\tcl_platform_id all_platform_id[num_platforms];\n\tif (clGetPlatformIDs(num_platforms, all_platform_id, NULL) != CL_SUCCESS) { printf(\"ERROR: clGetPlatformIDs(*,*,0) failed\\n\"); return -1; }\n    cl_platform_id platform_id = all_platform_id[platform_id_inuse];\n\n    if (clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_ALL, 0, NULL, &num_devices) != CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\tprintf(\"num_devices = %d\\n\", num_devices);\n    if (device_id_inuse > (int)num_devices) {\n        printf(\"Invalid Device Number\\n\");\n        return -1;\n    }\n\tcl_device_id *device_list = new cl_device_id[num_devices];\n\tif( !device_list ) { printf(\"ERROR: new cl_device_id[] failed\\n\"); return -1; }\n    if (clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_ALL, num_devices, device_list, NULL) != CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\n    if (clGetDeviceInfo(device_list[device_id_inuse], CL_DEVICE_TYPE, sizeof(device_type), (void *)&device_type, NULL)!= CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\n\tcl_context_properties ctxprop[] = { CL_CONTEXT_PLATFORM, (cl_context_properties)platform_id, 0};\n\tcontext = clCreateContextFromType( ctxprop, device_type, NULL, NULL, NULL );\n\tif( !context ) { printf(\"ERROR: clCreateContextFromType(%s) failed\\n\", device_type == CL_DEVICE_TYPE_GPU ? \"GPU\" : \"CPU\"); return -1; }\n\tprintf(\"Create %s context\\n\", device_type == CL_DEVICE_TYPE_GPU ? \"GPU\" : \"CPU\");\n\n#ifdef TIMING\n        cmd_queue = clCreateCommandQueue( context, device_list[device_id_inuse], CL_QUEUE_PROFILING_ENABLE, NULL );\n#else\n        cmd_queue = clCreateCommandQueue( context, device_list[device_id_inuse], 0, NULL );\n#endif\n\tif( !cmd_queue ) { printf(\"ERROR: clCreateCommandQueue() failed\\n\"); return -1; }\n\treturn 0;\n}\n\nstatic int shutdown()\n{\n\tif( cmd_queue ) clReleaseCommandQueue( cmd_queue );\n\tif( context ) clReleaseContext( context );\n\tif( device_list ) delete device_list;\n\n\tcmd_queue = 0;\n\tcontext = 0;\n\tdevice_list = 0;\n\tnum_devices = 0;\n\tdevice_type = 0;\n\n\treturn 0;\n}\n\nstatic int do_verify = 0;\nvoid lud_cuda(float *d_m, int matrix_dim);\n\nstatic struct option long_options[] = {\n      /* name, has_arg, flag, val */\n      {\"input\", 1, NULL, 'i'},\n      {\"size\", 1, NULL, 's'},\n      {\"verify\", 0, NULL, 'v'},\n      {\"platform\", 1, NULL, 'p'},\n      {\"device\", 1, NULL, 'd'},\n      {0,0,0,0}\n};\n\nint\nmain ( int argc, char *argv[] )\n{\n#ifdef TIMING\n    struct timeval tv;\n    struct timeval tv_total_start;\n    struct timeval tv_init_end;\n    struct timeval tv_mem_alloc_end;\n    struct timeval tv_close_start, tv_close_end;\n    float init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n          d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\n    printf(\"WG size of kernel = %d X %d\\n\", BLOCK_SIZE, BLOCK_SIZE);\n\tsize_t matrix_dim = 32; /* default matrix_dim */\n\tint opt, option_index=0;\n\tfunc_ret_t ret;\n\tconst char *input_file = NULL;\n\tfloat *m, *mm;\n\tstopwatch sw;\n\tint platform_id_inuse = 0;\n\tint device_id_inuse = 0;\n\n\twhile ((opt = getopt_long(argc, argv, \"::vs:i:p:d:\", \n                            long_options, &option_index)) != -1 ) {\n\t\tswitch(opt){\n\t\t\tcase 'i':\n\t\t\tinput_file = optarg;\n\t\t\tbreak;\n\t\t\tcase 'v':\n\t\t\tdo_verify = 1;\n\t\t\tbreak;\n        case 's':\n\t\t\tmatrix_dim = atoi(optarg);\n\t\t\tprintf(\"Generate input matrix internally, size =%lu\\n\", matrix_dim);\n\t\t\tbreak;\n        case 'p':\n\t\t\tplatform_id_inuse = atoi(optarg);\n            break;\n        case 'd':\n\t\t\tdevice_id_inuse = atoi(optarg);\n            break;\n        case '?':\n\t\t\tfprintf(stderr, \"invalid option\\n\");\n\t\t\tbreak;\n        case ':':\n\t\t\tfprintf(stderr, \"missing argument\\n\");\n\t\t\tbreak;\n        default:\n\t\t\tfprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\",\n                  argv[0]);\n\t\t\texit(EXIT_FAILURE);\n\t\t}\n\t}\n  \n\tif ( (optind < argc) || (optind == 1)) {\n\t\tfprintf(stderr, \"Usage: %s [-v] [-s matrix_size|-i input_file]\\n\", argv[0]);\n\t\texit(EXIT_FAILURE);\n\t}\t\n\n\tif (input_file) {\n\t\tprintf(\"Reading matrix from file %s\\n\", input_file);\n\t\tret = create_matrix_from_file(&m, input_file, &matrix_dim);\n\t\tif (ret != RET_SUCCESS) {\n\t\t\tm = NULL;\n\t\t\tfprintf(stderr, \"error create matrix from file %s\\n\", input_file);\n\t\t\texit(EXIT_FAILURE);\n\t\t}\n\t} \n\t\n\telse if (matrix_dim) {\n\t  printf(\"Creating matrix internally size=%lu\\n\", matrix_dim);\n\t  ret = create_matrix(&m, matrix_dim);\n\t  if (ret != RET_SUCCESS) {\n\t    m = NULL;\n\t    fprintf(stderr, \"error create matrix internally size=%lu\\n\", matrix_dim);\n\t    exit(EXIT_FAILURE);\n\t  }\n\t}\n\n\telse {\n\t  printf(\"No input file specified!\\n\");\n\t  exit(EXIT_FAILURE);\n\t}\n\n\tif (do_verify){\n\t\tprintf(\"Before LUD\\n\");\n\t\tmatrix_duplicate(m, &mm, matrix_dim);\n\t}\n\t\n\tint sourcesize = 1024*1024;\n\tchar * source = (char *)calloc(sourcesize, sizeof(char)); \n\tif(!source) { printf(\"ERROR: calloc(%d) failed\\n\", sourcesize); return -1; }\n\n\tconst char * kernel_lud_diag   = \"lud_diagonal\";\n\tconst char * kernel_lud_peri   = \"lud_perimeter\";\n\tconst char * kernel_lud_inter  = \"lud_internal\";\n\tFILE * fp = fopen(\"./lud_kernel.cl\", \"rb\"); \n\tif(!fp) { printf(\"ERROR: unable to open '%s'\\n\", \"./lud_kernel.cl\"); return -1; }\n\tfread(source + strlen(source), sourcesize, 1, fp);\n\tfclose(fp);\n\n#ifdef  TIMING\n    gettimeofday(&tv_total_start, NULL);\n#endif\n\tif(initialize(platform_id_inuse, device_id_inuse)) return -1;\n\n\tcl_int err = 0;\n\tconst char * slist[2] = { source, 0 };\n\tcl_program prog = clCreateProgramWithSource(context, 1, slist, NULL, &err);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateProgramWithSource() => %d\\n\", err); return -1; }\n\tchar clOptions[110];\n\tsprintf(clOptions,\" \");\n#ifdef BLOCK_SIZE\n\tsprintf(clOptions + strlen(clOptions), \" -DBLOCK_SIZE=%d\", BLOCK_SIZE);\n#endif\n\n\terr = clBuildProgram(prog, 0, NULL, clOptions, NULL, NULL);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clBuildProgram() => %d\\n\", err); return -1; }\n    \n\tcl_kernel diagnal;\n\tcl_kernel perimeter;\n\tcl_kernel internal;\n\tdiagnal   = clCreateKernel(prog, kernel_lud_diag, &err);  \n\tperimeter = clCreateKernel(prog, kernel_lud_peri, &err);  \n\tinternal  = clCreateKernel(prog, kernel_lud_inter, &err);  \n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateKernel() 0 => %d\\n\", err); return -1; }\n\tclReleaseProgram(prog);\n\n#ifdef  TIMING\n    gettimeofday(&tv_init_end, NULL);\n    tvsub(&tv_init_end, &tv_total_start, &tv);\n    init_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tcl_mem d_m;\n\td_m = clCreateBuffer(context, CL_MEM_READ_WRITE, matrix_dim*matrix_dim * sizeof(float), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer d_m (size:%lu) => %d\\n\", matrix_dim*matrix_dim, err); return -1;} \n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_init_end, &tv);\n    mem_alloc_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tstopwatch_start(&sw);\n\tcl_event event;\n\terr = clEnqueueWriteBuffer(cmd_queue, d_m, 1, 0, matrix_dim*matrix_dim*sizeof(float), m, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer d_m (size:%lu) => %d\\n\", matrix_dim*matrix_dim, err); return -1; }\n#ifdef TIMING\n    h2d_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\t\n\tsize_t i=0;\n\tfor (i=0; i < matrix_dim-BLOCK_SIZE; i += BLOCK_SIZE) {\n\t \n\t  clSetKernelArg(diagnal, 0, sizeof(void *), (void*) &d_m);\n\t  clSetKernelArg(diagnal, 1, sizeof(float) * BLOCK_SIZE * BLOCK_SIZE, (void*)NULL );\n\t  clSetKernelArg(diagnal, 2, sizeof(cl_int), (void*) &matrix_dim);\n\t  clSetKernelArg(diagnal, 3, sizeof(cl_int), (void*) &i);\n      \n\t  size_t global_work1[3]  = {BLOCK_SIZE, 1, 1};\n\t  size_t local_work1[3]  = {BLOCK_SIZE, 1, 1};\n\t   \n\t  err = clEnqueueNDRangeKernel(cmd_queue, diagnal, 2, NULL, global_work1, local_work1, 0, 0, &event);\n\t  if(err != CL_SUCCESS) { printf(\"ERROR:  diagnal clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\t\n#ifdef TIMING\n      kernel_time += probe_event_time(event,cmd_queue);\n#endif\n      clReleaseEvent(event);\n\t  \n\t  clSetKernelArg(perimeter, 0, sizeof(void *), (void*) &d_m);\n\t  clSetKernelArg(perimeter, 1, sizeof(float) * BLOCK_SIZE * BLOCK_SIZE, (void*)NULL );\n\t  clSetKernelArg(perimeter, 2, sizeof(float) * BLOCK_SIZE * BLOCK_SIZE, (void*)NULL );\n\t  clSetKernelArg(perimeter, 3, sizeof(float) * BLOCK_SIZE * BLOCK_SIZE, (void*)NULL );\n\t  clSetKernelArg(perimeter, 4, sizeof(cl_int), (void*) &matrix_dim);\n\t  clSetKernelArg(perimeter, 5, sizeof(cl_int), (void*) &i);\n\t  \n\t  size_t global_work2[3] = {BLOCK_SIZE * 2 * ((matrix_dim-i)/BLOCK_SIZE-1), 1, 1};\n\t  size_t local_work2[3]  = {BLOCK_SIZE * 2, 1, 1};\n      if (global_work2[0] > 0) {\n          err = clEnqueueNDRangeKernel(cmd_queue, perimeter, 2, NULL, global_work2, local_work2, 0, 0, &event);\n          if(err != CL_SUCCESS) { printf(\"ERROR:  perimeter clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\t\n#ifdef TIMING\n          kernel_time += probe_event_time(event,cmd_queue);\n#endif\n          clReleaseEvent(event);\n      }\n\t  \n\t  clSetKernelArg(internal, 0, sizeof(void *), (void*) &d_m);\n\t  clSetKernelArg(internal, 1, sizeof(float) * BLOCK_SIZE * BLOCK_SIZE, (void*)NULL );\n\t  clSetKernelArg(internal, 2, sizeof(float) * BLOCK_SIZE * BLOCK_SIZE, (void*)NULL );\n\t  clSetKernelArg(internal, 3, sizeof(cl_int), (void*) &matrix_dim);\n\t  clSetKernelArg(internal, 4, sizeof(cl_int), (void*) &i);\n      \n\t  size_t global_work3[3] = {BLOCK_SIZE * ((matrix_dim-i)/BLOCK_SIZE-1), BLOCK_SIZE * ((matrix_dim-i)/BLOCK_SIZE-1), 1};\n\t  size_t local_work3[3] = {BLOCK_SIZE, BLOCK_SIZE, 1};\n      if (global_work3[0] > 0) {\n          err = clEnqueueNDRangeKernel(cmd_queue, internal, 2, NULL, global_work3, local_work3, 0, 0, &event);\n          if(err != CL_SUCCESS) { printf(\"ERROR:  internal clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\t\n#ifdef TIMING\n          kernel_time += probe_event_time(event,cmd_queue);\n#endif\n          clReleaseEvent(event);\n      }\n\t}\n\tclSetKernelArg(diagnal, 0, sizeof(void *), (void*) &d_m);\n\tclSetKernelArg(diagnal, 1, sizeof(float) * BLOCK_SIZE * BLOCK_SIZE, (void*)NULL );\n\tclSetKernelArg(diagnal, 2, sizeof(cl_int), (void*) &matrix_dim);\n\tclSetKernelArg(diagnal, 3, sizeof(cl_int), (void*) &i);\n      \n\tsize_t global_work1[3]  = {BLOCK_SIZE, 1, 1};\n\tsize_t local_work1[3]  = {BLOCK_SIZE, 1, 1};\n\terr = clEnqueueNDRangeKernel(cmd_queue, diagnal, 2, NULL, global_work1, local_work1, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR:  diagnal clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\t\n#ifdef TIMING\n    kernel_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\tclFinish(cmd_queue);\n\terr = clEnqueueReadBuffer(cmd_queue, d_m, 1, 0, matrix_dim*matrix_dim*sizeof(float), m, 0, 0, &event);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueReadBuffer  d_m (size:%lu) => %d\\n\", matrix_dim*matrix_dim, err); return -1; }\n#ifdef TIMING\n    d2h_time += probe_event_time(event,cmd_queue);\n#endif\n    clReleaseEvent(event);\n\n\tclFinish(cmd_queue);\n\n#ifdef  TIMING\n    gettimeofday(&tv_close_start, NULL);\n#endif\n\tclReleaseMemObject(d_m);\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\ttvsub(&tv_close_end, &tv_total_start, &tv);\n\ttotal_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n\tprintf(\"Init: %f\\n\", init_time);\n\tprintf(\"MemAlloc: %f\\n\", mem_alloc_time);\n\tprintf(\"HtoD: %f\\n\", h2d_time);\n\tprintf(\"Exec: %f\\n\", kernel_time);\n\tprintf(\"DtoH: %f\\n\", d2h_time);\n\tprintf(\"Close: %f\\n\", close_time);\n\tprintf(\"Total: %f\\n\", total_time);\n#endif\n\n\tif (do_verify){\n\t\tprintf(\"After LUD\\n\");\n\t\tprintf(\">>>Verify<<<<\\n\");\n\t\tlud_verify(mm, m, matrix_dim); \n\t\tfree(mm);\n\t}\n\n\tfree(m);\n\t\n\tif(shutdown()) return -1;\n\t\n}\t\t\t\t\n\n", "lud_kernel.cl": "// #define BLOCK_SIZE 16\n__kernel void \nlud_diagonal(__global float *m, \n\t\t\t __local  float *shadow,\n\t\t\t int   matrix_dim, \n\t\t\t int   offset)\n{ \n\tint i,j;\n\tint tx = get_local_id(0);\n\n\tint array_offset = offset*matrix_dim+offset;\n\tfor(i=0; i < BLOCK_SIZE; i++){\n\t\tshadow[i * BLOCK_SIZE + tx]=m[array_offset + tx];\n\t\tarray_offset += matrix_dim;\n\t}\n  \n\tbarrier(CLK_LOCAL_MEM_FENCE);\n  \n\tfor(i=0; i < BLOCK_SIZE-1; i++) {\n\n    if (tx>i){\n      for(j=0; j < i; j++)\n        shadow[tx * BLOCK_SIZE + i] -= shadow[tx * BLOCK_SIZE + j] * shadow[j * BLOCK_SIZE + i];\n\t\tshadow[tx * BLOCK_SIZE + i] /= shadow[i * BLOCK_SIZE + i];\n    }\n\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n    if (tx>i){\n\n      for(j=0; j < i+1; j++)\n        shadow[(i+1) * BLOCK_SIZE + tx] -= shadow[(i+1) * BLOCK_SIZE + j]*shadow[j * BLOCK_SIZE + tx];\n    }\n    \n\tbarrier(CLK_LOCAL_MEM_FENCE);\n    }\n\n    array_offset = (offset+1)*matrix_dim+offset;\n    for(i=1; i < BLOCK_SIZE; i++){\n      m[array_offset+tx]=shadow[i * BLOCK_SIZE + tx];\n      array_offset += matrix_dim;\n    }\n  \n}\n\n__kernel void\nlud_perimeter(__global float *m, \n\t\t\t  __local  float *dia,\n\t\t\t  __local  float *peri_row,\n\t\t\t  __local  float *peri_col,\n\t\t\t  int matrix_dim, \n\t\t\t  int offset)\n{\n    int i,j, array_offset;\n    int idx;\n\n    int  bx = get_group_id(0);\t\n    int  tx = get_local_id(0);\n\n    if (tx < BLOCK_SIZE) {\n      idx = tx;\n      array_offset = offset*matrix_dim+offset;\n      for (i=0; i < BLOCK_SIZE/2; i++){\n      dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n      array_offset += matrix_dim;\n      }\n    \n    array_offset = offset*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE; i++) {\n      peri_row[i * BLOCK_SIZE+ idx]=m[array_offset+(bx+1)*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n\n    } else {\n    idx = tx-BLOCK_SIZE;\n    \n    array_offset = (offset+BLOCK_SIZE/2)*matrix_dim+offset;\n    for (i=BLOCK_SIZE/2; i < BLOCK_SIZE; i++){\n      dia[i * BLOCK_SIZE + idx]=m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n    \n    array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n    for (i=0; i < BLOCK_SIZE; i++) {\n      peri_col[i * BLOCK_SIZE + idx] = m[array_offset+idx];\n      array_offset += matrix_dim;\n    }\n  \n   }\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    if (tx < BLOCK_SIZE) { //peri-row\n     idx=tx;\n      for(i=1; i < BLOCK_SIZE; i++){\n      for (j=0; j < i; j++)\n        peri_row[i * BLOCK_SIZE + idx]-=dia[i * BLOCK_SIZE+ j]*peri_row[j * BLOCK_SIZE + idx];\n    }\n    } else { //peri-col\n     idx=tx - BLOCK_SIZE;\n     for(i=0; i < BLOCK_SIZE; i++){\n      for(j=0; j < i; j++)\n        peri_col[idx * BLOCK_SIZE + i]-=peri_col[idx * BLOCK_SIZE+ j]*dia[j * BLOCK_SIZE + i];\n      peri_col[idx * BLOCK_SIZE + i] /= dia[i * BLOCK_SIZE+ i];\n     }\n   }\n\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n    \n  if (tx < BLOCK_SIZE) { //peri-row\n    idx=tx;\n    array_offset = (offset+1)*matrix_dim+offset;\n    for(i=1; i < BLOCK_SIZE; i++){\n      m[array_offset+(bx+1)*BLOCK_SIZE+idx] = peri_row[i*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n  } else { //peri-col\n    idx=tx - BLOCK_SIZE;\n    array_offset = (offset+(bx+1)*BLOCK_SIZE)*matrix_dim+offset;\n    for(i=0; i < BLOCK_SIZE; i++){\n      m[array_offset+idx] =  peri_col[i*BLOCK_SIZE+idx];\n      array_offset += matrix_dim;\n    }\n  }\n\n}\n\n__kernel void\nlud_internal(__global float *m, \n\t\t\t __local  float *peri_row,\n\t\t\t __local  float *peri_col,\n\t\t\tint matrix_dim, \n\t\t\tint offset)\n{\n  \n  int  bx = get_group_id(0);\t\n  int  by = get_group_id(1);\t\n  \n  int  tx = get_local_id(0);\n  int  ty = get_local_id(1);\n\n  int i;\n  float sum;\n\n  int global_row_id = offset + (by+1)*BLOCK_SIZE;\n  int global_col_id = offset + (bx+1)*BLOCK_SIZE;\n\n  peri_row[ty * BLOCK_SIZE + tx] = m[(offset+ty)*matrix_dim+global_col_id+tx];\n  peri_col[ty * BLOCK_SIZE + tx] = m[(global_row_id+ty)*matrix_dim+offset+tx];\n\n  barrier(CLK_LOCAL_MEM_FENCE);\n\n  sum = 0;\n  for (i=0; i < BLOCK_SIZE; i++)\n    sum += peri_col[ty * BLOCK_SIZE + i] * peri_row[i * BLOCK_SIZE + tx];\n  m[(global_row_id+ty)*matrix_dim+global_col_id+tx] -= sum;\n\n\n}\n"}, "code_dirs": {"lud.cpp": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/lud/ocl", "lud_kernel.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/lud"}}
{"kernel_name": "hybridsort_bucket", "parallel_api": "cuda", "code": {"bucketsort.cu": "#ifdef _WIN32\n#  define WINDOWS_LEAN_AND_MEAN\n#  define NOMINMAX\n#  include <windows.h>\n#endif\n\n#include <GL/glew.h>\n#include <GL/glut.h>\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include \"helper_cuda.h\"\n#include <cuda_gl_interop.h>\n#include \"bucketsort.cuh\"\n#include \"bucketsort_kernel.cu\"\n#include \"histogram1024_kernel.cu\"\n\nvoid calcPivotPoints(float *histogram, int histosize, int listsize, \n\t\t\t\t\t int divisions, float min, float max, float *pivotPoints, \n\t\t\t\t\t float histo_width);\n\nconst int histosize = 1024; \nunsigned int* h_offsets = NULL; \nunsigned int* d_offsets = NULL; \nint *d_indice = NULL; \nfloat *pivotPoints = NULL; \nfloat *historesult = NULL; \nfloat *l_pivotpoints = NULL; \nunsigned int *d_prefixoffsets = NULL; \nunsigned int *l_offsets = NULL; \n\nvoid init_bucketsort(int listsize)\n{\n\th_offsets = (unsigned int *) malloc(histosize * sizeof(int)); \n    checkCudaErrors(cudaMalloc((void**) &d_offsets, histosize * sizeof(unsigned int)));\n\tpivotPoints = (float *)malloc(DIVISIONS * sizeof(float)); \n\n    checkCudaErrors(cudaMalloc((void**) &d_indice, listsize * sizeof(int)));\n\thistoresult = (float *)malloc(histosize * sizeof(float)); \n\n\tcheckCudaErrors(cudaMalloc((void**) &l_pivotpoints, DIVISIONS * sizeof(float))); \n\tcheckCudaErrors(cudaMalloc((void**) &l_offsets, DIVISIONS * sizeof(int))); \n\n\tint blocks = ((listsize - 1) / (BUCKET_THREAD_N * BUCKET_BAND)) + 1; \n\tcheckCudaErrors(cudaMalloc((void**) &d_prefixoffsets, blocks * BUCKET_BLOCK_MEMORY * sizeof(int))); \n\n\tinitHistogram1024();\n}\n\nvoid finish_bucketsort()\n{\n    checkCudaErrors(cudaFree(d_indice));\n\tcheckCudaErrors(cudaFree(d_offsets));\n\tcheckCudaErrors(cudaFree(l_pivotpoints));\n\tcheckCudaErrors(cudaFree(l_offsets)); \n\tfree(pivotPoints); \n\tfree(h_offsets);\n\tfree(historesult);\t\n\tcheckCudaErrors(cudaFree(d_prefixoffsets)); \n\tcloseHistogram1024();\n}\n\nvoid bucketSort(float *d_input, float *d_output, int listsize,\n\t\t\t\tint *sizes, int *nullElements, float minimum, float maximum, \n\t\t\t\tunsigned int *origOffsets)\n{\n\tcheckCudaErrors(cudaMemset((void *) d_offsets, 0, histosize * sizeof(int))); \n\thistogram1024GPU(h_offsets, d_input, minimum, maximum, listsize); \n\tfor(int i=0; i<histosize; i++) historesult[i] = (float)h_offsets[i];\n\n\tcalcPivotPoints(historesult, histosize, listsize, DIVISIONS, \n\t\t\tminimum, maximum, pivotPoints,\n\t\t\t(maximum - minimum)/(float)histosize); \n\tcheckCudaErrors(cudaMemcpy(l_pivotpoints, pivotPoints, (DIVISIONS)*sizeof(int), cudaMemcpyHostToDevice)); \n\tcheckCudaErrors(cudaMemset((void *) d_offsets, 0, DIVISIONS * sizeof(int))); \n\tcheckCudaErrors(cudaBindTexture(0, texPivot, l_pivotpoints, DIVISIONS * sizeof(int))); \n    dim3 threads(BUCKET_THREAD_N, 1);\n\tint blocks = ((listsize - 1) / (threads.x * BUCKET_BAND)) + 1; \n    dim3 grid(blocks, 1);\n\tbucketcount <<< grid, threads >>>(d_input, d_indice, d_prefixoffsets, listsize);\n#ifdef BUCKET_WG_SIZE_0\nthreads.x = BUCKET_WG_SIZE_0;\n#else\n\tthreads.x = 128;  \n#endif\n\tgrid.x = DIVISIONS / threads.x; \n\tbucketprefixoffset <<< grid, threads >>>(d_prefixoffsets, d_offsets, blocks); \t\n\n\tcudaMemcpy(h_offsets, d_offsets, DIVISIONS * sizeof(int), cudaMemcpyDeviceToHost);\n\n\torigOffsets[0] = 0;\n\tfor(int i=0; i<DIVISIONS; i++){\n\t\torigOffsets[i+1] = h_offsets[i] + origOffsets[i]; \n\t\tif((h_offsets[i] % 4) != 0){\n\t\t\tnullElements[i] = (h_offsets[i] & ~3) + 4 - h_offsets[i]; \n\t\t}\n\t\telse nullElements[i] = 0; \n\t}\n\tfor(int i=0; i<DIVISIONS; i++) sizes[i] = (h_offsets[i] + nullElements[i])/4; \n\tfor(int i=0; i<DIVISIONS; i++) {\n\t\tif((h_offsets[i] % 4) != 0)\th_offsets[i] = (h_offsets[i] & ~3) + 4; \n\t}\n\tfor(int i=1; i<DIVISIONS; i++) h_offsets[i] = h_offsets[i-1] + h_offsets[i]; \n\tfor(int i=DIVISIONS - 1; i>0; i--) h_offsets[i] = h_offsets[i-1]; \n\th_offsets[0] = 0; \n\tcudaMemcpy(l_offsets, h_offsets, (DIVISIONS)*sizeof(int), cudaMemcpyHostToDevice); \n\tcudaMemset(d_output, 0x0, (listsize + (DIVISIONS*4))*sizeof(float)); \n    threads.x = BUCKET_THREAD_N; \n\tblocks = ((listsize - 1) / (threads.x * BUCKET_BAND)) + 1; \n    grid.x = blocks; \n\tbucketsort <<< grid, threads >>>(d_input, d_indice, d_output, listsize, d_prefixoffsets, l_offsets);\n}\n\n\nvoid calcPivotPoints(float *histogram, int histosize, int listsize, \n\t\t\t\t\t int divisions, float min, float max, float *pivotPoints, float histo_width)\n{\n\tfloat elemsPerSlice = listsize/(float)divisions; \n\tfloat startsAt = min; \n\tfloat endsAt = min + histo_width; \n\tfloat we_need = elemsPerSlice; \n\tint p_idx = 0; \n\tfor(int i=0; i<histosize; i++)\n\t{\n\t\tif(i == histosize - 1){\n\t\t\tif(!(p_idx < divisions)){\n\t\t\t\tpivotPoints[p_idx++] = startsAt + (we_need/histogram[i]) * histo_width;\n\t\t\t}\n\t\t\tbreak; \n\t\t}\n\t\twhile(histogram[i] > we_need){\n\t\t\tif(!(p_idx < divisions)){\n\t\t\t\tprintf(\"i=%d, p_idx = %d, divisions = %d\\n\", i, p_idx, divisions); \n\t\t\t\texit(0);\n\t\t\t}\n\t\t\tpivotPoints[p_idx++] = startsAt + (we_need/histogram[i]) * histo_width;\n\t\t\tstartsAt += (we_need/histogram[i]) * histo_width; \n\t\t\thistogram[i] -= we_need; \n\t\t\twe_need = elemsPerSlice; \n\t\t}\n\t\twe_need -= histogram[i]; \n\n\t\tstartsAt = endsAt; \n\t\tendsAt += histo_width; \n\t}\n\twhile(p_idx < divisions){\n\t\tpivotPoints[p_idx] = pivotPoints[p_idx-1]; \n\t\tp_idx++; \n\t}\n}\n\n", "bucketsort_kernel.cu": "#ifndef _BUCKETSORT_KERNEL_H_\n#define _BUCKETSORT_KERNEL_H_\n\n#include <stdio.h>\n\n#define BUCKET_WARP_LOG_SIZE\t5\n#define BUCKET_WARP_N\t\t\t1\n#ifdef BUCKET_WG_SIZE_1\n#define BUCKET_THREAD_N BUCKET_WG_SIZE_1\n#else\n#define BUCKET_THREAD_N\t\t\t(BUCKET_WARP_N << BUCKET_WARP_LOG_SIZE)\n#endif\n#define BUCKET_BLOCK_MEMORY\t\t(DIVISIONS * BUCKET_WARP_N)\n#define BUCKET_BAND\t\t\t\t128\n\ntexture<float, 1, cudaReadModeElementType> texPivot; \n\n__device__ int addOffset(volatile unsigned int *s_offset, unsigned int data, unsigned int threadTag){\n    unsigned int count;\n\n    do{\n        count = s_offset[data] & 0x07FFFFFFU;\n        count = threadTag | (count + 1);\n        s_offset[data] = count;\n    }while(s_offset[data] != count);\n\n\treturn (count & 0x07FFFFFFU) - 1;\n}\n\n__global__ void\nbucketcount( float *input, int *indice, unsigned int *d_prefixoffsets, int size)\n{\n\tvolatile __shared__ unsigned int s_offset[BUCKET_BLOCK_MEMORY]; \n\n    const unsigned int threadTag = threadIdx.x << (32 - BUCKET_WARP_LOG_SIZE);\n    const int warpBase = (threadIdx.x >> BUCKET_WARP_LOG_SIZE) * DIVISIONS; \n    const int numThreads = blockDim.x * gridDim.x;\n\tfor (int i = threadIdx.x; i < BUCKET_BLOCK_MEMORY; i += blockDim.x)\n\t\ts_offset[i] = 0; \n\n\t__syncthreads(); \n\n\tfor (int tid = blockIdx.x * blockDim.x + threadIdx.x; tid < size; tid += numThreads) {\n\t\tfloat elem = input[tid]; \n\n\t\tint idx  = DIVISIONS/2 - 1; \n\t\tint jump = DIVISIONS/4; \n\t\tfloat piv = tex1Dfetch(texPivot, idx); //s_pivotpoints[idx]; \n\n\t\twhile(jump >= 1){\n\t\t\tidx = (elem < piv) ? (idx - jump) : (idx + jump);\n\t\t\tpiv = tex1Dfetch(texPivot, idx); //s_pivotpoints[idx]; \n\t\t\tjump /= 2; \n\t\t}\n\t\tidx = (elem < piv) ? idx : (idx + 1); \n\n\t\tindice[tid] = (addOffset(s_offset + warpBase, idx, threadTag) << LOG_DIVISIONS) + idx;  //atomicInc(&offsets[idx], size + 1);\n\t}\n\n\t__syncthreads(); \n\n\tint prefixBase = blockIdx.x * BUCKET_BLOCK_MEMORY; \n\n\tfor (int i = threadIdx.x; i < BUCKET_BLOCK_MEMORY; i += blockDim.x)\n\t\td_prefixoffsets[prefixBase + i] = s_offset[i] & 0x07FFFFFFU; \n}\n\n__global__ void bucketprefixoffset(unsigned int *d_prefixoffsets, unsigned int *d_offsets, int blocks) {\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x; \n\tint size = blocks * BUCKET_BLOCK_MEMORY; \n\tint sum = 0; \n\n\tfor (int i = tid; i < size; i += DIVISIONS) {\n\t\tint x = d_prefixoffsets[i]; \n\t\td_prefixoffsets[i] = sum; \n\t\tsum += x; \n\t}\n\n\td_offsets[tid] = sum; \n}\n\n__global__ void\nbucketsort(float *input, int *indice, float *output, int size, unsigned int *d_prefixoffsets, \n\t\t   unsigned int *l_offsets)\n{\n\tvolatile __shared__ unsigned int s_offset[BUCKET_BLOCK_MEMORY]; \n\n\tint prefixBase = blockIdx.x * BUCKET_BLOCK_MEMORY; \n    const int warpBase = (threadIdx.x >> BUCKET_WARP_LOG_SIZE) * DIVISIONS; \n    const int numThreads = blockDim.x * gridDim.x;\n\tfor (int i = threadIdx.x; i < BUCKET_BLOCK_MEMORY; i += blockDim.x)\n\t\ts_offset[i] = l_offsets[i & (DIVISIONS - 1)] + d_prefixoffsets[prefixBase + i]; \n\n\t__syncthreads(); \n\n\tfor (int tid = blockIdx.x * blockDim.x + threadIdx.x; tid < size; tid += numThreads) {\n\n\t\tfloat elem = input[tid]; \n\t\tint id = indice[tid]; \n\n\t\toutput[s_offset[warpBase + (id & (DIVISIONS - 1))] + (id >> LOG_DIVISIONS)] = elem;\n\t\tint test = s_offset[warpBase + (id & (DIVISIONS - 1))] + (id >> LOG_DIVISIONS);\n\n\t}\n}\n\n#endif \n"}, "code_dirs": {"bucketsort.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/hybridsort_bucket", "bucketsort_kernel.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/hybridsort_bucket"}}
{"kernel_name": "hybridsort_bucket", "parallel_api": "ocl", "code": {"bucketsort.c": "#define BUCKET_WARP_LOG_SIZE\t5\n#define BUCKET_WARP_N\t\t\t1\n\n#ifdef BUCKET_WG_SIZE_1\n#define BUCKET_THREAD_N BUCKET_WG_SIZE_1\n#else\n#define BUCKET_THREAD_N\t\t\t(BUCKET_WARP_N << BUCKET_WARP_LOG_SIZE)\n#endif\n#define BUCKET_BLOCK_MEMORY\t\t(DIVISIONS * BUCKET_WARP_N)\n#define BUCKET_BAND\t\t\t\t128\n#define SIZE (1 << 22)\n\n#define DATA_SIZE (1024)\n#define MAX_SOURCE_SIZE (0x100000)\n#define HISTOGRAM_SIZE (1024 * sizeof(unsigned int))\n\n\n#include <fcntl.h>\n#include <float.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n#include <unistd.h>\n#include <sys/types.h>\n#include <sys/stat.h>\n#include <CL/cl.h>\n#include \"bucketsort.h\"\n#include <time.h>\n\n#ifdef TIMING\n#include \"timing.h\"\n\nextern struct timeval tv;\nextern struct timeval tv_total_start, tv_total_end;\nextern struct timeval tv_init_start, tv_init_end;\nextern struct timeval tv_h2d_start, tv_h2d_end;\nextern struct timeval tv_d2h_start, tv_d2h_end;\nextern struct timeval tv_kernel_start, tv_kernel_end;\nextern struct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nextern struct timeval tv_close_start, tv_close_end;\nextern float init_time, mem_alloc_time, h2d_time, kernel_time,\n      d2h_time, close_time, total_time;\n#endif\n\nvoid calcPivotPoints(float *histogram, int histosize, int listsize,\n\t\t\t\t\t int divisions, float min, float max, float *pivotPoints,\n\t\t\t\t\t float histo_width);\n\nconst int histosize = 1024;\nunsigned int* h_offsets = NULL;\nunsigned int* d_offsets = NULL;\ncl_mem d_offsets_buff;\nint *d_indice = NULL;\ncl_mem d_indice_buff;\ncl_mem d_input_buff;\ncl_mem d_indice_input_buff;\nfloat *pivotPoints = NULL;\nfloat *historesult = NULL;\nfloat *l_pivotpoints = NULL;\ncl_mem l_pivotpoints_buff;\nunsigned int *d_prefixoffsets = NULL;\nunsigned int *d_prefixoffsets_altered = NULL;\ncl_mem d_prefixoffsets_buff;\ncl_mem d_prefixoffsets_input_buff;\nunsigned int *l_offsets = NULL;\ncl_mem l_offsets_buff;\nunsigned int *d_Result1024;\ncl_device_id device_id;\ncl_context bucketContext;\ncl_context histoContext;\ncl_command_queue bucketCommands;\ncl_command_queue histoCommands;\ncl_program bucketProgram;\ncl_program histoProgram;\ncl_kernel bucketcountKernel;\ncl_kernel histoKernel;\ncl_kernel bucketprefixKernel;\ncl_kernel bucketsortKernel;\ncl_mem histoInput;\ncl_mem histoOutput;\ncl_mem bucketOutput;\ncl_int err;\ncl_uint num_platforms;\ncl_event histoEvent;\ncl_event bucketCountEvent;\ncl_event bucketPrefixEvent;\ncl_event bucketSortEvent;\ndouble sum = 0;\n\nextern int platform_id_inuse;\nextern int device_id_inuse;\n\nvoid init_bucketsort(int listsize)\n{\n    cl_uint num = 0;\n    clGetPlatformIDs(0, NULL, &num);\n    cl_platform_id platformID[num];\n    clGetPlatformIDs(num, platformID, NULL);\n    \n    clGetDeviceIDs(platformID[platform_id_inuse],CL_DEVICE_TYPE_ALL,0,NULL,&num);\n    \n    cl_device_id devices[num];\n    err = clGetDeviceIDs(platformID[platform_id_inuse],CL_DEVICE_TYPE_ALL,num,devices,NULL);\n    \n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to create a device group! (Init_bucketsort)\\n\");\n        exit(1);\n    }\n\n    char name[128];\n    clGetDeviceInfo(devices[device_id_inuse],CL_DEVICE_NAME,128,name,NULL);\n\n    bucketContext = clCreateContext(0, 1, &devices[device_id_inuse], NULL, NULL, &err);\n\n    bucketCommands = clCreateCommandQueue(bucketContext, devices[device_id_inuse], CL_QUEUE_PROFILING_ENABLE, &err);\n    \n    FILE *fp;\n    const char fileName[]=\"./bucketsort_kernels.cl\";\n    size_t source_size;\n    char *source_str;\n    \n    fp = fopen(fileName, \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load bucket kernel.\\n\");\n\t\texit(1);\n\t}\n    \n    \n\tsource_str = (char *)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread(source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose(fp);\n    \n    bucketProgram = clCreateProgramWithSource(bucketContext, 1, (const char **) &source_str, (const size_t *)&source_size, &err);\n    if (!bucketProgram)\n    {\n        printf(\"Error: Failed to create bucket compute program!\\n\");\n        exit(1);\n    }\n    \n    err = clBuildProgram(bucketProgram, 0, NULL, NULL, NULL, NULL);\n    if (err != CL_SUCCESS)\n    {\n        size_t len;\n        char buffer[2048];\n        \n        printf(\"Error: Failed to build bucket program executable!\\n\");\n        clGetProgramBuildInfo(bucketProgram, devices[0], CL_PROGRAM_BUILD_LOG, sizeof(buffer), buffer, &len);\n        printf(\"%s\\n\", buffer);\n        exit(1);\n    }\n#ifdef  TIMING\n\tgettimeofday(&tv_init_end, NULL);\n\ttvsub(&tv_init_end, &tv_total_start, &tv);\n\tinit_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\th_offsets = (unsigned int *) malloc(DIVISIONS * sizeof(unsigned int));\n    for(int i = 0; i < DIVISIONS; i++){\n        h_offsets[i] = 0;\n    }\n    d_offsets_buff = clCreateBuffer(bucketContext,CL_MEM_READ_WRITE, DIVISIONS * sizeof(unsigned int),NULL,NULL);\n\tpivotPoints = (float *)malloc(DIVISIONS * sizeof(float));\n    \n    d_indice_buff = clCreateBuffer(bucketContext,CL_MEM_READ_WRITE, listsize * sizeof(int),NULL,NULL);\n    d_indice_input_buff = clCreateBuffer(bucketContext,CL_MEM_READ_WRITE, listsize * sizeof(int),NULL,NULL);\n    d_indice = (int *)malloc(listsize * sizeof(int));\n\thistoresult = (float *)malloc(histosize * sizeof(float));\n    l_pivotpoints = (float *)malloc(DIVISIONS*sizeof(float));\n\tl_pivotpoints_buff = clCreateBuffer(bucketContext,CL_MEM_READ_WRITE, DIVISIONS * sizeof(float), NULL, NULL);\n\tl_offsets_buff = clCreateBuffer(bucketContext,CL_MEM_READ_WRITE, DIVISIONS * sizeof(unsigned int), NULL, NULL);\n    \n\tint blocks = ((listsize - 1) / (BUCKET_THREAD_N * BUCKET_BAND)) + 1;\n\td_prefixoffsets_buff = clCreateBuffer(bucketContext,CL_MEM_READ_WRITE, blocks * BUCKET_BLOCK_MEMORY * sizeof(int), NULL, NULL);\n    d_prefixoffsets = (unsigned int *)malloc(blocks*BUCKET_BLOCK_MEMORY*sizeof(int));\n    d_prefixoffsets_altered = (unsigned int *)malloc(blocks*BUCKET_BLOCK_MEMORY*sizeof(int));\n    d_prefixoffsets_input_buff = clCreateBuffer(bucketContext,CL_MEM_READ_WRITE, blocks * BUCKET_BLOCK_MEMORY * sizeof(int), NULL, NULL);\n    bucketOutput = clCreateBuffer(bucketContext, CL_MEM_READ_WRITE, (listsize + (DIVISIONS*4))*sizeof(float), NULL, NULL);\n\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_init_end, &tv);\n    mem_alloc_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n}\n\nvoid finish_bucketsort()\n{\n    clReleaseMemObject(d_offsets_buff);\n    clReleaseMemObject(d_indice_buff);\n    clReleaseMemObject(l_pivotpoints_buff);\n    clReleaseMemObject(l_offsets_buff);\n    clReleaseMemObject(d_prefixoffsets_buff);\n    clReleaseMemObject(d_input_buff);\n    clReleaseMemObject(d_indice_input_buff);\n    clReleaseMemObject(bucketOutput);\n    clReleaseProgram(bucketProgram);\n    clReleaseKernel(bucketcountKernel);\n    clReleaseKernel(bucketprefixKernel);\n    clReleaseKernel(bucketsortKernel);\n    clReleaseCommandQueue(bucketCommands);\n    clReleaseContext(bucketContext);\n\tfree(pivotPoints);\n\tfree(h_offsets);\n\tfree(historesult);\n}\n\nvoid histogramInit(int listsize) {\n    cl_uint num = 0;\n    clGetPlatformIDs(0, NULL, &num);\n    cl_platform_id platformID[num];\n    clGetPlatformIDs(num, platformID, NULL);\n    \n    clGetDeviceIDs(platformID[platform_id_inuse],CL_DEVICE_TYPE_ALL,0,NULL,&num);\n    \n    char name[128];\n    clGetPlatformInfo(platformID[platform_id_inuse], CL_PLATFORM_PROFILE,128,name,NULL);\n    \n    \n    cl_device_id devices[num];\n    err = clGetDeviceIDs(platformID[platform_id_inuse],CL_DEVICE_TYPE_ALL,num,devices,NULL);\n    \n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to create a device group! (HistogramInit)\\n\");\n        exit(1);\n    }\n    \n    clGetDeviceInfo(devices[device_id_inuse],CL_DEVICE_NAME,128,name,NULL);\n    \n    printf(\"%s \\n\", name);\n    \n    cl_context_properties contextProperties[] =\n    {\n        CL_CONTEXT_PLATFORM,\n        (cl_context_properties)platformID[platform_id_inuse],\n        0\n    };\n    \n    histoContext = clCreateContext(contextProperties, 1, &devices[device_id_inuse], NULL, NULL, &err);\n    histoCommands = clCreateCommandQueue(histoContext, devices[device_id_inuse], CL_QUEUE_PROFILING_ENABLE, &err);\n\n    FILE *fp;\n    const char fileName[]=\"./histogram1024.cl\";\n    size_t source_size;\n    char *source_str;\n\n    fp = fopen(fileName, \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\n\n\tsource_str = (char *)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread(source_str, 1, MAX_SOURCE_SIZE, fp);\n    source_str[source_size] = '\\0';\n\tfclose(fp);\n\n    histoProgram = clCreateProgramWithSource(histoContext, 1, (const char **) &source_str, (const size_t *)&source_size, &err);\n    if (!histoProgram)\n    {\n        printf(\"Error: Failed to create compute program! %d\\n\", err);\n        exit(1);\n    }\n    free(source_str);\n\n    err = clBuildProgram(histoProgram, 0, NULL, NULL, NULL, NULL);\n    if (err != CL_SUCCESS)\n    {\n        size_t len;\n        char buffer[2048];\n\n        printf(\"Error: Failed to build program executable!\\n\");\n        clGetProgramBuildInfo(histoProgram, devices[0], CL_PROGRAM_BUILD_LOG, sizeof(buffer), buffer, &len);\n        printf(\"%s\\n\", buffer);\n        exit(1);\n    }\n\n    histoKernel = clCreateKernel(histoProgram, \"histogram1024Kernel\", &err);\n    if (!histoKernel || err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to create compute kernel!\\n\");\n        exit(1);\n    }\n\n#ifdef  TIMING\n\tgettimeofday(&tv_init_end, NULL);\n\ttvsub(&tv_init_end, &tv_init_start, &tv);\n\tinit_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n    histoInput = clCreateBuffer(histoContext,  CL_MEM_READ_ONLY,  listsize*(sizeof(float)), NULL, NULL);\n    histoOutput = clCreateBuffer(histoContext, CL_MEM_READ_WRITE, 1024 * sizeof(unsigned int), NULL, NULL);\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_init_end, &tv);\n    mem_alloc_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n}\n\nvoid histogram1024GPU(unsigned int *h_Result, float *d_Data, float minimum, float maximum,int listsize){\n    cl_event write_event[2];\n    err = clEnqueueWriteBuffer(histoCommands, histoInput, CL_TRUE, 0, listsize*sizeof(float), d_Data, 0, NULL, &write_event[0]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to source array!\\n\");\n        exit(1);\n    }\n    err = clEnqueueWriteBuffer(histoCommands, histoOutput, CL_TRUE, 0, DIVISIONS*sizeof(unsigned int), h_Result, 0, NULL, &write_event[1]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to source array!\\n\");\n        exit(1);\n    }\n    err = 0;\n    err  = clSetKernelArg(histoKernel, 0, sizeof(cl_mem), &histoOutput);\n    err  = clSetKernelArg(histoKernel, 1, sizeof(cl_mem), &histoInput);\n    err  = clSetKernelArg(histoKernel, 2, sizeof(float), &minimum);\n    err  = clSetKernelArg(histoKernel, 3, sizeof(float), &maximum);\n    err  = clSetKernelArg(histoKernel, 4, sizeof(int), &listsize);\n    \n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to set kernel arguments! %d\\n\", err);\n        exit(1);\n    }\n    \n    size_t global = 6144;\n    size_t local;\n#ifdef HISTO_WG_SIZE_0\n    local = HISTO_WG_SIZE_0;\n#else\n    local = 96;\n#endif\n    err = clEnqueueNDRangeKernel(histoCommands, histoKernel, 1, NULL, &global, &local, 0, NULL, &histoEvent);\n    if (err)\n    {\n        printf(\"Error: Failed to execute histogram kernel!\\n\");\n        exit(1);\n    }\n    clWaitForEvents(1 , &histoEvent);\n    clFinish(histoCommands);\n#ifdef TIMING\n    h2d_time += probe_event_time(write_event[0], histoCommands);\n    h2d_time += probe_event_time(write_event[1], histoCommands);\n    kernel_time += probe_event_time(histoEvent, histoCommands);\n#endif\n    clReleaseEvent(write_event[0]);\n    clReleaseEvent(write_event[1]);\n\n    cl_event read_event;\n    err = clEnqueueReadBuffer( histoCommands, histoOutput, CL_TRUE, 0, 1024 * sizeof(unsigned int), h_Result, 0, NULL, &read_event);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to read histo output array! %d\\n\", err);\n        exit(1);\n    }\n    clFinish(histoCommands);\n#ifdef TIMING\n    d2h_time += probe_event_time(read_event, histoCommands);\n#endif\n    clReleaseEvent(read_event);\n\n    cl_ulong time_start, time_end;\n    double total_time;\n    clGetEventProfilingInfo(histoEvent, CL_PROFILING_COMMAND_START, sizeof(time_start), &time_start, NULL);\n    clGetEventProfilingInfo(histoEvent, CL_PROFILING_COMMAND_END, sizeof(time_end), &time_end, NULL);\n    total_time = time_end - time_start;\n    sum+= total_time/1000000.0;\n    printf(\"Histogram Kernel Time: %0.3f \\n\", total_time/1000000);\n}\n\nvoid finish_histogram() {\n    clReleaseProgram(histoProgram);\n    clReleaseKernel(histoKernel);\n    clReleaseCommandQueue(histoCommands);\n    clReleaseContext(histoContext);\n    clReleaseMemObject((histoInput));\n    clReleaseMemObject((histoOutput));\n}\n\nvoid bucketSort(float *d_input, float *d_output, int listsize,\n\t\t\t\tint *sizes, int *nullElements, float minimum, float maximum,\n\t\t\t\tunsigned int *origOffsets)\n{\n#ifdef  TIMING\n    gettimeofday(&tv_init_start, NULL);\n#endif\n    histogramInit(listsize);\n\n\thistogram1024GPU(h_offsets, d_input, minimum, maximum, listsize);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n    finish_histogram();\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n    for(int i=0; i<histosize; i++) historesult[i] = (float)h_offsets[i];\n\n\tcalcPivotPoints(historesult, histosize, listsize, DIVISIONS,\n                    minimum, maximum, pivotPoints,\n                    (maximum - minimum)/(float)histosize);\n\n    cl_event write_event[4], read_event[2];\n\n    bucketcountKernel = clCreateKernel(bucketProgram, \"bucketcount\", &err);\n    if (!bucketcountKernel || err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to create bucketsort compute kernel!\\n\");\n        exit(1);\n    }\n    err = clEnqueueWriteBuffer(bucketCommands, l_pivotpoints_buff, CL_TRUE, 0, DIVISIONS*sizeof(float), pivotPoints, 0, NULL, &write_event[0]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to l_pivotpoints source array!\\n\");\n        exit(1);\n    }\n\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_start, NULL);\n#endif\n    d_input_buff = clCreateBuffer(bucketContext,CL_MEM_READ_WRITE, (listsize + (DIVISIONS*4))*sizeof(float),NULL,NULL);\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_mem_alloc_start, &tv);\n    mem_alloc_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n    err = clEnqueueWriteBuffer(bucketCommands, d_input_buff, CL_TRUE, 0, (listsize + (DIVISIONS*4))*sizeof(float), d_input, 0, NULL, &write_event[1]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to d_input_buff source array!\\n\");\n        exit(1);\n    }\n    err = 0;\n    err  = clSetKernelArg(bucketcountKernel, 0, sizeof(cl_mem), &d_input_buff);\n    err  = clSetKernelArg(bucketcountKernel, 1, sizeof(cl_mem), &d_indice_buff);\n    err  = clSetKernelArg(bucketcountKernel, 2, sizeof(cl_mem), &d_prefixoffsets_buff);\n    err  = clSetKernelArg(bucketcountKernel, 3, sizeof(cl_int), &listsize);\n    err  = clSetKernelArg(bucketcountKernel, 4, sizeof(cl_mem), &l_pivotpoints_buff);\n    \n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to set kernel arguments! %d\\n\", err);\n        exit(1);\n    }\n\n    int blocks =((listsize -1) / (BUCKET_THREAD_N*BUCKET_BAND)) + 1;\n    size_t global[] = {blocks*BUCKET_THREAD_N,1,1};\n    size_t local[] = {BUCKET_THREAD_N,1,1};\n    \n    err = clEnqueueNDRangeKernel(bucketCommands, bucketcountKernel, 3, NULL, global, local, 0, NULL, &bucketCountEvent);\n    if (err)\n    {\n        printf(\"Error: Failed to execute bucket count kernel!\\n\");\n        exit(1);\n    }\n    clWaitForEvents(1 , &bucketCountEvent);\n    clFinish(bucketCommands);\n    err = clEnqueueReadBuffer( bucketCommands, d_prefixoffsets_buff, CL_TRUE, 0, blocks * BUCKET_BLOCK_MEMORY * sizeof(unsigned int), d_prefixoffsets, 0, NULL, &read_event[0]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to read prefix output array! %d\\n\", err);\n        exit(1);\n    }\n    err = clEnqueueReadBuffer( bucketCommands, d_indice_buff, CL_TRUE, 0, listsize * sizeof(int), d_indice, 0, NULL, &read_event[1]);\n    \n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to read indice output array! %d\\n\", err);\n        exit(1);\n    }\n    clFinish(bucketCommands);\n#ifdef TIMING\n    h2d_time += probe_event_time(write_event[0], bucketCommands);\n    h2d_time += probe_event_time(write_event[1], bucketCommands);\n    d2h_time += probe_event_time(read_event[0], bucketCommands);\n    d2h_time += probe_event_time(read_event[1], bucketCommands);\n    kernel_time += probe_event_time(bucketCountEvent, bucketCommands);\n#endif\n    clReleaseEvent(write_event[0]);\n    clReleaseEvent(write_event[1]);\n    clReleaseEvent(read_event[0]);\n    clReleaseEvent(read_event[1]);\n\n    cl_ulong time_start, time_end;\n    double total_time;\n    clGetEventProfilingInfo(bucketCountEvent, CL_PROFILING_COMMAND_START, sizeof(time_start), &time_start, NULL);\n    clGetEventProfilingInfo(bucketCountEvent, CL_PROFILING_COMMAND_END, sizeof(time_end), &time_end, NULL);\n    total_time = time_end - time_start;\n    sum+= total_time/1000000;\n    printf(\"Bucket Count Kernel Time: %0.3f \\n\", total_time/1000000);\n    \n\n#ifdef BUCKET_WG_SIZE_0\n    size_t localpre[] = {BUCKET_WG_SIZE_0,1,1};\n#else\n    size_t localpre[] = {128,1,1};\n#endif\n    size_t globalpre[] = {(DIVISIONS),1,1};\n    \n    bucketprefixKernel = clCreateKernel(bucketProgram, \"bucketprefixoffset\", &err);\n    if (!bucketprefixKernel || err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to create bucket prefix compute kernel!\\n\");\n        exit(1);\n    }\n\n\n    err = clEnqueueWriteBuffer(bucketCommands, d_prefixoffsets_buff, CL_TRUE, 0, blocks * BUCKET_BLOCK_MEMORY * sizeof(int), d_prefixoffsets, 0, NULL, &write_event[0]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to prefix offsets source array!\\n\");\n        exit(1);\n    }\n    err = 0;\n    err  = clSetKernelArg(bucketprefixKernel, 0, sizeof(cl_mem), &d_prefixoffsets_buff);\n    err  = clSetKernelArg(bucketprefixKernel, 1, sizeof(cl_mem), &d_offsets_buff);\n    err  = clSetKernelArg(bucketprefixKernel, 2, sizeof(cl_int), &blocks);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to set kernel arguments! %d\\n\", err);\n        exit(1);\n    }\n    err = clEnqueueNDRangeKernel(bucketCommands, bucketprefixKernel, 3, NULL, globalpre, localpre, 0, NULL, &bucketPrefixEvent);\n    if (err)\n    {\n        printf(\"%d Error: Failed to execute bucket prefix kernel!\\n\", err);\n        exit(1);\n    }\n    clWaitForEvents(1 , &bucketPrefixEvent);\n    clFinish(bucketCommands);\n    err = clEnqueueReadBuffer( bucketCommands, d_offsets_buff, CL_TRUE, 0, DIVISIONS * sizeof(unsigned int), h_offsets, 0, NULL, &read_event[0]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to read d_offsets output array! %d\\n\", err);\n        exit(1);\n    }\n    err = clEnqueueReadBuffer( bucketCommands, d_prefixoffsets_buff, CL_TRUE, 0, blocks * BUCKET_BLOCK_MEMORY * sizeof(int), d_prefixoffsets_altered, 0, NULL, &read_event[1]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to read d_offsets output array! %d\\n\", err);\n        exit(1);\n    }\n    clFinish(bucketCommands);\n#ifdef TIMING\n    h2d_time += probe_event_time(write_event[0], bucketCommands);\n    d2h_time += probe_event_time(read_event[0], bucketCommands);\n    d2h_time += probe_event_time(read_event[1], bucketCommands);\n    kernel_time += probe_event_time(bucketPrefixEvent, bucketCommands);\n#endif\n    clReleaseEvent(write_event[0]);\n    clReleaseEvent(read_event[0]);\n    clReleaseEvent(read_event[1]);\n\n    clGetEventProfilingInfo(bucketPrefixEvent, CL_PROFILING_COMMAND_START, sizeof(time_start), &time_start, NULL);\n    clGetEventProfilingInfo(bucketPrefixEvent, CL_PROFILING_COMMAND_END, sizeof(time_end), &time_end, NULL);\n    total_time = time_end - time_start;\n    sum+= total_time/1000000;\n    printf(\"Bucket Prefix Kernel Time: %0.3f \\n\", total_time/1000000);\n\torigOffsets[0] = 0;\n\tfor(int i=0; i<DIVISIONS; i++){\n\t\torigOffsets[i+1] = h_offsets[i] + origOffsets[i];\n\t\tif((h_offsets[i] % 4) != 0){\n\t\t\tnullElements[i] = (h_offsets[i] & ~3) + 4 - h_offsets[i];\n\t\t}\n\t\telse nullElements[i] = 0;\n\t}\n\tfor(int i=0; i<DIVISIONS; i++) sizes[i] = (h_offsets[i] + nullElements[i])/4;\n\tfor(int i=0; i<DIVISIONS; i++) {\n\t\tif((h_offsets[i] % 4) != 0)\th_offsets[i] = (h_offsets[i] & ~3) + 4;\n\t}\n\tfor(int i=1; i<DIVISIONS; i++) h_offsets[i] = h_offsets[i-1] + h_offsets[i];\n\tfor(int i=DIVISIONS - 1; i>0; i--) h_offsets[i] = h_offsets[i-1];\n\th_offsets[0] = 0;\n    \n\n\n    bucketsortKernel = clCreateKernel(bucketProgram, \"bucketsort\", &err);\n    if (!bucketsortKernel|| err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to create bucketsort compute kernel!\\n\");\n        exit(1);\n    }\n\n    err = clEnqueueWriteBuffer(bucketCommands, l_offsets_buff, CL_TRUE, 0, DIVISIONS * sizeof(unsigned int), h_offsets, 0, NULL, &write_event[0]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to  l_offsets source array!\\n\");\n        exit(1);\n    }\n    err = clEnqueueWriteBuffer(bucketCommands, d_input_buff, CL_TRUE, 0, (listsize + (DIVISIONS*4))*sizeof(float), d_input, 0, NULL, &write_event[1]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to d_input_buff source array!\\n\");\n        exit(1);\n    }\n    err = clEnqueueWriteBuffer(bucketCommands, d_indice_input_buff, CL_TRUE, 0, listsize*sizeof(int), d_indice, 0, NULL, &write_event[2]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to d_input_buff source array!\\n\");\n        exit(1);\n    }\n    err = clEnqueueWriteBuffer(bucketCommands, d_prefixoffsets_input_buff, CL_TRUE, 0, blocks * BUCKET_BLOCK_MEMORY * sizeof(int), d_prefixoffsets_altered, 0, NULL, &write_event[3]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to prefix offsets source array!\\n\");\n        exit(1);\n    }\n    err = clEnqueueWriteBuffer(bucketCommands, bucketOutput, CL_TRUE, 0, (listsize + (DIVISIONS*4))*sizeof(float), d_output, 0, NULL, &write_event[4]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to write to source array!\\n\");\n        exit(1);\n    }\n\n    size_t localfinal[] = {BUCKET_THREAD_N,1,1};\n    blocks = ((listsize - 1) / (BUCKET_THREAD_N * BUCKET_BAND)) + 1;\n    size_t globalfinal[] = {blocks*BUCKET_THREAD_N,1,1};\n    err = 0;\n    err  = clSetKernelArg(bucketsortKernel, 0, sizeof(cl_mem), &d_input_buff);\n    err  = clSetKernelArg(bucketsortKernel, 1, sizeof(cl_mem), &d_indice_input_buff);\n    err  = clSetKernelArg(bucketsortKernel, 2, sizeof(cl_mem), &bucketOutput);\n    err  = clSetKernelArg(bucketsortKernel, 3, sizeof(cl_int), &listsize);\n    err  = clSetKernelArg(bucketsortKernel, 4, sizeof(cl_mem), &d_prefixoffsets_input_buff);\n    err  = clSetKernelArg(bucketsortKernel, 5, sizeof(cl_mem), &l_offsets_buff);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to set kernel arguments! %d\\n\", err);\n        exit(1);\n    }\n    err = clEnqueueNDRangeKernel(bucketCommands, bucketsortKernel, 3, NULL, globalfinal, localfinal, 0, NULL, &bucketSortEvent);\n    if (err)\n    {\n        printf(\"%d Error: Failed to execute bucketsort kernel!\\n\", err);\n    }\n    err = clEnqueueReadBuffer( bucketCommands, bucketOutput, CL_TRUE, 0, (listsize + (DIVISIONS*4))*sizeof(float), d_output, 0, NULL, &read_event[0]);\n    if (err != CL_SUCCESS)\n    {\n        printf(\"Error: Failed to read d_output array! %d\\n\", err);\n    }\n     clWaitForEvents(1 , &bucketSortEvent);\n    clFinish(bucketCommands);\n#ifdef TIMING\n    for (int event_id = 0; event_id < 4; event_id++)\n        h2d_time += probe_event_time(write_event[event_id], bucketCommands);\n    d2h_time += probe_event_time(read_event[0], bucketCommands);\n    kernel_time += probe_event_time(bucketSortEvent, bucketCommands);\n#endif\n    clReleaseEvent(write_event[0]);\n    clReleaseEvent(write_event[1]);\n    clReleaseEvent(write_event[2]);\n    clReleaseEvent(write_event[3]);\n    clReleaseEvent(read_event[0]);\n\n    clGetEventProfilingInfo(bucketSortEvent, CL_PROFILING_COMMAND_START, sizeof(time_start), &time_start, NULL);\n    clGetEventProfilingInfo(bucketSortEvent, CL_PROFILING_COMMAND_END, sizeof(time_end), &time_end, NULL);\n    total_time = time_end - time_start;\n    sum+= total_time/1000000;\n    printf(\"Bucket Sort Kernel Time: %0.3f \\n\", total_time/1000000);\n\n}\ndouble getBucketTime() {\n  return sum;\n}\n\nvoid calcPivotPoints(float *histogram, int histosize, int listsize,\n\t\t\t\t\t int divisions, float min, float max, float *pivotPoints, float histo_width)\n{\n\tfloat elemsPerSlice = listsize/(float)divisions;\n\tfloat startsAt = min;\n\tfloat endsAt = min + histo_width;\n\tfloat we_need = elemsPerSlice;\n\tint p_idx = 0;\n\tfor(int i=0; i<histosize; i++)\n\t{\n\t\tif(i == histosize - 1){\n\t\t\tif(!(p_idx < divisions)){\n\t\t\t\tpivotPoints[p_idx++] = startsAt + (we_need/histogram[i]) * histo_width;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\twhile(histogram[i] > we_need){\n\t\t\tif(!(p_idx < divisions)){\n\t\t\t\tprintf(\"i=%d, p_idx = %d, divisions = %d\\n\", i, p_idx, divisions);\n\t\t\t\texit(0);\n\t\t\t}\n\t\t\tpivotPoints[p_idx++] = startsAt + (we_need/histogram[i]) * histo_width;\n\t\t\tstartsAt += (we_need/histogram[i]) * histo_width;\n\t\t\thistogram[i] -= we_need;\n\t\t\twe_need = elemsPerSlice;\n\t\t}\n\t\twe_need -= histogram[i];\n        \n\t\tstartsAt = endsAt;\n\t\tendsAt += histo_width;\n\t}\n\twhile(p_idx < divisions){\n\t\tpivotPoints[p_idx] = pivotPoints[p_idx-1];\n\t\tp_idx++;\n\t}\n}\n", "bucketsort_kernels.cl": "#define DIVISIONS               (1 << 10)\n#define LOG_DIVISIONS\t(10)\n#define BUCKET_WARP_LOG_SIZE\t(5)\n#define BUCKET_WARP_N\t\t\t(1)\n#ifdef BUCKET_WG_SIZE_1\n#define BUCKET_THREAD_N BUCKET_WG_SIZE_1\n#else\n#define BUCKET_THREAD_N\t\t\t(BUCKET_WARP_N << BUCKET_WARP_LOG_SIZE)\n#endif\n#define BUCKET_BLOCK_MEMORY\t\t(DIVISIONS * BUCKET_WARP_N)\n#define BUCKET_BAND\t\t\t\t(128)\n\n\nint addOffset(volatile __local uint *s_offset, uint data, uint threadTag){\n    uint count;\n\n    do{\n        count = s_offset[data] & 0x07FFFFFFU;\n        count = threadTag | (count + 1);\n        s_offset[data] = count;\n    }while(s_offset[data] != count);\n\n    return (count & 0x07FFFFFFU) - 1;\n}\n\n__kernel void\nbucketcount( global float *input, global int *indice, global uint *d_prefixoffsets, const int size, global float *l_pivotpoints)\n{\n    \n\tvolatile __local uint s_offset[BUCKET_BLOCK_MEMORY];\n    \n    const uint threadTag = get_local_id(0) << (32 - BUCKET_WARP_LOG_SIZE);\n    const int warpBase = (get_local_id(0) >> BUCKET_WARP_LOG_SIZE) * DIVISIONS;\n    const int numThreads = get_global_size(0);\n\tfor (int i = get_local_id(0); i < BUCKET_BLOCK_MEMORY; i += get_local_size(0))\n\t\ts_offset[i] = 0;\n    \n    barrier(CLK_LOCAL_MEM_FENCE | CLK_GLOBAL_MEM_FENCE);\n    \n\tfor (int tid = get_global_id(0); tid < size; tid += numThreads) {\n\t\tfloat elem = input[tid];\n        \n\t\tint idx  = DIVISIONS/2 - 1;\n\t\tint jump = DIVISIONS/4;\n\t\tfloat piv = l_pivotpoints[idx]; //s_pivotpoints[idx];\n        \n\t\twhile(jump >= 1){\n\t\t\tidx = (elem < piv) ? (idx - jump) : (idx + jump);\n\t\t\tpiv = l_pivotpoints[idx]; //s_pivotpoints[idx];\n\t\t\tjump /= 2;\n\t\t}\n\t\tidx = (elem < piv) ? idx : (idx + 1);\n        \n\t\tindice[tid] = (addOffset(s_offset + warpBase, idx, threadTag) << LOG_DIVISIONS) + idx;\n\t}\n    \n    barrier(CLK_LOCAL_MEM_FENCE | CLK_GLOBAL_MEM_FENCE);\n    \n\tint prefixBase = get_group_id(0) * BUCKET_BLOCK_MEMORY;\n    \n\tfor (int i = get_local_id(0); i < BUCKET_BLOCK_MEMORY; i += get_local_size(0))\n\t\td_prefixoffsets[prefixBase + i] = s_offset[i] & 0x07FFFFFFU;\n}\n\n__kernel void bucketprefixoffset(global uint *d_prefixoffsets, global uint *d_offsets, const int blocks) {\n\tint tid = get_global_id(0);\n\tint size = blocks * BUCKET_BLOCK_MEMORY;\n\tint sum = 0;\n    \n\tfor (int i = tid; i < size; i += DIVISIONS) {\n\t\tint x = d_prefixoffsets[i];\n\t\td_prefixoffsets[i] = sum;\n\t\tsum += x;\n\t}\n    \n\td_offsets[tid] = sum;\n}\n\n__kernel void\nbucketsort(global float *input, global int *indice, __global float *output, const int size, global uint *d_prefixoffsets,\n\t\t   global uint *l_offsets)\n{\n\tvolatile __local unsigned int s_offset[BUCKET_BLOCK_MEMORY];\n    \n\tint prefixBase = get_group_id(0) * BUCKET_BLOCK_MEMORY;\n    const int warpBase = (get_local_id(0) >> BUCKET_WARP_LOG_SIZE) * DIVISIONS;\n    const int numThreads = get_global_size(0);\n    \n\tfor (int i = get_local_id(0); i < BUCKET_BLOCK_MEMORY; i += get_local_size(0)){\n\t\ts_offset[i] = l_offsets[i & (DIVISIONS - 1)] + d_prefixoffsets[prefixBase + i];\n    }\n    \n    barrier(CLK_LOCAL_MEM_FENCE | CLK_GLOBAL_MEM_FENCE);\n\n\tfor (int tid = get_global_id(0); tid < size; tid += numThreads) {\n       \n\t\tfloat elem = input[tid];\n\t\tint id = indice[tid];\n\t\toutput[s_offset[warpBase + (id & (DIVISIONS - 1))] + (id >> LOG_DIVISIONS)] = elem;\n        int test = s_offset[warpBase + (id & (DIVISIONS - 1))] + (id >> LOG_DIVISIONS);\n\t}\n}\n"}, "code_dirs": {"bucketsort.c": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/hybridsort_bucket", "bucketsort_kernels.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/hybridsort_bucket"}}
{"kernel_name": "nw", "parallel_api": "cuda", "code": {"needle_kernel.cu": "\n#include \"needle.h\"\n#include <stdio.h>\n\n\n#define SDATA( index)      CUT_BANK_CHECKER(sdata, index)\n\n__device__ __host__ int \nmaximum( int a,\n\t\t int b,\n\t\t int c){\n\nint k;\nif( a <= b )\nk = b;\nelse \nk = a;\n\nif( k <=c )\nreturn(c);\nelse\nreturn(k);\n\n}\n\n__global__ void\nneedle_cuda_shared_1(  int* referrence,\n\t\t\t  int* matrix_cuda, \n\t\t\t  int cols,\n\t\t\t  int penalty,\n\t\t\t  int i,\n\t\t\t  int block_width) \n{\n  int bx = blockIdx.x;\n  int tx = threadIdx.x;\n\n  int b_index_x = bx;\n  int b_index_y = i - 1 - bx;\n\n  int index   = cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( cols + 1 );\n  int index_n   = cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n  int index_w   = cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( cols );\n  int index_nw =  cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n\n  __shared__  int temp[BLOCK_SIZE+1][BLOCK_SIZE+1];\n  __shared__  int ref[BLOCK_SIZE][BLOCK_SIZE];\n\n   if (tx == 0)\n\t\t  temp[tx][0] = matrix_cuda[index_nw];\n\n\n  for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n  ref[ty][tx] = referrence[index + cols * ty];\n\n  __syncthreads();\n\n  temp[tx + 1][0] = matrix_cuda[index_w + cols * tx];\n\n  __syncthreads();\n\n  temp[0][tx + 1] = matrix_cuda[index_n];\n  \n  __syncthreads();\n  \n\n  for( int m = 0 ; m < BLOCK_SIZE ; m++){\n   \n\t  if ( tx <= m ){\n\n\t\t  int t_index_x =  tx + 1;\n\t\t  int t_index_y =  m - tx + 1;\n\n          temp[t_index_y][t_index_x] = maximum( temp[t_index_y-1][t_index_x-1] + ref[t_index_y-1][t_index_x-1],\n\t\t                                        temp[t_index_y][t_index_x-1]  - penalty, \n\t\t\t\t\t\t\t\t\t\t\t\ttemp[t_index_y-1][t_index_x]  - penalty);\n\n\t\t  \n\t  \n\t  }\n\n\t  __syncthreads();\n  \n    }\n\n for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n   \n\t  if ( tx <= m){\n\n\t\t  int t_index_x =  tx + BLOCK_SIZE - m ;\n\t\t  int t_index_y =  BLOCK_SIZE - tx;\n\n          temp[t_index_y][t_index_x] = maximum( temp[t_index_y-1][t_index_x-1] + ref[t_index_y-1][t_index_x-1],\n\t\t                                        temp[t_index_y][t_index_x-1]  - penalty, \n\t\t\t\t\t\t\t\t\t\t\t\ttemp[t_index_y-1][t_index_x]  - penalty);\n\t   \n\t  }\n\n\t  __syncthreads();\n  }\n\n  for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n  matrix_cuda[index + ty * cols] = temp[ty+1][tx+1];\n\n}\n\n\n__global__ void\nneedle_cuda_shared_2(  int* referrence,\n\t\t\t  int* matrix_cuda, \n\t\t\t \n\t\t\t  int cols,\n\t\t\t  int penalty,\n\t\t\t  int i,\n\t\t\t  int block_width) \n{\n\n  int bx = blockIdx.x;\n  int tx = threadIdx.x;\n\n  int b_index_x = bx + block_width - i  ;\n  int b_index_y = block_width - bx -1;\n\n  int index   = cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( cols + 1 );\n  int index_n   = cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n  int index_w   = cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( cols );\n    int index_nw =  cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n\n  __shared__  int temp[BLOCK_SIZE+1][BLOCK_SIZE+1];\n  __shared__  int ref[BLOCK_SIZE][BLOCK_SIZE];\n\n  for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n  ref[ty][tx] = referrence[index + cols * ty];\n\n  __syncthreads();\n\n   if (tx == 0)\n\t\t  temp[tx][0] = matrix_cuda[index_nw];\n \n \n  temp[tx + 1][0] = matrix_cuda[index_w + cols * tx];\n\n  __syncthreads();\n\n  temp[0][tx + 1] = matrix_cuda[index_n];\n  \n  __syncthreads();\n  \n\n  for( int m = 0 ; m < BLOCK_SIZE ; m++){\n   \n\t  if ( tx <= m ){\n\n\t\t  int t_index_x =  tx + 1;\n\t\t  int t_index_y =  m - tx + 1;\n\n          temp[t_index_y][t_index_x] = maximum( temp[t_index_y-1][t_index_x-1] + ref[t_index_y-1][t_index_x-1],\n\t\t                                        temp[t_index_y][t_index_x-1]  - penalty, \n\t\t\t\t\t\t\t\t\t\t\t\ttemp[t_index_y-1][t_index_x]  - penalty);\t  \n\t  \n\t  }\n\n\t  __syncthreads();\n  \n    }\n\n\n for( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n   \n\t  if ( tx <= m){\n\n\t\t  int t_index_x =  tx + BLOCK_SIZE - m ;\n\t\t  int t_index_y =  BLOCK_SIZE - tx;\n\n          temp[t_index_y][t_index_x] = maximum( temp[t_index_y-1][t_index_x-1] + ref[t_index_y-1][t_index_x-1],\n\t\t                                        temp[t_index_y][t_index_x-1]  - penalty, \n\t\t\t\t\t\t\t\t\t\t\t\ttemp[t_index_y-1][t_index_x]  - penalty);\n\n\n\t  }\n\n\t  __syncthreads();\n  }\n\n\n  for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n  matrix_cuda[index + ty * cols] = temp[ty+1][tx+1];\n\n}\n\n", "needle.cu": "#define LIMIT -999\n#include <stdlib.h>\n#include <stdio.h>\n#include <string.h>\n#include <math.h>\n#include \"needle.h\"\n#include <cuda.h>\n#include <sys/time.h>\n\n#include \"needle_kernel.cu\"\n\n#ifdef TIMING\n#include \"timing.h\"\n\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nvoid runTest( int argc, char** argv);\n\n\nint blosum62[24][24] = {\n{ 4, -1, -2, -2,  0, -1, -1,  0, -2, -1, -1, -1, -1, -2, -1,  1,  0, -3, -2,  0, -2, -1,  0, -4},\n{-1,  5,  0, -2, -3,  1,  0, -2,  0, -3, -2,  2, -1, -3, -2, -1, -1, -3, -2, -3, -1,  0, -1, -4},\n{-2,  0,  6,  1, -3,  0,  0,  0,  1, -3, -3,  0, -2, -3, -2,  1,  0, -4, -2, -3,  3,  0, -1, -4},\n{-2, -2,  1,  6, -3,  0,  2, -1, -1, -3, -4, -1, -3, -3, -1,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n{ 0, -3, -3, -3,  9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1, -3, -3, -2, -4},\n{-1,  1,  0,  0, -3,  5,  2, -2,  0, -3, -2,  1,  0, -3, -1,  0, -1, -2, -1, -2,  0,  3, -1, -4},\n{-1,  0,  0,  2, -4,  2,  5, -2,  0, -3, -3,  1, -2, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n{ 0, -2,  0, -1, -3, -2, -2,  6, -2, -4, -4, -2, -3, -3, -2,  0, -2, -2, -3, -3, -1, -2, -1, -4},\n{-2,  0,  1, -1, -3,  0,  0, -2,  8, -3, -3, -1, -2, -1, -2, -1, -2, -2,  2, -3,  0,  0, -1, -4},\n{-1, -3, -3, -3, -1, -3, -3, -4, -3,  4,  2, -3,  1,  0, -3, -2, -1, -3, -1,  3, -3, -3, -1, -4},\n{-1, -2, -3, -4, -1, -2, -3, -4, -3,  2,  4, -2,  2,  0, -3, -2, -1, -2, -1,  1, -4, -3, -1, -4},\n{-1,  2,  0, -1, -3,  1,  1, -2, -1, -3, -2,  5, -1, -3, -1,  0, -1, -3, -2, -2,  0,  1, -1, -4},\n{-1, -1, -2, -3, -1,  0, -2, -3, -2,  1,  2, -1,  5,  0, -2, -1, -1, -1, -1,  1, -3, -1, -1, -4},\n{-2, -3, -3, -3, -2, -3, -3, -3, -1,  0,  0, -3,  0,  6, -4, -2, -2,  1,  3, -1, -3, -3, -1, -4},\n{-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4,  7, -1, -1, -4, -3, -2, -2, -1, -2, -4},\n{ 1, -1,  1,  0, -1,  0,  0,  0, -1, -2, -2,  0, -1, -2, -1,  4,  1, -3, -2, -2,  0,  0,  0, -4},\n{ 0, -1,  0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1,  1,  5, -2, -2,  0, -1, -1,  0, -4},\n{-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1,  1, -4, -3, -2, 11,  2, -3, -4, -3, -2, -4},\n{-2, -2, -2, -3, -2, -1, -2, -3,  2, -1, -1, -2, -1,  3, -3, -2, -2,  2,  7, -1, -3, -2, -1, -4},\n{ 0, -3, -3, -3, -1, -2, -2, -3, -3,  3,  1, -2,  1, -1, -2, -2,  0, -3, -1,  4, -3, -2, -1, -4},\n{-2, -1,  3,  4, -3,  0,  1, -1,  0, -3, -4,  0, -3, -3, -2,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n{-1,  0,  0,  1, -3,  3,  4, -2,  0, -3, -3,  1, -1, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n{ 0, -1, -1, -1, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -2,  0,  0, -2, -1, -1, -1, -1, -1, -4},\n{-4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4,  1}\n};\n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nint\nmain( int argc, char** argv) \n{\n\n  printf(\"WG size of kernel = %d \\n\", BLOCK_SIZE);\n\n    runTest( argc, argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid usage(int argc, char **argv)\n{\n\tfprintf(stderr, \"Usage: %s <max_rows/max_cols> <penalty> \\n\", argv[0]);\n\tfprintf(stderr, \"\\t<dimension>  - x and y dimensions\\n\");\n\tfprintf(stderr, \"\\t<penalty> - penalty(positive integer)\\n\");\n\texit(1);\n}\n\nvoid runTest( int argc, char** argv) \n{\n    int max_rows, max_cols, penalty;\n    int *input_itemsets, *output_itemsets, *referrence;\n\tint *matrix_cuda,  *referrence_cuda;\n\tint size;\n\t\n    \n\tif (argc == 3)\n\t{\n\t\tmax_rows = atoi(argv[1]);\n\t\tmax_cols = atoi(argv[1]);\n\t\tpenalty = atoi(argv[2]);\n\t}\n    else{\n\tusage(argc, argv);\n    }\n\t\n\tif(atoi(argv[1])%16!=0){\n\tfprintf(stderr,\"The dimension values must be a multiple of 16\\n\");\n\texit(1);\n\t}\n\t\n\n\tmax_rows = max_rows + 1;\n\tmax_cols = max_cols + 1;\n\treferrence = (int *)malloc( max_rows * max_cols * sizeof(int) );\n    input_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n\toutput_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n\t\n\n\tif (!input_itemsets)\n\t\tfprintf(stderr, \"error: can not allocate memory\");\n\n    srand ( 7 );\n\t\n\t\n    for (int i = 0 ; i < max_cols; i++){\n\t\tfor (int j = 0 ; j < max_rows; j++){\n\t\t\tinput_itemsets[i*max_cols+j] = 0;\n\t\t}\n\t}\n\t\n\tprintf(\"Start Needleman-Wunsch\\n\");\n\t\n\tfor( int i=1; i< max_rows ; i++){\n       input_itemsets[i*max_cols] = rand() % 10 + 1;\n\t}\n    for( int j=1; j< max_cols ; j++){\n       input_itemsets[j] = rand() % 10 + 1;\n\t}\n\n\n\tfor (int i = 1 ; i < max_cols; i++){\n\t\tfor (int j = 1 ; j < max_rows; j++){\n\t\treferrence[i*max_cols+j] = blosum62[input_itemsets[i*max_cols]][input_itemsets[j]];\n\t\t}\n\t}\n\n    for( int i = 1; i< max_rows ; i++)\n       input_itemsets[i*max_cols] = -i * penalty;\n\tfor( int j = 1; j< max_cols ; j++)\n       input_itemsets[j] = -j * penalty;\n\n\n    size = max_cols * max_rows;\n\tcudaMalloc((void**)& referrence_cuda, sizeof(int)*size);\n\tcudaMalloc((void**)& matrix_cuda, sizeof(int)*size);\n\t\n\tcudaMemcpy(referrence_cuda, referrence, sizeof(int) * size, cudaMemcpyHostToDevice);\n\tcudaMemcpy(matrix_cuda, input_itemsets, sizeof(int) * size, cudaMemcpyHostToDevice);\n\n    dim3 dimGrid;\n\tdim3 dimBlock(BLOCK_SIZE, 1);\n\tint block_width = ( max_cols - 1 )/BLOCK_SIZE;\n\n#ifdef  TIMING\n  gettimeofday(&tv_kernel_start, NULL);\n#endif\n\n\tprintf(\"Processing top-left matrix\\n\");\n\tfor( int i = 1 ; i <= block_width ; i++){\n\t\tdimGrid.x = i;\n\t\tdimGrid.y = 1;\n\t\tneedle_cuda_shared_1<<<dimGrid, dimBlock>>>(referrence_cuda, matrix_cuda\n\t\t                                      ,max_cols, penalty, i, block_width); \n\t}\n\tprintf(\"Processing bottom-right matrix\\n\");\n\tfor( int i = block_width - 1  ; i >= 1 ; i--){\n\t\tdimGrid.x = i;\n\t\tdimGrid.y = 1;\n\t\tneedle_cuda_shared_2<<<dimGrid, dimBlock>>>(referrence_cuda, matrix_cuda\n\t\t                                      ,max_cols, penalty, i, block_width); \n\t}\n\n#ifdef  TIMING\n    gettimeofday(&tv_kernel_end, NULL);\n    tvsub(&tv_kernel_end, &tv_kernel_start, &tv);\n    kernel_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n    cudaMemcpy(output_itemsets, matrix_cuda, sizeof(int) * size, cudaMemcpyDeviceToHost);\n\t\n#ifdef TRACEBACK\n\t\n\tFILE *fpo = fopen(\"result.txt\",\"w\");\n\tfprintf(fpo, \"print traceback value GPU:\\n\");\n    \n\tfor (int i = max_rows - 2,  j = max_rows - 2; i>=0, j>=0;){\n\t\tint nw, n, w, traceback;\n\t\tif ( i == max_rows - 2 && j == max_rows - 2 )\n\t\t\tfprintf(fpo, \"%d \", output_itemsets[ i * max_cols + j]); //print the first element\n\t\tif ( i == 0 && j == 0 )\n           break;\n\t\tif ( i > 0 && j > 0 ){\n\t\t\tnw = output_itemsets[(i - 1) * max_cols + j - 1];\n\t\t    w  = output_itemsets[ i * max_cols + j - 1 ];\n            n  = output_itemsets[(i - 1) * max_cols + j];\n\t\t}\n\t\telse if ( i == 0 ){\n\t\t    nw = n = LIMIT;\n\t\t    w  = output_itemsets[ i * max_cols + j - 1 ];\n\t\t}\n\t\telse if ( j == 0 ){\n\t\t    nw = w = LIMIT;\n            n  = output_itemsets[(i - 1) * max_cols + j];\n\t\t}\n\t\telse{\n\t\t}\n\n\t\tint new_nw, new_w, new_n;\n\t\tnew_nw = nw + referrence[i * max_cols + j];\n\t\tnew_w = w - penalty;\n\t\tnew_n = n - penalty;\n\t\t\n\t\ttraceback = maximum(new_nw, new_w, new_n);\n\t\tif(traceback == new_nw)\n\t\t\ttraceback = nw;\n\t\tif(traceback == new_w)\n\t\t\ttraceback = w;\n\t\tif(traceback == new_n)\n            traceback = n;\n\t\t\t\n\t\tfprintf(fpo, \"%d \", traceback);\n\n\t\tif(traceback == nw )\n\t\t{i--; j--; continue;}\n\n        else if(traceback == w )\n\t\t{j--; continue;}\n\n        else if(traceback == n )\n\t\t{i--; continue;}\n\n\t\telse\n\t\t;\n\t}\n\t\n\tfclose(fpo);\n\n#endif\n\n\tcudaFree(referrence_cuda);\n\tcudaFree(matrix_cuda);\n\n\tfree(referrence);\n\tfree(input_itemsets);\n\tfree(output_itemsets);\n\n#ifdef  TIMING\n    printf(\"Exec: %f\\n\", kernel_time);\n#endif\n}\n\n"}, "code_dirs": {"needle_kernel.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/nw", "needle.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/nw/needle.cu"}}
{"kernel_name": "nw", "parallel_api": "ocl", "code": {"nw.c": "#ifdef RD_WG_SIZE_0_0\n\t#define BLOCK_SIZE RD_WG_SIZE_0_0\n#elif defined(RD_WG_SIZE_0)\n\t#define BLOCK_SIZE RD_WG_SIZE_0\n#elif defined(RD_WG_SIZE)\n\t#define BLOCK_SIZE RD_WG_SIZE\n#else\n\t#define BLOCK_SIZE 16\n#endif\n\n#define LIMIT -999\n\n#include <stdio.h>\n#include <string.h>\n#include <stdlib.h>\n#include <iostream>\n#include <string>\n#include <sys/time.h>\n\n#ifdef NV //NVIDIA\n\t#include <oclUtils.h>\n#else \n\t#include <CL/cl.h>\n#endif\n\nint blosum62[24][24] = {\n{ 4, -1, -2, -2,  0, -1, -1,  0, -2, -1, -1, -1, -1, -2, -1,  1,  0, -3, -2,  0, -2, -1,  0, -4},\n{-1,  5,  0, -2, -3,  1,  0, -2,  0, -3, -2,  2, -1, -3, -2, -1, -1, -3, -2, -3, -1,  0, -1, -4},\n{-2,  0,  6,  1, -3,  0,  0,  0,  1, -3, -3,  0, -2, -3, -2,  1,  0, -4, -2, -3,  3,  0, -1, -4},\n{-2, -2,  1,  6, -3,  0,  2, -1, -1, -3, -4, -1, -3, -3, -1,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n{ 0, -3, -3, -3,  9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1, -3, -3, -2, -4},\n{-1,  1,  0,  0, -3,  5,  2, -2,  0, -3, -2,  1,  0, -3, -1,  0, -1, -2, -1, -2,  0,  3, -1, -4},\n{-1,  0,  0,  2, -4,  2,  5, -2,  0, -3, -3,  1, -2, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n{ 0, -2,  0, -1, -3, -2, -2,  6, -2, -4, -4, -2, -3, -3, -2,  0, -2, -2, -3, -3, -1, -2, -1, -4},\n{-2,  0,  1, -1, -3,  0,  0, -2,  8, -3, -3, -1, -2, -1, -2, -1, -2, -2,  2, -3,  0,  0, -1, -4},\n{-1, -3, -3, -3, -1, -3, -3, -4, -3,  4,  2, -3,  1,  0, -3, -2, -1, -3, -1,  3, -3, -3, -1, -4},\n{-1, -2, -3, -4, -1, -2, -3, -4, -3,  2,  4, -2,  2,  0, -3, -2, -1, -2, -1,  1, -4, -3, -1, -4},\n{-1,  2,  0, -1, -3,  1,  1, -2, -1, -3, -2,  5, -1, -3, -1,  0, -1, -3, -2, -2,  0,  1, -1, -4},\n{-1, -1, -2, -3, -1,  0, -2, -3, -2,  1,  2, -1,  5,  0, -2, -1, -1, -1, -1,  1, -3, -1, -1, -4},\n{-2, -3, -3, -3, -2, -3, -3, -3, -1,  0,  0, -3,  0,  6, -4, -2, -2,  1,  3, -1, -3, -3, -1, -4},\n{-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4,  7, -1, -1, -4, -3, -2, -2, -1, -2, -4},\n{ 1, -1,  1,  0, -1,  0,  0,  0, -1, -2, -2,  0, -1, -2, -1,  4,  1, -3, -2, -2,  0,  0,  0, -4},\n{ 0, -1,  0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1,  1,  5, -2, -2,  0, -1, -1,  0, -4},\n{-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1,  1, -4, -3, -2, 11,  2, -3, -4, -3, -2, -4},\n{-2, -2, -2, -3, -2, -1, -2, -3,  2, -1, -1, -2, -1,  3, -3, -2, -2,  2,  7, -1, -3, -2, -1, -4},\n{ 0, -3, -3, -3, -1, -2, -2, -3, -3,  3,  1, -2,  1, -1, -2, -2,  0, -3, -1,  4, -3, -2, -1, -4},\n{-2, -1,  3,  4, -3,  0,  1, -1,  0, -3, -4,  0, -3, -3, -2,  0, -1, -4, -3, -3,  4,  1, -1, -4},\n{-1,  0,  0,  1, -3,  3,  4, -2,  0, -3, -3,  1, -1, -3, -1,  0, -1, -3, -2, -2,  1,  4, -1, -4},\n{ 0, -1, -1, -1, -2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -2,  0,  0, -2, -1, -1, -1, -1, -1, -4},\n{-4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4, -4,  1}\n};\n\nint platform_id_inuse = 0;\nint device_id_inuse = 0;\n\n#ifdef TIMING\n#include \"timing.h\"\n\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_init_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nstatic cl_context\t    context;\nstatic cl_command_queue cmd_queue;\nstatic cl_device_type   device_type;\nstatic cl_device_id   * device_list;\nstatic cl_uint          num_devices;\nstatic cl_uint          num_platforms;\n\nstatic int initialize()\n{\n\tcl_platform_id platform_id;\n\tif (clGetPlatformIDs(0, NULL, &num_platforms) != CL_SUCCESS) { printf(\"ERROR: clGetPlatformIDs(0,0,*) failed\\n\"); return -1; }\n\tcl_platform_id all_platform_id[num_platforms];\n\tif (clGetPlatformIDs(num_platforms, all_platform_id, NULL) != CL_SUCCESS) { printf(\"ERROR: clGetPlatformIDs(*,*,0) failed\\n\"); return -1; }\n    platform_id = all_platform_id[platform_id_inuse];\n\n    if (clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_ALL, 0, NULL, &num_devices) != CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\tprintf(\"num_devices = %d\\n\", num_devices);\n    if(device_id_inuse > (int)num_devices) {\n        printf(\"Invalid Device Number\\n\");\n        return -1;\n    }\n\tdevice_list = new cl_device_id[num_devices];\n\tif( !device_list ) { printf(\"ERROR: new cl_device_id[] failed\\n\"); return -1; }\n    if (clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_ALL, num_devices, device_list, NULL) != CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\n    if (clGetDeviceInfo(device_list[device_id_inuse], CL_DEVICE_TYPE, sizeof(device_type), (void *)&device_type, NULL)!= CL_SUCCESS) { printf(\"ERROR: clGetDeviceIDs failed\\n\"); return -1; };\n\n\tcl_context_properties ctxprop[] = { CL_CONTEXT_PLATFORM, (cl_context_properties)platform_id, 0};\n\tcontext = clCreateContextFromType( ctxprop, device_type, NULL, NULL, NULL );\n\tif( !context ) { printf(\"ERROR: clCreateContextFromType(%s) failed\\n\", device_type == CL_DEVICE_TYPE_GPU ? \"GPU\" : \"CPU\"); return -1; }\n\n#ifdef TIMING\n\tcmd_queue = clCreateCommandQueue( context, device_list[device_id_inuse], CL_QUEUE_PROFILING_ENABLE, NULL );\n#else\n\tcmd_queue = clCreateCommandQueue( context, device_list[device_id_inuse], 0, NULL );\n#endif\n\tif( !cmd_queue ) { printf(\"ERROR: clCreateCommandQueue() failed\\n\"); return -1; }\n\n\treturn 0;\n}\n\nstatic int shutdown()\n{\n\tif( cmd_queue ) clReleaseCommandQueue( cmd_queue );\n\tif( context ) clReleaseContext( context );\n\tif( device_list ) delete device_list;\n\n\tcmd_queue = 0;\n\tcontext = 0;\n\tdevice_list = 0;\n\tnum_devices = 0;\n\tdevice_type = 0;\n\n\treturn 0;\n}\n\nint maximum( int a,\n\t\t int b,\n\t\t int c){\n\n\tint k;\n\tif( a <= b )\n\t  k = b;\n\telse \n\t  k = a;\n\tif( k <=c )\n\t  return(c);\n\telse\n\t  return(k);\n}\n\nvoid usage(int argc, char **argv)\n{\n\tfprintf(stderr, \"Usage: %s <max_rows/max_cols> <penalty> [-p platform] [-d device]\\n\", argv[0]);\n\tfprintf(stderr, \"\\t<dimension>  - x and y dimensions\\n\");\n\tfprintf(stderr, \"\\t<penalty> - penalty(positive integer)\\n\");\n\tfprintf(stderr, \"\\t<file> - filename\\n\");\n\tfprintf(stderr, \"\\t[platform] - platform id\\n\");\n\tfprintf(stderr, \"\\t[device] - device id\\n\");\n\texit(1);\n}\n\ndouble gettime() {\n  struct timeval t;\n  gettimeofday(&t,NULL);\n  return t.tv_sec+t.tv_usec*1e-6;\n}\n\nint main(int argc, char **argv){\n\n  printf(\"WG size of kernel = %d \\n\", BLOCK_SIZE);\n\n    int max_rows, max_cols, penalty;\n\tchar * tempchar;\n\tif (argc >= 4)\n\t{\n\t\tmax_rows = atoi(argv[1]);\n\t\tmax_cols = atoi(argv[1]);\n\t\tpenalty = atoi(argv[2]);\n\t\ttempchar = argv[3];\n\n        int cur_arg;\n        for (cur_arg = 1; cur_arg<argc; cur_arg++) {\n            if (strcmp(argv[cur_arg], \"-p\") == 0) {\n                if (argc >= cur_arg + 1) {\n                    platform_id_inuse = atoi(argv[cur_arg+1]);\n                    cur_arg++;\n                }\n            }\n            else if (strcmp(argv[cur_arg], \"-d\") == 0) {\n                if (argc >= cur_arg + 1) {\n                    device_id_inuse = atoi(argv[cur_arg+1]);\n                    cur_arg++;\n                }\n            }\n        }\n\t}\n    else{\n\t     usage(argc, argv);\n    }\n\n\tif(atoi(argv[1])%16!=0){\n\tfprintf(stderr,\"The dimension values must be a multiple of 16\\n\");\n\texit(1);\n\t}\n\n\tmax_rows = max_rows + 1;\n\tmax_cols = max_cols + 1;\n\n\tint *reference;\n\tint *input_itemsets;\n\tint *output_itemsets;\n\t\n\treference = (int *)malloc( max_rows * max_cols * sizeof(int) );\n    input_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n\toutput_itemsets = (int *)malloc( max_rows * max_cols * sizeof(int) );\n\t\n\tsrand(7);\n\t\n\tfor (int i = 0 ; i < max_cols; i++){\n\t\tfor (int j = 0 ; j < max_rows; j++){\n\t\t\tinput_itemsets[i*max_cols+j] = 0;\n\t\t}\n\t}\n\n\tfor( int i=1; i< max_rows ; i++){\n\t\t\tinput_itemsets[i*max_cols] = rand() % 10 + 1;\n\t}\n\t\n    for( int j=1; j< max_cols ; j++){\n\t\t\tinput_itemsets[j] = rand() % 10 + 1;\n\t}\n\t\n\tfor (int i = 1 ; i < max_cols; i++){\n\t\tfor (int j = 1 ; j < max_rows; j++){\n\t\treference[i*max_cols+j] = blosum62[input_itemsets[i*max_cols]][input_itemsets[j]];\n\t\t}\n\t}\n\n    for( int i = 1; i< max_rows ; i++)\n       input_itemsets[i*max_cols] = -i * penalty;\n\tfor( int j = 1; j< max_cols ; j++)\n       input_itemsets[j] = -j * penalty;\n\t\n\tint sourcesize = 1024*1024;\n\t\t\n\tchar * source = (char *)calloc(sourcesize, sizeof(char)); \n\tif(!source) { printf(\"ERROR: calloc(%d) failed\\n\", sourcesize); return -1; }\n\n\tconst char * kernel_nw1  = \"nw_kernel1\";\n\tconst char * kernel_nw2  = \"nw_kernel2\";\n\tFILE * fp = fopen(tempchar, \"rb\"); \n\tif(!fp) { printf(\"ERROR: unable to open '%s'\\n\", tempchar); return -1; }\n\tfread(source + strlen(source), sourcesize, 1, fp);\n\tfclose(fp);\n\n\tsize_t nworkitems, workgroupsize = 0;\n\tnworkitems = BLOCK_SIZE;\n\n\tif(nworkitems < 1 || workgroupsize < 0){\n\t\tprintf(\"ERROR: invalid or missing <num_work_items>[/<work_group_size>]\\n\"); \n\t\treturn -1;\n\t}\n\tsize_t local_work[3] = { (workgroupsize>0)?workgroupsize:1, 1, 1 };\n\tsize_t global_work[3] = { nworkitems, 1, 1 };\n\n#ifdef  TIMING\n    gettimeofday(&tv_total_start, NULL);\n#endif\n\tif(initialize()) return -1;\n\n\tcl_int err = 0;\n\tconst char * slist[2] = { source, 0 };\n\tcl_program prog = clCreateProgramWithSource(context, 1, slist, NULL, &err);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateProgramWithSource() => %d\\n\", err); return -1; }\n\n\tchar clOptions[110];\n\t//  sprintf(clOptions,\"-I../../src\");                                                                                 \n\tsprintf(clOptions,\" \");\n\n#ifdef BLOCK_SIZE\n\tsprintf(clOptions + strlen(clOptions), \" -DBLOCK_SIZE=%d\", BLOCK_SIZE);\n#endif\n\n\terr = clBuildProgram(prog, 0, NULL, clOptions, NULL, NULL);\n\t/*{ // show warnings/errors\n\t\tstatic char log[65536]; memset(log, 0, sizeof(log));\n\t\tcl_device_id device_id = 0;\n\t\terr = clGetContextInfo(context, CL_CONTEXT_DEVICES, sizeof(device_id), &device_id, NULL);\n\t\tclGetProgramBuildInfo(prog, device_id, CL_PROGRAM_BUILD_LOG, sizeof(log)-1, log, NULL);\n\t\tif(err || strstr(log,\"warning:\") || strstr(log, \"error:\")) printf(\"<<<<\\n%s\\n>>>>\\n\", log);\n\t}*/\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clBuildProgram() => %d\\n\", err); return -1; }\n    \t\n\tcl_kernel kernel1;\n\tcl_kernel kernel2;\n\tkernel1 = clCreateKernel(prog, kernel_nw1, &err);  \n\tkernel2 = clCreateKernel(prog, kernel_nw2, &err);  \n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateKernel() 0 => %d\\n\", err); return -1; }\n\tclReleaseProgram(prog);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_init_end, NULL);\n\ttvsub(&tv_init_end, &tv_total_start, &tv);\n\tinit_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tcl_mem input_itemsets_d;\n\tcl_mem output_itemsets_d;\n\tcl_mem reference_d;\n\t\n\tinput_itemsets_d = clCreateBuffer(context, CL_MEM_READ_WRITE, max_cols * max_rows * sizeof(int), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer input_item_set (size:%d) => %d\\n\", max_cols * max_rows, err); return -1;}\n\treference_d\t\t = clCreateBuffer(context, CL_MEM_READ_WRITE, max_cols * max_rows * sizeof(int), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer reference (size:%d) => %d\\n\", max_cols * max_rows, err); return -1;}\n\toutput_itemsets_d = clCreateBuffer(context, CL_MEM_READ_WRITE, max_cols * max_rows * sizeof(int), NULL, &err );\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer output_item_set (size:%d) => %d\\n\", max_cols * max_rows, err); return -1;}\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_init_end, &tv);\n    mem_alloc_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n    cl_event event[2];\n\terr = clEnqueueWriteBuffer(cmd_queue, input_itemsets_d, 1, 0, max_cols * max_rows * sizeof(int), input_itemsets, 0, 0, &event[0]);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer bufIn1 (size:%d) => %d\\n\", max_cols * max_rows, err); return -1; }\n\terr = clEnqueueWriteBuffer(cmd_queue, reference_d, 1, 0, max_cols * max_rows * sizeof(int), reference, 0, 0, &event[1]);\n\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer bufIn2 (size:%d) => %d\\n\", max_cols * max_rows, err); return -1; }\n\n\tint worksize = max_cols - 1;\n\tprintf(\"worksize = %d\\n\", worksize);\n\tint offset_r = 0, offset_c = 0;\n\tint block_width = worksize/BLOCK_SIZE ;\n\t\n\tclSetKernelArg(kernel1, 0, sizeof(void *), (void*) &reference_d);\n\tclSetKernelArg(kernel1, 1, sizeof(void *), (void*) &input_itemsets_d);\n\tclSetKernelArg(kernel1, 2, sizeof(void *), (void*) &output_itemsets_d);\n\tclSetKernelArg(kernel1, 3, sizeof(cl_int) * (BLOCK_SIZE + 1) *(BLOCK_SIZE+1), (void*)NULL );\n\tclSetKernelArg(kernel1, 4, sizeof(cl_int) *  BLOCK_SIZE * BLOCK_SIZE, (void*)NULL );\n\tclSetKernelArg(kernel1, 5, sizeof(cl_int), (void*) &max_cols);\n\tclSetKernelArg(kernel1, 6, sizeof(cl_int), (void*) &penalty);\n\tclSetKernelArg(kernel1, 8, sizeof(cl_int), (void*) &block_width);\n\tclSetKernelArg(kernel1, 9, sizeof(cl_int), (void*) &worksize);\n\tclSetKernelArg(kernel1, 10, sizeof(cl_int), (void*) &offset_r);\n\tclSetKernelArg(kernel1, 11, sizeof(cl_int), (void*) &offset_c);\n\n\tclSetKernelArg(kernel2, 0, sizeof(void *), (void*) &reference_d);\n\tclSetKernelArg(kernel2, 1, sizeof(void *), (void*) &input_itemsets_d);\n\tclSetKernelArg(kernel2, 2, sizeof(void *), (void*) &output_itemsets_d);\n\tclSetKernelArg(kernel2, 3, sizeof(cl_int) * (BLOCK_SIZE + 1) *(BLOCK_SIZE+1), (void*)NULL );\n\tclSetKernelArg(kernel2, 4, sizeof(cl_int) * BLOCK_SIZE *BLOCK_SIZE, (void*)NULL );\n\tclSetKernelArg(kernel2, 5, sizeof(cl_int), (void*) &max_cols);\n\tclSetKernelArg(kernel2, 6, sizeof(cl_int), (void*) &penalty);\n\tclSetKernelArg(kernel2, 8, sizeof(cl_int), (void*) &block_width);\n\tclSetKernelArg(kernel2, 9, sizeof(cl_int), (void*) &worksize);\n\tclSetKernelArg(kernel2, 10, sizeof(cl_int), (void*) &offset_r);\n\tclSetKernelArg(kernel2, 11, sizeof(cl_int), (void*) &offset_c);\n\t\n\tprintf(\"Processing upper-left matrix\\n\");\n    cl_event kernel_event[worksize/BLOCK_SIZE];\n\tfor( int blk = 1 ; blk <= worksize/BLOCK_SIZE ; blk++){\n\t\n\t\tglobal_work[0] = BLOCK_SIZE * blk;\n\t\tlocal_work[0]  = BLOCK_SIZE;\n\t\tclSetKernelArg(kernel1, 7, sizeof(cl_int), (void*) &blk);\n\t\terr = clEnqueueNDRangeKernel(cmd_queue, kernel1, 2, NULL, global_work, local_work, 0, 0, &kernel_event[blk-1]);\n\t\tif(err != CL_SUCCESS) { printf(\"ERROR: 1  clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\t\t\t\n\t}\n\tclFinish(cmd_queue);\n\n#ifdef TIMING\n    h2d_time += probe_event_time(event[0], cmd_queue);\n    h2d_time += probe_event_time(event[1], cmd_queue);\n    clReleaseEvent(event[0]);\n    clReleaseEvent(event[1]);\n\tfor( int blk = 1 ; blk <= worksize/BLOCK_SIZE ; blk++) {\n        kernel_time += probe_event_time(kernel_event[blk-1], cmd_queue);\n        clReleaseEvent(kernel_event[blk-1]);\n    }\n#endif\n\n\tprintf(\"Processing lower-right matrix\\n\");\n\tfor( int blk =  worksize/BLOCK_SIZE - 1  ; blk >= 1 ; blk--){\t   \n\t\tglobal_work[0] = BLOCK_SIZE * blk;\n\t\tlocal_work[0] =  BLOCK_SIZE;\n\t\tclSetKernelArg(kernel2, 7, sizeof(cl_int), (void*) &blk);\n        err = clEnqueueNDRangeKernel(cmd_queue, kernel2, 2, NULL, global_work, local_work, 0, 0, &kernel_event[blk-1]);\n\t\tif(err != CL_SUCCESS) { printf(\"ERROR: 2 clEnqueueNDRangeKernel()=>%d failed\\n\", err); return -1; }\n\t}\n    \n    err = clEnqueueReadBuffer(cmd_queue, input_itemsets_d, 1, 0, max_cols * max_rows * sizeof(int), output_itemsets, 0, 0, &event[0]);\n\tclFinish(cmd_queue);\n#ifdef TIMING\n\tfor( int blk = worksize/BLOCK_SIZE -1; blk >= 1; blk--) {\n        kernel_time += probe_event_time(kernel_event[blk-1], cmd_queue);\n        clReleaseEvent(kernel_event[blk-1]);\n    }\n    d2h_time += probe_event_time(event[0], cmd_queue);\n    clReleaseEvent(event[0]);\n#endif\n\n#ifdef TRACEBACK\n\tFILE *fpo = fopen(\"result.txt\",\"w\");\n\tfprintf(fpo, \"print traceback value GPU:\\n\");\n    \n\tfor (int i = max_rows - 2,  j = max_rows - 2; i>=0, j>=0;){\n\t\tint nw, n, w, traceback;\n\t\tif ( i == max_rows - 2 && j == max_rows - 2 )\n\t\t\tfprintf(fpo, \"%d \", output_itemsets[ i * max_cols + j]); //print the first element\n\t\tif ( i == 0 && j == 0 )\n           break;\n\t\tif ( i > 0 && j > 0 ){\n\t\t\tnw = output_itemsets[(i - 1) * max_cols + j - 1];\n\t\t    w  = output_itemsets[ i * max_cols + j - 1 ];\n            n  = output_itemsets[(i - 1) * max_cols + j];\n\t\t}\n\t\telse if ( i == 0 ){\n\t\t    nw = n = LIMIT;\n\t\t    w  = output_itemsets[ i * max_cols + j - 1 ];\n\t\t}\n\t\telse if ( j == 0 ){\n\t\t    nw = w = LIMIT;\n            n  = output_itemsets[(i - 1) * max_cols + j];\n\t\t}\n\t\telse{\n\t\t}\n\n\t\t//traceback = maximum(nw, w, n);\n\t\tint new_nw, new_w, new_n;\n\t\tnew_nw = nw + reference[i * max_cols + j];\n\t\tnew_w = w - penalty;\n\t\tnew_n = n - penalty;\n\t\t\n\t\ttraceback = maximum(new_nw, new_w, new_n);\n\t\tif(traceback == new_nw)\n\t\t\ttraceback = nw;\n\t\tif(traceback == new_w)\n\t\t\ttraceback = w;\n\t\tif(traceback == new_n)\n            traceback = n;\n\t\t\t\n\t\tfprintf(fpo, \"%d \", traceback);\n\n\t\tif(traceback == nw )\n\t\t{i--; j--; continue;}\n\n        else if(traceback == w )\n\t\t{j--; continue;}\n\n        else if(traceback == n )\n\t\t{i--; continue;}\n\n\t\telse\n\t\t;\n\t}\n\t\n\tfclose(fpo);\n\n#endif\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n\n\tprintf(\"Computation Done\\n\");\n\tif(shutdown()) return -1;\n\n\tclReleaseMemObject(input_itemsets_d);\n\tclReleaseMemObject(output_itemsets_d);\n\tclReleaseMemObject(reference_d);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\ttvsub(&tv_close_end, &tv_total_start, &tv);\n\ttotal_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n\tprintf(\"Init: %f\\n\", init_time);\n\tprintf(\"MemAlloc: %f\\n\", mem_alloc_time);\n\tprintf(\"HtoD: %f\\n\", h2d_time);\n\tprintf(\"Exec: %f\\n\", kernel_time);\n\tprintf(\"DtoH: %f\\n\", d2h_time);\n\tprintf(\"Close: %f\\n\", close_time);\n\tprintf(\"Total: %f\\n\", total_time);\n#endif\n\n\tfree(reference);\n\tfree(input_itemsets);\n\tfree(output_itemsets);\n}", "nw.cl": "#define SCORE(i, j) input_itemsets_l[j + i * (BLOCK_SIZE+1)]\n#define REF(i, j)   reference_l[j + i * BLOCK_SIZE]\n\nint maximum( int a,\n\t\t int b,\n\t\t int c){\n\n\tint k;\n\tif( a <= b )\n\t\tk = b;\n\telse \n\tk = a;\n\n\tif( k <=c )\n\treturn(c);\n\telse\n\treturn(k);\n}\n\n__kernel void \nnw_kernel1(__global int  * reference_d, \n\t\t   __global int  * input_itemsets_d, \n\t\t   __global int  * output_itemsets_d, \n\t\t   __local\tint  * input_itemsets_l,\n\t\t   __local\tint  * reference_l,\n           int cols,\n           int penalty,\n           int blk,\n           int block_width,\n           int worksize,\n           int offset_r,\n           int offset_c\n    )\n{  \n\n    int bx = get_group_id(0);\t\n   \n    int tx = get_local_id(0);\n    \n    int base = offset_r * cols + offset_c;\n    \n    int b_index_x = bx;\n\tint b_index_y = blk - 1 - bx;\n\t\n\t\n\tint index   =   base + cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( cols + 1 );\n\tint index_n   = base + cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n\tint index_w   = base + cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( cols );\n\tint index_nw =  base + cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n   \n    \n\tif (tx == 0){\n\t\tSCORE(tx, 0) = input_itemsets_d[index_nw + tx];\n\t}\n\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\tfor ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n\t\tREF(ty, tx) =  reference_d[index + cols * ty];\n\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\tSCORE((tx + 1), 0) = input_itemsets_d[index_w + cols * tx];\n\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\tSCORE(0, (tx + 1)) = input_itemsets_d[index_n];\n  \n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\t\n\t\n\tfor( int m = 0 ; m < BLOCK_SIZE ; m++){\n\t\n\t  if ( tx <= m ){\n\t  \n\t\t  int t_index_x =  tx + 1;\n\t\t  int t_index_y =  m - tx + 1;\n\t\t\t\n\t\t  SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n\t\t                                         SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n\t\t\t\t\t\t\t\t\t\t\t\t SCORE((t_index_y-1), (t_index_x))   - (penalty));\n\t  }\n\t  barrier(CLK_LOCAL_MEM_FENCE);\n    }\n    \n     barrier(CLK_LOCAL_MEM_FENCE);\n    \n\tfor( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n   \n\t  if ( tx <= m){\n \n\t\t  int t_index_x =  tx + BLOCK_SIZE - m ;\n\t\t  int t_index_y =  BLOCK_SIZE - tx;\n\n         SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n\t\t                                         SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n\t\t \t\t\t\t\t\t\t\t\t\t SCORE((t_index_y-1), (t_index_x))   - (penalty));\n\t   \n\t  }\n\n\t  barrier(CLK_LOCAL_MEM_FENCE);\n\t}\n\t\n\n   for ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n     input_itemsets_d[index + cols * ty] = SCORE((ty+1), (tx+1));\n    \n    return;\n   \n}\n\n__kernel void \nnw_kernel2(__global int  * reference_d, \n\t\t   __global int  * input_itemsets_d, \n\t\t   __global int  * output_itemsets_d, \n\t\t   __local\tint  * input_itemsets_l,\n\t\t   __local\tint  * reference_l,\n           int cols,\n           int penalty,\n           int blk,\n           int block_width,\n           int worksize,\n           int offset_r,\n           int offset_c\n    )\n{  \n\n\tint bx = get_group_id(0);\t\n\t//int bx = get_global_id(0)/BLOCK_SIZE;\n   \n    int tx = get_local_id(0);\n    \n    int base = offset_r * cols + offset_c;\n    \n    int b_index_x = bx + block_width - blk  ;\n\tint b_index_y = block_width - bx -1;\n\t\n\t\n\tint index   =   base + cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( cols + 1 );\n\tint index_n   = base + cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + tx + ( 1 );\n\tint index_w   = base + cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x + ( cols );\n\tint index_nw =  base + cols * BLOCK_SIZE * b_index_y + BLOCK_SIZE * b_index_x;\n    \n\tif (tx == 0)\n\t\tSCORE(tx, 0) = input_itemsets_d[index_nw];\n\n\tfor ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n\t\tREF(ty, tx) =  reference_d[index + cols * ty];\n\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\tSCORE((tx + 1), 0) = input_itemsets_d[index_w + cols * tx];\n\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\tSCORE(0, (tx + 1)) = input_itemsets_d[index_n];\n  \n\tbarrier(CLK_LOCAL_MEM_FENCE);\n  \n\tfor( int m = 0 ; m < BLOCK_SIZE ; m++){\n\t\n\t  if ( tx <= m ){\n\t  \n\t\t  int t_index_x =  tx + 1;\n\t\t  int t_index_y =  m - tx + 1;\n\n         SCORE(t_index_y, t_index_x) = maximum(  SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n\t\t                                         SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n\t\t \t\t\t\t\t\t\t\t\t\t SCORE((t_index_y-1), (t_index_x))   - (penalty));\n\t  }\n\t  barrier(CLK_LOCAL_MEM_FENCE);\n    }\n\n\tfor( int m = BLOCK_SIZE - 2 ; m >=0 ; m--){\n   \n\t  if ( tx <= m){\n \n\t\t  int t_index_x =  tx + BLOCK_SIZE - m ;\n\t\t  int t_index_y =  BLOCK_SIZE - tx;\n\n          SCORE(t_index_y, t_index_x) = maximum( SCORE((t_index_y-1), (t_index_x-1)) + REF((t_index_y-1), (t_index_x-1)),\n\t\t                                         SCORE((t_index_y),   (t_index_x-1)) - (penalty), \n\t\t \t\t\t\t\t\t\t\t\t\t SCORE((t_index_y-1), (t_index_x))   - (penalty));\n\t   \n\t  }\n\n\t  barrier(CLK_LOCAL_MEM_FENCE);\n\t}\n\n\tfor ( int ty = 0 ; ty < BLOCK_SIZE ; ty++)\n\t\tinput_itemsets_d[index + ty * cols] = SCORE((ty+1), (tx+1));\n\t\n    \n    return;\n  \n}\n"}, "code_dirs": {"nw.c": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/nw", "nw.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/nw"}}
{"kernel_name": "particlefilter", "parallel_api": "cuda", "code": {"ex_particle_CUDA_naive_seq.cu": "\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <limits.h>\n#include <math.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <float.h>\n#include <sys/time.h>\n#define PI 3.1415926535897932\n#define BLOCK_X 16\n#define BLOCK_Y 16\n\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\n\nconst int threads_per_block = 128;\n\nlong long get_time() {\n\tstruct timeval tv;\n\tgettimeofday(&tv, NULL);\n\treturn (tv.tv_sec * 1000000) + tv.tv_usec;\n}\n\nfloat elapsed_time(long long start_time, long long end_time) {\n        return (float) (end_time - start_time) / (1000 * 1000);\n}\n\nvoid check_error(cudaError e) {\n     if (e != cudaSuccess) {\n     \tprintf(\"\\nCUDA error: %s\\n\", cudaGetErrorString(e));\n\t    exit(1);\n     }\n}\n__device__ int findIndexSeq(double * CDF, int lengthCDF, double value)\n{\n\tint index = -1;\n\tint x;\n\tfor(x = 0; x < lengthCDF; x++)\n\t{\n\t\tif(CDF[x] >= value)\n\t\t{\n\t\t\tindex = x;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif(index == -1)\n\t\treturn lengthCDF-1;\n\treturn index;\n}\n__device__ int findIndexBin(double * CDF, int beginIndex, int endIndex, double value)\n{\n\tif(endIndex < beginIndex)\n\t\treturn -1;\n\tint middleIndex;\n\twhile(endIndex > beginIndex)\n\t{\n\t\tmiddleIndex = beginIndex + ((endIndex-beginIndex)/2);\n\t\tif(CDF[middleIndex] >= value)\n\t\t{\n\t\t\tif(middleIndex == 0)\n\t\t\t\treturn middleIndex;\n\t\t\telse if(CDF[middleIndex-1] < value)\n\t\t\t\treturn middleIndex;\n\t\t\telse if(CDF[middleIndex-1] == value)\n\t\t\t{\n\t\t\t\twhile(CDF[middleIndex] == value && middleIndex >= 0)\n\t\t\t\t\tmiddleIndex--;\n\t\t\t\tmiddleIndex++;\n\t\t\t\treturn middleIndex;\n\t\t\t}\n\t\t}\n\t\tif(CDF[middleIndex] > value)\n\t\t\tendIndex = middleIndex-1;\n\t\telse\n\t\t\tbeginIndex = middleIndex+1;\n\t}\n\treturn -1;\n}\n\n__global__ void kernel(double * arrayX, double * arrayY, double * CDF, double * u, double * xj, double * yj, int Nparticles){\n\tint block_id = blockIdx.x;// + gridDim.x * blockIdx.y;\n\tint i = blockDim.x * block_id + threadIdx.x;\n\t\n\tif(i < Nparticles){\n\t\n\t\tint index = -1;\n\t\tint x;\n\t\t\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\tif(CDF[x] >= u[i]){\n\t\t\t\tindex = x;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif(index == -1){\n\t\t\tindex = Nparticles-1;\n\t\t}\n\t\t\n\t\txj[i] = arrayX[index];\n\t\tyj[i] = arrayY[index];\n\t\t\n\t}\n}\n\ndouble roundDouble(double value){\n\tint newValue = (int)(value);\n\tif(value - newValue < .5)\n\treturn newValue;\n\telse\n\treturn newValue++;\n}\n\nvoid setIf(int testValue, int newValue, int * array3D, int * dimX, int * dimY, int * dimZ){\n\tint x, y, z;\n\tfor(x = 0; x < *dimX; x++){\n\t\tfor(y = 0; y < *dimY; y++){\n\t\t\tfor(z = 0; z < *dimZ; z++){\n\t\t\t\tif(array3D[x * *dimY * *dimZ+y * *dimZ + z] == testValue)\n\t\t\t\tarray3D[x * *dimY * *dimZ + y * *dimZ + z] = newValue;\n\t\t\t}\n\t\t}\n\t}\n}\n\ndouble randu(int * seed, int index)\n{\n\tint num = A*seed[index] + C;\n\tseed[index] = num % M;\n\treturn fabs(seed[index]/((double) M));\n}\n\ndouble randn(int * seed, int index){\n\tdouble u = randu(seed, index);\n\tdouble v = randu(seed, index);\n\tdouble cosine = cos(2*PI*v);\n\tdouble rt = -2*log(u);\n\treturn sqrt(rt)*cosine;\n}\n\nvoid addNoise(int * array3D, int * dimX, int * dimY, int * dimZ, int * seed){\n\tint x, y, z;\n\tfor(x = 0; x < *dimX; x++){\n\t\tfor(y = 0; y < *dimY; y++){\n\t\t\tfor(z = 0; z < *dimZ; z++){\n\t\t\t\tarray3D[x * *dimY * *dimZ + y * *dimZ + z] = array3D[x * *dimY * *dimZ + y * *dimZ + z] + (int)(5*randn(seed, 0));\n\t\t\t}\n\t\t}\n\t}\n}\n\nvoid strelDisk(int * disk, int radius)\n{\n\tint diameter = radius*2 - 1;\n\tint x, y;\n\tfor(x = 0; x < diameter; x++){\n\t\tfor(y = 0; y < diameter; y++){\n\t\t\tdouble distance = sqrt(pow((double)(x-radius+1),2) + pow((double)(y-radius+1),2));\n\t\t\tif(distance < radius)\n\t\t\t    disk[x*diameter + y] = 1;\n            else\n\t\t\t    disk[x*diameter + y] = 0;\n\t\t}\n\t}\n}\n\nvoid dilate_matrix(int * matrix, int posX, int posY, int posZ, int dimX, int dimY, int dimZ, int error)\n{\n\tint startX = posX - error;\n\twhile(startX < 0)\n\tstartX++;\n\tint startY = posY - error;\n\twhile(startY < 0)\n\tstartY++;\n\tint endX = posX + error;\n\twhile(endX > dimX)\n\tendX--;\n\tint endY = posY + error;\n\twhile(endY > dimY)\n\tendY--;\n\tint x,y;\n\tfor(x = startX; x < endX; x++){\n\t\tfor(y = startY; y < endY; y++){\n\t\t\tdouble distance = sqrt( pow((double)(x-posX),2) + pow((double)(y-posY),2) );\n\t\t\tif(distance < error)\n\t\t\tmatrix[x*dimY*dimZ + y*dimZ + posZ] = 1;\n\t\t}\n\t}\n}\n\n\nvoid imdilate_disk(int * matrix, int dimX, int dimY, int dimZ, int error, int * newMatrix)\n{\n\tint x, y, z;\n\tfor(z = 0; z < dimZ; z++){\n\t\tfor(x = 0; x < dimX; x++){\n\t\t\tfor(y = 0; y < dimY; y++){\n\t\t\t\tif(matrix[x*dimY*dimZ + y*dimZ + z] == 1){\n\t\t\t\t\tdilate_matrix(newMatrix, x, y, z, dimX, dimY, dimZ, error);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nvoid getneighbors(int * se, int numOnes, double * neighbors, int radius){\n\tint x, y;\n\tint neighY = 0;\n\tint center = radius - 1;\n\tint diameter = radius*2 -1;\n\tfor(x = 0; x < diameter; x++){\n\t\tfor(y = 0; y < diameter; y++){\n\t\t\tif(se[x*diameter + y]){\n\t\t\t\tneighbors[neighY*2] = (int)(y - center);\n\t\t\t\tneighbors[neighY*2 + 1] = (int)(x - center);\n\t\t\t\tneighY++;\n\t\t\t}\n\t\t}\n\t}\n}\n\nvoid videoSequence(int * I, int IszX, int IszY, int Nfr, int * seed){\n\tint k;\n\tint max_size = IszX*IszY*Nfr;\n\tint x0 = (int)roundDouble(IszY/2.0);\n\tint y0 = (int)roundDouble(IszX/2.0);\n\tI[x0 *IszY *Nfr + y0 * Nfr  + 0] = 1;\n\t\n\tint xk, yk, pos;\n\tfor(k = 1; k < Nfr; k++){\n\t\txk = abs(x0 + (k-1));\n\t\tyk = abs(y0 - 2*(k-1));\n\t\tpos = yk * IszY * Nfr + xk *Nfr + k;\n\t\tif(pos >= max_size)\n\t\tpos = 0;\n\t\tI[pos] = 1;\n\t}\n\t\n\tint * newMatrix = (int *)malloc(sizeof(int)*IszX*IszY*Nfr);\n\timdilate_disk(I, IszX, IszY, Nfr, 5, newMatrix);\n\tint x, y;\n\tfor(x = 0; x < IszX; x++){\n\t\tfor(y = 0; y < IszY; y++){\n\t\t\tfor(k = 0; k < Nfr; k++){\n\t\t\t\tI[x*IszY*Nfr + y*Nfr + k] = newMatrix[x*IszY*Nfr + y*Nfr + k];\n\t\t\t}\n\t\t}\n\t}\n\tfree(newMatrix);\n\t\n\tsetIf(0, 100, I, &IszX, &IszY, &Nfr);\n\tsetIf(1, 228, I, &IszX, &IszY, &Nfr);\n\taddNoise(I, &IszX, &IszY, &Nfr, seed);\n}\n\ndouble calcLikelihoodSum(int * I, int * ind, int numOnes){\n\tdouble likelihoodSum = 0.0;\n\tint y;\n\tfor(y = 0; y < numOnes; y++)\n\tlikelihoodSum += (pow((double)(I[ind[y]] - 100),2) - pow((double)(I[ind[y]]-228),2))/50.0;\n\treturn likelihoodSum;\n}\n\nint findIndex(double * CDF, int lengthCDF, double value){\n\tint index = -1;\n\tint x;\n\tfor(x = 0; x < lengthCDF; x++){\n\t\tif(CDF[x] >= value){\n\t\t\tindex = x;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif(index == -1){\n\t\treturn lengthCDF-1;\n\t}\n\treturn index;\n}\n\nvoid particleFilter(int * I, int IszX, int IszY, int Nfr, int * seed, int Nparticles){\n\tint max_size = IszX*IszY*Nfr;\n\tlong long start = get_time();\n\tdouble xe = roundDouble(IszY/2.0);\n\tdouble ye = roundDouble(IszX/2.0);\n\t\n\tint radius = 5;\n\tint diameter = radius*2 - 1;\n\tint * disk = (int *)malloc(diameter*diameter*sizeof(int));\n\tstrelDisk(disk, radius);\n\tint countOnes = 0;\n\tint x, y;\n\tfor(x = 0; x < diameter; x++){\n\t\tfor(y = 0; y < diameter; y++){\n\t\t\tif(disk[x*diameter + y] == 1)\n\t\t\t\tcountOnes++;\n\t\t}\n\t}\n\tdouble * objxy = (double *)malloc(countOnes*2*sizeof(double));\n\tgetneighbors(disk, countOnes, objxy, radius);\n\t\n\tlong long get_neighbors = get_time();\n\tprintf(\"TIME TO GET NEIGHBORS TOOK: %f\\n\", elapsed_time(start, get_neighbors));\n\tdouble * weights = (double *)malloc(sizeof(double)*Nparticles);\n\tfor(x = 0; x < Nparticles; x++){\n\t\tweights[x] = 1/((double)(Nparticles));\n\t}\n\tlong long get_weights = get_time();\n\tprintf(\"TIME TO GET WEIGHTSTOOK: %f\\n\", elapsed_time(get_neighbors, get_weights));\n\tdouble * likelihood = (double *)malloc(sizeof(double)*Nparticles);\n\tdouble * arrayX = (double *)malloc(sizeof(double)*Nparticles);\n\tdouble * arrayY = (double *)malloc(sizeof(double)*Nparticles);\n\tdouble * xj = (double *)malloc(sizeof(double)*Nparticles);\n\tdouble * yj = (double *)malloc(sizeof(double)*Nparticles);\n\tdouble * CDF = (double *)malloc(sizeof(double)*Nparticles);\n\t\n\tdouble * arrayX_GPU;\n\tdouble * arrayY_GPU;\n\tdouble * xj_GPU;\n\tdouble * yj_GPU;\n\tdouble * CDF_GPU;\n\t\n\tint * ind = (int*)malloc(sizeof(int)*countOnes);\n\tdouble * u = (double *)malloc(sizeof(double)*Nparticles);\n\tdouble * u_GPU;\n\t\n\tcheck_error(cudaMalloc((void **) &arrayX_GPU, sizeof(double)*Nparticles));\n\tcheck_error(cudaMalloc((void **) &arrayY_GPU, sizeof(double)*Nparticles));\n\tcheck_error(cudaMalloc((void **) &xj_GPU, sizeof(double)*Nparticles));\n\tcheck_error(cudaMalloc((void **) &yj_GPU, sizeof(double)*Nparticles));\n\tcheck_error(cudaMalloc((void **) &CDF_GPU, sizeof(double)*Nparticles));\n\tcheck_error(cudaMalloc((void **) &u_GPU, sizeof(double)*Nparticles));\n\t\n\tfor(x = 0; x < Nparticles; x++){\n\t\tarrayX[x] = xe;\n\t\tarrayY[x] = ye;\n\t}\n\tint k;\n\tint indX, indY;\n\tfor(k = 1; k < Nfr; k++){\n\t\tlong long set_arrays = get_time();\n\t\t\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\tarrayX[x] = arrayX[x] + 1.0 + 5.0*randn(seed, x);\n\t\t\tarrayY[x] = arrayY[x] - 2.0 + 2.0*randn(seed, x);\n\t\t}\n\t\tlong long error = get_time();\n\t\tprintf(\"TIME TO SET ERROR TOOK: %f\\n\", elapsed_time(set_arrays, error));\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\n\t\t\tfor(y = 0; y < countOnes; y++){\n\t\t\t\tindX = roundDouble(arrayX[x]) + objxy[y*2 + 1];\n\t\t\t\tindY = roundDouble(arrayY[x]) + objxy[y*2];\n\t\t\t\tind[y] = fabs(indX*IszY*Nfr + indY*Nfr + k);\n\t\t\t\tif(ind[y] >= max_size)\n\t\t\t\t\tind[y] = 0;\n\t\t\t}\n\t\t\tlikelihood[x] = calcLikelihoodSum(I, ind, countOnes);\n\t\t\tlikelihood[x] = likelihood[x]/countOnes;\n\t\t}\n\t\tlong long likelihood_time = get_time();\n\t\tprintf(\"TIME TO GET LIKELIHOODS TOOK: %f\\n\", elapsed_time(error, likelihood_time));\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\tweights[x] = weights[x] * exp(likelihood[x]);\n\t\t}\n\t\tlong long exponential = get_time();\n\t\tprintf(\"TIME TO GET EXP TOOK: %f\\n\", elapsed_time(likelihood_time, exponential));\n\t\tdouble sumWeights = 0;\t\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\tsumWeights += weights[x];\n\t\t}\n\t\tlong long sum_time = get_time();\n\t\tprintf(\"TIME TO SUM WEIGHTS TOOK: %f\\n\", elapsed_time(exponential, sum_time));\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\t\tweights[x] = weights[x]/sumWeights;\n\t\t}\n\t\tlong long normalize = get_time();\n\t\tprintf(\"TIME TO NORMALIZE WEIGHTS TOOK: %f\\n\", elapsed_time(sum_time, normalize));\n\t\txe = 0;\n\t\tye = 0;\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\txe += arrayX[x] * weights[x];\n\t\t\tye += arrayY[x] * weights[x];\n\t\t}\n\t\tlong long move_time = get_time();\n\t\tprintf(\"TIME TO MOVE OBJECT TOOK: %f\\n\", elapsed_time(normalize, move_time));\n\t\tprintf(\"XE: %lf\\n\", xe);\n\t\tprintf(\"YE: %lf\\n\", ye);\n\t\tdouble distance = sqrt( pow((double)(xe-(int)roundDouble(IszY/2.0)),2) + pow((double)(ye-(int)roundDouble(IszX/2.0)),2) );\n\t\tprintf(\"%lf\\n\", distance);\n\t\t\n\t\t\n\t\tCDF[0] = weights[0];\n\t\tfor(x = 1; x < Nparticles; x++){\n\t\t\tCDF[x] = weights[x] + CDF[x-1];\n\t\t}\n\t\tlong long cum_sum = get_time();\n\t\tprintf(\"TIME TO CALC CUM SUM TOOK: %f\\n\", elapsed_time(move_time, cum_sum));\n\t\tdouble u1 = (1/((double)(Nparticles)))*randu(seed, 0);\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\tu[x] = u1 + x/((double)(Nparticles));\n\t\t}\n\t\tlong long u_time = get_time();\n\t\tprintf(\"TIME TO CALC U TOOK: %f\\n\", elapsed_time(cum_sum, u_time));\n\t\tlong long start_copy = get_time();\n\t\tcudaMemcpy(arrayX_GPU, arrayX, sizeof(double)*Nparticles, cudaMemcpyHostToDevice);\n\t\tcudaMemcpy(arrayY_GPU, arrayY, sizeof(double)*Nparticles, cudaMemcpyHostToDevice);\n\t\tcudaMemcpy(xj_GPU, xj, sizeof(double)*Nparticles, cudaMemcpyHostToDevice);\n\t\tcudaMemcpy(yj_GPU, yj, sizeof(double)*Nparticles, cudaMemcpyHostToDevice);\n\t\tcudaMemcpy(CDF_GPU, CDF, sizeof(double)*Nparticles, cudaMemcpyHostToDevice);\n\t\tcudaMemcpy(u_GPU, u, sizeof(double)*Nparticles, cudaMemcpyHostToDevice);\n\t\tlong long end_copy = get_time();\n\t\tint num_blocks = ceil((double) Nparticles/(double) threads_per_block);\n\t\t\n\t\tkernel <<< num_blocks, threads_per_block >>> (arrayX_GPU, arrayY_GPU, CDF_GPU, u_GPU, xj_GPU, yj_GPU, Nparticles);\n                cudaThreadSynchronize();\n                long long start_copy_back = get_time();\n\t\tcudaMemcpy(yj, yj_GPU, sizeof(double)*Nparticles, cudaMemcpyDeviceToHost);\n\t\tcudaMemcpy(xj, xj_GPU, sizeof(double)*Nparticles, cudaMemcpyDeviceToHost);\n\t\tlong long end_copy_back = get_time();\n\t\tprintf(\"SENDING TO GPU TOOK: %lf\\n\", elapsed_time(start_copy, end_copy));\n\t\tprintf(\"CUDA EXEC TOOK: %lf\\n\", elapsed_time(end_copy, start_copy_back));\n\t\tprintf(\"SENDING BACK FROM GPU TOOK: %lf\\n\", elapsed_time(start_copy_back, end_copy_back));\n\t\tlong long xyj_time = get_time();\n\t\tprintf(\"TIME TO CALC NEW ARRAY X AND Y TOOK: %f\\n\", elapsed_time(u_time, xyj_time));\n\t\t\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\tarrayX[x] = xj[x];\n\t\t\tarrayY[x] = yj[x];\n\t\t\tweights[x] = 1/((double)(Nparticles));\n\t\t}\n\t\tlong long reset = get_time();\n\t\tprintf(\"TIME TO RESET WEIGHTS TOOK: %f\\n\", elapsed_time(xyj_time, reset));\n\t}\n\t\n\tcudaFree(u_GPU);\n\tcudaFree(CDF_GPU);\n\tcudaFree(yj_GPU);\n\tcudaFree(xj_GPU);\n\tcudaFree(arrayY_GPU);\n\tcudaFree(arrayX_GPU);\n\t\n\tfree(disk);\n\tfree(objxy);\n\tfree(weights);\n\tfree(likelihood);\n\tfree(arrayX);\n\tfree(arrayY);\n\tfree(xj);\n\tfree(yj);\n\tfree(CDF);\n\tfree(u);\n\tfree(ind);\n}\nint main(int argc, char * argv[]){\n\t\n\tchar* usage = \"naive.out -x <dimX> -y <dimY> -z <Nfr> -np <Nparticles>\";\n\tif(argc != 9)\n\t{\n\t\tprintf(\"%s\\n\", usage);\n\t\treturn 0;\n\t}\n\tif( strcmp( argv[1], \"-x\" ) ||  strcmp( argv[3], \"-y\" ) || strcmp( argv[5], \"-z\" ) || strcmp( argv[7], \"-np\" ) ) {\n\t\tprintf( \"%s\\n\",usage );\n\t\treturn 0;\n\t}\n\t\n\tint IszX, IszY, Nfr, Nparticles;\n\t\n\tif( sscanf( argv[2], \"%d\", &IszX ) == EOF ) {\n\t   printf(\"ERROR: dimX input is incorrect\");\n\t   return 0;\n\t}\n\t\n\tif( IszX <= 0 ) {\n\t\tprintf(\"dimX must be > 0\\n\");\n\t\treturn 0;\n\t}\n\t\n\tif( sscanf( argv[4], \"%d\", &IszY ) == EOF ) {\n\t   printf(\"ERROR: dimY input is incorrect\");\n\t   return 0;\n\t}\n\t\n\tif( IszY <= 0 ) {\n\t\tprintf(\"dimY must be > 0\\n\");\n\t\treturn 0;\n\t}\n\t\n\tif( sscanf( argv[6], \"%d\", &Nfr ) == EOF ) {\n\t   printf(\"ERROR: Number of frames input is incorrect\");\n\t   return 0;\n\t}\n\t\n\tif( Nfr <= 0 ) {\n\t\tprintf(\"number of frames must be > 0\\n\");\n\t\treturn 0;\n\t}\n\t\n\tif( sscanf( argv[8], \"%d\", &Nparticles ) == EOF ) {\n\t   printf(\"ERROR: Number of particles input is incorrect\");\n\t   return 0;\n\t}\n\t\n\tif( Nparticles <= 0 ) {\n\t\tprintf(\"Number of particles must be > 0\\n\");\n\t\treturn 0;\n\t}\n\tint * seed = (int *)malloc(sizeof(int)*Nparticles);\n\tint i;\n\tfor(i = 0; i < Nparticles; i++)\n\t\tseed[i] = time(0)*i;\n\tint * I = (int *)malloc(sizeof(int)*IszX*IszY*Nfr);\n\tlong long start = get_time();\n\tvideoSequence(I, IszX, IszY, Nfr, seed);\n\tlong long endVideoSequence = get_time();\n\tprintf(\"VIDEO SEQUENCE TOOK %f\\n\", elapsed_time(start, endVideoSequence));\n\tparticleFilter(I, IszX, IszY, Nfr, seed, Nparticles);\n\tlong long endParticleFilter = get_time();\n\tprintf(\"PARTICLE FILTER TOOK %f\\n\", elapsed_time(endVideoSequence, endParticleFilter));\n\tprintf(\"ENTIRE PROGRAM TOOK %f\\n\", elapsed_time(start, endParticleFilter));\n\t\n\tfree(seed);\n\tfree(I);\n\treturn 0;\n}\n"}, "code_dirs": {"ex_particle_CUDA_naive_seq.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/particlefilter"}}
{"kernel_name": "particlefilter", "parallel_api": "ocl", "code": {"ex_particle_OCL_naive_seq.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <limits.h>\n#include <math.h>\n#include <unistd.h>\n#include <fcntl.h>\n#include <float.h>\n#include <sys/time.h>\n#include <CL/cl.h>\n#define PI 3.1415926535897932\n#define BLOCK_X 16\n#define BLOCK_Y 16\n\nlong M = INT_MAX;\nint A = 1103515245;\nint C = 12345;\n\nconst int threads_per_block = 128;\n\n#ifdef WIN\n#include <windows.h>\n#else\n#include <pthread.h>\n#include <sys/time.h>\n\ndouble gettime() {\n    struct timeval t;\n    gettimeofday(&t, NULL);\n    return t.tv_sec + t.tv_usec * 1e-6;\n}\n#endif\n\nint device_id_inuse = 0;\nint platform_id_inuse = 0;\n\n#ifndef FLT_MAX\n#define FLT_MAX 3.40282347e+38\n#endif\n\nstatic cl_context context;\nstatic cl_command_queue cmd_queue;\nstatic cl_device_type device_type;\nstatic cl_device_id * device_list;\nstatic cl_int num_devices;\nstatic cl_mem arrayX_GPU;\nstatic cl_mem arrayY_GPU;\nstatic cl_mem xj_GPU;\nstatic cl_mem yj_GPU;\nstatic cl_mem CDF_GPU;\nstatic cl_mem u_GPU;\n\nstatic cl_kernel kernel_s;\ndouble * likelihood ;\ndouble * arrayX ;\ndouble * arrayY ;\ndouble * xj ;\ndouble * yj ;\ndouble * CDF ;\n\nint * ind ;\ndouble * u;\n\nstatic int initialize() {\n    cl_int result;\n    size_t size;\n\n    cl_platform_id platform_id;\n    if (clGetPlatformIDs(1, &platform_id, NULL) != CL_SUCCESS) {\n        printf(\"ERROR: clGetPlatformIDs(1,*,0) failed\\n\");\n        return -1;\n    }\n    cl_context_properties ctxprop[] = {CL_CONTEXT_PLATFORM, (cl_context_properties) platform_id, 0};\n    context = clCreateContextFromType(ctxprop, CL_DEVICE_TYPE_ALL, NULL, NULL, NULL);\n    if (!context) {\n        printf(\"ERROR: clCreateContextFromType() failed\\n\");\n        return -1;\n    }\n\n    result = clGetContextInfo(context, CL_CONTEXT_DEVICES, 0, NULL, &size);\n    num_devices = (int) (size / sizeof (cl_device_id));\n\n    if (result != CL_SUCCESS || num_devices < 1) {\n        printf(\"ERROR: clGetContextInfo() failed\\n\");\n        return -1;\n    }\n    device_list = new cl_device_id[num_devices];\n    if (!device_list) {\n        printf(\"ERROR: new cl_device_id[] failed\\n\");\n        return -1;\n    }\n    result = clGetContextInfo(context, CL_CONTEXT_DEVICES, size, device_list, NULL);\n    if (result != CL_SUCCESS) {\n        printf(\"ERROR: clGetContextInfo() failed\\n\");\n        return -1;\n    }\n\n#ifdef TIMING\n    cmd_queue = clCreateCommandQueue(context, device_list[device_id_inuse], CL_QUEUE_PROFILING_ENABLE, NULL);\n#else\n    cmd_queue = clCreateCommandQueue(context, device_list[device_id_inuse], 0, NULL);\n#endif\n    if (!cmd_queue) {\n        printf(\"ERROR: clCreateCommandQueue() failed\\n\");\n        return -1;\n    }\n\n    return 0;\n}\n\nstatic int shutdown() {\n    if (cmd_queue) clReleaseCommandQueue(cmd_queue);\n    if (context) clReleaseContext(context);\n    if (device_list) delete device_list;\n\n    cmd_queue = 0;\n    context = 0;\n    device_list = 0;\n    num_devices = 0;\n    device_type = 0;\n\n    return 0;\n}\n\nlong long get_time() {\n    struct timeval tv;\n    gettimeofday(&tv, NULL);\n    return (tv.tv_sec * 1000000) +tv.tv_usec;\n}\n\nfloat elapsed_time(long long start_time, long long end_time) {\n    return (float) (end_time - start_time) / (1000 * 1000);\n}\n\ndouble roundDouble(double value) {\n    int newValue = (int) (value);\n    if (value - newValue < .5)\n        return newValue;\n    else\n        return newValue++;\n}\n\n\nvoid setIf(int testValue, int newValue, int * array3D, int * dimX, int * dimY, int * dimZ) {\n    int x, y, z;\n    for (x = 0; x < *dimX; x++) {\n        for (y = 0; y < *dimY; y++) {\n            for (z = 0; z < *dimZ; z++) {\n                if (array3D[x * *dimY * *dimZ + y * *dimZ + z] == testValue)\n                    array3D[x * *dimY * *dimZ + y * *dimZ + z] = newValue;\n            }\n        }\n    }\n}//eo setIf\n\n\ndouble randu(int * seed, int index) {\n    int num = A * seed[index] + C;\n    seed[index] = num % M;\n    return fabs(seed[index] / ((double) M));\n}//eo randu\n\n\ndouble randn(int * seed, int index) {\n    /*Box-Muller algorithm*/\n    double u = randu(seed, index);\n    double v = randu(seed, index);\n    double cosine = cos(2 * PI * v);\n    double rt = -2 * log(u);\n    return sqrt(rt) * cosine;\n}\n\n\nvoid addNoise(int * array3D, int * dimX, int * dimY, int * dimZ, int * seed) {\n    int x, y, z;\n    for (x = 0; x < *dimX; x++) {\n        for (y = 0; y < *dimY; y++) {\n            for (z = 0; z < *dimZ; z++) {\n                array3D[x * *dimY * *dimZ + y * *dimZ + z] = array3D[x * *dimY * *dimZ + y * *dimZ + z] + (int) (5 * randn(seed, 0));\n            }\n        }\n    }\n}\n\n\nvoid strelDisk(int * disk, int radius) {\n    int diameter = radius * 2 - 1;\n    int x, y;\n    for (x = 0; x < diameter; x++) {\n        for (y = 0; y < diameter; y++) {\n            double distance = sqrt(pow((double) (x - radius + 1), 2) + pow((double) (y - radius + 1), 2));\n            if (distance < radius)\n                disk[x * diameter + y] = 1;\n        }\n    }\n}\n\n\nvoid dilate_matrix(int * matrix, int posX, int posY, int posZ, int dimX, int dimY, int dimZ, int error) {\n    int startX = posX - error;\n    while (startX < 0)\n        startX++;\n    int startY = posY - error;\n    while (startY < 0)\n        startY++;\n    int endX = posX + error;\n    while (endX > dimX)\n        endX--;\n    int endY = posY + error;\n    while (endY > dimY)\n        endY--;\n    int x, y;\n    for (x = startX; x < endX; x++) {\n        for (y = startY; y < endY; y++) {\n            double distance = sqrt(pow((double) (x - posX), 2) + pow((double) (y - posY), 2));\n            if (distance < error)\n                matrix[x * dimY * dimZ + y * dimZ + posZ] = 1;\n        }\n    }\n}\n\n\nvoid imdilate_disk(int * matrix, int dimX, int dimY, int dimZ, int error, int * newMatrix) {\n    int x, y, z;\n    for (z = 0; z < dimZ; z++) {\n        for (x = 0; x < dimX; x++) {\n            for (y = 0; y < dimY; y++) {\n                if (matrix[x * dimY * dimZ + y * dimZ + z] == 1) {\n                    dilate_matrix(newMatrix, x, y, z, dimX, dimY, dimZ, error);\n                }\n            }\n        }\n    }\n}\n\n\nvoid getneighbors(int * se, int numOnes, double * neighbors, int radius) {\n    int x, y;\n    int neighY = 0;\n    int center = radius - 1;\n    int diameter = radius * 2 - 1;\n    for (x = 0; x < diameter; x++) {\n        for (y = 0; y < diameter; y++) {\n            if (se[x * diameter + y]) {\n                neighbors[neighY * 2] = (int) (y - center);\n                neighbors[neighY * 2 + 1] = (int) (x - center);\n                neighY++;\n            }\n        }\n    }\n}\n\n\nvoid videoSequence(int * I, int IszX, int IszY, int Nfr, int * seed) {\n    int k;\n    int max_size = IszX * IszY*Nfr;\n    /*get object centers*/\n    int x0 = (int) roundDouble(IszY / 2.0);\n    int y0 = (int) roundDouble(IszX / 2.0);\n    I[x0 * IszY * Nfr + y0 * Nfr + 0] = 1;\n\n    /*move point*/\n    int xk, yk, pos;\n    for (k = 1; k < Nfr; k++) {\n        xk = abs(x0 + (k - 1));\n        yk = abs(y0 - 2 * (k - 1));\n        pos = yk * IszY * Nfr + xk * Nfr + k;\n        if (pos >= max_size)\n            pos = 0;\n        I[pos] = 1;\n    }\n\n    /*dilate matrix*/\n    int * newMatrix = (int *) malloc(sizeof (int) *IszX * IszY * Nfr);\n    imdilate_disk(I, IszX, IszY, Nfr, 5, newMatrix);\n    int x, y;\n    for (x = 0; x < IszX; x++) {\n        for (y = 0; y < IszY; y++) {\n            for (k = 0; k < Nfr; k++) {\n                I[x * IszY * Nfr + y * Nfr + k] = newMatrix[x * IszY * Nfr + y * Nfr + k];\n            }\n        }\n    }\n    free(newMatrix);\n\n    /*define background, add noise*/\n    setIf(0, 100, I, &IszX, &IszY, &Nfr);\n    setIf(1, 228, I, &IszX, &IszY, &Nfr);\n    /*add noise*/\n    addNoise(I, &IszX, &IszY, &Nfr, seed);\n}\n\n\ndouble calcLikelihoodSum(int * I, int * ind, int numOnes) {\n    double likelihoodSum = 0.0;\n    int y;\n    for (y = 0; y < numOnes; y++)\n        likelihoodSum += (pow((double) (I[ind[y]] - 100), 2) - pow((double) (I[ind[y]] - 228), 2)) / 50.0;\n    return likelihoodSum;\n}\n\n\nint findIndex(double * CDF, int lengthCDF, double value) {\n    int index = -1;\n    int x;\n    for (x = 0; x < lengthCDF; x++) {\n        if (CDF[x] >= value) {\n            index = x;\n            break;\n        }\n    }\n    if (index == -1) {\n        return lengthCDF - 1;\n    }\n    return index;\n}\n\nstatic int allocate(int Nparticles, int countOnes){\n\tint sourcesize = 1024 * 1024;\n\tchar * source = (char *) calloc(sourcesize, sizeof (char));\n\tif (!source) {\n\t\tprintf(\"ERROR: calloc(%d) failed\\n\", sourcesize);\n\t\treturn -1;\n\t}\n\n\tconst char * tempchar = \"./particle_naive.cl\";\n\tFILE * fp = fopen(tempchar, \"rb\");\n\tif (!fp) {\n\t\tprintf(\"ERROR: unable to open '%s'\\n\", tempchar);\n\t\treturn -1;\n\t}\n\tfread(source + strlen(source), sourcesize, 1, fp);\n\tfclose(fp);\n\n\tif (initialize()) return -1;\n\n\tcl_int err = 0;\n\tconst char * slist[2] = {source, 0};\n\tcl_program prog = clCreateProgramWithSource(context, 1, slist, NULL, &err);\n\tif (err != CL_SUCCESS) {\n\t\tprintf(\"ERROR: clCreateProgramWithSource() => %d\\n\", err);\n\t\treturn -1;\n\t}\n\terr = clBuildProgram(prog, 0, NULL, \"-cl-fast-relaxed-math\", NULL, NULL);\n\t{\n\t\tstatic char log[65536];\n\t\tmemset(log, 0, sizeof (log));\n\t\tcl_device_id device_id[2] = {0};\n\t\terr = clGetContextInfo(context, CL_CONTEXT_DEVICES, sizeof (device_id), &device_id[device_id_inuse], NULL);\n\t\tif (err != CL_SUCCESS) {\n\t\t\tif (err == CL_INVALID_CONTEXT)\n\t\t\t\tprintf(\"ERROR: clGetContextInfo() => CL_INVALID_CONTEXT\\n\");\n\t\t\tif (err == CL_INVALID_VALUE)\n\t\t\t\tprintf(\"ERROR: clGetContextInfo() => CL_INVALID_VALUE\\n\");\n\t\t}\n\t\terr = clGetProgramBuildInfo(prog, device_id[device_id_inuse], CL_PROGRAM_BUILD_LOG, sizeof (log) - 1, log, NULL);\n\t\tif (err != CL_SUCCESS) {\n\t\t\tprintf(\"ERROR: clGetProgramBuildInfo() => %d\\n\", err);\n\t\t}\n\t\tif (err || strstr(log, \"warning:\") || strstr(log, \"error:\")) printf(\"<<<<\\n%s\\n>>>>\\n\", log);\n\t}\n\tif (err != CL_SUCCESS) {\n\t\tprintf(\"ERROR: clBuildProgram() => %d\\n\", err);\n\t\treturn -1;\n\t}\n\n\tconst char * particle_kernel = \"particle_kernel\";\n\n\tkernel_s = clCreateKernel(prog, particle_kernel, &err);\n\tif (err != CL_SUCCESS) {\n\t\tprintf(\"ERROR: clCreateKernel() 0 => %d\\n\", err);\n\t\treturn -1;\n\t}\n\n\tclReleaseProgram(prog);\n\n\n\tlikelihood = (double *) malloc(sizeof (double) *Nparticles);\n\tarrayX = (double *) malloc(sizeof (double) *Nparticles);\n\tarrayY = (double *) malloc(sizeof (double) *Nparticles);\n\txj = (double *) malloc(sizeof (double) *Nparticles);\n\tyj = (double *) malloc(sizeof (double) *Nparticles);\n\tCDF = (double *) malloc(sizeof (double) *Nparticles);\n\n\tind = (int*) malloc(sizeof (int) *countOnes);\n\tu = (double *) malloc(sizeof (double) *Nparticles);\n\n\tarrayX_GPU = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof (double) *Nparticles, NULL, &err);\n\tif (err != CL_SUCCESS) {\n\t\tprintf(\"ERROR: clCreateBuffer arrayX_GPU (size:%d) => %d\\n\", Nparticles, err);\n\t\treturn -1;\n\t}\n\tarrayY_GPU = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof (double) *Nparticles, NULL, &err);\n\tif (err != CL_SUCCESS) {\n\t\tprintf(\"ERROR: clCreateBuffer arrayY_GPU (size:%d) => %d\\n\", Nparticles, err);\n\t\treturn -1;\n\t}\n\txj_GPU = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof (double) *Nparticles, NULL, &err);\n\tif (err != CL_SUCCESS) {\n\t\tprintf(\"ERROR: clCreateBuffer xj_GPU (size:%d) => %d\\n\", Nparticles, err);\n\t\treturn -1;\n\t}\n\tyj_GPU = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof (double) *Nparticles, NULL, &err);\n\tif (err != CL_SUCCESS) {\n\t\tprintf(\"ERROR: clCreateBuffer yj_GPU (size:%d) => %d\\n\", Nparticles, err);\n\t\treturn -1;\n\t}\n\tCDF_GPU = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof (double) *Nparticles, NULL, &err);\n\tif (err != CL_SUCCESS) {\n\t\tprintf(\"ERROR: clCreateBuffer CDF_GPU (size:%d) => %d\\n\", Nparticles, err);\n\t\treturn -1;\n\t}\n\tu_GPU = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof (double) *Nparticles, NULL, &err);\n\tif (err != CL_SUCCESS) { printf(\"ERROR: clCreateBuffer u_GPU (size:%d) => %d\\n\", Nparticles, err); return -1; }\n\n  \n\n}//eo allocate\n\n\nint particleFilter(int * I, int IszX, int IszY, int Nfr, int * seed, int Nparticles) {\n\tint max_size = IszX * IszY*Nfr;\n\tlong long start = get_time();\n\tdouble xe = roundDouble(IszY / 2.0);\n\tdouble ye = roundDouble(IszX / 2.0);\n\n\tint radius = 5;\n\tint diameter = radius * 2 - 1;\n\tint * disk = (int *) malloc(diameter * diameter * sizeof (int));\n\tstrelDisk(disk, radius);\n\tint countOnes = 0;\n\tint x, y;\n\tfor (x = 0; x < diameter; x++) {\n\t\tfor (y = 0; y < diameter; y++) {\n\t\t\tif (disk[x * diameter + y] == 1)\n\t\t\t\tcountOnes++;\n\t\t}\n\t}\n\tdouble * objxy = (double *) malloc(countOnes * 2 * sizeof (double));\n\tgetneighbors(disk, countOnes, objxy, radius);\n\n\tlong long get_neighbors = get_time();\n\tprintf(\"TIME TO GET NEIGHBORS TOOK: %f\\n\", elapsed_time(start, get_neighbors));\n\tdouble * weights = (double *) malloc(sizeof (double) *Nparticles);\n\tfor (x = 0; x < Nparticles; x++) {\n\t\tweights[x] = 1 / ((double) (Nparticles));\n\t}\n\tlong long get_weights = get_time();\n\tprintf(\"TIME TO GET WEIGHTSTOOK: %f\\n\", elapsed_time(get_neighbors, get_weights));\n\n\tallocate(Nparticles, countOnes);\n\t\n\tfor (x = 0; x < Nparticles; x++) {\n\t\tarrayX[x] = xe;\n\t\tarrayY[x] = ye;\n\t}\n\tint k;\n\tint indX, indY;\n\tfor (k = 1; k < Nfr; k++) {\n\t\tlong long set_arrays = get_time();\n\n\n\t\tfor (x = 0; x < Nparticles; x++) {\n\t\t\tarrayX[x] = arrayX[x] + 1.0 + 5.0 * randn(seed, x);\n\t\t\tarrayY[x] = arrayY[x] - 2.0 + 2.0 * randn(seed, x);\n\t\t}   \n\t\tlong long error = get_time();\n\t\tprintf(\"TIME TO SET ERROR TOOK: %f\\n\", elapsed_time(set_arrays, error));\n\t\tfor (x = 0; x < Nparticles; x++) {\n\t\t\tfor (y = 0; y < countOnes; y++) {\n\t\t\t\tindX = roundDouble(arrayX[x]) + objxy[y * 2 + 1];\n\t\t\t\tindY = roundDouble(arrayY[x]) + objxy[y * 2];\n\t\t\t\tind[y] = fabs(indX * IszY * Nfr + indY * Nfr + k);\n\t\t\t\tif (ind[y] >= max_size)\n\t\t\t\t\tind[y] = 0;\n\t\t\t}\n\t\t\tlikelihood[x] = calcLikelihoodSum(I, ind, countOnes);\n\t\t\tlikelihood[x] = likelihood[x] / countOnes;\n\t\t}\n\t\tlong long likelihood_time = get_time();\n\t\tprintf(\"TIME TO GET LIKELIHOODS TOOK: %f\\n\", elapsed_time(error, likelihood_time));\n\t\tfor (x = 0; x < Nparticles; x++) {\n\t\t\tweights[x] = weights[x] * exp(likelihood[x]);\n\t\t}\n\t\tlong long exponential = get_time();\n\t\tprintf(\"TIME TO GET EXP TOOK: %f\\n\", elapsed_time(likelihood_time, exponential));\n\t\tdouble sumWeights = 0;\n\t\tfor (x = 0; x < Nparticles; x++) {\n\t\t\tsumWeights += weights[x];\n\t\t}\n\t\tlong long sum_time = get_time();\n\t\tprintf(\"TIME TO SUM WEIGHTS TOOK: %f\\n\", elapsed_time(exponential, sum_time));\n\t\tfor (x = 0; x < Nparticles; x++) {\n\t\t\tweights[x] = weights[x] / sumWeights;\n\t\t}\n\t\tlong long normalize = get_time();\n\t\tprintf(\"TIME TO NORMALIZE WEIGHTS TOOK: %f\\n\", elapsed_time(sum_time, normalize));\n\t\txe = 0;\n\t\tye = 0;\n\t\tfor (x = 0; x < Nparticles; x++) {\n\t\t\txe += arrayX[x] * weights[x];\n\t\t\tye += arrayY[x] * weights[x];\n\t\t}\n\t\tlong long move_time = get_time();\n\t\tprintf(\"TIME TO MOVE OBJECT TOOK: %f\\n\", elapsed_time(normalize, move_time));\n\t\tprintf(\"XE: %lf\\n\", xe);\n\t\tprintf(\"YE: %lf\\n\", ye);\n\t\tdouble distance = sqrt(pow((double) (xe - (int) roundDouble(IszY / 2.0)), 2) + pow((double) (ye - (int) roundDouble(IszX / 2.0)), 2));\n\t\tprintf(\"%lf\\n\", distance);\n\n\t\tCDF[0] = weights[0];\n\t\tfor (x = 1; x < Nparticles; x++) {\n\t\t\tCDF[x] = weights[x] + CDF[x - 1];\n\t\t}\n\t\tlong long cum_sum = get_time();\n\t\tprintf(\"TIME TO CALC CUM SUM TOOK: %f\\n\", elapsed_time(move_time, cum_sum));\n\t\tdouble u1 = (1 / ((double) (Nparticles))) * randu(seed, 0);\n\t\tfor (x = 0; x < Nparticles; x++) {\n\t\t\tu[x] = u1 + x / ((double) (Nparticles));\n\t\t}\n\t\tlong long u_time = get_time();\n\t\tprintf(\"TIME TO CALC U TOOK: %f\\n\", elapsed_time(cum_sum, u_time));\n\t\tlong long start_copy = get_time();\n\n\t\tcl_int err = clEnqueueWriteBuffer(cmd_queue, arrayX_GPU, 1, 0, sizeof (double) *Nparticles, arrayX, 0, 0, 0);\n\t\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer arrayX_GPU (size:%d) => %d\\n\", Nparticles, err); return -1; }\n\t\terr = clEnqueueWriteBuffer(cmd_queue, arrayY_GPU, 1, 0, sizeof (double) *Nparticles, arrayY, 0, 0, 0);\n\t\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer arrayY_GPU (size:%d) => %d\\n\", Nparticles, err); return -1; }\n\t\terr = clEnqueueWriteBuffer(cmd_queue, CDF_GPU, 1, 0, sizeof (double) *Nparticles, CDF, 0, 0, 0);\n\t\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer CDF_GPU (size:%d) => %d\\n\", Nparticles, err); return -1; }\n\t\terr = clEnqueueWriteBuffer(cmd_queue, u_GPU, 1, 0, sizeof (double) *Nparticles, u, 0, 0, 0);\n\t\tif(err != CL_SUCCESS) { printf(\"ERROR: clEnqueueWriteBuffer u_GPU (size:%d) => %d\\n\", Nparticles, err); return -1; }\n\n\n\t\tlong long end_copy = get_time();\n\t\tint num_blocks = ceil((double) Nparticles / (double) threads_per_block);\n\n\t\tclSetKernelArg(kernel_s, 0, sizeof (void *), (void*) &arrayX_GPU);\n\t\tclSetKernelArg(kernel_s, 1, sizeof (void *), (void*) &arrayY_GPU);\n\t\tclSetKernelArg(kernel_s, 2, sizeof (void *), (void*) &CDF_GPU);\n\t\tclSetKernelArg(kernel_s, 3, sizeof (void *), (void*) &u_GPU);\n\t\tclSetKernelArg(kernel_s, 4, sizeof (void *), (void*) &xj_GPU);\n\t\tclSetKernelArg(kernel_s, 5, sizeof (void *), (void*) &yj_GPU);\n\t\tclSetKernelArg(kernel_s, 6, sizeof (cl_int), (void*) &Nparticles);\n\n\n\t\tsize_t global_work[3] = {num_blocks*threads_per_block, 1, 1};\n\t\terr = clEnqueueNDRangeKernel(cmd_queue, kernel_s, 1, NULL, global_work, NULL, 0, 0, 0);\n\t\tclFinish(cmd_queue);\n\t\tlong long start_copy_back = get_time();\n                \n                if (err != CL_SUCCESS) {\n\t\t\tprintf(\"ERROR: clEnqueueNDRangeKernel()=>%d failed\\n\", err);\n\t\t\treturn -1;\n\t\t}\n\t\terr = clEnqueueReadBuffer(cmd_queue, yj_GPU, 1, 0, sizeof (double) *Nparticles, yj, 0, 0, 0);\n\t\tif (err != CL_SUCCESS) {\n\t\t\tprintf(\"ERROR: Memcopy Out\\n\");\n\t\t\treturn -1;\n\t\t}\n\t\terr = clEnqueueReadBuffer(cmd_queue, xj_GPU, 1, 0, sizeof (double) *Nparticles, xj, 0, 0, 0);\n\t\tif (err != CL_SUCCESS) {\n\t\t\tprintf(\"ERROR: Memcopy Out\\n\");\n\t\t\treturn -1;\n\t\t}\n\n\t\tlong long end_copy_back = get_time();\n\n\t\tprintf(\"SENDING TO GPU TOOK: %lf\\n\", elapsed_time(start_copy, end_copy));\n        printf(\"OPEN_CL EXEC TOOK: %lf\\n\", elapsed_time(end_copy, start_copy_back));\n        printf(\"SENDING BACK FROM GPU TOOK: %lf\\n\", elapsed_time(start_copy_back, end_copy_back));\n        long long xyj_time = get_time();\n        printf(\"TIME TO CALC NEW ARRAY X AND Y TOOK: %f\\n\", elapsed_time(u_time, xyj_time));\n        \n        for (x = 0; x < Nparticles; x++) {\n            arrayX[x] = xj[x];\n            arrayY[x] = yj[x];\n            weights[x] = 1 / ((double) (Nparticles));\n        }\n        long long reset = get_time();\n        printf(\"TIME TO RESET WEIGHTS TOOK: %f\\n\", elapsed_time(xyj_time, reset));\n    }\n\n    \n\n    clReleaseMemObject(u_GPU);\n    clReleaseMemObject(CDF_GPU);\n    clReleaseMemObject(yj_GPU);\n    clReleaseMemObject(xj_GPU);\n    clReleaseMemObject(arrayY_GPU);\n    clReleaseMemObject(arrayX_GPU);\n\n\n    free(disk);\n    free(objxy);\n    free(weights);\n    free(likelihood);\n    free(xj);\n    free(yj);\n    free(arrayX);\n    free(arrayY);\n    free(CDF);\n    free(u);\n    free(ind);\n}\n\nint main(int argc, char * argv[]) {\n\n    const char* usage = \"naive.out -x <dimX> -y <dimY> -z <Nfr> -np <Nparticles> [-p platform] [-d device]\";\n    if (argc != 9) {\n        printf(\"%s\\n\", usage);\n        return 0;\n    }\n\n    if (strcmp(argv[1], \"-x\") || strcmp(argv[3], \"-y\") || strcmp(argv[5], \"-z\") || strcmp(argv[7], \"-np\")) {\n        printf(\"%s\\n\", usage);\n        return 0;\n    }\n\n    int IszX, IszY, Nfr, Nparticles;\n\n    if (sscanf(argv[2], \"%d\", &IszX) == EOF) {\n        printf(\"ERROR: dimX input is incorrect\");\n        return 0;\n    }\n\n    if (IszX <= 0) {\n        printf(\"dimX must be > 0\\n\");\n        return 0;\n    }\n\n    if (sscanf(argv[4], \"%d\", &IszY) == EOF) {\n        printf(\"ERROR: dimY input is incorrect\");\n        return 0;\n    }\n\n    if (IszY <= 0) {\n        printf(\"dimY must be > 0\\n\");\n        return 0;\n    }\n\n    if (sscanf(argv[6], \"%d\", &Nfr) == EOF) {\n        printf(\"ERROR: Number of frames input is incorrect\");\n        return 0;\n    }\n\n    if (Nfr <= 0) {\n        printf(\"number of frames must be > 0\\n\");\n        return 0;\n    }\n\n    if (sscanf(argv[8], \"%d\", &Nparticles) == EOF) {\n        printf(\"ERROR: Number of particles input is incorrect\");\n        return 0;\n    }\n\n    if (Nparticles <= 0) {\n        printf(\"Number of particles must be > 0\\n\");\n        return 0;\n    }\n\n\tfor (int i = 9; i < argc; ++i) {\n\t\tswitch (argv[i][1]) {\n\t\tcase 'p':\t//--p stands for platform id\n\t\t\tif (++i < argc)\n\t\t\t\tsscanf(argv[i], \"%d\", &platform_id_inuse);\n\t\tbreak;\n\t\tcase 'd':\t //--d stands for device id\n\t\t\tif (++i < argc)\n\t\t\t\tsscanf(argv[i], \"%d\", &device_id_inuse);\n\t\tbreak;\n\t\tdefault:\n            ;\n\t\t}\n\t}\n\n    int * seed = (int *) malloc(sizeof (int) *Nparticles);\n    int i;\n    for (i = 0; i < Nparticles; i++)\n        seed[i] = time(0) * i;\n    int * I = (int *) malloc(sizeof (int) *IszX * IszY * Nfr);\n    long long start = get_time();\n    videoSequence(I, IszX, IszY, Nfr, seed);\n    long long endVideoSequence = get_time();\n    printf(\"VIDEO SEQUENCE TOOK %f\\n\", elapsed_time(start, endVideoSequence));\n    particleFilter(I, IszX, IszY, Nfr, seed, Nparticles);\n    long long endParticleFilter = get_time();\n    printf(\"PARTICLE FILTER TOOK %f\\n\", elapsed_time(endVideoSequence, endParticleFilter));\n    printf(\"ENTIRE PROGRAM TOOK %f\\n\", elapsed_time(start, endParticleFilter));\n\n    free(seed);\n    free(I);\n    return 0;\n}\n", "particle_naive.cl": "#pragma OPENCL EXTENSION cl_khr_fp64: enable\n\nint findIndexSeq(double * CDF, int lengthCDF, double value)\n{\n\tint index = -1;\n\tint x;\n\tfor(x = 0; x < lengthCDF; x++)\n\t{\n\t\tif(CDF[x] >= value)\n\t\t{\n\t\t\tindex = x;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif(index == -1)\n\t\treturn lengthCDF-1;\n\treturn index;\n}\n\nint findIndexBin(double * CDF, int beginIndex, int endIndex, double value)\n{\n\tif(endIndex < beginIndex)\n\t\treturn -1;\n\tint middleIndex;\n\twhile(endIndex > beginIndex)\n\t{\n\t\tmiddleIndex = beginIndex + ((endIndex-beginIndex)/2);\n\t\tif(CDF[middleIndex] >= value)\n\t\t{\n\t\t\tif(middleIndex == 0)\n\t\t\t\treturn middleIndex;\n\t\t\telse if(CDF[middleIndex-1] < value)\n\t\t\t\treturn middleIndex;\n\t\t\telse if(CDF[middleIndex-1] == value)\n\t\t\t{\n\t\t\t\twhile(CDF[middleIndex] == value && middleIndex >= 0)\n\t\t\t\t\tmiddleIndex--;\n\t\t\t\tmiddleIndex++;\n\t\t\t\treturn middleIndex;\n\t\t\t}\n\t\t}\n\t\tif(CDF[middleIndex] > value)\n\t\t\tendIndex = middleIndex-1;\n\t\telse\n\t\t\tbeginIndex = middleIndex+1;\n\t}\n\treturn -1;\n}\n\n__kernel void particle_kernel(__global double * arrayX, __global double * arrayY, __global double * CDF, __global double * u, __global double * xj, __global double * yj, int Nparticles){\n\tint i = get_global_id(0);\n\t\n\tif(i < Nparticles){\n\t\n\t\tint index = -1;\n\t\tint x;\n\t\t\n\t\tfor(x = 0; x < Nparticles; x++){\n\t\t\tif(CDF[x] >= u[i]){\n\t\t\t\tindex = x;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif(index == -1){\n\t\t\tindex = Nparticles-1;\n\t\t}\n\t\t\n\t\txj[i] = arrayX[index];\n\t\tyj[i] = arrayY[index];\n\t\t\n\t}\n}"}, "code_dirs": {"ex_particle_OCL_naive_seq.cpp": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/particlefilter", "particle_naive.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/particlefilter"}}
{"kernel_name": "pathfinder", "parallel_api": "cuda", "code": {"pathfinder.cu": "#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n\n#ifdef TIMING\n#include \"timing.h\"\n\nstruct timeval tv;\nstruct timeval tv_total_start, tv_total_end;\nstruct timeval tv_h2d_start, tv_h2d_end;\nstruct timeval tv_d2h_start, tv_d2h_end;\nstruct timeval tv_kernel_start, tv_kernel_end;\nstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\nstruct timeval tv_close_start, tv_close_end;\nfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n      d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\n#define BLOCK_SIZE 256\n#define STR_SIZE 256\n#define DEVICE 0\n#define HALO 1 \n\nvoid run(int argc, char** argv);\n\nint rows, cols;\nint* data;\nint** wall;\nint* result;\n#define M_SEED 9\nint pyramid_height;\n\nvoid\ninit(int argc, char** argv)\n{\n\tif(argc==4){\n\t\tcols = atoi(argv[1]);\n\t\trows = atoi(argv[2]);\n                pyramid_height=atoi(argv[3]);\n\t}else{\n                printf(\"Usage: dynproc row_len col_len pyramid_height\\n\");\n                exit(0);\n        }\n\tdata = new int[rows*cols];\n\twall = new int*[rows];\n\tfor(int n=0; n<rows; n++)\n\t\twall[n]=data+cols*n;\n\tresult = new int[cols];\n\t\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            wall[i][j] = rand() % 10;\n        }\n    }\n#ifdef BENCH_PRINT\n    for (int i = 0; i < rows; i++)\n    {\n        for (int j = 0; j < cols; j++)\n        {\n            printf(\"%d \",wall[i][j]) ;\n        }\n        printf(\"\\n\") ;\n    }\n#endif\n}\n\nvoid \nfatal(char *s)\n{\n\tfprintf(stderr, \"error: %s\\n\", s);\n\n}\n\n#define IN_RANGE(x, min, max)   ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\n__global__ void dynproc_kernel(\n                int iteration, \n                int *gpuWall,\n                int *gpuSrc,\n                int *gpuResults,\n                int cols, \n                int rows,\n                int startStep,\n                int border)\n{\n\n        __shared__ int prev[BLOCK_SIZE];\n        __shared__ int result[BLOCK_SIZE];\n\n\tint bx = blockIdx.x;\n\tint tx=threadIdx.x;\n\t\n\n\tint small_block_cols = BLOCK_SIZE-iteration*HALO*2;\n\n        int blkX = small_block_cols*bx-border;\n        int blkXmax = blkX+BLOCK_SIZE-1;\n\n\tint xidx = blkX+tx;\n       \n        int validXmin = (blkX < 0) ? -blkX : 0;\n        int validXmax = (blkXmax > cols-1) ? BLOCK_SIZE-1-(blkXmax-cols+1) : BLOCK_SIZE-1;\n\n        int W = tx-1;\n        int E = tx+1;\n        \n        W = (W < validXmin) ? validXmin : W;\n        E = (E > validXmax) ? validXmax : E;\n\n        bool isValid = IN_RANGE(tx, validXmin, validXmax);\n\n\tif(IN_RANGE(xidx, 0, cols-1)){\n            prev[tx] = gpuSrc[xidx];\n\t}\n\t__syncthreads(); \n        bool computed;\n        for (int i=0; i<iteration ; i++){ \n            computed = false;\n            if( IN_RANGE(tx, i+1, BLOCK_SIZE-i-2) &&  \\\n                  isValid){\n                  computed = true;\n                  int left = prev[W];\n                  int up = prev[tx];\n                  int right = prev[E];\n                  int shortest = MIN(left, up);\n                  shortest = MIN(shortest, right);\n                  int index = cols*(startStep+i)+xidx;\n                  result[tx] = shortest + gpuWall[index];\n\t\n            }\n            __syncthreads();\n            if(i==iteration-1)\n                break;\n            if(computed)\t //Assign the computation range\n                prev[tx]= result[tx];\n\t    __syncthreads(); \n      }\n\n      if (computed){\n          gpuResults[xidx]=result[tx];\t\t\n      }\n}\n\nint calc_path(int *gpuWall, int *gpuResult[2], int rows, int cols, \\\n\t int pyramid_height, int blockCols, int borderCols)\n{\n        dim3 dimBlock(BLOCK_SIZE);\n        dim3 dimGrid(blockCols);  \n\t\n        int src = 1, dst = 0;\n\tfor (int t = 0; t < rows-1; t+=pyramid_height) {\n            int temp = src;\n            src = dst;\n            dst = temp;\n            dynproc_kernel<<<dimGrid, dimBlock>>>(\n                MIN(pyramid_height, rows-t-1), \n                gpuWall, gpuResult[src], gpuResult[dst],\n                cols,rows, t, borderCols);\n\n            cudaDeviceSynchronize();\n\t}\n        return dst;\n}\n\nint main(int argc, char** argv)\n{\n    int num_devices;\n    cudaGetDeviceCount(&num_devices);\n    if (num_devices > 1) cudaSetDevice(DEVICE);\n\n    run(argc,argv);\n\n    return EXIT_SUCCESS;\n}\n\nvoid run(int argc, char** argv)\n{\n    init(argc, argv);\n\n    int borderCols = (pyramid_height)*HALO;\n    int smallBlockCol = BLOCK_SIZE-(pyramid_height)*HALO*2;\n    int blockCols = cols/smallBlockCol+((cols%smallBlockCol==0)?0:1);\n\n    printf(\"pyramidHeight: %d\\ngridSize: [%d]\\nborder:[%d]\\nblockSize: %d\\nblockGrid:[%d]\\ntargetBlock:[%d]\\n\",\\\n\tpyramid_height, cols, borderCols, BLOCK_SIZE, blockCols, smallBlockCol);\n\t\n    int *gpuWall, *gpuResult[2];\n    int size = rows*cols;\n\n    cudaMalloc((void**)&gpuResult[0], sizeof(int)*cols);\n    cudaMalloc((void**)&gpuResult[1], sizeof(int)*cols);\n    cudaMemcpy(gpuResult[0], data, sizeof(int)*cols, cudaMemcpyHostToDevice);\n    cudaMalloc((void**)&gpuWall, sizeof(int)*(size-cols));\n    cudaMemcpy(gpuWall, data+cols, sizeof(int)*(size-cols), cudaMemcpyHostToDevice);\n\n#ifdef  TIMING\n    gettimeofday(&tv_kernel_start, NULL);\n#endif\n\n    int final_ret = calc_path(gpuWall, gpuResult, rows, cols, \\\n\t pyramid_height, blockCols, borderCols);\n\n#ifdef  TIMING\n    gettimeofday(&tv_kernel_end, NULL);\n    tvsub(&tv_kernel_end, &tv_kernel_start, &tv);\n    kernel_time += tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n    cudaMemcpy(result, gpuResult[final_ret], sizeof(int)*cols, cudaMemcpyDeviceToHost);\n\n#ifdef BENCH_PRINT\n    for (int i = 0; i < cols; i++)\n            printf(\"%d \",data[i]) ;\n    printf(\"\\n\") ;\n    for (int i = 0; i < cols; i++)\n            printf(\"%d \",result[i]) ;\n    printf(\"\\n\") ;\n#endif\n\n    cudaFree(gpuWall);\n    cudaFree(gpuResult[0]);\n    cudaFree(gpuResult[1]);\n\n    delete [] data;\n    delete [] wall;\n    delete [] result;\n\n#ifdef  TIMING\n    printf(\"Exec: %f\\n\", kernel_time);\n#endif\n}\n\n"}, "code_dirs": {"pathfinder.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/pathfinder"}}
{"kernel_name": "pathfinder", "parallel_api": "ocl", "code": {"main.cpp": "#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <assert.h>\n#include <iostream>\n#include \"OpenCL.h\"\n#include \"timing.h\"\n\nusing namespace std;\n\n#define HALO     1\n#define STR_SIZE 256\n#define DEVICE   0\n#define M_SEED   9\n// #define BENCH_PRINT\n#define IN_RANGE(x, min, max)\t((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\n// Program variables.\nint   rows = -1, cols = -1;\nint   Ne = rows * cols;\nint*  data;\nint** wall;\nint*  result;\nint   pyramid_height = -1;\nint   verbose = 0;\n\n// OCL config\nint platform_id_inuse = 0;\nint device_id_inuse = 0;\n\n#ifdef TIMING\n\tstruct timeval tv;\n\tstruct timeval tv_total_start, tv_total_end;\n\tstruct timeval tv_init_end;\n\tstruct timeval tv_h2d_start, tv_h2d_end;\n\tstruct timeval tv_d2h_start, tv_d2h_end;\n\tstruct timeval tv_kernel_start, tv_kernel_end;\n\tstruct timeval tv_mem_alloc_start, tv_mem_alloc_end;\n\tstruct timeval tv_close_start, tv_close_end;\n\tfloat init_time = 0, mem_alloc_time = 0, h2d_time = 0, kernel_time = 0,\n\t\t  d2h_time = 0, close_time = 0, total_time = 0;\n#endif\n\nvoid init(int argc, char** argv)\n{\n    int cur_arg;\n\tfor (cur_arg = 1; cur_arg<argc; cur_arg++) {\n        if (strcmp(argv[cur_arg], \"-c\") == 0) {\n            if (argc >= cur_arg + 1) {\n                cols = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n        else if (strcmp(argv[cur_arg], \"-r\") == 0) {\n            if (argc >= cur_arg + 1) {\n                rows = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n        else if (strcmp(argv[cur_arg], \"-h\") == 0) {\n            if (argc >= cur_arg + 1) {\n                pyramid_height = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n        if (strcmp(argv[cur_arg], \"-v\") == 0) {\n\t\t\tverbose = 1;\n        }\n        else if (strcmp(argv[cur_arg], \"-p\") == 0) {\n            if (argc >= cur_arg + 1) {\n                platform_id_inuse = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n        else if (strcmp(argv[cur_arg], \"-d\") == 0) {\n            if (argc >= cur_arg + 1) {\n                device_id_inuse = atoi(argv[cur_arg+1]);\n                cur_arg++;\n            }\n        }\n    }\n\n\tif (cols < 0 || rows < 0 || pyramid_height < 0)\n\t{\n        fprintf(stderr, \"usage: %s <-r rows> <-c cols> <-h pyramid_height> [-v] [-p platform_id] [-d device_id] [-t device_type]\\n\", argv[0]);\n\t\texit(0);\n\t}\n\tdata = new int[rows * cols];\n\twall = new int*[rows];\n\tfor (int n = 0; n < rows; n++)\n\t{\n\t\t// wall[n] is set to be the nth row of the data array.\n\t\twall[n] = data + cols * n;\n\t}\n\tresult = new int[cols];\n\n\tint seed = M_SEED;\n\tsrand(seed);\n\n\tfor (int i = 0; i < rows; i++)\n\t{\n\t\tfor (int j = 0; j < cols; j++)\n\t\t{\n\t\t\twall[i][j] = rand() % 10;\n\t\t}\n\t}\n#ifdef BENCH_PRINT\n\tfor (int i = 0; i < rows; i++)\n\t{\n\t\tfor (int j = 0; j < cols; j++)\n\t\t{\n\t\t\tprintf(\"%d \", wall[i][j]);\n\t\t}\n\t\tprintf(\"\\n\");\n\t}\n#endif\n}\n\nvoid fatal(char *s)\n{\n\tfprintf(stderr, \"error: %s\\n\", s);\n}\n\nint main(int argc, char** argv)\n{\n\tinit(argc, argv);\n\t\n\tint borderCols = (pyramid_height) * HALO;\n\tint size = rows * cols;\n\n\tOpenCL cl(verbose);\n\n#ifdef  TIMING\n    gettimeofday(&tv_total_start, NULL);\n#endif\n\tcl.init();\n\n\tcl.gwSize(rows * cols);\n\n\tstring kn = \"dynproc_kernel\";\n\tcl.createKernel(kn);\n\n#ifdef  TIMING\n\tgettimeofday(&tv_init_end, NULL);\n\ttvsub(&tv_init_end, &tv_total_start, &tv);\n\tinit_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n    cl_int* h_outputBuffer = (cl_int*)malloc(16384 * sizeof(cl_int));\n    for (int i = 0; i < 16384; i++) {\n        h_outputBuffer[i] = 0;\n\t}\n\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_start, NULL);\n#endif\n    cl_mem d_gpuWall = clCreateBuffer(cl.ctxt(), CL_MEM_READ_ONLY,\n        sizeof(cl_int) * (size - cols), NULL, NULL);\n\n    cl_mem d_gpuResult[2];\n\n    d_gpuResult[0] = clCreateBuffer(cl.ctxt(), CL_MEM_READ_WRITE,\n        sizeof(cl_int) * cols, NULL, NULL);\n\n    d_gpuResult[1] = clCreateBuffer(cl.ctxt(), CL_MEM_READ_WRITE,\n        sizeof(cl_int) * cols, NULL, NULL);\n\n    cl_mem d_outputBuffer = clCreateBuffer(cl.ctxt(),\n        CL_MEM_READ_WRITE, sizeof(cl_int) * 16384, NULL, NULL);\n\n#ifdef  TIMING\n    gettimeofday(&tv_mem_alloc_end, NULL);\n    tvsub(&tv_mem_alloc_end, &tv_mem_alloc_start, &tv);\n    mem_alloc_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n    cl_event write_event[3];\n    clEnqueueWriteBuffer(cl.q(), d_gpuWall, 1, 0,\n        sizeof(cl_int) * (size - cols), (data + cols), 0, 0, &write_event[0]);\n\n    clEnqueueWriteBuffer(cl.q(), d_gpuResult[0], 1, 0,\n        sizeof(cl_int) * cols, data, 0, 0, &write_event[1]);\n\n    clEnqueueWriteBuffer(cl.q(), d_outputBuffer, 1, 0,\n        sizeof(cl_int) * 16384, h_outputBuffer, 0, 0, &write_event[2]);\n\n#ifdef TIMING\n    h2d_time += probe_event_time(write_event[0], cl.q());\n    h2d_time += probe_event_time(write_event[1], cl.q());\n    h2d_time += probe_event_time(write_event[2], cl.q());\n#endif\n\n\tint src = 1, final_ret = 0;\n\tfor (int t = 0; t < rows - 1; t += pyramid_height)\n\t{\n\t\tint temp = src;\n\t\tsrc = final_ret;\n\t\tfinal_ret = temp;\n\n\t\tint arg0 = MIN(pyramid_height, rows-t-1);\n\t\tint theHalo = HALO;\n\n\t\tclSetKernelArg(cl.kernel(kn), 0,  sizeof(cl_int), (void*) &arg0);\n\t\tclSetKernelArg(cl.kernel(kn), 1,  sizeof(cl_mem), (void*) &d_gpuWall);\n\t\tclSetKernelArg(cl.kernel(kn), 2,  sizeof(cl_mem), (void*) &d_gpuResult[src]);\n\t\tclSetKernelArg(cl.kernel(kn), 3,  sizeof(cl_mem), (void*) &d_gpuResult[final_ret]);\n\t\tclSetKernelArg(cl.kernel(kn), 4,  sizeof(cl_int), (void*) &cols);\n\t\tclSetKernelArg(cl.kernel(kn), 5,  sizeof(cl_int), (void*) &rows);\n\t\tclSetKernelArg(cl.kernel(kn), 6,  sizeof(cl_int), (void*) &t);\n\t\tclSetKernelArg(cl.kernel(kn), 7,  sizeof(cl_int), (void*) &borderCols);\n\t\tclSetKernelArg(cl.kernel(kn), 8,  sizeof(cl_int), (void*) &theHalo);\n\t\tclSetKernelArg(cl.kernel(kn), 9,  sizeof(cl_int) * (cl.localSize()), 0);\n\t\tclSetKernelArg(cl.kernel(kn), 10, sizeof(cl_int) * (cl.localSize()), 0);\n\t\tclSetKernelArg(cl.kernel(kn), 11, sizeof(cl_mem), (void*) &d_outputBuffer);\n\t\tcl.launch(kn);\n\t}\n\n\tcl_event event;\n\tclEnqueueReadBuffer(cl.q(),\n\t                    d_gpuResult[final_ret],\n\t                    CL_TRUE,\n\t                    0,\n\t                    sizeof(cl_int)*cols,\n\t                    result,\n\t                    0,\n\t                    NULL,\n\t                    &event);\n#ifdef TIMING\n    d2h_time += probe_event_time(event,cl.q());\n#endif\n    clReleaseEvent(event);\n\n\tclEnqueueReadBuffer(cl.q(),\n\t                    d_outputBuffer,\n\t                    CL_TRUE,\n\t                    0,\n\t                    sizeof(cl_char)*16384,\n\t                    h_outputBuffer,\n\t                    0,\n\t                    NULL,\n\t                    &event);\n#ifdef TIMING\n    d2h_time += probe_event_time(event,cl.q());\n#endif\n\n\th_outputBuffer[16383] = '\\0';\n\t\n#ifdef BENCH_PRINT\n\tfor (int i = 0; i < cols; i++)\n\t\tprintf(\"%d \", data[i]);\n\tprintf(\"\\n\");\n\tfor (int i = 0; i < cols; i++)\n\t\tprintf(\"%d \", result[i]);\n\tprintf(\"\\n\");\n#endif\n\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n\tclReleaseMemObject(d_gpuWall);\n\tclReleaseMemObject(d_gpuResult[0]);\n\tclReleaseMemObject(d_gpuResult[1]);\n\tclReleaseMemObject(d_outputBuffer);\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n\tdelete[] data;\n\tdelete[] wall;\n\tdelete[] result;\n\n\treturn EXIT_SUCCESS;\n}\n", "kernels.cl": "#define IN_RANGE(x, min, max) ((x)>=(min) && (x)<=(max))\n#define CLAMP_RANGE(x, min, max) x = (x<(min)) ? min : ((x>(max)) ? max : x )\n#define MIN(a, b) ((a)<=(b) ? (a) : (b))\n\n__kernel void dynproc_kernel (int iteration,\n                              __global int* gpuWall,\n                              __global int* gpuSrc,\n                              __global int* gpuResults,\n                              int cols,\n                              int rows,\n                              int startStep,\n                              int border,\n                              int HALO,\n                              __local int* prev,\n                              __local int* result,\n                              __global int* outputBuffer)\n{\n\tint BLOCK_SIZE = get_local_size(0);\n\tint bx = get_group_id(0);\n\tint tx = get_local_id(0);\n\n\n\tint small_block_cols = BLOCK_SIZE - (iteration*HALO*2);\n\n\tint blkX = (small_block_cols*bx) - border;\n\tint blkXmax = blkX+BLOCK_SIZE-1;\n\n\tint xidx = blkX+tx;\n\n\tint validXmin = (blkX < 0) ? -blkX : 0;\n\tint validXmax = (blkXmax > cols-1) ? BLOCK_SIZE-1-(blkXmax-cols+1) : BLOCK_SIZE-1;\n\t\n\tint W = tx-1;\n\tint E = tx+1;\n\n\tW = (W < validXmin) ? validXmin : W;\n\tE = (E > validXmax) ? validXmax : E;\n\n\tbool isValid = IN_RANGE(tx, validXmin, validXmax);\n\n\tif(IN_RANGE(xidx, 0, cols-1))\n\t{\n\t\tprev[tx] = gpuSrc[xidx];\n\t}\n\t\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\tbool computed;\n\tfor (int i = 0; i < iteration; i++)\n\t{\n\t\tcomputed = false;\n\t\t\n\t\tif( IN_RANGE(tx, i+1, BLOCK_SIZE-i-2) && isValid )\n\t\t{\n\t\t\tcomputed = true;\n\t\t\tint left = prev[W];\n\t\t\tint up = prev[tx];\n\t\t\tint right = prev[E];\n\t\t\tint shortest = MIN(left, up);\n\t\t\tshortest = MIN(shortest, right);\n\t\t\t\n\t\t\tint index = cols*(startStep+i)+xidx;\n\t\t\tresult[tx] = shortest + gpuWall[index];\n\t\t\t\n\t\t\tif (tx==11 && i==0)\n\t\t\t{\n\t\t\t\tint bufIndex = gpuSrc[xidx];\n\t\t\t\toutputBuffer[bufIndex] = 1;\n\t\t\t}\n\t\t}\n\n\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\t\tif(i==iteration-1)\n\t\t{\n\t\t\tbreak;\n\t\t}\n\n\t\tif(computed)\n\t\t{\n\t\t\tprev[tx] = result[tx];\n\t\t}\n\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n\t}\n\tif (computed)\n\t{\n\t\tgpuResults[xidx] = result[tx];\n\t}\n}\n\n\n\n\n"}, "code_dirs": {"main.cpp": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/pathfinder", "kernels.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/pathfinder"}}
{"kernel_name": "streamcluster", "parallel_api": "cuda", "code": {"streamcluster_cuda.cu": "#include \"streamcluster_header.cu\"\n\nusing namespace std;\n\n#define CUDA_SAFE_CALL( call) do {\t\t\t\t\t\t\t\t\t\t\\\n   cudaError err = call;\t\t\t\t\t\t\t\t\t\t\t\t\\\n   if( cudaSuccess != err) {\t\t\t\t\t\t\t\t\t\t\t\\\n       fprintf(stderr, \"Cuda error in file '%s' in line %i : %s.\\n\",\t\\\n               __FILE__, __LINE__, cudaGetErrorString( err) );\t\t\t\\\n   exit(EXIT_FAILURE);\t\t\t\t\t\t\t\t\t\t\t\t\t\\\n   } } while (0)\n\n#define THREADS_PER_BLOCK 512\n#define MAXBLOCKS 65536\n#define CUDATIME\n\nfloat *work_mem_h;\nfloat *coord_h;\n\nfloat *work_mem_d;\nfloat *coord_d;\nint   *center_table_d;\nbool  *switch_membership_d;\nPoint *p;\n\nstatic int iter = 0;\t\t// counter for total# of iteration\n\n\n__device__ float\nd_dist(int p1, int p2, int num, int dim, float *coord_d)\n{\n\tfloat retval = 0.0;\n\tfor(int i = 0; i < dim; i++){\n\t\tfloat tmp = coord_d[(i*num)+p1] - coord_d[(i*num)+p2];\n\t\tretval += tmp * tmp;\n\t}\n\treturn retval;\n}\n\n__global__ void\nkernel_compute_cost(int num, int dim, long x, Point *p, int K, int stride,\n\t\t\t\t\tfloat *coord_d, float *work_mem_d, int *center_table_d, bool *switch_membership_d)\n{\n\t// block ID and global thread ID\n\tconst int bid  = blockIdx.x + gridDim.x * blockIdx.y;\n\tconst int tid = blockDim.x * bid + threadIdx.x;\n\n\tif(tid < num)\n\t{\n\t\tfloat *lower = &work_mem_d[tid*stride];\n\t\t\n\t\t// cost between this point and point[x]: euclidean distance multiplied by weight\n\t\tfloat x_cost = d_dist(tid, x, num, dim, coord_d) * p[tid].weight;\n\t\t\n\t\t// if computed cost is less then original (it saves), mark it as to reassign\n\t\tif ( x_cost < p[tid].cost )\n\t\t{\n\t\t\tswitch_membership_d[tid] = 1;\n\t\t\tlower[K] += x_cost - p[tid].cost;\n\t\t}\n\t\t// if computed cost is larger, save the difference\n\t\telse\n\t\t{\n\t\t\tlower[center_table_d[p[tid].assign]] += p[tid].cost - x_cost;\n\t\t}\n\t}\n}\n\nvoid allocDevMem(int num, int dim)\n{\n\tCUDA_SAFE_CALL( cudaMalloc((void**) &center_table_d,\t  num * sizeof(int))   );\n\tCUDA_SAFE_CALL( cudaMalloc((void**) &switch_membership_d, num * sizeof(bool))  );\n\tCUDA_SAFE_CALL( cudaMalloc((void**) &p,\t\t\t\t\t  num * sizeof(Point)) );\n\tCUDA_SAFE_CALL( cudaMalloc((void**) &coord_d,\t\tnum * dim * sizeof(float)) );\n}\n\nvoid allocHostMem(int num, int dim)\n{\n\tcoord_h\t= (float*) malloc( num * dim * sizeof(float) );\n}\n\nvoid freeDevMem()\n{\n\tCUDA_SAFE_CALL( cudaFree(center_table_d)\t  );\n\tCUDA_SAFE_CALL( cudaFree(switch_membership_d) );\n\tCUDA_SAFE_CALL( cudaFree(p)\t\t\t\t\t  );\n\tCUDA_SAFE_CALL( cudaFree(coord_d)\t\t\t  );\n}\n\nvoid freeHostMem()\n{\n\tfree(coord_h);\n}\n\nfloat pgain( long x, Points *points, float z, long int *numcenters, int kmax, bool *is_center, int *center_table, bool *switch_membership, bool isCoordChanged,\n\t\t\t\t\t\t\tdouble *serial_t, double *cpu_to_gpu_t, double *gpu_to_cpu_t, double *alloc_t, double *kernel_t, double *free_t)\n{\t\n#ifdef CUDATIME\n\tfloat tmp_t;\n\tcudaEvent_t start, stop;\n\tcudaEventCreate(&start);\n\tcudaEventCreate(&stop);\n\t\n\tcudaEventRecord(start, 0);\n#endif\n\n\tcudaError_t error;\n\t\n\tint stride\t= *numcenters + 1;\t\t\t// size of each work_mem segment\n\tint K\t\t= *numcenters ;\t\t\t\t// number of centers\n\tint num\t\t=  points->num;\t\t\t\t// number of points\n\tint dim\t\t=  points->dim;\t\t\t\t// number of dimension\n\tint nThread =  num;\t\t\t\t\t\t// number of threads == number of data points\n\n\twork_mem_h = (float*) malloc(stride * (nThread + 1) * sizeof(float) );\n\tif(iter == 0)\n\t{\n\t\tallocHostMem(num, dim);\n\t}\n\t\n\tint count = 0;\n\tfor( int i=0; i<num; i++)\n\t{\n\t\tif( is_center[i] )\n\t\t{\n\t\t\tcenter_table[i] = count++;\n\t\t}\n\t}\n\n\tif(isCoordChanged || iter == 0)\n\t{\n\t\tfor(int i=0; i<dim; i++)\n\t\t{\n\t\t\tfor(int j=0; j<num; j++)\n\t\t\t{\n\t\t\t\tcoord_h[ (num*i)+j ] = points->p[j].coord[i];\n\t\t\t}\n\t\t}\n\t}\n\t\n#ifdef CUDATIME\n\tcudaEventRecord(stop,0);\n\tcudaEventSynchronize(stop);\n\tcudaEventElapsedTime(&tmp_t, start, stop);\n\t*serial_t += (double) tmp_t;\n\t\n\tcudaEventRecord(start,0);\n#endif\n\n\tCUDA_SAFE_CALL( cudaMalloc((void**) &work_mem_d,  stride * (nThread + 1) * sizeof(float)) );\n\tif( iter == 0 )\n\t{\n\t\tallocDevMem(num, dim);\n\t}\n\t\n#ifdef CUDATIME\n\tcudaEventRecord(stop,0);\n\tcudaEventSynchronize(stop);\n\tcudaEventElapsedTime(&tmp_t, start, stop);\n\t*alloc_t += (double) tmp_t;\n\t\n\tcudaEventRecord(start,0);\n#endif\n\n\tif(isCoordChanged || iter == 0)\n\t{\n\t\tCUDA_SAFE_CALL( cudaMemcpy(coord_d,  coord_h,\t num * dim * sizeof(float), cudaMemcpyHostToDevice) );\n\t}\n\tCUDA_SAFE_CALL( cudaMemcpy(center_table_d,  center_table,  num * sizeof(int),   cudaMemcpyHostToDevice) );\n\tCUDA_SAFE_CALL( cudaMemcpy(p,  points->p,\t\t\t\t   num * sizeof(Point), cudaMemcpyHostToDevice) );\n\t\n\tCUDA_SAFE_CALL( cudaMemset((void*) switch_membership_d, 0,\t\t\tnum * sizeof(bool))  );\n\tCUDA_SAFE_CALL( cudaMemset((void*) work_mem_d,  \t\t0, stride * (nThread + 1) * sizeof(float)) );\n\t\n#ifdef CUDATIME\n\tcudaEventRecord(stop,0);\n\tcudaEventSynchronize(stop);\n\tcudaEventElapsedTime(&tmp_t, start, stop);\n\t*cpu_to_gpu_t += (double) tmp_t;\n\t\n\tcudaEventRecord(start,0);\n#endif\n\t\n\t// Determine the number of thread blocks in the x- and y-dimension\n\tint num_blocks \t = (int) ((float) (num + THREADS_PER_BLOCK - 1) / (float) THREADS_PER_BLOCK);\n\tint num_blocks_y = (int) ((float) (num_blocks + MAXBLOCKS - 1)  / (float) MAXBLOCKS);\n\tint num_blocks_x = (int) ((float) (num_blocks+num_blocks_y - 1) / (float) num_blocks_y);\t\n\tdim3 grid_size(num_blocks_x, num_blocks_y, 1);\n\n\tkernel_compute_cost<<<grid_size, THREADS_PER_BLOCK>>>(\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tnum,\t\t\t\t\t// in:\t# of data\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tdim,\t\t\t\t\t// in:\tdimension of point coordinates\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tx,\t\t\t\t\t\t// in:\tpoint to open a center at\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tp,\t\t\t\t\t\t// in:\tdata point array\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tK,\t\t\t\t\t\t// in:\tnumber of centers\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstride,\t\t\t\t\t// in:  size of each work_mem segment\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcoord_d,\t\t\t\t// in:\tarray of point coordinates\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\twork_mem_d,\t\t\t\t// out:\tcost and lower field array\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcenter_table_d,\t\t\t// in:\tcenter index table\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tswitch_membership_d\t\t// out:  changes in membership\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t);\n\tcudaThreadSynchronize();\n\t\n\t// error check\n\terror = cudaGetLastError();\n\tif (error != cudaSuccess)\n\t{\n\t\tprintf(\"kernel error: %s\\n\", cudaGetErrorString(error));\n\t\texit(EXIT_FAILURE);\n\t}\n\t\n#ifdef CUDATIME\n\tcudaEventRecord(stop,0);\n\tcudaEventSynchronize(stop);\n\tcudaEventElapsedTime(&tmp_t, start, stop);\n\t*kernel_t += (double) tmp_t;\n\t\n\tcudaEventRecord(start,0);\n#endif\n\t\n\tCUDA_SAFE_CALL( cudaMemcpy(work_mem_h, \t\t  work_mem_d, \tstride * (nThread + 1) * sizeof(float), cudaMemcpyDeviceToHost) );\n\tCUDA_SAFE_CALL( cudaMemcpy(switch_membership, switch_membership_d,\t num * sizeof(bool),  cudaMemcpyDeviceToHost) );\n\t\n#ifdef CUDATIME\n\tcudaEventRecord(stop,0);\n\tcudaEventSynchronize(stop);\n\tcudaEventElapsedTime(&tmp_t, start, stop);\n\t*gpu_to_cpu_t += (double) tmp_t;\n\t\n\tcudaEventRecord(start,0);\n#endif\n\t\n\tint number_of_centers_to_close = 0;\n\tfloat gl_cost_of_opening_x = z;\n\tfloat *gl_lower = &work_mem_h[stride * nThread];\n\tfor(int i=0; i < num; i++)\n\t{\n\t\tif( is_center[i] )\n\t\t{\n\t\t\tfloat low = z;\n\t\t    for( int j = 0; j < num; j++ )\n\t\t\t{\n\t\t\t\tlow += work_mem_h[ j*stride + center_table[i] ];\n\t\t\t}\n\t\t\t\n\t\t    gl_lower[center_table[i]] = low;\n\t\t\t\t\n\t\t    if ( low > 0 )\n\t\t\t{\n\t\t\t\t++number_of_centers_to_close;\n\t\t\t\twork_mem_h[i*stride+K] -= low;\n\t\t    }\n\t\t}\n\t\tgl_cost_of_opening_x += work_mem_h[i*stride+K];\n\t}\n\n\tif ( gl_cost_of_opening_x < 0 )\n\t{\n\t\tfor(int i = 0; i < num; i++)\n\t\t{\n\t\t\tbool close_center = gl_lower[center_table[points->p[i].assign]] > 0 ;\n\t\t\tif ( switch_membership[i] || close_center )\n\t\t\t{\n\t\t\t\tpoints->p[i].cost = dist(points->p[i], points->p[x], dim) * points->p[i].weight;\n\t\t\t\tpoints->p[i].assign = x;\n\t\t\t}\n\t\t}\n\t\t\n\t\tfor(int i = 0; i < num; i++)\n\t\t{\n\t\t\tif( is_center[i] && gl_lower[center_table[i]] > 0 )\n\t\t\t{\n\t\t\t\tis_center[i] = false;\n\t\t\t}\n\t\t}\n\t\t\n\t\tif( x >= 0 && x < num)\n\t\t{\n\t\t\tis_center[x] = true;\n\t\t}\n\t\t*numcenters = *numcenters + 1 - number_of_centers_to_close;\n\t}\n\telse\n\t{\n\t\tgl_cost_of_opening_x = 0;\n\t}\n\n\tfree(work_mem_h);\n\n\t// free device memory\n#ifdef CUDATIME\n\tcudaEventRecord(stop,0);\n\tcudaEventSynchronize(stop);\n\tcudaEventElapsedTime(&tmp_t, start, stop);\n\t*serial_t += (double) tmp_t;\n\t\n\tcudaEventRecord(start,0);\n#endif\n\n\tCUDA_SAFE_CALL( cudaFree(work_mem_d) );\n\t\n#ifdef CUDATIME\n\tcudaEventRecord(stop,0);\n\tcudaEventSynchronize(stop);\n\tcudaEventElapsedTime(&tmp_t, start, stop);\n\t*free_t += (double) tmp_t;\n#endif\n\titer++;\n\treturn -gl_cost_of_opening_x;\n}\n", "streamcluster_header.cu": "/************************************************\n\tstreamcluster_cuda_header.cu\n\t: header file to streamcluster\n\t\n\t- original code from PARSEC Benchmark Suite\n\t- parallelization with CUDA API has been applied by\n\t\n\tSang-Ha (a.k.a Shawn) Lee - sl4ge@virginia.edu\n\tUniversity of Virginia\n\tDepartment of Electrical and Computer Engineering\n\tDepartment of Computer Science\n\t\n***********************************************/\n\n#ifndef STREAMCLUSTER_CUDA_HEADER_CU\n#define STREAMCLUSTER_CUDA_HEADER_CU\n\n#include <stdio.h>\n#include <iostream>\n#include <fstream>\n#include <stdlib.h>\n#include <sys/time.h>\n#include <string.h>\n#include <assert.h>\n#include <math.h>\n#include <sys/resource.h>\n#include <limits.h>\n\n#include <cuda.h>\n\n#ifdef ENABLE_PARSEC_HOOKS\n#include <hooks.h>\n#endif\n\nusing namespace std;\n\n/* this structure represents a point */\n/* these will be passed around to avoid copying coordinates */\ntypedef struct {\n  float weight;\n  float *coord;\n  long assign;  /* number of point where this one is assigned */\n  float cost;  /* cost of that assignment, weight*distance */\n} Point;\n\n/* this is the array of points */\ntypedef struct {\n  long num; /* number of points; may not be N if this is a sample */\n  int dim;  /* dimensionality */\n  Point *p; /* the array itself */\n} Points;\n\nstruct pkmedian_arg_t\n{\n  Points* points;\n  long kmin;\n  long kmax;\n  long* kfinal;\n  int pid;\n  pthread_barrier_t* barrier;\n};\n\nclass PStream {\npublic:\n  virtual size_t read( float* dest, int dim, int num ) = 0;\n  virtual int ferror() = 0;\n  virtual int feof() = 0;\n  virtual ~PStream() {\n  }\n};\n\n//synthetic stream\nclass SimStream : public PStream {\npublic:\n  SimStream(long n_ ) {\n    n = n_;\n  }\n  size_t read( float* dest, int dim, int num ) {\n    size_t count = 0;\n    for( int i = 0; i < num && n > 0; i++ ) {\n      for( int k = 0; k < dim; k++ ) {\n\tdest[i*dim + k] = lrand48()/(float)INT_MAX;\n      }\n      n--;\n      count++;\n    }\n    return count;\n  }\n  int ferror() {\n    return 0;\n  }\n  int feof() {\n    return n <= 0;\n  }\n  ~SimStream() { \n  }\nprivate:\n  long n;\n};\n\nclass FileStream : public PStream {\npublic:\n  FileStream(char* filename) {\n    fp = fopen( filename, \"rb\");\n    if( fp == NULL ) {\n      fprintf(stderr,\"error opening file %s\\n.\",filename);\n      exit(1);\n    }\n  }\n  size_t read( float* dest, int dim, int num ) {\n    return std::fread(dest, sizeof(float)*dim, num, fp); \n  }\n  int ferror() {\n    return std::ferror(fp);\n  }\n  int feof() {\n    return std::feof(fp);\n  }\n  ~FileStream() {\n    printf(\"closing file stream\\n\");\n    fclose(fp);\n  }\nprivate:\n  FILE* fp;\n};\n\n/* function prototypes */\ndouble gettime();\nint isIdentical(float*, float*, int);\n//static int floatcomp(const void*, const void*);\nvoid shuffle(Points*);\nvoid intshuffle(int*, int);\nfloat waste(float);\nfloat dist(Point, Point, int);\nfloat pspeedy(Points*, float, long, int, pthread_barrier_t*);\nfloat pgain_old(long, Points*, float, long int*, int, pthread_barrier_t*);\nfloat pFL(Points*, int*, int, float, long*, float, long, float, int, pthread_barrier_t*);\nint selectfeasible_fast(Points*, int**, int, int, pthread_barrier_t*);\nfloat pkmedian(Points*, long, long, long*, int, pthread_barrier_t*);\nint contcenters(Points*);\nvoid copycenters(Points*, Points*, long*, long);\nvoid* localSearchSub(void*);\nvoid localSearch(Points*, long, long, long*);\nvoid outcenterIDs(Points*, long*, char*);\nvoid streamCluster(PStream*, long, long, int, long, long, char*);\nfloat pgain(long, Points*, float, long int*, int, bool*, int*, bool*, bool, double*, double*, double*, double*, double*, double*);\nvoid allocDevMem(int, int, int);\nvoid allocHostMem(int, int, int);\nvoid freeDevMem();\nvoid freeHostMem();\n\n#endif\n"}, "code_dirs": {"streamcluster_cuda.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/streamcluster", "streamcluster_header.cu": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/cuda/streamcluster"}}
{"kernel_name": "streamcluster", "parallel_api": "ocl", "code": {"streamcluster.cpp": "\n#include \"streamcluster.h\"\n#include \"CLHelper.h\"\n#include \"streamcluster_cl.h\"\n\nusing namespace std;\n\n#define MAXNAMESIZE 1024\n#define SEED 1\n#define SP 1\n#define ITER 3\n\n#define CACHE_LINE 512\n\nstatic char *switch_membership;\nstatic bool *is_center;\nstatic int  *center_table;\nstatic int nproc;\n\nstatic double serial;\nstatic double cpu_gpu_memcpy;\nstatic double memcpy_back;\nstatic double gpu_malloc;\nstatic double kernel;\nstatic double gpu_free;\nstatic int cnt_speedy;\n\n#ifdef PROFILE_TMP\ndouble time_local_search;\ndouble time_speedy;\ndouble time_select_feasible;\ndouble time_gain;\ndouble time_shuffle;\ndouble time_gain_dist;\ndouble time_gain_init;\ndouble time_FL;\n#endif \n\nvoid inttofile(int data, char *filename){\n\tFILE *fp = fopen(filename, \"w\");\n\tfprintf(fp, \"%d \", data);\n\tfclose(fp);\t\n}\n\nint isIdentical(float *i, float *j, int D){\n  int a = 0;\n  int equal = 1;\n\n  while (equal && a < D) {\n    if (i[a] != j[a]) equal = 0;\n    else a++;\n  }\n  if (equal) return 1;\n  else return 0;\n\n}\n\nstatic int floatcomp(const void *i, const void *j)\n{\n  float a, b;\n  a = *(float *)(i);\n  b = *(float *)(j);\n  if (a > b) return (1);\n  if (a < b) return (-1);\n  return(0);\n}\n\nvoid shuffle(Points *points)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  Point temp;\n  for (i=0;i<points->num-1;i++) {\n    j=(lrand48()%(points->num - i)) + i;\n    temp = points->p[i];\n    points->p[i] = points->p[j];\n    points->p[j] = temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\nvoid intshuffle(int *intarray, int length)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n  long i, j;\n  int temp;\n  for (i=0;i<length;i++) {\n    j=(lrand48()%(length - i))+i;\n    temp = intarray[i];\n    intarray[i]=intarray[j];\n    intarray[j]=temp;\n  }\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_shuffle += t2-t1;\n#endif\n}\n\n#ifdef INSERT_WASTE\nfloat waste(float s )\n{\n  for( int i =0 ; i< 4; i++ ) {\n    s += pow(s,0.78);\n  }\n  return s;\n}\n#endif\n\nfloat dist(Point p1, Point p2, int dim)\n{\n  int i;\n  float result=0.0;\n  for (i=0;i<dim;i++)\n    result += (p1.coord[i] - p2.coord[i])*(p1.coord[i] - p2.coord[i]);\n#ifdef INSERT_WASTE\n  float s = waste(result);\n  result += s;\n  result -= s;\n#endif\n  return(result);\n}\n\nfloat pspeedy(Points *points, float z, long *kcenter, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\ncnt_speedy++;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n  static float totalcost;\n  \n  static bool open = false;\n  static float* costs;\n  static int i;\n\n#ifdef ENABLE_THREADS\n  static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;\n  static pthread_cond_t cond = PTHREAD_COND_INITIALIZER;\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 ){\n    fprintf(stderr, \"Speedy: facility cost %lf\\n\", z);\n  }\n#endif\n\n  for( int k = k1; k < k2; k++ )    {\n    float distance = dist(points->p[k],points->p[0],points->dim);\n    points->p[k].cost = distance * points->p[k].weight;\n    points->p[k].assign=0;\n  }\n\n  if( pid==0 )   {\n    *kcenter = 1;\n    costs = (float*)malloc(sizeof(float)*nproc);\n  }\n    \n  if( pid != 0 ) {\n    while(1) {\n#ifdef ENABLE_THREADS\n      pthread_mutex_lock(&mutex);\n      while(!open) pthread_cond_wait(&cond,&mutex);\n      pthread_mutex_unlock(&mutex);\n#endif\n      if( i >= points->num ) break;\n      for( int k = k1; k < k2; k++ )\n\t{\n\t  float distance = dist(points->p[i],points->p[k],points->dim);\n\t  if( distance*points->p[k].weight < points->p[k].cost )\n\t    {\n\t      points->p[k].cost = distance * points->p[k].weight;\n\t      points->p[k].assign=i;\n\t    }\n\t}\n#ifdef ENABLE_THREADS\n      pthread_barrier_wait(barrier);\n      pthread_barrier_wait(barrier);\n#endif\n    } \n  }\n  else  {\n    for(i = 1; i < points->num; i++ )  {\n      bool to_open = ((float)lrand48()/(float)INT_MAX)<(points->p[i].cost/z);\n      if( to_open )  {\n\t(*kcenter)++;\n#ifdef ENABLE_THREADS\n\tpthread_mutex_lock(&mutex);\n#endif\n\topen = true;\n#ifdef ENABLE_THREADS\n\tpthread_mutex_unlock(&mutex);\n\tpthread_cond_broadcast(&cond);\n#endif\n\tfor( int k = k1; k < k2; k++ )  {\n\t  float distance = dist(points->p[i],points->p[k],points->dim);\n\t  if( distance*points->p[k].weight < points->p[k].cost )  {\n\t    points->p[k].cost = distance * points->p[k].weight;\n\t    points->p[k].assign=i;\n\t  }\n\t}\n#ifdef ENABLE_THREADS\n\tpthread_barrier_wait(barrier);\n#endif\n\topen = false;\n#ifdef ENABLE_THREADS\n\tpthread_barrier_wait(barrier);\n#endif\n      }\n    }\n#ifdef ENABLE_THREADS\n    pthread_mutex_lock(&mutex);\n#endif\n    open = true;\n#ifdef ENABLE_THREADS\n    pthread_mutex_unlock(&mutex);\n    pthread_cond_broadcast(&cond);\n#endif\n  }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  open = false;\n  float mytotal = 0;\n  for( int k = k1; k < k2; k++ )  {\n    mytotal += points->p[k].cost;\n  }\n  costs[pid] = mytotal;\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  if( pid == 0 )\n    {\n      totalcost=z*(*kcenter);\n      for( int i = 0; i < nproc; i++ )\n\t{\n\t  totalcost += costs[i];\n\t} \n      free(costs);\n    }\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n    {\n      fprintf(stderr, \"Speedy opened %d facilities for total cost %lf\\n\",\n\t      *kcenter, totalcost);\n      fprintf(stderr, \"Distance Cost %lf\\n\", totalcost - z*(*kcenter));\n    }\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  if( pid== 0 ) {\n    time_speedy += t2 -t1;\n  }\n#endif\n  return(totalcost);\n}\n\nfloat pFL(Points *points, int *feasible, int numfeasible,\n\t  float z, long *k, int kmax, float cost, long iter, float e, \n\t  int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n\tdouble t1 = gettime();\n#endif\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n  long i;\n  long x;\n  float change;\n  long numberOfPoints;\n\n  change = cost;\n  while (change/cost > 1.0*e) {\n    change = 0.0;\n    numberOfPoints = points->num;\n\n    if( pid == 0 ) {\n      intshuffle(feasible, numfeasible);\n    }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n    for (i=0;i<iter;i++) {\n\t    x = i%numfeasible;\n\t    change += pgain(feasible[x], points, z, k, kmax, is_center, center_table, switch_membership,\n\t\t\t\t\t\t\t\t\t\t\t\t&serial, &cpu_gpu_memcpy, &memcpy_back, &gpu_malloc, &kernel);\n    }\t\t\n    cost -= change;\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      fprintf(stderr, \"%d centers, cost %lf, total distance %lf\\n\",\n\t      *k, cost, cost - z*(*k));\n    }\n#endif\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n#ifdef PROFILE_TMP\n\tdouble t2 = gettime();\n\ttime_FL += t2 - t1;\n#endif\n  return(cost);\n}\n\nint selectfeasible_fast(Points *points, int **feasible, int kmin, int pid, pthread_barrier_t* barrier)\n{\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n  int numfeasible = points->num;\n  if (numfeasible > (ITER*kmin*log((float)kmin)))\n    numfeasible = (int)(ITER*kmin*log((float)kmin));\n  *feasible = (int *)malloc(numfeasible*sizeof(int));\n  \n  float* accumweight;\n  float totalweight;\n\n\n  long k1 = 0;\n  long k2 = numfeasible;\n\n  float w;\n  int l,r,k;\n\n  /* not many points, all will be feasible */\n  if (numfeasible == points->num) {\n    for (int i=k1;i<k2;i++)\n      (*feasible)[i] = i;\n    return numfeasible;\n  }\n\n  accumweight= (float*)malloc(sizeof(float)*points->num);\n  accumweight[0] = points->p[0].weight;\n  totalweight=0;\n  for( int i = 1; i < points->num; i++ ) {\n    accumweight[i] = accumweight[i-1] + points->p[i].weight;\n  }\n  totalweight=accumweight[points->num-1];\n\n  for(int i=k1; i<k2; i++ ) {\n    w = (lrand48()/(float)INT_MAX)*totalweight;\n    l=0;\n    r=points->num-1;\n    if( accumweight[0] > w )  { \n      (*feasible)[i]=0; \n      continue;\n    }\n    while( l+1 < r ) {\n      k = (l+r)/2;\n      if( accumweight[k] > w ) {\n\tr = k;\n      } \n      else {\n\tl=k;\n      }\n    }\n    (*feasible)[i]=r;\n  }\n  free(accumweight); \n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_select_feasible += t2-t1;\n#endif\n  return numfeasible;\n}\n\nfloat pkmedian(Points *points, long kmin, long kmax, long* kfinal,\n\t       int pid, pthread_barrier_t* barrier )\n{\n  int i;\n  float cost;\n  float lastcost;\n  float hiz, loz, z;\n\n  static long k;\n  static int *feasible;\n  static int numfeasible;\n  static float* hizs;\n\n  if( pid==0 ) hizs = (float*)calloc(nproc,sizeof(float));\n  hiz = loz = 0.0;\n  long numberOfPoints = points->num;\n  long ptDimension = points->dim;\n\n  long bsize = points->num/nproc;\n  long k1 = bsize * pid;\n  long k2 = k1 + bsize;\n  if( pid == nproc-1 ) k2 = points->num;\n\n#ifdef PRINTINFO\n  if( pid == 0 )\n    {\n      printf(\"Starting Kmedian procedure\\n\");\n      printf(\"%i points in %i dimensions\\n\", numberOfPoints, ptDimension);\n    }\n#endif\n\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  float myhiz = 0;\n  for (long kk=k1;kk < k2; kk++ ) {\n    myhiz += dist(points->p[kk], points->p[0],\n\t\t      ptDimension)*points->p[kk].weight;\n  }\n  hizs[pid] = myhiz;\n\n#ifdef ENABLE_THREADS  \n  pthread_barrier_wait(barrier);\n#endif\n\n  for( int i = 0; i < nproc; i++ )   {\n    hiz += hizs[i];\n  }\n\n  loz=0.0; z = (hiz+loz)/2.0;\n  /* NEW: Check whether more centers than points! */\n  if (points->num <= kmax) {\n    /* just return all points as facilities */\n    for (long kk=k1;kk<k2;kk++) {\n      points->p[kk].assign = kk;\n      points->p[kk].cost = 0;\n    }\n    cost = 0;\n    if( pid== 0 ) {\n      free(hizs); \n      *kfinal = k;\n    }\n    return cost;\n  }\n\n  if( pid == 0 ) shuffle(points);\n  cost = pspeedy(points, z, &k, pid, barrier);\n#ifdef PRINTINFO\n  if( pid == 0 )\n    printf(\"thread %d: Finished first call to speedy, cost=%lf, k=%i\\n\",pid,cost,k);\n#endif\n  i=0;\n  while ((k < kmin)&&(i<SP)) {\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n\n#ifdef PRINTINFO\n  if( pid==0)\n    printf(\"thread %d: second call to speedy, cost=%lf, k=%d\\n\",pid,cost,k);\n#endif \n  while (k < kmin) {\n#ifdef PRINTINFO\n    if( pid == 0 ) {\n      printf(\"%lf %lf\\n\", loz, hiz);\n      printf(\"Speedy indicates we should try lower z\\n\");\n    }\n#endif\n    if (i >= SP) {hiz=z; z=(hiz+loz)/2.0; i=0;}\n    if( pid == 0 ) shuffle(points);\n    cost = pspeedy(points, z, &k, pid, barrier);\n    i++;\n  }\n \n  if( pid == 0 )\n    {\n      numfeasible = selectfeasible_fast(points,&feasible,kmin,pid,barrier); //--cambine?\n      for( int i = 0; i< points->num; i++ ) {\n\tis_center[points->p[i].assign]= true;\n      }\n    }\n\t\n#ifdef ENABLE_THREADS\n  pthread_barrier_wait(barrier);\n#endif\n\n  while(1) {\n#ifdef PRINTINFO\n    if( pid==0 )\n      {\n\tprintf(\"loz = %lf, hiz = %lf\\n\", loz, hiz);\n\tprintf(\"Running Local Search...\\n\");\n      }\n#endif\n    lastcost = cost;\n    cost = pFL(points, feasible, numfeasible,\n\t       z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.1, pid, barrier);\n    if (((k <= (1.1)*kmax)&&(k >= (0.9)*kmin))||\n\t((k <= kmax+2)&&(k >= kmin-2))) {\n#ifdef PRINTINFO\n      if( pid== 0)\n\t{\n\t  printf(\"Trying a more accurate local search...\\n\");\n\t}\n#endif\n      cost = pFL(points, feasible, numfeasible,\n\t\t z, &k, kmax, cost, (long)(ITER*kmax*log((float)kmax)), 0.001, pid, barrier);\n    }\n\n    if (k > kmax) {\n      loz = z; z = (hiz+loz)/2.0;\n      cost += (z-loz)*k;\n    }\n    if (k < kmin) {\n      hiz = z; z = (hiz+loz)/2.0;\n      cost += (z-hiz)*k;\n    }\n\n    if (((k <= kmax)&&(k >= kmin))||((loz >= (0.999)*hiz)) )\n      { \n\tbreak;\n      }\n#ifdef ENABLE_THREADS\n    pthread_barrier_wait(barrier);\n#endif\n  }\n\n  if( pid==0 ) {\n    free(feasible); \n    free(hizs);\n    *kfinal = k;\n  }\n\n  return cost;\n}\n\nint contcenters(Points *points)\n{\n  long i, ii;\n  float relweight;\n\n  for (i=0;i<points->num;i++) {\n    if (points->p[i].assign != i) {\n      relweight=points->p[points->p[i].assign].weight + points->p[i].weight;\n\n      relweight = points->p[i].weight/relweight;\n      for (ii=0;ii<points->dim;ii++) {\n\t\t\t\tpoints->p[points->p[i].assign].coord[ii]*=1.0-relweight;\n\t\t\t\tpoints->p[points->p[i].assign].coord[ii]+=\n\t\t\t\tpoints->p[i].coord[ii]*relweight;\n      }\n      points->p[points->p[i].assign].weight += points->p[i].weight;\n    }\n  }\n  \n  return 0;\n}\n\nvoid copycenters(Points *points, Points* centers, long* centerIDs, long offset)\n{\n  long i;\n  long k;\n\n  bool *is_a_median = (bool *) calloc(points->num, sizeof(bool));\n\n  for ( i = 0; i < points->num; i++ ) {\n    is_a_median[points->p[i].assign] = 1;\n  }\n\n  k=centers->num;\n\n  for ( i = 0; i < points->num; i++ ) {\n    if ( is_a_median[i] ) {\n      memcpy( centers->p[k].coord, points->p[i].coord, points->dim * sizeof(float));\n      centers->p[k].weight = points->p[i].weight;\n      centerIDs[k] = i + offset;\n      k++;\n    }\n  }\n\n  centers->num = k;\n  free(is_a_median);\n}\n\n\n\nvoid* localSearchSub(void* arg_) {\n  pkmedian_arg_t* arg= (pkmedian_arg_t*)arg_;\n  pkmedian(arg->points,arg->kmin,arg->kmax,arg->kfinal,arg->pid,arg->barrier);\n\n  return NULL;\n}\n\nvoid localSearch( Points* points, long kmin, long kmax, long* kfinal ) {\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n\n    pthread_barrier_t barrier;\n#ifdef ENABLE_THREADS\n    pthread_barrier_init(&barrier,NULL,nproc);\n#endif\n    pthread_t* threads = new pthread_t[nproc];\n    pkmedian_arg_t* arg = new pkmedian_arg_t[nproc];\n\n\n    for( int i = 0; i < nproc; i++ ) {\n      arg[i].points = points;\n      arg[i].kmin = kmin;\n      arg[i].kmax = kmax;\n      arg[i].pid = i;\n      arg[i].kfinal = kfinal;\n\n      arg[i].barrier = &barrier;\n#ifdef ENABLE_THREADS\n      pthread_create(threads+i,NULL,localSearchSub,(void*)&arg[i]);\n#else\n      localSearchSub(&arg[0]);\n#endif\n    }\n\n    for ( int i = 0; i < nproc; i++) {\n#ifdef ENABLE_THREADS\n      pthread_join(threads[i],NULL);\n#endif\n    }\n\n    delete[] threads;\n    delete[] arg;\n#ifdef ENABLE_THREADS\n    pthread_barrier_destroy(&barrier);\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  time_local_search += t2-t1;\n#endif\n \n}\n\n\nvoid outcenterIDs( Points* centers, long* centerIDs, char* outfile ) {\n  FILE* fp = fopen(outfile, \"w\");\n  if( fp==NULL ) {\n    fprintf(stderr, \"error opening %s\\n\",outfile);\n    exit(1);\n  }\n  int* is_a_median = (int*)calloc( sizeof(int), centers->num );\n  for( int i =0 ; i< centers->num; i++ ) {\n    is_a_median[centers->p[i].assign] = 1;\n  }\n\n  for( int i = 0; i < centers->num; i++ ) {\n    if( is_a_median[i] ) {\n      fprintf(fp, \"%ld\\n\", centerIDs[i]);\n      fprintf(fp, \"%lf\\n\", centers->p[i].weight);\n      for( int k = 0; k < centers->dim; k++ ) {\n\tfprintf(fp, \"%lf \", centers->p[i].coord[k]);\n      }\n      fprintf(fp,\"\\n\\n\");\n    }\n  }\n  fclose(fp);\n}\n\nvoid streamCluster( PStream* stream, \n\t\t    long kmin, long kmax, int dim,\n\t\t    long chunksize, long centersize, char* outfile )\n{\n\n  float* block = (float*)malloc( chunksize*dim*sizeof(float) );\n  float* centerBlock = (float*)malloc(centersize*dim*sizeof(float) );\n  long* centerIDs = (long*)malloc(centersize*dim*sizeof(long));\n\n  if( block == NULL ) { \n    fprintf(stderr,\"not enough memory for a chunk!\\n\");\n    exit(1);\n  }\n\n  Points points;\n  points.dim = dim;\n  points.num = chunksize;\n  points.p = (Point *)malloc(chunksize*sizeof(Point));\n  for( int i = 0; i < chunksize; i++ ) {\n    points.p[i].coord = &block[i*dim];\t\t\n  }\n\t\n\n  Points centers;\n  centers.dim = dim;\n  centers.p = (Point *)malloc(centersize*sizeof(Point));\n  centers.num = 0;\n\n  for( int i = 0; i< centersize; i++ ) {\n    centers.p[i].coord = &centerBlock[i*dim];\n    centers.p[i].weight = 1.0;\n  }\n\n  long IDoffset = 0;\n  long kfinal;\n  while(1) {\n\n    size_t numRead  = stream->read(block, dim, chunksize ); \n    fprintf(stderr,\"read %lu points\\n\",numRead);\n\n    if( stream->ferror() || numRead < (unsigned int)chunksize && !stream->feof() ) {\n      fprintf(stderr, \"error reading data!\\n\");\n      exit(1);\n    }\n\n    points.num = numRead;\n    for( int i = 0; i < points.num; i++ ) {\n      points.p[i].weight = 1.0;\n    }\n\n    switch_membership = (char*)malloc(points.num*sizeof(char));\n    is_center = (bool*)calloc(points.num,sizeof(bool));\n    center_table = (int*)malloc(points.num*sizeof(int));\n\n    localSearch(&points,kmin, kmax,&kfinal);\n\n    fprintf(stderr,\"finish local search\\n\");\n    contcenters(&points);\n    if( kfinal + centers.num > centersize ) { \n      fprintf(stderr,\"oops! no more space for centers\\n\");\n      exit(1);\n    }\n\n#ifdef PRINTINFO\n    printf(\"finish cont center\\n\");\n#endif\n\n    copycenters(&points, &centers, centerIDs, IDoffset);\n    IDoffset += numRead;\n\n#ifdef PRINTINFO\n    printf(\"finish copy centers\\n\"); \n#endif\n    free(is_center);\n    free(switch_membership);\n    free(center_table);\n    if( stream->feof() ) {\n      break;\n    }\n  }\n\n  switch_membership = (char*)malloc(centers.num*sizeof(char));\n  is_center = (bool*)calloc(centers.num,sizeof(bool));\n  center_table = (int*)malloc(centers.num*sizeof(int));\n\n  localSearch( &centers, kmin, kmax ,&kfinal );\n  contcenters(&centers);\n  outcenterIDs( &centers, centerIDs, outfile);\n}\n\nint main(int argc, char **argv)\n{\n  char *outfilename = new char[MAXNAMESIZE];\n  char *infilename = new char[MAXNAMESIZE];\n  long kmin, kmax, n, chunksize, clustersize;\n  int dim;\n#ifdef PARSEC_VERSION\n#define __PARSEC_STRING(x) #x\n#define __PARSEC_XSTRING(x) __PARSEC_STRING(x)\n        printf(\"PARSEC Benchmark Suite Version \"__PARSEC_XSTRING(PARSEC_VERSION)\"\\n\");\n\tfflush(NULL);\n#else\n        printf(\"PARSEC Benchmark Suite\\n\");\n\tfflush(NULL);\n#endif //PARSEC_VERSION\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_begin(__parsec_streamcluster);\n#endif\n\n  if (argc<11) {\n    fprintf(stderr,\"usage: %s k1 k2 d n chunksize clustersize infile outfile nproc [-p platform] [-d device]\\n\",\n\t    argv[0]);\n    fprintf(stderr,\"  k1:          Min. number of centers allowed\\n\");\n    fprintf(stderr,\"  k2:          Max. number of centers allowed\\n\");\n    fprintf(stderr,\"  d:           Dimension of each data point\\n\");\n    fprintf(stderr,\"  n:           Number of data points\\n\");\n    fprintf(stderr,\"  chunksize:   Number of data points to handle per step\\n\");\n    fprintf(stderr,\"  clustersize: Maximum number of intermediate centers\\n\");\n    fprintf(stderr,\"  infile:      Input file (if n<=0)\\n\");\n    fprintf(stderr,\"  outfile:     Output file\\n\");\n    fprintf(stderr,\"  nproc:       Number of threads to use\\n\");\n    fprintf(stderr,\"  platform:    Platform id\\n\");\n    fprintf(stderr,\"  device:      Device id\\n\");\n    fprintf(stderr,\"\\n\");\n    fprintf(stderr, \"if n > 0, points will be randomly generated instead of reading from infile.\\n\");\n    exit(1);\n  }\n  kmin = atoi(argv[1]);\n  kmax = atoi(argv[2]);\n  dim = atoi(argv[3]);\n  n = atoi(argv[4]);\n  chunksize = atoi(argv[5]);\n  clustersize = atoi(argv[6]);\n  strcpy(infilename, argv[7]);\n  strcpy(outfilename, argv[8]);\n  nproc = atoi(argv[9]);\n  _clCmdParams(argc, argv);\n\n#ifdef  TIMING\n    gettimeofday(&tv_total_start, NULL);\n#endif\n  try{\n\t  _clInit(platform_id, device_id);\n   }\n   catch(std::string msg){\n   \tstd::cout<<\"exception caught in main function->\"<<msg<<std::endl;\n   \treturn -1;\n   }\n#ifdef  TIMING\n\tgettimeofday(&tv_init_end, NULL);\n\ttvsub(&tv_init_end, &tv_total_start, &tv);\n\tinit_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n  srand48(SEED);\n  PStream* stream;\n  if( n > 0 ) {\n    stream = new SimStream(n);\n  }\n  else {\n    stream = new FileStream(infilename);\n  }\n#ifdef PROFILE_TMP\n  double t1 = gettime();\n#endif\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_begin();\n#endif\n#ifdef PROFILE_TMP\n\tserial = 0.0;\n\tcpu_gpu_memcpy = 0.0;\n\tgpu_malloc = 0.0;\n\tgpu_free = 0.0;\n\tkernel = 0.0;\n\ttime_FL = 0.0;\n\tcnt_speedy = 0;\n#endif\n  std::cout<<\"before sc\"<<std::endl;\n  streamCluster(stream, kmin, kmax, dim, chunksize, clustersize, outfilename );\n  std::cout<<\"after sc\"<<std::endl;\n#ifdef PROFILE_TMP \n\tgpu_free = gettime();\n#endif\n#ifdef  TIMING\n\tgettimeofday(&tv_close_start, NULL);\n#endif\n\n\tfreeDevMem();\n#ifdef PROFILE_TMP\n\tgpu_free = gettime() - gpu_free;\n#endif\n\t_clRelease();\n#ifdef  TIMING\n\tgettimeofday(&tv_close_end, NULL);\n\ttvsub(&tv_close_end, &tv_close_start, &tv);\n\tclose_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n#endif\n\n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_roi_end();\n#endif\n\n#ifdef PROFILE_TMP\n  double t2 = gettime();\n  printf(\"time = %lf\\n\",t2-t1);\n#endif\n\n  delete stream;\n  \n#ifdef  TIMING\n\ttvsub(&tv_close_end, &tv_total_start, &tv);\n\ttotal_time = tv.tv_sec * 1000.0 + (float) tv.tv_usec / 1000.0;\n\n\tprintf(\"Init: %f\\n\", init_time);\n\tprintf(\"MemAlloc: %f\\n\", mem_alloc_time);\n\tprintf(\"HtoD: %f\\n\", h2d_time);\n\tprintf(\"Exec: %f\\n\", kernel_time);\n\tprintf(\"DtoH: %f\\n\", d2h_time);\n\tprintf(\"Close: %f\\n\", close_time);\n\tprintf(\"Total: %f\\n\", total_time);\n#endif\n\n#ifdef PROFILE_TMP\n  printf(\"time pgain = %lf\\n\", time_gain);\n  printf(\"time pgain_dist = %lf\\n\", time_gain_dist);\n  printf(\"time pgain_init = %lf\\n\", time_gain_init);\n  printf(\"time pselect = %lf\\n\", time_select_feasible);\n  printf(\"time pspeedy = %lf\\n\", time_speedy);\n  printf(\"time pshuffle = %lf\\n\", time_shuffle);\n  printf(\"time FL = %lf\\n\", time_FL);\n  printf(\"time localSearch = %lf\\n\", time_local_search);\n\tprintf(\"\\n\");\n\tprintf(\"====GPU Timing info====\\n\");\n\tprintf(\"time serial = %lf\\n\", serial);\n\tprintf(\"time CPU to GPU memory copy = %lf\\n\", cpu_gpu_memcpy);\n\tprintf(\"time GPU to CPU memory copy back = %lf\\n\", memcpy_back);\n\tprintf(\"time GPU malloc = %lf\\n\", gpu_malloc);\n\tprintf(\"time GPU free = %lf\\n\", gpu_free);\n\tprintf(\"time kernel = %lf\\n\", kernel);\n\t\n  FILE *fp = fopen(\"PD.txt\", \"w\");\n  fprintf(fp, \"%lf, %lf, %lf, %lf, %lf, %lf, %lf, %lf, %lf\\n\", time_FL, cpu_gpu_memcpy, memcpy_back, kernel, gpu_malloc, gpu_free, 0.0);\n  fclose(fp);\t\n #endif\n _clStatistics(); \n#ifdef ENABLE_PARSEC_HOOKS\n  __parsec_bench_end();\n#endif\n  \n  return 0;\n}\n", "Kernels.cl": "typedef struct {\n  float weight;\n  long assign;\n  float cost;\n} Point_Struct;\n\n\n__kernel void memset_kernel(__global char * mem_d, short val, int number_bytes){\n\tconst int thread_id = get_global_id(0);\n\tmem_d[thread_id] = val;\n}\n__kernel void pgain_kernel(\n\t\t\t __global Point_Struct *p,\t\t\t \n\t\t\t __global float *coord_d,\n\t\t\t __global float * work_mem_d,\t\t\t\n\t\t\t __global int *center_table_d,\n\t\t\t __global char *switch_membership_d,\t\t\t\n\t\t\t __local float *coord_s,\n\t\t\t int num,\n\t\t\t int dim,\n\t\t\t long x,\n\t\t\t int K){\t\n\t/* block ID and global thread ID */\n\tconst int thread_id = get_global_id(0);\n\tconst int local_id = get_local_id(0);\n\t\n\tif(thread_id<num){\n\t  // coordinate mapping of point[x] to shared mem\n\t  if(local_id == 0)\n\t   \tfor(int i=0; i<dim; i++){ \n\t   \t\tcoord_s[i] = coord_d[i*num + x];\n\t   \t}\n\t  barrier(CLK_LOCAL_MEM_FENCE);\n\t\n\t  // cost between this point and point[x]: euclidean distance multiplied by weight\n\t  float x_cost = 0.0;\n\t  for(int i=0; i<dim; i++)\n\t\t  x_cost += (coord_d[(i*num)+thread_id]-coord_s[i]) * (coord_d[(i*num)+thread_id]-coord_s[i]);\n\t  x_cost = x_cost * p[thread_id].weight;\n\t\n\t  float current_cost = p[thread_id].cost;\n\n\t  int base = thread_id*(K+1);\t \n\t  // if computed cost is less then original (it saves), mark it as to reassign\t  \n\t  if ( x_cost < current_cost ){\n\t\t  switch_membership_d[thread_id] = '1';\n\t      int addr_1 = base + K;\n\t      work_mem_d[addr_1] = x_cost - current_cost;\n\t  }\n\t  // if computed cost is larger, save the difference\n\t  else {\n\t      int assign = p[thread_id].assign;\n\t      int addr_2 = base + center_table_d[assign];\n\t      work_mem_d[addr_2] += current_cost - x_cost;\n\t  }\n\t}\n}\n\n"}, "code_dirs": {"streamcluster.cpp": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/streamcluster", "Kernels.cl": "/home/erel.kaplan/atca_proj/data/gpu-rodinia/opencl/streamcluster"}}
