{"kernel_name": "2mm", "parallel_api": "cuda", "code": {"2mm.cu": "/**\n * 2mm.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <unistd.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"2mm.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid init_array(int ni, int nj, int nk, int nl, DATA_TYPE *alpha, DATA_TYPE *beta, DATA_TYPE POLYBENCH_2D(A, NI, NK, ni, nk), \n\t\tDATA_TYPE POLYBENCH_2D(B, NK, NJ, nk, nj), DATA_TYPE POLYBENCH_2D(C, NL, NJ, nl, nj), \n\t\tDATA_TYPE POLYBENCH_2D(D, NI, NL, ni, nl))\n{\n\tint i, j;\n\n\t*alpha = 32412;\n\t*beta = 2123;\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nk; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / NI;\n\t\t}\n\t}\n\n\tfor (i = 0; i < nk; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tB[i][j] = ((DATA_TYPE) i*(j+1)) / NJ;\n\t\t}\n\t}\n\n\tfor (i = 0; i < nl; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tC[i][j] = ((DATA_TYPE) i*(j+3)) / NL;\n\t\t}\n\t}\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nl; j++)\n\t\t{\n\t\t\tD[i][j] = ((DATA_TYPE) i*(j+2)) / NK;\t\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int ni, int nl, DATA_TYPE POLYBENCH_2D(D, NI, NL, ni, nl), DATA_TYPE POLYBENCH_2D(D_outputFromGpu, NI, NL, ni, nl))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\tfor (i=0; i < ni; i++)\n\t{\n\t\tfor (j=0; j < nl; j++)\n\t\t{\n\t\t\tif (percentDiff(D[i][j], D_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void mm2_kernel1(int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *tmp, DATA_TYPE *A, DATA_TYPE *B)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < _PB_NI) && (j < _PB_NJ))\n\t{ \n\t\ttmp[i * NJ + j] = 0;\n\t\tint k;\n\t\tfor (k = 0; k < _PB_NK; k++)\n\t\t{\n\t\t\ttmp[i * NJ + j] += alpha * A[i * NK + k] * B[k * NJ + j];\n\t\t}\n\t}\n}\n\n\n__global__ void mm2_kernel2(int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *tmp, DATA_TYPE *C, DATA_TYPE *D)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < _PB_NI) && (j < _PB_NL))\n\t{ \n\t\tD[i * NL + j] *= beta;\n\t\tint k;\n\t\tfor (k = 0; k < _PB_NJ; k++)\n\t\t{\n\t\t\tD[i * NL + j] += tmp[i * NJ + k] * C[k * NL + j];\n\t\t}\n\t}\n}\n\n\nvoid mm2_cpu(int ni, int nj, int nk, int nl,\n\t\tDATA_TYPE alpha,\n\t\tDATA_TYPE beta,\n\t\tDATA_TYPE POLYBENCH_2D(tmp,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk),\n\t\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj),\n\t\tDATA_TYPE POLYBENCH_2D(C,NL,NJ,nl,nj),\n\t\tDATA_TYPE POLYBENCH_2D(D,NI,NL,ni,nl))\n{\n\tint i, j, k;\n\t\n\t/* D := alpha*A*B*C + beta*D */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NJ; j++)\n\t\t{\n\t\t\ttmp[i][j] = 0;\n\t\t\tfor (k = 0; k < _PB_NK; ++k)\n\t\t\t{\n\t\t\t\ttmp[i][j] += alpha * A[i][k] * B[k][j];\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NL; j++)\n\t\t{\n\t\t\tD[i][j] *= beta;\n\t\t\tfor (k = 0; k < _PB_NJ; ++k)\n\t\t\t{\n\t\t\t\tD[i][j] += tmp[i][k] * C[k][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nl,\n\t\t DATA_TYPE POLYBENCH_2D(D,NI,NL,ni,nl))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nl; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, D[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nvoid mm2Cuda(int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(tmp,NI,NJ,ni,nj), \n\tDATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk), DATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj), DATA_TYPE POLYBENCH_2D(C,NL,NJ,nl,nj), \n\tDATA_TYPE POLYBENCH_2D(D,NI,NL,ni,nl), DATA_TYPE POLYBENCH_2D(D_outputFromGpu,NI,NL,ni,nl))\n{\n\tDATA_TYPE *tmp_gpu;\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *B_gpu;\n\tDATA_TYPE *C_gpu;\n\tDATA_TYPE *D_gpu;\n\n\tcudaMalloc((void **)&tmp_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NI * NK);\n\tcudaMalloc((void **)&B_gpu, sizeof(DATA_TYPE) * NK * NJ);\n\tcudaMalloc((void **)&C_gpu, sizeof(DATA_TYPE) * NL * NJ);\n\tcudaMalloc((void **)&D_gpu, sizeof(DATA_TYPE) * NI * NL);\n\t\n\tcudaMemcpy(tmp_gpu, tmp, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyHostToDevice);\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NI * NK, cudaMemcpyHostToDevice);\n\tcudaMemcpy(B_gpu, B, sizeof(DATA_TYPE) * NK * NJ, cudaMemcpyHostToDevice);\n\tcudaMemcpy(C_gpu, C, sizeof(DATA_TYPE) * NL * NJ, cudaMemcpyHostToDevice);\n\tcudaMemcpy(D_gpu, D, sizeof(DATA_TYPE) * NI * NL, cudaMemcpyHostToDevice);\t\n\t\t\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid1((size_t)ceil( ((float)NJ) / ((float)block.x) ), (size_t)ceil( ((float)NI) / ((float)block.y)) );\n\tdim3 grid2((size_t)ceil( ((float)NL) / ((float)block.x) ), (size_t)ceil( ((float)NI) / ((float)block.y)) );\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tmm2_kernel1<<<grid1,block>>>(ni, nj, nk, nl, alpha, beta, tmp_gpu, A_gpu, B_gpu);\n\tcudaThreadSynchronize();\n\tmm2_kernel2<<<grid2,block>>>(ni, nj, nk, nl, alpha, beta, tmp_gpu, C_gpu, D_gpu);\n\tcudaThreadSynchronize();\n\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tcudaMemcpy(D_outputFromGpu, D_gpu, sizeof(DATA_TYPE) * NI * NL, cudaMemcpyDeviceToHost);\n\n\tcudaFree(tmp_gpu);\n\tcudaFree(A_gpu);\n\tcudaFree(B_gpu);\n\tcudaFree(C_gpu);\n\tcudaFree(D_gpu);\n}\n\n\nint main(int argc, char** argv)\n{\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\tint nk = NK;\n\tint nl = NL;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\tPOLYBENCH_2D_ARRAY_DECL(tmp,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NK,ni,nk);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,NK,NJ,nk,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(C,DATA_TYPE,NL,NJ,nl,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(D,DATA_TYPE,NI,NL,ni,nl);\n\tPOLYBENCH_2D_ARRAY_DECL(D_outputFromGpu,DATA_TYPE,NI,NL,ni,nl);\n\t\n\t/* Initialize array(s). */\n  \tinit_array(ni, nj, nk, nl, &alpha, &beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D));\n\tGPU_argv_init();\n\n\tmm2Cuda(ni, nj, nk, nl, alpha, beta, POLYBENCH_ARRAY(tmp), POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), \n\t\tPOLYBENCH_ARRAY(D), POLYBENCH_ARRAY(D_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tmm2_cpu(ni, nj, nk, nl, alpha, beta, POLYBENCH_ARRAY(tmp), POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D));\n\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ni, nl, POLYBENCH_ARRAY(D), POLYBENCH_ARRAY(D_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nl, POLYBENCH_ARRAY(D_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tPOLYBENCH_FREE_ARRAY(tmp);\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(C);\n\tPOLYBENCH_FREE_ARRAY(D);\n\tPOLYBENCH_FREE_ARRAY(D_outputFromGpu);\n\n  \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"2mm.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/2mm"}}
{"kernel_name": "2mm", "parallel_api": "ocl", "code": {"2mm.c": "/**\n * 2mm.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"2mm.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 1.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem tmp_mem_obj;\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\ncl_mem c_mem_obj;\ncl_mem dOutputFromGpu_mem_obj;\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int ni, int nl, DATA_TYPE POLYBENCH_2D(D, NI, NL, ni, nl), DATA_TYPE POLYBENCH_2D(D_outputFromGpu, NI, NL, ni, nl))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\tfor (i=0; i < ni; i++)\n\t{\n\t\tfor (j=0; j < nl; j++)\n\t\t{\n\t\t\tif (percentDiff(D[i][j], D_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"2mm.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_array(int ni, int nj, int nk, int nl, DATA_TYPE *alpha, DATA_TYPE *beta, DATA_TYPE POLYBENCH_2D(A, NI, NK, ni, nk), \n\t\tDATA_TYPE POLYBENCH_2D(B, NK, NJ, nk, nj), DATA_TYPE POLYBENCH_2D(C, NL, NJ, nl, nj), \n\t\tDATA_TYPE POLYBENCH_2D(D, NI, NL, ni, nl), DATA_TYPE POLYBENCH_2D(D_outputFromGpu, NI, NL, ni, nl))\n{\n\tint i, j;\n\n\t*alpha = 32412;\n\t*beta = 2123;\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nk; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / NI;\n\t\t}\n\t}\n\n\tfor (i = 0; i < nk; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tB[i][j] = ((DATA_TYPE) i*(j+1)) / NJ;\n\t\t}\n\t}\n\n\tfor (i = 0; i < nl; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tC[i][j] = ((DATA_TYPE) i*(j+3)) / NL;\n\t\t}\n\t}\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nl; j++)\n\t\t{\n\t\t\tD[i][j] = ((DATA_TYPE) i*(j+2)) / NK;\t\n\t\t\tD_outputFromGpu[i][j] = ((DATA_TYPE) i*(j+2)) / NK;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(tmp, NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(A, NI,NK,ni,nk), DATA_TYPE POLYBENCH_2D(B, NK,NJ,nk,nj), \n\t\tDATA_TYPE POLYBENCH_2D(C, NL,NJ,nl,nj), DATA_TYPE POLYBENCH_2D(D_outputFromGpu,NI,NL,ni,nl))\n{\n\ttmp_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_ONLY, sizeof(DATA_TYPE) * NI * NK, NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_ONLY, sizeof(DATA_TYPE) * NK * NJ, NULL, &errcode);\n\tc_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NL * NJ, NULL, &errcode);\n\tdOutputFromGpu_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NL, NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, tmp_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NJ, tmp, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NK, A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NK * NJ, B, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NL * NJ, C, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, dOutputFromGpu_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NL, D_outputFromGpu, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"mm2_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\t\n\tclKernel2 = clCreateKernel(clProgram, \"mm2_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NI) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NL) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&tmp_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(int), (void *)&ni);\n\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(int), (void *)&nj);\n\terrcode |= clSetKernelArg(clKernel1, 5, sizeof(int), (void *)&nk);\n\terrcode |= clSetKernelArg(clKernel1, 6, sizeof(int), (void *)&nl);\n\terrcode |= clSetKernelArg(clKernel1, 7, sizeof(DATA_TYPE), (void *)&alpha);\n\terrcode |= clSetKernelArg(clKernel1, 8, sizeof(DATA_TYPE), (void *)&beta);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\n\tglobalWorkSize[0] = (size_t)ceil(((float)NI) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NL) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\t\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&tmp_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&c_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(cl_mem), (void *)&dOutputFromGpu_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(int), (void *)&ni);\n\terrcode |= clSetKernelArg(clKernel2, 4, sizeof(int), (void *)&nj);\n\terrcode |= clSetKernelArg(clKernel2, 5, sizeof(int), (void *)&nk);\n\terrcode |= clSetKernelArg(clKernel2, 6, sizeof(int), (void *)&nl);\n\terrcode |= clSetKernelArg(clKernel2, 7, sizeof(DATA_TYPE), (void *)&alpha);\n\terrcode |= clSetKernelArg(clKernel2, 8, sizeof(DATA_TYPE), (void *)&beta);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(tmp_mem_obj);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseMemObject(c_mem_obj);\n\terrcode = clReleaseMemObject(dOutputFromGpu_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid mm2_cpu(int ni, int nj, int nk, int nl,\n\t\tDATA_TYPE alpha,\n\t\tDATA_TYPE beta,\n\t\tDATA_TYPE POLYBENCH_2D(tmp,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk),\n\t\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj),\n\t\tDATA_TYPE POLYBENCH_2D(C,NL,NJ,nl,nj),\n\t\tDATA_TYPE POLYBENCH_2D(D,NI,NL,ni,nl))\n{\n\tint i, j, k;\n\t\n\t/* D := alpha*A*B*C + beta*D */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NJ; j++)\n\t\t{\n\t\t\ttmp[i][j] = 0;\n\t\t\tfor (k = 0; k < _PB_NK; ++k)\n\t\t\t{\n\t\t\t\ttmp[i][j] += alpha * A[i][k] * B[k][j];\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NL; j++)\n\t\t{\n\t\t\tD[i][j] *= beta;\n\t\t\tfor (k = 0; k < _PB_NJ; ++k)\n\t\t\t{\n\t\t\t\tD[i][j] += tmp[i][k] * C[k][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nl,\n\t\t DATA_TYPE POLYBENCH_2D(D,NI,NL,ni,nl))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nl; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, D[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\tint nk = NK;\n\tint nl = NL;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\tPOLYBENCH_2D_ARRAY_DECL(tmp,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NK,ni,nk);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,NK,NJ,nk,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(C,DATA_TYPE,NL,NJ,nl,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(D,DATA_TYPE,NI,NL,ni,nl);\n\tPOLYBENCH_2D_ARRAY_DECL(D_outputFromGpu,DATA_TYPE,NI,NL,ni,nl);\n\t\n\t/* Initialize array(s). */\n  \tinit_array(ni, nj, nk, nl, &alpha, &beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D), POLYBENCH_ARRAY(D_outputFromGpu));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(tmp), POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D_outputFromGpu));\n\tcl_load_prog();\n\n\tcl_launch_kernel(ni, nj, nk, nl, alpha, beta);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, dOutputFromGpu_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NL, POLYBENCH_ARRAY(D_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tmm2_cpu(ni, nj, nk, nl, alpha, beta, POLYBENCH_ARRAY(tmp), POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ni, nl, POLYBENCH_ARRAY(D), POLYBENCH_ARRAY(D_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nl, POLYBENCH_ARRAY(D_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(tmp);\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(C);\n\tPOLYBENCH_FREE_ARRAY(D);\n\tPOLYBENCH_FREE_ARRAY(D_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>", "2mm.cl": "/**\n * 2mm.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n/* Can switch DATA_TYPE between float and double */\ntypedef float DATA_TYPE;\n\n__kernel void mm2_kernel1(__global DATA_TYPE *tmp, __global DATA_TYPE *A, __global DATA_TYPE *B, int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta) \n{    \n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < ni) && (j < nj))\n\t{ \n\t\ttmp[i * nj + j] = 0;\n\t\tint k;\n\t\tfor (k = 0; k < nk; k++)\n\t\t{\n\t\t\ttmp[i * nj + j] += alpha * A[i * nk + k] * B[k * nj + j];\n\t\t}\n\t}\n}\n\n\n__kernel void mm2_kernel2(__global DATA_TYPE *tmp, __global DATA_TYPE *C, __global DATA_TYPE *D, int ni, int nj, int nk, int nl, DATA_TYPE alpha, DATA_TYPE beta) \n{    \n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < ni) && (j < nl))\n\t{ \n\t\tD[i * nl + j] *= beta;\n\t\tint k;\n\t\tfor (k = 0; k < nj; k++)\n\t\t{\n\t\t\tD[i * nl + j] += tmp[i * nj + k] * C[k * nl + j];\n\t\t}\n\t}\n}\n"}, "code_dirs": {"2mm.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/2mm", "2mm.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/2mm"}}
{"kernel_name": "3mm", "parallel_api": "cuda", "code": {"3mm.cu": "/**\n * 3mm.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <unistd.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"3mm.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n#define GPU_DEVICE 0\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define RUN_ON_CPU\n\n\nvoid init_array(int ni, int nj, int nk, int nl, int nm, DATA_TYPE POLYBENCH_2D(A, NI, NK, ni, nk), DATA_TYPE POLYBENCH_2D(B, NK, NJ, nk, nj), \n\t\tDATA_TYPE POLYBENCH_2D(C, NJ, NM, nj, nm), DATA_TYPE POLYBENCH_2D(D, NM, NL, nm, nl))\n{\n\tint i, j;\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nk; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n  \n\tfor (i = 0; i < nk; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tB[i][j] = ((DATA_TYPE) i*(j+1)) / nj;\n\t\t}\n\t}\n  \n\tfor (i = 0; i < nj; i++)\n\t{\n\t\tfor (j = 0; j < nm; j++)\n\t\t{\n\t\t\tC[i][j] = ((DATA_TYPE) i*(j+3)) / nl;\n\t\t}\n\t}\n  \n\tfor (i = 0; i < nm; i++)\n\t{\n\t\tfor (j = 0; j < nl; j++)\n\t\t{\n\t\t\tD[i][j] = ((DATA_TYPE) i*(j+2)) / nk;\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int ni, int nl, DATA_TYPE POLYBENCH_2D(G, NI, NL, ni, nl), DATA_TYPE POLYBENCH_2D(G_outputFromGpu, NI, NL, ni, nl))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\tfor (i=0; i < ni; i++)\n\t{\n\t\tfor (j=0; j < nl; j++)\n\t\t{\n\t\t\tif (percentDiff(G[i][j], G_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\t\t\t\t\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\t\n__global__ void mm3_kernel1(int ni, int nj, int nk, int nl, int nm, DATA_TYPE *A, DATA_TYPE *B, DATA_TYPE *E)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < _PB_NI) && (j < _PB_NJ))\n\t{\n\t\tE[i * NJ + j] = 0;\n\t\tint k;\n\t\tfor(k=0; k < _PB_NK; k++)\n\t\t{\n\t\t\tE[i * NJ + j] += A[i * NK + k] * B[k * NJ + j];\n\t\t}\n\t}\n}\n\n\t\n__global__ void mm3_kernel2(int ni, int nj, int nk, int nl, int nm, DATA_TYPE *C, DATA_TYPE *D, DATA_TYPE *F)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < _PB_NJ) && (j < _PB_NL))\n\t{\n\t\tF[i * NL + j] = 0;\n\t\tint k;\n\t\tfor(k=0; k < _PB_NM; k++)\n\t\t{\n\t\t\tF[i * NL + j] += C[i * NM + k] * D[k * NL +j];\n\t\t}\n\t}\n}\n\n\t\n__global__ void mm3_kernel3(int ni, int nj, int nk, int nl, int nm, DATA_TYPE *E, DATA_TYPE *F, DATA_TYPE *G)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < _PB_NI) && (j < _PB_NL))\n\t{\n\t\tG[i * NL + j] = 0;\n\t\tint k;\n\t\tfor(k=0; k < _PB_NJ; k++)\n\t\t{\n\t\t\tG[i * NL + j] += E[i * NJ + k] * F[k * NL + j];\n\t\t}\n\t}\n}\n\n\n/* Main computational kernel on CPU */\nvoid mm3_cpu(int ni, int nj, int nk, int nl, int nm,\n\t\tDATA_TYPE POLYBENCH_2D(E,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk),\n\t\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj),\n\t\tDATA_TYPE POLYBENCH_2D(F,NJ,NL,nj,nl),\n\t\tDATA_TYPE POLYBENCH_2D(C,NJ,NM,nj,nm),\n\t\tDATA_TYPE POLYBENCH_2D(D,NM,NL,nm,nl),\n\t\tDATA_TYPE POLYBENCH_2D(G,NI,NL,ni,nl))\n{\n\tint i, j, k;\n\n\t/* E := A*B */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NJ; j++)\n\t\t{\n\t\t\tE[i][j] = 0;\n\t\t\tfor (k = 0; k < _PB_NK; ++k)\n\t\t\t{\n\t\t\t\tE[i][j] += A[i][k] * B[k][j];\n\t\t\t}\n\t\t}\n\t}\n\n\t/* F := C*D */\n\tfor (i = 0; i < _PB_NJ; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NL; j++)\n\t\t{\n\t\t\tF[i][j] = 0;\n\t\t\tfor (k = 0; k < _PB_NM; ++k)\n\t\t\t{\n\t\t\t\tF[i][j] += C[i][k] * D[k][j];\n\t\t\t}\n\t\t}\n\t}\n\n\t/* G := E*F */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NL; j++)\n\t\t{\n\t\t\tG[i][j] = 0;\n\t\t\tfor (k = 0; k < _PB_NJ; ++k)\n\t\t\t{\n\t\t\t\tG[i][j] += E[i][k] * F[k][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\nvoid mm3Cuda(int ni, int nj, int nk, int nl, int nm,\n\t\tDATA_TYPE POLYBENCH_2D(E,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk),\n\t\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj),\n\t\tDATA_TYPE POLYBENCH_2D(F,NJ,NL,nj,nl),\n\t\tDATA_TYPE POLYBENCH_2D(C,NJ,NM,nj,nm),\n\t\tDATA_TYPE POLYBENCH_2D(D,NM,NL,nm,nl),\n\t\tDATA_TYPE POLYBENCH_2D(G,NI,NL,ni,nl),\n\t\tDATA_TYPE POLYBENCH_2D(G_outputFromGpu,NI,NL,ni,nl))\n{\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *B_gpu;\n\tDATA_TYPE *C_gpu;\n\tDATA_TYPE *D_gpu;\n\tDATA_TYPE *E_gpu;\n\tDATA_TYPE *F_gpu;\n\tDATA_TYPE *G_gpu;\n\t\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NI * NK);\n\tcudaMalloc((void **)&B_gpu, sizeof(DATA_TYPE) * NK * NJ);\n\tcudaMalloc((void **)&C_gpu, sizeof(DATA_TYPE) * NJ * NM);\n\tcudaMalloc((void **)&D_gpu, sizeof(DATA_TYPE) * NM * NL);\n\tcudaMalloc((void **)&E_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\tcudaMalloc((void **)&F_gpu, sizeof(DATA_TYPE) * NJ * NL);\n\tcudaMalloc((void **)&G_gpu, sizeof(DATA_TYPE) * NI * NL);\n\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NI * NK, cudaMemcpyHostToDevice);\n\tcudaMemcpy(B_gpu, B, sizeof(DATA_TYPE) * NK * NJ, cudaMemcpyHostToDevice);\n\tcudaMemcpy(C_gpu, C, sizeof(DATA_TYPE) * NJ * NM, cudaMemcpyHostToDevice);\n\tcudaMemcpy(D_gpu, D, sizeof(DATA_TYPE) * NM * NL, cudaMemcpyHostToDevice);\n\tcudaMemcpy(E_gpu, E, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyHostToDevice);\n\tcudaMemcpy(F_gpu, F, sizeof(DATA_TYPE) * NJ * NL, cudaMemcpyHostToDevice);\n\tcudaMemcpy(G_gpu, G, sizeof(DATA_TYPE) * NI * NL, cudaMemcpyHostToDevice);\t\n\t\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid1((size_t)(ceil( ((float)NJ) / ((float)DIM_THREAD_BLOCK_X) )),(size_t)(ceil((float)NI/ ((float)DIM_THREAD_BLOCK_Y) )));\n\tdim3 grid2((size_t)(ceil( ((float)NL) / ((float)DIM_THREAD_BLOCK_X) )),(size_t)(ceil((float)NJ/ ((float)DIM_THREAD_BLOCK_Y) )));\n\tdim3 grid3((size_t)(ceil( ((float)NL) / ((float)DIM_THREAD_BLOCK_X) )),(size_t)(ceil((float)NI/ ((float)DIM_THREAD_BLOCK_Y) )));\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tmm3_kernel1<<<grid1,block>>>(ni, nj, nk, nl, nm, A_gpu, B_gpu, E_gpu);\n\tcudaThreadSynchronize();\n\tmm3_kernel2<<<grid2,block>>>(ni, nj, nk, nl, nm, C_gpu, D_gpu, F_gpu);\n\tcudaThreadSynchronize();\n\tmm3_kernel3<<<grid3,block>>>(ni, nj, nk, nl, nm, E_gpu, F_gpu, G_gpu);\n\tcudaThreadSynchronize();\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\tcudaMemcpy(G_outputFromGpu, G_gpu, sizeof(DATA_TYPE) * NI * NL, cudaMemcpyDeviceToHost);\n\t\n\tcudaFree(A_gpu);\n\tcudaFree(B_gpu);\n\tcudaFree(C_gpu);\n\tcudaFree(D_gpu);\n\tcudaFree(E_gpu);\n\tcudaFree(F_gpu);\n\tcudaFree(G_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nl,\n\t\t DATA_TYPE POLYBENCH_2D(G,NI,NL,ni,nl))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nl; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, G[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char** argv)\n{\n\tint ni = NI;\n\tint nj = NJ;\n\tint nk = NK;\n\tint nl = NL;\n\tint nm = NM;\n\n\t/* Variable declaration/allocation. */\n\tPOLYBENCH_2D_ARRAY_DECL(E, DATA_TYPE, NI, NJ, ni, nj);\n\tPOLYBENCH_2D_ARRAY_DECL(A, DATA_TYPE, NI, NK, ni, nk);\n\tPOLYBENCH_2D_ARRAY_DECL(B, DATA_TYPE, NK, NJ, nk, nj);\n\tPOLYBENCH_2D_ARRAY_DECL(F, DATA_TYPE, NJ, NL, nj, nl);\n\tPOLYBENCH_2D_ARRAY_DECL(C, DATA_TYPE, NJ, NM, nj, nm);\n\tPOLYBENCH_2D_ARRAY_DECL(D, DATA_TYPE, NM, NL, nm, nl);\n\tPOLYBENCH_2D_ARRAY_DECL(G, DATA_TYPE, NI, NL, ni, nl);\n\tPOLYBENCH_2D_ARRAY_DECL(G_outputFromGpu, DATA_TYPE, NI, NL, ni, nl);\n\n\tinit_array(ni, nj, nk, nl, nm, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D));\n\n\tGPU_argv_init();\n\n\tmm3Cuda(ni, nj, nk, nl, nm, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D), POLYBENCH_ARRAY(E), \n\t\tPOLYBENCH_ARRAY(F), POLYBENCH_ARRAY(G), POLYBENCH_ARRAY(G_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tmm3_cpu(ni, nj, nk, nl, nm, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D), POLYBENCH_ARRAY(E), \n\t\t\tPOLYBENCH_ARRAY(F), POLYBENCH_ARRAY(G));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ni, nl, POLYBENCH_ARRAY(G), POLYBENCH_ARRAY(G_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nl, POLYBENCH_ARRAY(G_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(C);\n\tPOLYBENCH_FREE_ARRAY(D);\n\tPOLYBENCH_FREE_ARRAY(E);\n\tPOLYBENCH_FREE_ARRAY(F);\n\tPOLYBENCH_FREE_ARRAY(G);\n\tPOLYBENCH_FREE_ARRAY(G_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"3mm.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/3mm"}}
{"kernel_name": "3mm", "parallel_api": "ocl", "code": {"3mm.c": "/**\n * 3mm.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"3mm.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 10.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_kernel clKernel3;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\ncl_mem c_mem_obj;\ncl_mem d_mem_obj;\ncl_mem e_mem_obj;\ncl_mem f_mem_obj;\ncl_mem g_mem_obj;\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int ni, int nl, DATA_TYPE POLYBENCH_2D(G, NI, NL, ni, nl), DATA_TYPE POLYBENCH_2D(G_outputFromGpu, NI, NL, ni, nl))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\tfor (i=0; i < ni; i++)\n\t{\n\t\tfor (j=0; j < nl; j++)\n\t\t{\n\t\t\tif (percentDiff(G[i][j], G_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\t\t\t\t\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"3mm.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\nvoid init_array(int ni, int nj, int nk, int nl, int nm, DATA_TYPE POLYBENCH_2D(A, NI, NK, ni, nk), DATA_TYPE POLYBENCH_2D(B, NK, NJ, nk, nj), \n\t\tDATA_TYPE POLYBENCH_2D(C, NJ, NM, nj, nm), DATA_TYPE POLYBENCH_2D(D, NM, NL, nm, nl))\n{\n\tint i, j;\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nk; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n  \n\tfor (i = 0; i < nk; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tB[i][j] = ((DATA_TYPE) i*(j+1)) / nj;\n\t\t}\n\t}\n  \n\tfor (i = 0; i < nj; i++)\n\t{\n\t\tfor (j = 0; j < nm; j++)\n\t\t{\n\t\t\tC[i][j] = ((DATA_TYPE) i*(j+3)) / nl;\n\t\t}\n\t}\n  \n\tfor (i = 0; i < nm; i++)\n\t{\n\t\tfor (j = 0; j < nl; j++)\n\t\t{\n\t\t\tD[i][j] = ((DATA_TYPE) i*(j+2)) / nk;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(B, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(C, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(D, NI, NJ, ni, nj),\n\t\tDATA_TYPE POLYBENCH_2D(E, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(F, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(G, NI, NJ, ni, nj))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_ONLY, sizeof(DATA_TYPE) * NI * NK, NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_ONLY, sizeof(DATA_TYPE) * NK * NJ, NULL, &errcode);\n\tc_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NJ * NM, NULL, &errcode);\n\td_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NM * NL, NULL, &errcode);\n\te_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\tf_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NJ * NL, NULL, &errcode);\n\tg_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NL, NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NK, A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NK * NJ, B, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NJ * NM, C, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, d_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NM * NL, D, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, e_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NJ, E, 0, NULL, NULL);\t\n\terrcode = clEnqueueWriteBuffer(clCommandQue, f_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NJ * NL, F, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, g_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NL, G, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n }\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernels\n\tclKernel1 = clCreateKernel(clProgram, \"mm3_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclKernel2 = clCreateKernel(clProgram, \"mm3_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclKernel3 = clCreateKernel(clProgram, \"mm3_kernel3\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel(int ni, int nj, int nk, int nl, int nm)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NJ) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NI) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&e_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(int), (void *)&ni);\n\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(int), (void *)&nj);\n\terrcode |= clSetKernelArg(clKernel1, 5, sizeof(int), (void *)&nk);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\t// Execute the OpenCL kernel\n\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\n\tglobalWorkSize[0] = (size_t)ceil(((float)NL) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NJ) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&c_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&d_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(cl_mem), (void *)&f_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(int), (void *)&nj);\n\terrcode |= clSetKernelArg(clKernel2, 4, sizeof(int), (void *)&nl);\n\terrcode |= clSetKernelArg(clKernel2, 5, sizeof(int), (void *)&nm);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\n\tglobalWorkSize[0] = (size_t)ceil(((float)NL) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NI) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\terrcode =  clSetKernelArg(clKernel3, 0, sizeof(cl_mem), (void *)&e_mem_obj);\n\terrcode |= clSetKernelArg(clKernel3, 1, sizeof(cl_mem), (void *)&f_mem_obj);\n\terrcode |= clSetKernelArg(clKernel3, 2, sizeof(cl_mem), (void *)&g_mem_obj);\n\terrcode |= clSetKernelArg(clKernel3, 3, sizeof(int), (void *)&ni);\n\terrcode |= clSetKernelArg(clKernel3, 4, sizeof(int), (void *)&nl);\n\terrcode |= clSetKernelArg(clKernel3, 5, sizeof(int), (void *)&nj);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel3, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseKernel(clKernel3);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseMemObject(c_mem_obj);\n\terrcode = clReleaseMemObject(d_mem_obj);\n\terrcode = clReleaseMemObject(e_mem_obj);\n\terrcode = clReleaseMemObject(f_mem_obj);\n\terrcode = clReleaseMemObject(g_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\n/* Main computational kernel on CPU */\nvoid mm3_cpu(int ni, int nj, int nk, int nl, int nm,\n\t\tDATA_TYPE POLYBENCH_2D(E,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk),\n\t\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj),\n\t\tDATA_TYPE POLYBENCH_2D(F,NJ,NL,nj,nl),\n\t\tDATA_TYPE POLYBENCH_2D(C,NJ,NM,nj,nm),\n\t\tDATA_TYPE POLYBENCH_2D(D,NM,NL,nm,nl),\n\t\tDATA_TYPE POLYBENCH_2D(G,NI,NL,ni,nl))\n{\n\tint i, j, k;\n\n\t/* E := A*B */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NJ; j++)\n\t\t{\n\t\t\tE[i][j] = 0;\n\t\t\tfor (k = 0; k < _PB_NK; ++k)\n\t\t\t{\n\t\t\t\tE[i][j] += A[i][k] * B[k][j];\n\t\t\t}\n\t\t}\n\t}\n\n\t/* F := C*D */\n\tfor (i = 0; i < _PB_NJ; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NL; j++)\n\t\t{\n\t\t\tF[i][j] = 0;\n\t\t\tfor (k = 0; k < _PB_NM; ++k)\n\t\t\t{\n\t\t\t\tF[i][j] += C[i][k] * D[k][j];\n\t\t\t}\n\t\t}\n\t}\n\n\t/* G := E*F */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NL; j++)\n\t\t{\n\t\t\tG[i][j] = 0;\n\t\t\tfor (k = 0; k < _PB_NJ; ++k)\n\t\t\t{\n\t\t\t\tG[i][j] += E[i][k] * F[k][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nl,\n\t\t DATA_TYPE POLYBENCH_2D(G,NI,NL,ni,nl))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nl; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, G[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint ni = NI;\n\tint nj = NJ;\n\tint nk = NK;\n\tint nl = NL;\n\tint nm = NM;\n\n\t/* Variable declaration/allocation. */\n\tPOLYBENCH_2D_ARRAY_DECL(E, DATA_TYPE, NI, NJ, ni, nj);\n\tPOLYBENCH_2D_ARRAY_DECL(A, DATA_TYPE, NI, NK, ni, nk);\n\tPOLYBENCH_2D_ARRAY_DECL(B, DATA_TYPE, NK, NJ, nk, nj);\n\tPOLYBENCH_2D_ARRAY_DECL(F, DATA_TYPE, NJ, NL, nj, nl);\n\tPOLYBENCH_2D_ARRAY_DECL(C, DATA_TYPE, NJ, NM, nj, nm);\n\tPOLYBENCH_2D_ARRAY_DECL(D, DATA_TYPE, NM, NL, nm, nl);\n\tPOLYBENCH_2D_ARRAY_DECL(G, DATA_TYPE, NI, NL, ni, nl);\n\tPOLYBENCH_2D_ARRAY_DECL(G_outputFromGpu, DATA_TYPE, NI, NL, ni, nl);\n\n\tinit_array(ni, nj, nk, nl, nm, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(D), POLYBENCH_ARRAY(E), POLYBENCH_ARRAY(F), POLYBENCH_ARRAY(G));\n\tcl_load_prog();\n\n\tcl_launch_kernel(ni, nj, nk, nl, nm);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, g_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NL, POLYBENCH_ARRAY(G_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tmm3_cpu(ni, nj, nk, nl, nm, POLYBENCH_ARRAY(E), POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(F), POLYBENCH_ARRAY(C), \n\t\t\tPOLYBENCH_ARRAY(D), POLYBENCH_ARRAY(G));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ni, nl, POLYBENCH_ARRAY(G), POLYBENCH_ARRAY(G_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nl, POLYBENCH_ARRAY(G_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(C);\n\tPOLYBENCH_FREE_ARRAY(D);\n\tPOLYBENCH_FREE_ARRAY(E);\n\tPOLYBENCH_FREE_ARRAY(F);\n\tPOLYBENCH_FREE_ARRAY(G);\n\tPOLYBENCH_FREE_ARRAY(G_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>", "3mm.cl": "/**\n * 3mm.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n__kernel void mm3_kernel1(__global DATA_TYPE *A, __global DATA_TYPE *B, __global DATA_TYPE *E, int ni, int nj, int nk) \n{    \n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < ni) && (j < nj))\n\t{\n\t\tint k;\n\t\tE[i*nj + j] = 0;\n\t\tfor(k=0; k < nk; k++)\n\t\t{\n\t\t\tE[i * nj + j] += A[i * nk + k] * B[k * nj + j];\n\t\t}\n\t}\n}\n\n__kernel void mm3_kernel2(__global DATA_TYPE *C, __global DATA_TYPE *D, __global DATA_TYPE *F, int nj, int nl, int nm) \n{\n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < nj) && (j < nl))\n\t{\n\t\tint k;\n\t\tF[i*nl + j] = 0;\n\t\tfor(k=0; k < nm; k++)\n\t\t{\n\t\t\tF[i * nl + j] += C[i * nm + k] * D[k * nl +j];\n\t\t}\n\t}\n\n}\n\n__kernel void mm3_kernel3(__global DATA_TYPE *E, __global DATA_TYPE *F, __global DATA_TYPE *G, int ni, int nl, int nj) \n{    \n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < ni) && (j < nl))\n\t{\n\t\tint k;\n\t\tG[i*nl + j] = 0;\n\t\tfor(k=0; k < nj; k++)\n\t\t{\n\t\t\tG[i * nl + j] += E[i * nj + k] * F[k * nl + j];\n\t\t}\n\t}\n}\n"}, "code_dirs": {"3mm.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/3mm", "3mm.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/3mm"}}
{"kernel_name": "atax", "parallel_api": "cuda", "code": {"atax.cu": "/**\n * atax.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <unistd.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"atax.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.5\n\n#define GPU_DEVICE 0\n\n\n#ifndef M_PI\n#define M_PI 3.14159\n#endif\n\n#define RUN_ON_CPU\n\n\nvoid init_array(int nx, int ny, DATA_TYPE POLYBENCH_1D(x,NX,nx), DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny))\n{\n\tint i, j;\n\n\tfor (i = 0; i < nx; i++)\n\t{\n\t\tx[i] = i * M_PI;\n\t\tfor (j = 0; j < ny; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / NX;\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int ny, DATA_TYPE POLYBENCH_1D(z,NY,ny), DATA_TYPE POLYBENCH_1D(z_outputFromGpu,NY,ny))\n{\n\tint i, fail;\n\tfail = 0;\n\n\tfor (i=0; i<ny; i++)\n\t{\n\t\tif (percentDiff(z[i], z_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\t\t\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void atax_kernel1(int nx, int ny, DATA_TYPE *A, DATA_TYPE *x, DATA_TYPE *tmp)\n{\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i < _PB_NX)\n\t{\n\t\ttmp[i] = 0;\n\t\tint j;\n\t\tfor(j=0; j < _PB_NY; j++)\n\t\t{\n\t\t\ttmp[i] += A[i*NY+j] * x[j];\n\t\t}\n\t}\n}\n\n__global__ void atax_kernel2(int nx, int ny, DATA_TYPE *A, DATA_TYPE *y, DATA_TYPE *tmp)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif (j < _PB_NY)\n\t{\n\t\ty[j] = 0;\n\t\tint i;\n\t\tfor(i=0; i < _PB_NX; i++)\n\t\t{\n\t\t\ty[j] += A[i*NY+j] * tmp[i];\n\t\t}\n\t}\n}\n\n\nvoid atax_cpu(int nx, int ny, DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny), DATA_TYPE POLYBENCH_1D(x,NY,ny), DATA_TYPE POLYBENCH_1D(y,NY,ny), \n\t\tDATA_TYPE POLYBENCH_1D(tmp,NX,nx))\n{\n\tint i,j;\n\t\n\tfor (i= 0; i < _PB_NY; i++)\n\t{\n    \t\ty[i] = 0;\n\t}\n  \n\tfor (i = 0; i < _PB_NX; i++)\n \t{\n      \t\ttmp[i] = 0;\n\n      \t\tfor (j = 0; j < _PB_NY; j++)\n\t\t{\n\t\t\ttmp[i] = tmp[i] + A[i][j] * x[j];\n\t\t}\n\t\t\n      \t\tfor (j = 0; j < _PB_NY; j++)\n\t\t{\n\t\t\ty[j] = y[j] + A[i][j] * tmp[i];\n\t\t}\n    }\n}\n\n\nvoid ataxGpu(int nx, int ny, DATA_TYPE POLYBENCH_2D(A, NX, NY,nx,ny), DATA_TYPE POLYBENCH_1D(x,NX,nx), DATA_TYPE POLYBENCH_1D(y,NY,ny), \n\t\tDATA_TYPE POLYBENCH_1D(tmp,NX,nx), DATA_TYPE POLYBENCH_1D(y_outputFromGpu,NY,ny))\n{\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *x_gpu;\n\tDATA_TYPE *y_gpu;\n\tDATA_TYPE *tmp_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NX * NY);\n\tcudaMalloc((void **)&x_gpu, sizeof(DATA_TYPE) * NY);\n\tcudaMalloc((void **)&y_gpu, sizeof(DATA_TYPE) * NY);\n\tcudaMalloc((void **)&tmp_gpu, sizeof(DATA_TYPE) * NX);\n\t\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NX * NY, cudaMemcpyHostToDevice);\n\tcudaMemcpy(x_gpu, x, sizeof(DATA_TYPE) * NY, cudaMemcpyHostToDevice);\n\tcudaMemcpy(y_gpu, y, sizeof(DATA_TYPE) * NY, cudaMemcpyHostToDevice);\n\tcudaMemcpy(tmp_gpu, tmp, sizeof(DATA_TYPE) * NX, cudaMemcpyHostToDevice);\n\t\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid1((size_t)(ceil( ((float)NX) / ((float)block.x) )), 1);\n\tdim3 grid2((size_t)(ceil( ((float)NY) / ((float)block.x) )), 1);\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tatax_kernel1<<< grid1, block >>>(nx, ny, A_gpu,x_gpu,tmp_gpu);\n\tcudaThreadSynchronize();\n\tatax_kernel2<<< grid2, block >>>(nx, ny, A_gpu,y_gpu,tmp_gpu);\n\tcudaThreadSynchronize();\n\t\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\t\n\tcudaMemcpy(y_outputFromGpu, y_gpu, sizeof(DATA_TYPE) * NX, cudaMemcpyDeviceToHost);\n\n\tcudaFree(A_gpu);\n\tcudaFree(x_gpu);\n\tcudaFree(y_gpu);\n\tcudaFree(tmp_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int nx, DATA_TYPE POLYBENCH_1D(y,NX,nx))\n{\n  int i;\n\n  for (i = 0; i < nx; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, y[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char** argv)\n{\n\tint nx = NX;\n\tint ny = NY;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(x,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(y,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(y_outputFromGpu,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(tmp,DATA_TYPE,NX,nx);\n\n\tinit_array(nx, ny, POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(A));\n\n\tGPU_argv_init();\n\tataxGpu(nx, ny, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(tmp), \n\t\tPOLYBENCH_ARRAY(y_outputFromGpu));\n\t\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tatax_cpu(nx, ny, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(tmp));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ny, POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(y_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ny, POLYBENCH_ARRAY(y_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(x);\n\tPOLYBENCH_FREE_ARRAY(y);\n\tPOLYBENCH_FREE_ARRAY(y_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(tmp);\n\n  \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"atax.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/atax"}}
{"kernel_name": "atax", "parallel_api": "ocl", "code": {"atax.c": "/**\n * atax.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"atax.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#ifndef M_PI\n#define M_PI 3.14159\n#endif\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n\nchar str_temp[1024];\n\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\ncl_mem x_mem_obj;\ncl_mem y_mem_obj;\ncl_mem tmp_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int ny, DATA_TYPE POLYBENCH_1D(z,NY,ny), DATA_TYPE POLYBENCH_1D(z_outputFromGpu,NY,ny))\n{\n\tint i, fail;\n\tfail = 0;\n\n\tfor (i=0; i<ny; i++)\n\t{\n\t\tif (percentDiff(z[i], z_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\t\t\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"atax.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_array(int nx, int ny, DATA_TYPE POLYBENCH_1D(x,NX,nx), DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny))\n{\n\tint i, j;\n\n\tfor (i = 0; i < nx; i++)\n\t{\n\t\tx[i] = i * M_PI;\n\t\tfor (j = 0; j < ny; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / NX;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny), DATA_TYPE POLYBENCH_1D(x,NY,ny), DATA_TYPE POLYBENCH_1D(y,NY,ny), DATA_TYPE POLYBENCH_1D(tmp,NX,nx))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX * NY, NULL, &errcode);\n\tx_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NY, NULL, &errcode);\n\ty_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NY, NULL, &errcode);\n\ttmp_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX, NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\t\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX * NY, A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, x_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NY, x, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, y_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NY, y, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, tmp_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX, tmp, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the 1st OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"atax_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\n\t// Create the 2nd OpenCL kernel\n\tclKernel2 = clCreateKernel(clProgram, \"atax_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int nx, int ny)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NX) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&tmp_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(int), (void *)&nx);\n\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(int), (void *)&ny);\n\tif(errcode != CL_SUCCESS) printf(\"Error in setting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\t\n\tglobalWorkSize[0] = (size_t)ceil(((float)NY) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&y_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(cl_mem), (void *)&tmp_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(int), (void *)&nx);\n\terrcode |= clSetKernelArg(clKernel2, 4, sizeof(int), (void *)&ny);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(x_mem_obj);\n\terrcode = clReleaseMemObject(y_mem_obj);\n\terrcode = clReleaseMemObject(tmp_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid atax_cpu(int nx, int ny, DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny), DATA_TYPE POLYBENCH_1D(x,NY,ny), DATA_TYPE POLYBENCH_1D(y,NY,ny), \n\t\tDATA_TYPE POLYBENCH_1D(tmp,NX,nx))\n{\n\tint i,j;\n\t\n\tfor (i= 0; i < _PB_NY; i++)\n\t{\n    \t\ty[i] = 0;\n\t}\n  \n\tfor (i = 0; i < _PB_NX; i++)\n \t{\n      \t\ttmp[i] = 0;\n\n      \t\tfor (j = 0; j < _PB_NY; j++)\n\t\t{\n\t\t\ttmp[i] = tmp[i] + A[i][j] * x[j];\n\t\t}\n\t\t\n      \t\tfor (j = 0; j < _PB_NY; j++)\n\t\t{\n\t\t\ty[j] = y[j] + A[i][j] * tmp[i];\n\t\t}\n    }\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int nx, DATA_TYPE POLYBENCH_1D(y,NX,nx))\n{\n  int i;\n\n  for (i = 0; i < nx; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, y[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint nx = NX;\n\tint ny = NY;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(x,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(y,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(y_outputFromGpu,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(tmp,DATA_TYPE,NX,nx);\n\n\tinit_array(nx, ny, POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(A));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(tmp));\n\tcl_load_prog();\n\n\tcl_launch_kernel(nx, ny);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, y_mem_obj, CL_TRUE, 0, NY*sizeof(DATA_TYPE), POLYBENCH_ARRAY(y_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tatax_cpu(nx, ny, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(tmp));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ny, POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(y_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ny, POLYBENCH_ARRAY(y_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tcl_clean_up();\n\t\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(x);\n\tPOLYBENCH_FREE_ARRAY(y);\n\tPOLYBENCH_FREE_ARRAY(y_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(tmp);\n\t\n\treturn 0;\n}\n\n#include <polybench.c>", "atax.cl": "/**\n * atax.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n__kernel void atax_kernel1(__global DATA_TYPE *A, __global DATA_TYPE *x, __global DATA_TYPE *tmp, int nx, int ny) {\n    \n\tint i = get_global_id(0);\n\n\tif (i < nx)\n\t{\n\t\tint j;\n\t\tfor(j=0; j < ny; j++)\n\t\t{\n\t\t\ttmp[i] += A[i * ny + j] * x[j];\n\t\t}\n\t}\n}\n\n__kernel void atax_kernel2(__global DATA_TYPE *A, __global DATA_TYPE *y, __global DATA_TYPE *tmp, int nx, int ny) {\n    \n\tint j = get_global_id(0);\n\n\tif (j < ny)\n\t{\n\t\tint i;\n\t\tfor(i=0; i < nx; i++)\n\t\t{\n\t\t\ty[j] += A[i * ny + j] * tmp[i];\n\t\t}\n\t}\n}\n\n"}, "code_dirs": {"atax.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/atax", "atax.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/atax"}}
{"kernel_name": "bicg", "parallel_api": "cuda", "code": {"bicg.cu": "/**\n * bicg.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"bicg.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//Error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.5\n\n#define GPU_DEVICE 0\n\n#ifndef M_PI\n#define M_PI 3.14159\n#endif\n\n#define RUN_ON_CPU\n\n\nvoid init_array(int nx, int ny, DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny), DATA_TYPE POLYBENCH_1D(p,NY,ny), DATA_TYPE POLYBENCH_1D(r,NX,nx))\n{\n\tint i, j;\n\t\n\tfor (i = 0; i < ny; i++)\n\t{\n    \t\tp[i] = i * M_PI;\n\t}\n\n\tfor (i = 0; i < nx; i++)\n\t{\n    \t\tr[i] = i * M_PI;\n\n    \t\tfor (j = 0; j < ny; j++)\n\t\t{\n      \t\t\tA[i][j] = ((DATA_TYPE) i*j) / NX;\n\t\t}\n \t}\n}\n\n\nvoid compareResults(int nx, int ny, DATA_TYPE POLYBENCH_1D(s,NY,ny), DATA_TYPE POLYBENCH_1D(s_outputFromGpu,NY,ny), \n\t\tDATA_TYPE POLYBENCH_1D(q,NX,nx), DATA_TYPE POLYBENCH_1D(q_outputFromGpu,NX,nx))\n{\n\tint i,fail;\n\tfail = 0;\n\n\t// Compare s with s_cuda\n\tfor (i=0; i<nx; i++)\n\t{\n\t\tif (percentDiff(q[i], q_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\n\tfor (i=0; i<ny; i++)\n\t{\n\t\tif (percentDiff(s[i], s_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\t\t\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n//Distributed (split) from initial loop and permuted into reverse order to allow parallelism...\n__global__ void bicg_kernel1(int nx, int ny, DATA_TYPE *A, DATA_TYPE *r, DATA_TYPE *s)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif (j < _PB_NY)\n\t{\n\t\ts[j] = 0.0f;\n\n\t\tint i;\n\t\tfor(i = 0; i < _PB_NX; i++)\n\t\t{\n\t\t\ts[j] += r[i] * A[i * NY + j];\n\t\t}\n\t}\t\n}\n\n\n//Distributed (split) from initial loop to allow parallelism\n__global__ void bicg_kernel2(int nx, int ny, DATA_TYPE *A, DATA_TYPE *p, DATA_TYPE *q)\n{\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif (i < _PB_NX)\n\t{\n\t\tq[i] = 0.0f;\n\n\t\tint j;\n\t\tfor(j=0; j < _PB_NY; j++)\n\t\t{\n\t\t\tq[i] += A[i * NY + j] * p[j];\n\t\t}\n\t}\n}\n\n\nvoid bicg_cpu(int nx, int ny, DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny), DATA_TYPE POLYBENCH_1D(r,NX,nx), DATA_TYPE POLYBENCH_1D(s,NY,ny), \n\t\tDATA_TYPE POLYBENCH_1D(p,NY,ny), DATA_TYPE POLYBENCH_1D(q,NX,nx))\n{\n\tint i,j;\n\t\n  \tfor (i = 0; i < _PB_NY; i++)\n\t{\n\t\ts[i] = 0.0;\n\t}\n\n\tfor (i = 0; i < _PB_NX; i++)\n\t{\n\t\tq[i] = 0.0;\n\t\tfor (j = 0; j < _PB_NY; j++)\n\t  \t{\n\t    \t\ts[j] = s[j] + r[i] * A[i][j];\n\t    \t\tq[i] = q[i] + A[i][j] * p[j];\n\t  \t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int nx, int ny,\n\t\t DATA_TYPE POLYBENCH_1D(s,NY,ny),\n\t\t DATA_TYPE POLYBENCH_1D(q,NX,nx))\n\n{\n  int i;\n\n  for (i = 0; i < ny; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, s[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n  for (i = 0; i < nx; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, q[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n  fprintf (stderr, \"\\n\");\n}\n\n\nvoid bicgCuda(int nx, int ny, DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny), DATA_TYPE POLYBENCH_1D(r,NX,nx), DATA_TYPE POLYBENCH_1D(s,NY,ny), \n\tDATA_TYPE POLYBENCH_1D(p,NY,ny), DATA_TYPE POLYBENCH_1D(q,NX,nx), DATA_TYPE POLYBENCH_1D(s_outputFromGpu,NY,ny), \n\tDATA_TYPE POLYBENCH_1D(q_outputFromGpu,NX,nx))\n{\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *q_gpu;\n\tDATA_TYPE *p_gpu;\n\tDATA_TYPE *r_gpu;\n\tDATA_TYPE *s_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NX * NY);\n\tcudaMalloc((void **)&r_gpu, sizeof(DATA_TYPE) * NX);\n\tcudaMalloc((void **)&s_gpu, sizeof(DATA_TYPE) * NY);\n\tcudaMalloc((void **)&p_gpu, sizeof(DATA_TYPE) * NY);\n\tcudaMalloc((void **)&q_gpu, sizeof(DATA_TYPE) * NX);\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NX * NY, cudaMemcpyHostToDevice);\n\tcudaMemcpy(r_gpu, r, sizeof(DATA_TYPE) * NX, cudaMemcpyHostToDevice);\n\tcudaMemcpy(s_gpu, s, sizeof(DATA_TYPE) * NY, cudaMemcpyHostToDevice);\n\tcudaMemcpy(p_gpu, p, sizeof(DATA_TYPE) * NY, cudaMemcpyHostToDevice);\n\tcudaMemcpy(q_gpu, q, sizeof(DATA_TYPE) * NX, cudaMemcpyHostToDevice);\n\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid1((size_t)(ceil( ((float)NY) / ((float)block.x) )), 1);\n\tdim3 grid2((size_t)(ceil( ((float)NX) / ((float)block.x) )), 1);\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tbicg_kernel1<<< grid1, block >>>(nx, ny, A_gpu, r_gpu, s_gpu);\n\tcudaThreadSynchronize();\n\tbicg_kernel2<<< grid2, block >>>(nx, ny, A_gpu, p_gpu, q_gpu);\n\tcudaThreadSynchronize();\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\t\n\tcudaMemcpy(s_outputFromGpu, s_gpu, sizeof(DATA_TYPE) * NY, cudaMemcpyDeviceToHost);\n\tcudaMemcpy(q_outputFromGpu, q_gpu, sizeof(DATA_TYPE) * NX, cudaMemcpyDeviceToHost);\n\n\tcudaFree(A_gpu);\n\tcudaFree(r_gpu);\n\tcudaFree(s_gpu);\n\tcudaFree(p_gpu);\n\tcudaFree(q_gpu);\n}\n\n\nint main(int argc, char** argv)\n{\n\tint nx = NX;\n\tint ny = NY;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(s,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(q,DATA_TYPE,NX,nx);\n\tPOLYBENCH_1D_ARRAY_DECL(p,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(r,DATA_TYPE,NX,nx);\n\tPOLYBENCH_1D_ARRAY_DECL(s_outputFromGpu,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(q_outputFromGpu,DATA_TYPE,NX,nx);\n\n\tinit_array(nx, ny, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(p), POLYBENCH_ARRAY(r));\n\n\tGPU_argv_init();\n\n\tbicgCuda(nx, ny, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(r), POLYBENCH_ARRAY(s), POLYBENCH_ARRAY(p), POLYBENCH_ARRAY(q), \n\t\tPOLYBENCH_ARRAY(s_outputFromGpu), POLYBENCH_ARRAY(q_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tbicg_cpu(nx, ny, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(r), POLYBENCH_ARRAY(s), POLYBENCH_ARRAY(p), POLYBENCH_ARRAY(q));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(nx, ny, POLYBENCH_ARRAY(s), POLYBENCH_ARRAY(s_outputFromGpu), POLYBENCH_ARRAY(q), \n\t\t\tPOLYBENCH_ARRAY(q_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(nx, ny, POLYBENCH_ARRAY(s_outputFromGpu), POLYBENCH_ARRAY(q_outputFromGpu)));\n\t\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(r);\n\tPOLYBENCH_FREE_ARRAY(s);\n\tPOLYBENCH_FREE_ARRAY(p);\n\tPOLYBENCH_FREE_ARRAY(q);\n\tPOLYBENCH_FREE_ARRAY(s_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(q_outputFromGpu);\n\n  \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"bicg.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/bicg"}}
{"kernel_name": "bicg", "parallel_api": "ocl", "code": {"bicg.c": "/**\n * bicg.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"bicg.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#ifndef M_PI\n#define M_PI 3.14159\n#endif\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_command_queue clCommandQue;\ncl_program clProgram;\n\ncl_mem a_mem_obj;\ncl_mem r_mem_obj;\ncl_mem p_mem_obj;\ncl_mem q_mem_obj;\ncl_mem s_mem_obj;\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int nx, int ny, DATA_TYPE POLYBENCH_1D(s,NY,ny), DATA_TYPE POLYBENCH_1D(s_outputFromGpu,NY,ny), \n\t\tDATA_TYPE POLYBENCH_1D(q,NX,nx), DATA_TYPE POLYBENCH_1D(q_outputFromGpu,NX,nx))\n{\n\tint i,fail;\n\tfail = 0;\n\n\t// Compare s with s_cuda\n\tfor (i=0; i<nx; i++)\n\t{\n\t\tif (percentDiff(q[i], q_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\n\tfor (i=0; i<ny; i++)\n\t{\n\t\tif (percentDiff(s[i], s_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\t\t\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"bicg.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_array(int nx, int ny, DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny), DATA_TYPE POLYBENCH_1D(p,NY,ny), DATA_TYPE POLYBENCH_1D(r,NX,nx))\n{\n\tint i, j;\n\t\n\tfor (i = 0; i < ny; i++)\n\t{\n    \t\tp[i] = i * M_PI;\n\t}\n\n\tfor (i = 0; i < nx; i++)\n\t{\n    \t\tr[i] = i * M_PI;\n\n    \t\tfor (j = 0; j < ny; j++)\n\t\t{\n      \t\t\tA[i][j] = ((DATA_TYPE) i*j) / NX;\n\t\t}\n \t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny), DATA_TYPE POLYBENCH_1D(r,NX,nx), DATA_TYPE POLYBENCH_1D(s,NX,nx), \n\tDATA_TYPE POLYBENCH_1D(p,NX,nx), DATA_TYPE POLYBENCH_1D(q,NX,nx))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX * NY, NULL, &errcode);\n\tr_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX, NULL, &errcode);\n\ts_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX, NULL, &errcode);\n\tp_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX, NULL, &errcode);\n\tq_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX, NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\t\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX * NY, A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, r_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX, r, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, s_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX, s, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, p_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX, p, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, q_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX, q, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n }\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the 1st OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"bicgKernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\n\t// Create the 2nd OpenCL kernel\n\tclKernel2 = clCreateKernel(clProgram, \"bicgKernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel(int nx, int ny)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NX) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&p_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&q_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(int), &nx);\n        errcode |= clSetKernelArg(clKernel1, 4, sizeof(int), &ny);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the 1st OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n\t\n\tglobalWorkSize[0] = (size_t)ceil(((float)NY) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&r_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(cl_mem), (void *)&s_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(int), &nx);\n        errcode |= clSetKernelArg(clKernel2, 4, sizeof(int), &ny);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\t\n\t// Execute the 2nd OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(p_mem_obj);\n\terrcode = clReleaseMemObject(q_mem_obj);\n\terrcode = clReleaseMemObject(r_mem_obj);\n\terrcode = clReleaseMemObject(s_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid bicg_cpu(int nx, int ny, DATA_TYPE POLYBENCH_2D(A,NX,NY,nx,ny), DATA_TYPE POLYBENCH_1D(r,NX,nx), DATA_TYPE POLYBENCH_1D(s,NY,ny), \n\t\tDATA_TYPE POLYBENCH_1D(p,NY,ny), DATA_TYPE POLYBENCH_1D(q,NX,nx))\n{\n\tint i,j;\n\t\n  \tfor (i = 0; i < _PB_NY; i++)\n\t{\n\t\ts[i] = 0.0;\n\t}\n\n\tfor (i = 0; i < _PB_NX; i++)\n\t{\n\t\tq[i] = 0.0;\n\t\tfor (j = 0; j < _PB_NY; j++)\n\t  \t{\n\t    \t\ts[j] = s[j] + r[i] * A[i][j];\n\t    \t\tq[i] = q[i] + A[i][j] * p[j];\n\t  \t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int nx, int ny,\n\t\t DATA_TYPE POLYBENCH_1D(s,NY,ny),\n\t\t DATA_TYPE POLYBENCH_1D(q,NX,nx))\n\n{\n  int i;\n\n  for (i = 0; i < ny; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, s[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n  for (i = 0; i < nx; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, q[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint nx = NX;\n\tint ny = NY;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(s,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(q,DATA_TYPE,NX,nx);\n\tPOLYBENCH_1D_ARRAY_DECL(p,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(r,DATA_TYPE,NX,nx);\n\tPOLYBENCH_1D_ARRAY_DECL(s_outputFromGpu,DATA_TYPE,NY,ny);\n\tPOLYBENCH_1D_ARRAY_DECL(q_outputFromGpu,DATA_TYPE,NX,nx);\n\n\tinit_array(nx, ny, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(p), POLYBENCH_ARRAY(r));\n\t\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(r), POLYBENCH_ARRAY(s), POLYBENCH_ARRAY(p), POLYBENCH_ARRAY(q));\n\tcl_load_prog();\n\n\tcl_launch_kernel(nx, ny);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, s_mem_obj, CL_TRUE, 0, NY*sizeof(DATA_TYPE), POLYBENCH_ARRAY(s_outputFromGpu), 0, NULL, NULL);\n\terrcode = clEnqueueReadBuffer(clCommandQue, q_mem_obj, CL_TRUE, 0, NX*sizeof(DATA_TYPE), POLYBENCH_ARRAY(q_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");  \n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tbicg_cpu(nx, ny, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(r), POLYBENCH_ARRAY(s), POLYBENCH_ARRAY(p), POLYBENCH_ARRAY(q));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(nx, ny, POLYBENCH_ARRAY(s), POLYBENCH_ARRAY(s_outputFromGpu), POLYBENCH_ARRAY(q), \n\t\t\tPOLYBENCH_ARRAY(q_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(nx, ny, POLYBENCH_ARRAY(s_outputFromGpu), POLYBENCH_ARRAY(q_outputFromGpu)));\n\t\n\t#endif //RUN_ON_CPU\n\n\tcl_clean_up();\n\t\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(r);\n\tPOLYBENCH_FREE_ARRAY(s);\n\tPOLYBENCH_FREE_ARRAY(p);\n\tPOLYBENCH_FREE_ARRAY(q);\n\tPOLYBENCH_FREE_ARRAY(s_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(q_outputFromGpu);\n\t\n    \treturn 0;\n}\n\n#include <polybench.c>", "bicg.cl": "/**\n * bicg.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n__kernel void bicgKernel1(__global DATA_TYPE *A, __global DATA_TYPE *p, __global DATA_TYPE *q, int nx, int ny) \n{\n    \tint i = get_global_id(0);\n\t\n\tif (i < nx)\n\t{\n\t\tq[i] = 0.0;\n\n\t\tint j;\n\t\tfor(j=0; j < ny; j++)\n\t\t{\n\t\t\tq[i] += A[i * ny + j] * p[j];\n\t\t}\n\t}\n\t\n}\n\n__kernel void bicgKernel2(__global DATA_TYPE *A, __global DATA_TYPE *r, __global DATA_TYPE *s, int nx, int ny) \n{\n\tint j = get_global_id(0);\n\t\n\tif (j < ny)\n\t{\n\t\ts[j] = 0.0;\n\n\t\tint i;\n\t\tfor(i = 0; i < nx; i++)\n\t\t{\n\t\t\ts[j] += A[i * ny + j] * r[i];\n\t\t}\n\t}\n\t\n}\n\n\n\n"}, "code_dirs": {"bicg.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/bicg", "bicg.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/bicg"}}
{"kernel_name": "correlation", "parallel_api": "cuda", "code": {"correlation.cu": "/**\n * correlation.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"correlation.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 1.05\n\n#define GPU_DEVICE 0\n\n#define sqrt_of_array_cell(x,j) sqrt(x[j])\n\n#define FLOAT_N 3214212.01f\n#define EPS 0.005f\n\n#define RUN_ON_CPU\n\n\nvoid init_arrays(int m, int n, DATA_TYPE POLYBENCH_2D(data, M, N, m, n))\n{\n\tint i, j;\n\t\n\tfor (i=0; i < m; i++) \n\t{\n    \t\tfor (j=0; j < n; j++) \n\t\t{\n       \t\tdata[i][j] = ((DATA_TYPE) i*j)/ M;\t\n       \t}\n    \t}\n}\n\n\nvoid correlation(int m, int n, DATA_TYPE POLYBENCH_2D(data, M, N, m, n), DATA_TYPE POLYBENCH_1D(mean, M, m), DATA_TYPE POLYBENCH_1D(stddev, M, m),\n\t\tDATA_TYPE POLYBENCH_2D(symmat, M, N, m, n))\n{\n\tint i, j, j1, j2;\t\n\t\n\t// Determine mean of column vectors of input data matrix \n  \tfor (j = 0; j < _PB_M; j++)\n   \t{\n  \t\tmean[j] = 0.0;\n\n   \t\tfor (i = 0; i < _PB_N; i++)\n\t\t{\n\t\t\tmean[j] += data[i][j];\n   \t\t}\n\t\t\n\t\tmean[j] /= (DATA_TYPE)FLOAT_N;\n   \t}\n\n\t// Determine standard deviations of column vectors of data matrix. \n  \tfor (j = 0; j < _PB_M; j++)\n   \t{\n   \t\tstddev[j] = 0.0;\n      \n\t\tfor (i = 0; i < _PB_N; i++)\n\t\t{\n\t\t\tstddev[j] += (data[i][j] - mean[j]) * (data[i][j] - mean[j]);\n\t\t}\n\t\t\n\t\tstddev[j] /= FLOAT_N;\n\t\tstddev[j] = sqrt_of_array_cell(stddev, j);\n\t\tstddev[j] = stddev[j] <= EPS ? 1.0 : stddev[j];\n\t}\n\n \t// Center and reduce the column vectors. \n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n\t\tfor (j = 0; j < _PB_M; j++)\n\t\t{\n\t\t\tdata[i][j] -= mean[j];\n\t\t\tdata[i][j] /= (sqrt(FLOAT_N)*stddev[j]) ;\n\t\t}\n\t}\n\n\t// Calculate the m * m correlation matrix. \n  \tfor (j1 = 0; j1 < _PB_M-1; j1++)\n\t{\t\n\t\tsymmat[j1][j1] = 1.0;\n    \n\t\tfor (j2 = j1+1; j2 < _PB_M; j2++)\n\t\t{\n\t  \t\tsymmat[j1][j2] = 0.0;\n\n\t  \t\tfor (i = 0; i < _PB_N; i++)\n\t\t\t{\n\t   \t\t\tsymmat[j1][j2] += (data[i][j1] * data[i][j2]);\n\t\t\t}\n\n\t  \t\tsymmat[j2][j1] = symmat[j1][j2];\n\t\t}\n\t}\n \n\tsymmat[M-1][M-1] = 1.0;\n}\n\n\nvoid compareResults(int m, int n, DATA_TYPE POLYBENCH_2D(symmat, M, N, m, n), DATA_TYPE POLYBENCH_2D(symmat_outputFromGpu, M, N, m, n))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\tfor (i=0; i < m; i++)\n\t{\n\t\tfor (j=0; j < n; j++)\n\t\t{\n\t\t\tif (percentDiff(symmat[i][j], symmat_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\t\t\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\t\n__global__ void mean_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *data)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (j < _PB_M)\n\t{\n\t\tmean[j] = 0.0;\n\n\t\tint i;\n\t\tfor(i=0; i < _PB_N; i++)\n\t\t{\n\t\t\tmean[j] += data[i*M + j];\n\t\t}\n\t\t\n\t\tmean[j] /= (DATA_TYPE)FLOAT_N;\n\t}\n}\n\n\n__global__ void std_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *std, DATA_TYPE *data)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif (j < _PB_M)\n\t{\n\t\tstd[j] = 0.0;\n\n\t\tint i;\n\t\tfor(i = 0; i < _PB_N; i++)\n\t\t{\n\t\t\tstd[j] += (data[i*M + j] - mean[j]) * (data[i*M + j] - mean[j]);\n\t\t}\n\t\tstd[j] /= (FLOAT_N);\n\t\tstd[j] = sqrt(std[j]);\n\t\tif(std[j] <= EPS) \n\t\t{\n\t\t\tstd[j] = 1.0;\n\t\t}\n\t}\n}\n\n\n__global__ void reduce_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *std, DATA_TYPE *data)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\tif ((i < _PB_N) && (j < _PB_M))\n\t{\n\t\tdata[i*M + j] -= mean[j];\n\t\tdata[i*M + j] /= (sqrt(FLOAT_N) * std[j]);\n\t}\n}\n\n\n__global__ void corr_kernel(int m, int n, DATA_TYPE *symmat, DATA_TYPE *data)\n{\n\tint j1 = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint i, j2;\n\tif (j1 < (_PB_M-1))\n\t{\n\t\tsymmat[j1*M + j1] = 1.0;\n\n\t\tfor (j2 = (j1 + 1); j2 < _PB_M; j2++)\n\t\t{\n\t\t\tsymmat[j1*M + j2] = 0.0;\n\n\t\t\tfor(i = 0; i < _PB_N; i++)\n\t\t\t{\n\t\t\t\tsymmat[j1*M + j2] += data[i*M + j1] * data[i*M + j2];\n\t\t\t}\n\t\t\tsymmat[j2*M + j1] = symmat[j1*M + j2];\n\t\t}\n\t}\n}\n\n\nvoid correlationCuda(int m, int n, DATA_TYPE POLYBENCH_2D(data, M, N, m, n), DATA_TYPE POLYBENCH_1D(mean, M, m), \n\t\t\tDATA_TYPE POLYBENCH_1D(stddev, M, m), DATA_TYPE POLYBENCH_2D(symmat, M, N, m, n), \n\t\t\tDATA_TYPE POLYBENCH_2D(symmat_outputFromGpu, M, N, m, n))\n{\n\tDATA_TYPE *data_gpu;\n\tDATA_TYPE *stddev_gpu;\n\tDATA_TYPE *mean_gpu;\n\tDATA_TYPE *symmat_gpu;\n\n\tcudaMalloc((void **)&data_gpu, sizeof(DATA_TYPE) * M * N);\n\tcudaMalloc((void **)&symmat_gpu, sizeof(DATA_TYPE) * M * N);\n\tcudaMalloc((void **)&stddev_gpu, sizeof(DATA_TYPE) * M);\n\tcudaMalloc((void **)&mean_gpu, sizeof(DATA_TYPE) * M);\n\tcudaMemcpy(data_gpu, data, sizeof(DATA_TYPE) * M * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(symmat_gpu, symmat, sizeof(DATA_TYPE) * M * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(stddev_gpu, stddev, sizeof(DATA_TYPE) * M, cudaMemcpyHostToDevice);\n\tcudaMemcpy(mean_gpu, mean, sizeof(DATA_TYPE) * M, cudaMemcpyHostToDevice);\n\t\t\n\tdim3 block1(DIM_THREAD_BLOCK_KERNEL_1_X, DIM_THREAD_BLOCK_KERNEL_1_Y);\n\tdim3 grid1((size_t)(ceil((float)(M)) / ((float)DIM_THREAD_BLOCK_KERNEL_1_X)), 1);\n\t\n\tdim3 block2(DIM_THREAD_BLOCK_KERNEL_2_X, DIM_THREAD_BLOCK_KERNEL_2_Y);\n\tdim3 grid2((size_t)(ceil((float)(M)) / ((float)DIM_THREAD_BLOCK_KERNEL_2_X)), 1);\n\t\n\tdim3 block3(DIM_THREAD_BLOCK_KERNEL_3_X, DIM_THREAD_BLOCK_KERNEL_3_Y);\n\tdim3 grid3((size_t)(ceil((float)(M)) / ((float)DIM_THREAD_BLOCK_KERNEL_3_X)), (size_t)(ceil((float)(N)) / ((float)DIM_THREAD_BLOCK_KERNEL_3_Y)));\n\t\n\tdim3 block4(DIM_THREAD_BLOCK_KERNEL_4_X, DIM_THREAD_BLOCK_KERNEL_4_Y);\n\tdim3 grid4((size_t)(ceil((float)(M)) / ((float)DIM_THREAD_BLOCK_KERNEL_4_X)), 1);\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tmean_kernel<<< grid1, block1 >>>(m, n, mean_gpu,data_gpu);\n\tcudaThreadSynchronize();\n\tstd_kernel<<< grid2, block2 >>>(m, n, mean_gpu,stddev_gpu,data_gpu);\n\tcudaThreadSynchronize();\n\treduce_kernel<<< grid3, block3 >>>(m, n, mean_gpu,stddev_gpu,data_gpu);\n\tcudaThreadSynchronize();\n\tcorr_kernel<<< grid4, block4 >>>(m, n, symmat_gpu,data_gpu);\n\tcudaThreadSynchronize();\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tDATA_TYPE valueAtSymmatIndexMTimesMPlus1PlusMPoint = 1.0;\n\tcudaMemcpy(&(symmat_gpu[(M-1)*M + (M-1)]), &valueAtSymmatIndexMTimesMPlus1PlusMPoint, sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\n\tcudaMemcpy(symmat_outputFromGpu, symmat_gpu, sizeof(DATA_TYPE) * M * N, cudaMemcpyDeviceToHost);\n\t\n\tcudaFree(data_gpu);\n\tcudaFree(symmat_gpu);\n\tcudaFree(stddev_gpu);\n\tcudaFree(mean_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int m,\n\t\t DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m))\n\n{\n  int i, j;\n\n  for (i = 0; i < m; i++)\n    for (j = 0; j < m; j++) {\n      fprintf (stderr, DATA_PRINTF_MODIFIER, symmat[i][j]);\n      if ((i * m + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char** argv)\n{\n\tint m = M;\n\tint n = N;\n\n\tPOLYBENCH_2D_ARRAY_DECL(data,DATA_TYPE,M,N,m,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(mean,DATA_TYPE,M,m);\n  \tPOLYBENCH_1D_ARRAY_DECL(stddev,DATA_TYPE,M,m);\n\tPOLYBENCH_2D_ARRAY_DECL(symmat,DATA_TYPE,M,N,m,n);\n  \tPOLYBENCH_2D_ARRAY_DECL(symmat_outputFromGpu,DATA_TYPE,M,N,m,n);\n  \t\n\tinit_arrays(m, n, POLYBENCH_ARRAY(data));\n    \n\tGPU_argv_init();\n\n\tcorrelationCuda(m, n, POLYBENCH_ARRAY(data), POLYBENCH_ARRAY(mean), POLYBENCH_ARRAY(stddev), POLYBENCH_ARRAY(symmat), \n\t\tPOLYBENCH_ARRAY(symmat_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tcorrelation(m, n, POLYBENCH_ARRAY(data), POLYBENCH_ARRAY(mean), POLYBENCH_ARRAY(stddev), POLYBENCH_ARRAY(symmat));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n    \n\t\tcompareResults(m, n, POLYBENCH_ARRAY(symmat), POLYBENCH_ARRAY(symmat_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(m, POLYBENCH_ARRAY(symmat_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(data);\n\tPOLYBENCH_FREE_ARRAY(mean);\n\tPOLYBENCH_FREE_ARRAY(stddev);\n\tPOLYBENCH_FREE_ARRAY(symmat);\n\tPOLYBENCH_FREE_ARRAY(symmat_outputFromGpu);\n\n  \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"correlation.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/datamining/correlation"}}
{"kernel_name": "correlation", "parallel_api": "ocl", "code": {"correlation.c": "/**\n * correlation.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <math.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"correlation.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 1.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n\n#define sqrt_of_array_cell(x,j) sqrt(x[j])\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\n#define FLOAT_N 3214212.01\n#define EPS 0.005\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel_mean;\ncl_kernel clKernel_std;\ncl_kernel clKernel_reduce;\ncl_kernel clKernel_corr;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem data_mem_obj;\ncl_mem stddev_mem_obj;\ncl_mem mean_mem_obj;\ncl_mem symmat_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int m, int n, DATA_TYPE POLYBENCH_2D(symmat, M, N, m, n), DATA_TYPE POLYBENCH_2D(symmat_outputFromGpu, M, N, m, n))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\tfor (i=0; i < m; i++)\n\t{\n\t\tfor (j=0; j < n; j++)\n\t\t{\n\t\t\tif (percentDiff(symmat[i][j], symmat_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\t\t\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"correlation.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_arrays(int m, int n, DATA_TYPE POLYBENCH_2D(data, M, N, m, n))\n{\n\tint i, j;\n\t\n\tfor (i=0; i < m; i++) \n\t{\n    \t\tfor (j=0; j < n; j++) \n\t\t{\n       \t\tdata[i][j] = ((DATA_TYPE) i*j)/ M;\t\n       \t}\n    \t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(data,M,N,m,n), DATA_TYPE POLYBENCH_1D(mean,M,m), DATA_TYPE POLYBENCH_1D(stddev,M,m), DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m))\n{\n\tdata_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * M * N, NULL, &errcode);\n\tsymmat_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * M * N, NULL, &errcode);\n\tstddev_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * M, NULL, &errcode);\n\tmean_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * M, NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, data_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * M * N, data, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, symmat_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * M * N, symmat, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, stddev_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * M, stddev, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, mean_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * M, mean, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel_mean = clCreateKernel(clProgram, \"mean_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\n\tclKernel_std = clCreateKernel(clProgram, \"std_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel2\\n\");\n\n\tclKernel_reduce = clCreateKernel(clProgram, \"reduce_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel3\\n\");\n\n\tclKernel_corr = clCreateKernel(clProgram, \"corr_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel4\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int m, int n)\n{\n\tDATA_TYPE float_n = FLOAT_N;\n\tDATA_TYPE eps = EPS;\n\n\tsize_t localWorkSize_Kernel1[2], globalWorkSize_Kernel1[2];\n\tsize_t localWorkSize_Kernel2[2], globalWorkSize_Kernel2[2];\n\tsize_t localWorkSize_Kernel3[2], globalWorkSize_Kernel3[2];\n\tsize_t localWorkSize_Kernel4[2], globalWorkSize_Kernel4[2];\n\n\tlocalWorkSize_Kernel1[0] = DIM_LOCAL_WORK_GROUP_KERNEL_1_X;\n\tlocalWorkSize_Kernel1[1] = DIM_LOCAL_WORK_GROUP_KERNEL_1_Y;\n\tglobalWorkSize_Kernel1[0] = (size_t)ceil(((float)M) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_1_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_1_X;\n\tglobalWorkSize_Kernel1[1] = 1;\n\n\tlocalWorkSize_Kernel2[0] = DIM_LOCAL_WORK_GROUP_KERNEL_2_X;\n\tlocalWorkSize_Kernel2[1] = DIM_LOCAL_WORK_GROUP_KERNEL_2_Y;\n\tglobalWorkSize_Kernel2[0] = (size_t)ceil(((float)M) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_2_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_2_X;\n\tglobalWorkSize_Kernel2[1] = 1;\n\n\tlocalWorkSize_Kernel3[0] = DIM_LOCAL_WORK_GROUP_KERNEL_3_X;\n\tlocalWorkSize_Kernel3[1] = DIM_LOCAL_WORK_GROUP_KERNEL_3_Y;\n\tglobalWorkSize_Kernel3[0] = (size_t)ceil(((float)M) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_3_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_3_X;\n\tglobalWorkSize_Kernel3[1] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_3_Y)) * DIM_LOCAL_WORK_GROUP_KERNEL_3_Y;\n\n\tlocalWorkSize_Kernel4[0] = DIM_LOCAL_WORK_GROUP_KERNEL_4_X;\n\tlocalWorkSize_Kernel4[1] = DIM_LOCAL_WORK_GROUP_KERNEL_4_Y;\n\tglobalWorkSize_Kernel4[0] = (size_t)ceil(((float)M) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_4_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_4_X;\n\tglobalWorkSize_Kernel4[1] = 1;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel_mean, 0, sizeof(cl_mem), (void *)&mean_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_mean, 1, sizeof(cl_mem), (void *)&data_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_mean, 2, sizeof(DATA_TYPE), (void *)&float_n);\n\terrcode |= clSetKernelArg(clKernel_mean, 3, sizeof(int), (void *)&m);\n\terrcode |= clSetKernelArg(clKernel_mean, 4, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel_mean, 1, NULL, globalWorkSize_Kernel1, localWorkSize_Kernel1, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel_std, 0, sizeof(cl_mem), (void *)&mean_mem_obj);\n\terrcode =  clSetKernelArg(clKernel_std, 1, sizeof(cl_mem), (void *)&stddev_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_std, 2, sizeof(cl_mem), (void *)&data_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_std, 3, sizeof(DATA_TYPE), (void *)&float_n);\n\terrcode |= clSetKernelArg(clKernel_std, 4, sizeof(DATA_TYPE), (void *)&eps);\n\terrcode |= clSetKernelArg(clKernel_std, 5, sizeof(int), (void *)&m);\n\terrcode |= clSetKernelArg(clKernel_std, 6, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments2\\n\");\n \n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel_std, 1, NULL, globalWorkSize_Kernel2, localWorkSize_Kernel2, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel2\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel_reduce, 0, sizeof(cl_mem), (void *)&mean_mem_obj);\n\terrcode =  clSetKernelArg(clKernel_reduce, 1, sizeof(cl_mem), (void *)&stddev_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_reduce, 2, sizeof(cl_mem), (void *)&data_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_reduce, 3, sizeof(DATA_TYPE), (void *)&float_n);\n\terrcode |= clSetKernelArg(clKernel_reduce, 4, sizeof(int), (void *)&m);\n\terrcode |= clSetKernelArg(clKernel_reduce, 5, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments3\\n\");\n \n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel_reduce, 2, NULL, globalWorkSize_Kernel3, localWorkSize_Kernel3, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel3\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\n\t// Set the arguments of the kernel\t\n\terrcode =  clSetKernelArg(clKernel_corr, 0, sizeof(cl_mem), (void *)&symmat_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_corr, 1, sizeof(cl_mem), (void *)&data_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_corr, 2, sizeof(int), (void *)&m);\n\terrcode |= clSetKernelArg(clKernel_corr, 3, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments4\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel_corr, 1, NULL, globalWorkSize_Kernel4, localWorkSize_Kernel4, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel4\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\n\tDATA_TYPE val = 1.0;\n\tclEnqueueWriteBuffer(clCommandQue, symmat_mem_obj, CL_TRUE, ((M-1)*M + (M-1))*sizeof(DATA_TYPE), sizeof(DATA_TYPE), &val, 0, NULL, NULL);\n\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel_reduce);\n\terrcode = clReleaseKernel(clKernel_mean);\n\terrcode = clReleaseKernel(clKernel_std);\n\terrcode = clReleaseKernel(clKernel_corr);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(symmat_mem_obj);\n\terrcode = clReleaseMemObject(data_mem_obj);\n\terrcode = clReleaseMemObject(mean_mem_obj);\n\terrcode = clReleaseMemObject(stddev_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid correlation(int m, int n, DATA_TYPE POLYBENCH_2D(data, M, N, m, n), DATA_TYPE POLYBENCH_1D(mean, M, m), DATA_TYPE POLYBENCH_1D(stddev, M, m),\n\t\tDATA_TYPE POLYBENCH_2D(symmat, M, N, m, n))\n{\n\tint i, j, j1, j2;\t\n\t\n\t// Determine mean of column vectors of input data matrix \n  \tfor (j = 0; j < _PB_M; j++)\n   \t{\n  \t\tmean[j] = 0.0;\n\n   \t\tfor (i = 0; i < _PB_N; i++)\n\t\t{\n\t\t\tmean[j] += data[i][j];\n   \t\t}\n\t\t\n\t\tmean[j] /= (DATA_TYPE)FLOAT_N;\n   \t}\n\n\t// Determine standard deviations of column vectors of data matrix. \n  \tfor (j = 0; j < _PB_M; j++)\n   \t{\n   \t\tstddev[j] = 0.0;\n      \n\t\tfor (i = 0; i < _PB_N; i++)\n\t\t{\n\t\t\tstddev[j] += (data[i][j] - mean[j]) * (data[i][j] - mean[j]);\n\t\t}\n\t\t\n\t\tstddev[j] /= FLOAT_N;\n\t\tstddev[j] = sqrt_of_array_cell(stddev, j);\n\t\tstddev[j] = stddev[j] <= EPS ? 1.0 : stddev[j];\n\t}\n\n \t// Center and reduce the column vectors. \n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n\t\tfor (j = 0; j < _PB_M; j++)\n\t\t{\n\t\t\tdata[i][j] -= mean[j];\n\t\t\tdata[i][j] /= (sqrt(FLOAT_N)*stddev[j]) ;\n\t\t}\n\t}\n\n\t// Calculate the m * m correlation matrix. \n  \tfor (j1 = 0; j1 < _PB_M-1; j1++)\n\t{\t\n\t\tsymmat[j1][j1] = 1.0;\n    \n\t\tfor (j2 = j1+1; j2 < _PB_M; j2++)\n\t\t{\n\t  \t\tsymmat[j1][j2] = 0.0;\n\n\t  \t\tfor (i = 0; i < _PB_N; i++)\n\t\t\t{\n\t   \t\t\tsymmat[j1][j2] += (data[i][j1] * data[i][j2]);\n\t\t\t}\n\n\t  \t\tsymmat[j2][j1] = symmat[j1][j2];\n\t\t}\n\t}\n \n\tsymmat[M-1][M-1] = 1.0;\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int m,\n\t\t DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m))\n\n{\n  int i, j;\n\n  for (i = 0; i < m; i++)\n    for (j = 0; j < m; j++) {\n      fprintf (stderr, DATA_PRINTF_MODIFIER, symmat[i][j]);\n      if ((i * m + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\t\n\tint m = M;\n\tint n = N;\n\n\tPOLYBENCH_2D_ARRAY_DECL(data,DATA_TYPE,M,N,m,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(mean,DATA_TYPE,M,m);\n  \tPOLYBENCH_1D_ARRAY_DECL(stddev,DATA_TYPE,M,m);\n\tPOLYBENCH_2D_ARRAY_DECL(symmat,DATA_TYPE,M,N,m,n);\n  \tPOLYBENCH_2D_ARRAY_DECL(symmat_outputFromGpu,DATA_TYPE,M,N,m,n);\n  \t\n\tinit_arrays(m, n, POLYBENCH_ARRAY(data));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(data), POLYBENCH_ARRAY(mean), POLYBENCH_ARRAY(stddev), POLYBENCH_ARRAY(symmat_outputFromGpu));\n\tcl_load_prog();\n\n\tcl_launch_kernel(m, n);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, symmat_mem_obj, CL_TRUE, 0, M * N * sizeof(DATA_TYPE), POLYBENCH_ARRAY(symmat_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tcorrelation(m, n, POLYBENCH_ARRAY(data), POLYBENCH_ARRAY(mean), POLYBENCH_ARRAY(stddev), POLYBENCH_ARRAY(symmat));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(m, n, POLYBENCH_ARRAY(symmat), POLYBENCH_ARRAY(symmat_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(m, POLYBENCH_ARRAY(symmat_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tPOLYBENCH_FREE_ARRAY(data);\n\tPOLYBENCH_FREE_ARRAY(mean);\n\tPOLYBENCH_FREE_ARRAY(stddev);\n\tPOLYBENCH_FREE_ARRAY(symmat);\n\tPOLYBENCH_FREE_ARRAY(symmat_outputFromGpu);\n\n\tcl_clean_up();\n\t\n\treturn 0;\n}\n\n#include <polybench.c>", "correlation.cl": "/**\n * correlation.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n__kernel void mean_kernel(__global DATA_TYPE *mean, __global DATA_TYPE *data, DATA_TYPE float_n, int m, int n) \n{    \n\tint j = get_global_id(0);\n\t\n\tif (j < m)\n\t{\n\t\tmean[j] = 0.0;\n\n\t\tint i;\n\t\tfor (i=0; i < n; i++)\n\t\t{\n\t\t\tmean[j] += data[i*m + j];\n\t\t}\n\t\t\n\t\tmean[j] /= (DATA_TYPE)float_n;\n\t}\n}\n\n\n__kernel void std_kernel(__global DATA_TYPE *mean, __global DATA_TYPE *std, __global DATA_TYPE *data, DATA_TYPE float_n, DATA_TYPE eps, int m, int n) \n{\n\tint j = get_global_id(0);\n\n\tif (j < m)\n\t{\n\t\tstd[j] = 0.0;\n\n\t\tint i;\n\t\tfor (i = 0; i < n; i++)\n\t\t{\n\t\t\tstd[j] += (data[i*m + j] - mean[j]) * (data[i*m + j] - mean[j]);\n\t\t}\n\t\tstd[j] /= float_n;\n\t\tstd[j] =  sqrt(std[j]);\n\t\tif(std[j] <= eps) \n\t\t{\n\t\t\tstd[j] = 1.0;\n\t\t}\n\t}\n}\n\n\n__kernel void reduce_kernel(__global DATA_TYPE *mean, __global DATA_TYPE *std, __global DATA_TYPE *data, DATA_TYPE float_n, int m, int n) \n{\n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < n) && (j < m))\n\t{\n\t\tdata[i*m + j] -= mean[j];\n\t\tdata[i*m + j] /= (sqrt(float_n) * std[j]);\n\t}\n}\n\n\n__kernel void corr_kernel(__global DATA_TYPE *symmat, __global DATA_TYPE *data, int m, int n) \n{\n\tint j1 = get_global_id(0);\n\t\n\tint i, j2;\n\tif (j1 < (m-1))\n\t{\n\t\tsymmat[j1*m + j1] = 1.0;\n\n\t\tfor (j2 = (j1 + 1); j2 < m; j2++)\n\t\t{\n\t\t\tfor(i = 0; i < n; i++)\n\t\t\t{\n\t\t\t\tsymmat[j1*m + j2] += data[i*m + j1] * data[i*m + j2];\n\t\t\t}\n\t\t\tsymmat[j2*m + j1] = symmat[j1*m + j2];\n\t\t}\n\t}\n}\n\n\n\n"}, "code_dirs": {"correlation.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/datamining/correlation", "correlation.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/datamining/correlation"}}
{"kernel_name": "covariance", "parallel_api": "cuda", "code": {"covariance.cu": "/**\n * covariance.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <unistd.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"covariance.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 1.05\n\n#define GPU_DEVICE 0\n\n#define sqrt_of_array_cell(x,j) sqrt(x[j])\n\n#define FLOAT_N 3214212.01\n#define EPS 0.005\n\n#define RUN_ON_CPU\n\n\nvoid init_arrays(int m, int n, DATA_TYPE POLYBENCH_2D(data,M,N,m,n))\n{\n\tint i, j;\n\n\tfor (i = 0; i < m; i++)\n\t{\n\t\tfor (j = 0; j < n; j++)\n\t\t{\n\t\t\tdata[i][j] = ((DATA_TYPE) i*j) / M;\n\t\t}\n\t}\n}\n\n\nvoid covariance(int m, int n, DATA_TYPE POLYBENCH_2D(data,M,N,m,n), DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m), DATA_TYPE POLYBENCH_1D(mean,M,m))\n{\n\tint i, j, j1,j2;\n\n  \t/* Determine mean of column vectors of input data matrix */\n\tfor (j = 0; j < _PB_M; j++)\n\t{\n\t\tmean[j] = 0.0;\n\t\tfor (i = 0; i < _PB_N; i++)\n\t\t{\n        \t\tmean[j] += data[i][j];\n\t\t}\n\t\tmean[j] /= FLOAT_N;\n\t}\n\n  \t/* Center the column vectors. */\n\tfor (i = 0; i < _PB_N; i++)\n\t{\n\t\tfor (j = 0; j < _PB_M; j++)\n\t\t{\n\t\t\tdata[i][j] -= mean[j];\n\t\t}\n\t}\n\n  \t/* Calculate the m * m covariance matrix. */\n\tfor (j1 = 0; j1 < _PB_M; j1++)\n\t{\n\t\tfor (j2 = j1; j2 < _PB_M; j2++)\n     \t\t{\n       \t\tsymmat[j1][j2] = 0.0;\n\t\t\tfor (i = 0; i < _PB_N; i++)\n\t\t\t{\n\t\t\t\tsymmat[j1][j2] += data[i][j1] * data[i][j2];\n\t\t\t}\n        \t\tsymmat[j2][j1] = symmat[j1][j2];\n      \t\t}\n\t}\n}\n\n\nvoid compareResults(int m, int n, DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m), DATA_TYPE POLYBENCH_2D(symmat_outputFromGpu,M,M,m,m))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\tfor (i=0; i < m; i++)\n\t{\n\t\tfor (j=0; j < n; j++)\n\t\t{\n\t\t\tif (percentDiff(symmat[i][j], symmat_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\t\t\t\n\t\t}\n\t}\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n\t\n\treturn;\n}\n\n\n__global__ void mean_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *data)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (j < _PB_M)\n\t{\n\t\tmean[j] = 0.0;\n\n\t\tint i;\n\t\tfor(i = 0; i < _PB_N; i++)\n\t\t{\n\t\t\tmean[j] += data[i * M + j];\n\t\t}\n\t\tmean[j] /= (DATA_TYPE)FLOAT_N;\n\t}\n}\n\n\n__global__ void reduce_kernel(int m, int n, DATA_TYPE *mean, DATA_TYPE *data)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\t\t\n\tif ((i < _PB_N) && (j < _PB_M))\n\t{\n\t\tdata[i * M + j] -= mean[j];\t\n\t}\n}\n\n\n__global__ void covar_kernel(int m, int n, DATA_TYPE *symmat, DATA_TYPE *data)\n{\n\tint j1 = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i, j2;\n\n\tif (j1 < _PB_M)\n\t{\n\t\tfor (j2 = j1; j2 < _PB_M; j2++)\n\t\t{\t\t\n\t\t\tsymmat[j1*M + j2] = 0.0;\n\t\t\tfor(i = 0; i < _PB_N; i++)\n\t\t\t{\n\t\t\t\tsymmat[j1 * M + j2] += data[i * M + j1] * data[i * M + j2];\n\t\t\t}\n\t\t\tsymmat[j2 * M + j1] = symmat[j1 * M + j2];\n\t\t}\n\t}\n}\n\n\nvoid covarianceCuda(int m, int n, DATA_TYPE POLYBENCH_2D(data,M,N,m,n), DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m), DATA_TYPE POLYBENCH_1D(mean,M,m), \n\t\tDATA_TYPE POLYBENCH_2D(symmat_outputFromGpu,M,M,m,m))\n{\n\tDATA_TYPE *data_gpu;\n\tDATA_TYPE *mean_gpu;\n\tDATA_TYPE *symmat_gpu;\n\n\tcudaMalloc((void **)&data_gpu, sizeof(DATA_TYPE) * M * N);\n\tcudaMalloc((void **)&symmat_gpu, sizeof(DATA_TYPE) * M * M);\n\tcudaMalloc((void **)&mean_gpu, sizeof(DATA_TYPE) * M);\n\tcudaMemcpy(data_gpu, data, sizeof(DATA_TYPE) * M * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(symmat_gpu, symmat, sizeof(DATA_TYPE) * M * M, cudaMemcpyHostToDevice);\n\tcudaMemcpy(mean_gpu, mean, sizeof(DATA_TYPE) * M, cudaMemcpyHostToDevice);\n\t\n\tdim3 block1(DIM_THREAD_BLOCK_KERNEL_1_X, DIM_THREAD_BLOCK_KERNEL_1_Y);\n\tdim3 grid1((size_t)(ceil((float)M) / ((float)DIM_THREAD_BLOCK_KERNEL_1_X)), 1);\n\t\n\tdim3 block2(DIM_THREAD_BLOCK_KERNEL_2_X, DIM_THREAD_BLOCK_KERNEL_2_Y);\n\tdim3 grid2((size_t)(ceil((float)M) / ((float)DIM_THREAD_BLOCK_KERNEL_2_X)), (size_t)(ceil((float)N) / ((float)DIM_THREAD_BLOCK_KERNEL_2_X)));\n\t\n\tdim3 block3(DIM_THREAD_BLOCK_KERNEL_3_X, DIM_THREAD_BLOCK_KERNEL_3_Y);\n\tdim3 grid3((size_t)(ceil((float)M) / ((float)DIM_THREAD_BLOCK_KERNEL_3_X)), 1);\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tmean_kernel<<<grid1, block1>>>(m,n,mean_gpu,data_gpu);\n\tcudaThreadSynchronize();\n\treduce_kernel<<<grid2, block2>>>(m,n,mean_gpu,data_gpu);\n\tcudaThreadSynchronize();\n\tcovar_kernel<<<grid3, block3>>>(m,n,symmat_gpu,data_gpu);\n\tcudaThreadSynchronize();\n\t\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tcudaMemcpy(symmat_outputFromGpu, symmat_gpu, sizeof(DATA_TYPE) * M * N, cudaMemcpyDeviceToHost);\n\t\n\tcudaFree(data_gpu);\n\tcudaFree(symmat_gpu);\n\tcudaFree(mean_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int m, DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m))\n{\n  int i, j;\n\n  for (i = 0; i < m; i++)\n    for (j = 0; j < m; j++) {\n      fprintf (stderr, DATA_PRINTF_MODIFIER, symmat[i][j]);\n      if ((i * m + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char** argv)\n{\n\tint m = M;\n\tint n = N;\n\n\tPOLYBENCH_2D_ARRAY_DECL(data,DATA_TYPE,M,N,m,n);\n\tPOLYBENCH_2D_ARRAY_DECL(symmat,DATA_TYPE,M,M,m,m);\n\tPOLYBENCH_1D_ARRAY_DECL(mean,DATA_TYPE,M,m);\n\tPOLYBENCH_2D_ARRAY_DECL(symmat_outputFromGpu,DATA_TYPE,M,M,m,m);\t\n\n\tinit_arrays(m, n, POLYBENCH_ARRAY(data));\n    \n\tGPU_argv_init();\n\n\tcovarianceCuda(m, n, POLYBENCH_ARRAY(data), POLYBENCH_ARRAY(symmat), POLYBENCH_ARRAY(mean), POLYBENCH_ARRAY(symmat_outputFromGpu));\n\t\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tcovariance(m, n, POLYBENCH_ARRAY(data), POLYBENCH_ARRAY(symmat), POLYBENCH_ARRAY(mean));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(m, n, POLYBENCH_ARRAY(symmat), POLYBENCH_ARRAY(symmat_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(m, POLYBENCH_ARRAY(symmat_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(data);\n\tPOLYBENCH_FREE_ARRAY(symmat);\n\tPOLYBENCH_FREE_ARRAY(mean);\n\tPOLYBENCH_FREE_ARRAY(symmat_outputFromGpu);\t\n\n  \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"covariance.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/datamining/covariance"}}
{"kernel_name": "covariance", "parallel_api": "ocl", "code": {"covariance.c": "/**\n * covariance.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <math.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"covariance.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#define sqrt_of_array_cell(x,j) sqrt(x[j])\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n\nchar str_temp[1024];\n\nDATA_TYPE float_n= 3214212.01;\nDATA_TYPE eps=  0.005;\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel_mean;\ncl_kernel clKernel_std;\ncl_kernel clKernel_reduce;\ncl_kernel clKernel_covar;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem data_mem_obj;\ncl_mem stddev_mem_obj;\ncl_mem mean_mem_obj;\ncl_mem symmat_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int m, int n, DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m), DATA_TYPE POLYBENCH_2D(symmat_outputFromGpu,M,M,m,m))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\tfor (i=0; i < m; i++)\n\t{\n\t\tfor (j=0; j < n; j++)\n\t\t{\n\t\t\tif (percentDiff(symmat[i][j], symmat_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\t\t\t\n\t\t}\n\t}\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"covariance.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_arrays(int m, int n, DATA_TYPE POLYBENCH_2D(data,M,N,m,n))\n{\n\tint i, j;\n\n\tfor (i = 0; i < m; i++)\n\t{\n\t\tfor (j = 0; j < n; j++)\n\t\t{\n\t\t\tdata[i][j] = ((DATA_TYPE) i*j) / M;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(data,M,N,m,n), DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m), DATA_TYPE POLYBENCH_1D(mean,M,m))\n{\n\tdata_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * M * N, NULL, &errcode);\n\tsymmat_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * M * N, NULL, &errcode);\n\tmean_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * M, NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, data_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * M * N, data, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, symmat_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * M * N, symmat, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, mean_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * M, mean, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n \nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel_mean = clCreateKernel(clProgram, \"mean_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\n\tclKernel_reduce = clCreateKernel(clProgram, \"reduce_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel2\\n\");\n\n\tclKernel_covar = clCreateKernel(clProgram, \"covar_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel3\\n\");\n\tclFinish(clCommandQue);\t\n}\n\n\nvoid cl_launch_kernel(int m, int n)\n{\n\tsize_t localWorkSize_Kernel1[2], globalWorkSize_Kernel1[2];\n\tsize_t localWorkSize_Kernel2[2], globalWorkSize_Kernel2[2];\n\tsize_t localWorkSize_Kernel3[2], globalWorkSize_Kernel3[2];\n\n\tlocalWorkSize_Kernel1[0] = DIM_LOCAL_WORK_GROUP_KERNEL_1_X;\n\tlocalWorkSize_Kernel1[1] = DIM_LOCAL_WORK_GROUP_KERNEL_1_Y;\n\tglobalWorkSize_Kernel1[0] = (size_t)ceil(((float)M) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_1_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_1_X;\n\tglobalWorkSize_Kernel1[1] = 1;\n\n\tlocalWorkSize_Kernel2[0] = DIM_LOCAL_WORK_GROUP_KERNEL_2_X;\n\tlocalWorkSize_Kernel2[1] = DIM_LOCAL_WORK_GROUP_KERNEL_2_Y;\n\tglobalWorkSize_Kernel2[0] = (size_t)ceil(((float)M) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_2_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_2_X;\n\tglobalWorkSize_Kernel2[1] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_2_Y)) * DIM_LOCAL_WORK_GROUP_KERNEL_2_Y;\n\n\tlocalWorkSize_Kernel3[0] = DIM_LOCAL_WORK_GROUP_KERNEL_3_X;\n\tlocalWorkSize_Kernel3[1] = DIM_LOCAL_WORK_GROUP_KERNEL_3_Y;\n\tglobalWorkSize_Kernel3[0] = (size_t)ceil(((float)M) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_3_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_3_X;\n\tglobalWorkSize_Kernel3[1] = 1;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel_mean, 0, sizeof(cl_mem), (void *)&mean_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_mean, 1, sizeof(cl_mem), (void *)&data_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_mean, 2, sizeof(DATA_TYPE), (void *)&float_n);\n\terrcode |= clSetKernelArg(clKernel_mean, 3, sizeof(int), (void *)&m);\n\terrcode |= clSetKernelArg(clKernel_mean, 4, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\t\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel_mean, 1, NULL, globalWorkSize_Kernel1, localWorkSize_Kernel1, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\n\t\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel_reduce, 0, sizeof(cl_mem), (void *)&mean_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_reduce, 1, sizeof(cl_mem), (void *)&data_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_reduce, 2, sizeof(int), (void *)&m);\n\terrcode |= clSetKernelArg(clKernel_reduce, 3, sizeof(int), (void *)&n);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments2\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel_reduce, 2, NULL, globalWorkSize_Kernel2, localWorkSize_Kernel2, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel2\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\t\n\t// Set the arguments of the kernel\n\t\n\terrcode =  clSetKernelArg(clKernel_covar, 0, sizeof(cl_mem), (void *)&symmat_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_covar, 1, sizeof(cl_mem), (void *)&data_mem_obj);\n\terrcode |= clSetKernelArg(clKernel_covar, 2, sizeof(int), (void *)&m);\n\terrcode |= clSetKernelArg(clKernel_covar, 3, sizeof(int), (void *)&n);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments4\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel_covar, 1, NULL, globalWorkSize_Kernel3, localWorkSize_Kernel3, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel4\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel_reduce);\n\terrcode = clReleaseKernel(clKernel_mean);\n\t//errcode = clReleaseKernel(clKernel_std);\n\terrcode = clReleaseKernel(clKernel_covar);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(symmat_mem_obj);\n\terrcode = clReleaseMemObject(data_mem_obj);\n\terrcode = clReleaseMemObject(mean_mem_obj);\n\t//errcode = clReleaseMemObject(stddev_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid covariance(int m, int n, DATA_TYPE POLYBENCH_2D(data,M,N,m,n), DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m), DATA_TYPE POLYBENCH_1D(mean,M,m))\n{\n\tint i, j, j1,j2;\n\n  \t/* Determine mean of column vectors of input data matrix */\n\tfor (j = 0; j < _PB_M; j++)\n\t{\n\t\tmean[j] = 0.0;\n\t\tfor (i = 0; i < _PB_N; i++)\n\t\t{\n        \t\tmean[j] += data[i][j];\n\t\t}\n\t\tmean[j] /= float_n;\n\t}\n\n  \t/* Center the column vectors. */\n\tfor (i = 0; i < _PB_N; i++)\n\t{\n\t\tfor (j = 0; j < _PB_M; j++)\n\t\t{\n\t\t\tdata[i][j] -= mean[j];\n\t\t}\n\t}\n\n  \t/* Calculate the m * m covariance matrix. */\n\tfor (j1 = 0; j1 < _PB_M; j1++)\n\t{\n\t\tfor (j2 = j1; j2 < _PB_M; j2++)\n     \t\t{\n       \t\tsymmat[j1][j2] = 0.0;\n\t\t\tfor (i = 0; i < _PB_N; i++)\n\t\t\t{\n\t\t\t\tsymmat[j1][j2] += data[i][j1] * data[i][j2];\n\t\t\t}\n        \t\tsymmat[j2][j1] = symmat[j1][j2];\n      \t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int m, DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m))\n{\n  int i, j;\n\n  for (i = 0; i < m; i++)\n    for (j = 0; j < m; j++) {\n      fprintf (stderr, DATA_PRINTF_MODIFIER, symmat[i][j]);\n      if ((i * m + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\t\n\tint m = M;\n\tint n = N;\n\n\tPOLYBENCH_2D_ARRAY_DECL(data,DATA_TYPE,M,N,m,n);\n\tPOLYBENCH_2D_ARRAY_DECL(symmat,DATA_TYPE,M,M,m,m);\n\tPOLYBENCH_1D_ARRAY_DECL(mean,DATA_TYPE,M,m);\n\tPOLYBENCH_2D_ARRAY_DECL(symmat_outputFromGpu,DATA_TYPE,M,M,m,m);\t\n\n\tinit_arrays(m, n, POLYBENCH_ARRAY(data));\n    \n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(data), POLYBENCH_ARRAY(symmat), POLYBENCH_ARRAY(mean));\n\tcl_load_prog();\n\n\tcl_launch_kernel(m, n);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, symmat_mem_obj, CL_TRUE, 0, M * N * sizeof(DATA_TYPE), POLYBENCH_ARRAY(symmat_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");   \n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tcovariance(m, n, POLYBENCH_ARRAY(data), POLYBENCH_ARRAY(symmat), POLYBENCH_ARRAY(mean));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(m, n, POLYBENCH_ARRAY(symmat), POLYBENCH_ARRAY(symmat_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(m, POLYBENCH_ARRAY(symmat_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\t\n\tPOLYBENCH_FREE_ARRAY(data);\n\tPOLYBENCH_FREE_ARRAY(symmat);\n\tPOLYBENCH_FREE_ARRAY(mean);\n\tPOLYBENCH_FREE_ARRAY(symmat_outputFromGpu);\t\n\t\n\treturn 0;\n}\n\n#include <polybench.c>", "covariance.cl": "/**\n * covariance.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n__kernel void mean_kernel(__global DATA_TYPE *mean, __global DATA_TYPE *data, DATA_TYPE float_n, int m, int n) \n{    \t \n\tint j = get_global_id(0);\n\t\n\tif (j < m)\n\t{\n\t\tmean[j] = 0.0;\n\n\t\tint i;\n\t\tfor(i = 0; i < n; i++)\n\t\t{\n\t\t\tmean[j] += data[i * m + j];\n\t\t}\n\t\tmean[j] /= (DATA_TYPE)float_n;\n\t}\n}\n\n__kernel void reduce_kernel(__global DATA_TYPE *mean, __global DATA_TYPE *data, int m, int n) \n{\n\tint j = get_global_id(0);    \n\tint i = get_global_id(1);\n\n\tif ((i < n) && (j < m))\n\t{\n\t\tdata[i * m + j] -= mean[j];\t\n\t}\n}\n\n\n__kernel void covar_kernel(__global DATA_TYPE *symmat, __global DATA_TYPE *data, int m, int n) \n{\n\tint j1 = get_global_id(0);\n\tint i, j2;\n\n\tif (j1 < m)\n\t{\n\t\tfor (j2 = j1; j2 < m; j2++)\n\t\t{\t\t\n\t      \t\tsymmat[j1*m + j2] = 0.0;\n\t\t\tfor(i = 0; i < n; i++)\n\t\t\t{\n\t\t\t\tsymmat[j1 * m + j2] += data[i * m + j1] * data[i * m + j2];\n\t\t\t}\n\t\t\tsymmat[j2 * m + j1] = symmat[j1 * m + j2];\n\t\t}\n\t}\n}\n\n"}, "code_dirs": {"covariance.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/datamining/covariance", "covariance.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/datamining/covariance"}}
{"kernel_name": "doitgen", "parallel_api": "cuda", "code": {"doitgen.cu": "/**\n * doitgen.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"doitgen.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_doitgenCpu(int nr, int nq, int np,\n\t\t    DATA_TYPE POLYBENCH_3D(A,NR,NQ,NP,nr,nq,np),\n\t\t    DATA_TYPE POLYBENCH_2D(C4,NP,NP,np,np),\n\t\t    DATA_TYPE POLYBENCH_3D(sum,NR,NQ,NP,nr,nq,np))\n{\n\tint r, q, p, s;\n\n\tfor (r = 0; r < _PB_NR; r++)\n\t{\n\t\tfor (q = 0; q < _PB_NQ; q++)  \n\t\t{\n\t\t\tfor (p = 0; p < _PB_NP; p++)  \n\t\t\t{\n\t\t\t\tsum[r][q][p] = 0;\n\t\t\t\tfor (s = 0; s < _PB_NP; s++)\n\t\t\t\t\tsum[r][q][p] = sum[r][q][p] + A[r][q][s] * C4[s][p];\n\t\t\t}\n\t\t\tfor (p = 0; p < _PB_NR; p++)\n\t\t\t\tA[r][q][p] = sum[r][q][p];\n\t\t}\n\t}\n\n}\n\n\n\n/* Array initialization. */\nvoid init_array(int nr, int nq, int np,\n\t\tDATA_TYPE POLYBENCH_3D(A,NR,NQ,NP,nr,nq,np),\n\t\tDATA_TYPE POLYBENCH_2D(C4,NP,NP,np,np))\n{\n\tint i, j, k;\n\n\tfor (i = 0; i < nr; i++)\n\t\tfor (j = 0; j < nq; j++)\n\t\t\tfor (k = 0; k < np; k++)\n\t\t\t\tA[i][j][k] = ((DATA_TYPE) i*j + k) / np;\n\n\tfor (i = 0; i < np; i++)\n\t\tfor (j = 0; j < np; j++)\n\t\t\tC4[i][j] = ((DATA_TYPE) i*j) / np;\n}\n\n\nvoid compareResults(int nr, int nq, int np, DATA_TYPE POLYBENCH_3D(sum,NR,NQ,NP,nr,nq,np), \n\t\t\tDATA_TYPE POLYBENCH_3D(sum_outputFromGpu,NR,NQ,NP,nr,nq,np))\n{\n\tint fail = 0;\n\t\n\tfor (int r = 0; r < nr; r++)\n\t{\n    \t\tfor (int q = 0; q < nq; q++)  \n\t\t{\n      \t\t\tfor (int p = 0; p < np; p++)  \n\t\t\t{\n\t\t\t\tif (percentDiff(sum[r][q][p], sum_outputFromGpu[r][q][p]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t\t{\n\t\t\t\t\tfail++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Number of misses: %d\\n\", fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void doitgen_kernel1(int nr, int nq, int np, DATA_TYPE *sum, DATA_TYPE *A, DATA_TYPE *C4, int r)\n{\n\tint p = blockIdx.x * blockDim.x + threadIdx.x;\n\tint q = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((p < np) && (q < nq))\n\t{\n\t\tsum[r * (nq * np) + q * np + p] = (DATA_TYPE)0.0;\n\t\n\t\tfor (int s = 0; s < np; s++)\n\t\t{\n\t\t\tsum[r * (nq * np) + q * np + p] = sum[r * (nq * np) + q * np + p] + A[r * (nq * np) + q * np + s] * C4[s * np + p];\n\t\t}\n\t}\n}\n\n__global__ void doitgen_kernel2(int nr, int nq, int np, DATA_TYPE *sum, DATA_TYPE *A, DATA_TYPE *C4, int r)\n{\n\tint p = blockIdx.x * blockDim.x + threadIdx.x;\n\tint q = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((p < np) && (q < nq))\n\t{\n\t\tA[r * (nq * np) + q * np + p] = sum[r * (nq * np) + q * np + p];\n\t}\n}\n\nvoid doitgenCuda(int nr, int nq, int np,\n\t\t    DATA_TYPE POLYBENCH_3D(A,NR,NQ,NP,nr,nq,np),\n\t\t    DATA_TYPE POLYBENCH_2D(C4,NP,NP,np,np),\n\t\t    DATA_TYPE POLYBENCH_3D(sum_outputFromGpu,NR,NQ,NP,nr,nq,np))\n{\n\tDATA_TYPE* AGpu;\n\tDATA_TYPE* C4Gpu;\n\tDATA_TYPE* sumGpu;\n\n\tcudaMalloc(&AGpu, nr * nq * np * sizeof(DATA_TYPE));\n\tcudaMalloc(&C4Gpu, np * np * sizeof(DATA_TYPE));\n\tcudaMalloc(&sumGpu, nr * nq * np * sizeof(DATA_TYPE));\n\n\tcudaMemcpy(AGpu, A, nr * nq * np * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\tcudaMemcpy(C4Gpu, C4, np * np * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\tcudaMemcpy(sumGpu, sum_outputFromGpu, nr * nq * np * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((unsigned int)ceil( ((float)np) / ((float)block.x) ), (unsigned int)ceil( ((float)nr) / ((float)block.y) ));\n\n\t/* Start timer. */\n\tpolybench_start_instruments;\t\n\n\tfor (int r = 0; r < nr; r++)\n\t{\n\t\tdoitgen_kernel1 <<<grid, block>>> (nr, nq, np, sumGpu, AGpu, C4Gpu, r);\n\t\tcudaThreadSynchronize();\n\t\tdoitgen_kernel2 <<<grid, block>>> (nr, nq, np, sumGpu, AGpu, C4Gpu, r);\n\t\tcudaThreadSynchronize();\n\t}\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n\tpolybench_print_instruments;\n\t\t\n\tcudaMemcpy(sum_outputFromGpu, sumGpu, NR * NQ * NP * sizeof(DATA_TYPE), cudaMemcpyDeviceToHost);\n\n\tcudaFree(AGpu);\n\tcudaFree(C4Gpu);\n\tcudaFree(sumGpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int nr, int nq, int np,\n\t\t DATA_TYPE POLYBENCH_3D(A,NR,NQ,NP,nr,nq,np))\n{\n\tint i, j, k;\n\n\tfor (i = 0; i < nr; i++)\n\t{\n\t\tfor (j = 0; j < nq; j++)\n\t\t{\n\t\t\tfor (k = 0; k < np; k++) \n\t\t\t{\n\t\t\t\tfprintf (stderr, DATA_PRINTF_MODIFIER, A[i][j][k]);\n\t\t\t\tif (i % 20 == 0) fprintf (stderr, \"\\n\");\n\t\t\t}\n\t\t}\n\t}\n\tfprintf (stderr, \"\\n\");\n}\n\t\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint nr = NR;\n\tint nq = NQ;\n\tint np = NP;\n\n\t/* Variable declaration/allocation. */\n\tPOLYBENCH_3D_ARRAY_DECL(A,DATA_TYPE,NR,NQ,NP,nr,nq,np);\n\tPOLYBENCH_3D_ARRAY_DECL(sum,DATA_TYPE,NR,NQ,NP,nr,nq,np);\n\tPOLYBENCH_3D_ARRAY_DECL(sum_outputFromGpu,DATA_TYPE,NR,NQ,NP,nr,nq,np);\n\tPOLYBENCH_2D_ARRAY_DECL(C4,DATA_TYPE,NP,NP,np,np);\n\n\t/* Initialize array(s). */\n\tinit_array (nr, nq, np,\n\t      POLYBENCH_ARRAY(A),\n\t      POLYBENCH_ARRAY(C4));\n\n\tdoitgenCuda(nr, nq, np,\n\t\tPOLYBENCH_ARRAY(A),\n\t\tPOLYBENCH_ARRAY(C4),\n\t\tPOLYBENCH_ARRAY(sum_outputFromGpu));\n\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\t/* Run kernel on CPU */\n\t\tkernel_doitgenCpu(nr, nq, np,\n\t\t  POLYBENCH_ARRAY(A),\n\t\t  POLYBENCH_ARRAY(C4),\n\t\t  POLYBENCH_ARRAY(sum));\t\n\t\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n  \t\tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(nr, nq, np, POLYBENCH_ARRAY(sum), POLYBENCH_ARRAY(sum_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(nr, nq, np, POLYBENCH_ARRAY(sum_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\t/* Garbage collection */\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(sum);\n\tPOLYBENCH_FREE_ARRAY(sum_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(C4);\t\n    \n\treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"doitgen.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/doitgen"}}
{"kernel_name": "doitgen", "parallel_api": "ocl", "code": {"doitgen.c": "/**\n * doitgen.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n#define POLYBENCH_TIME 1\n\n#include \"doitgen.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n\nchar str_temp[1024];\n\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\ncl_mem c_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n/* Main computational kernel. The whole function will be timed,\n   including the call and return. */\nvoid kernel_doitgenCpu(int nr, int nq, int np,\n\t\t    DATA_TYPE POLYBENCH_3D(A,NR,NQ,NP,nr,nq,np),\n\t\t    DATA_TYPE POLYBENCH_2D(C4,NP,NP,np,np),\n\t\t    DATA_TYPE POLYBENCH_3D(sum,NR,NQ,NP,nr,nq,np))\n{\n\tint r, q, p, s;\n\n\tfor (r = 0; r < _PB_NR; r++)\n\t{\n\t\tfor (q = 0; q < _PB_NQ; q++)  \n\t\t{\n\t\t\tfor (p = 0; p < _PB_NP; p++)  \n\t\t\t{\n\t\t\t\tsum[r][q][p] = 0;\n\t\t\t\tfor (s = 0; s < _PB_NP; s++)\n\t\t\t\t\tsum[r][q][p] = sum[r][q][p] + A[r][q][s] * C4[s][p];\n\t\t\t}\n\t\t\tfor (p = 0; p < _PB_NR; p++)\n\t\t\t\tA[r][q][p] = sum[r][q][p];\n\t\t}\n\t}\n\n}\n\n\n\n/* Array initialization. */\nvoid init_array(int nr, int nq, int np,\n\t\tDATA_TYPE POLYBENCH_3D(A,NR,NQ,NP,nr,nq,np),\n\t\tDATA_TYPE POLYBENCH_2D(C4,NP,NP,np,np))\n{\n\tint i, j, k;\n\n\tfor (i = 0; i < nr; i++)\n\t\tfor (j = 0; j < nq; j++)\n\t\t\tfor (k = 0; k < np; k++)\n\t\t\t\tA[i][j][k] = ((DATA_TYPE) i*j + k) / np;\n\n\tfor (i = 0; i < np; i++)\n\t\tfor (j = 0; j < np; j++)\n\t\t\tC4[i][j] = ((DATA_TYPE) i*j) / np;\n}\n\n\nvoid compareResults(int nr, int nq, int np, DATA_TYPE POLYBENCH_3D(sum,NR,NQ,NP,nr,nq,np), \n\t\t\tDATA_TYPE POLYBENCH_3D(sum_outputFromGpu,NR,NQ,NP,nr,nq,np))\n{\n\tint fail = 0;\n\t\n\tint r, q, p;\n\tfor (r = 0; r < nr; r++)\n\t{\n    \t\tfor (q = 0; q < nq; q++)  \n\t\t{\n      \t\t\tfor (p = 0; p < np; p++)  \n\t\t\t{\n\t\t\t\tif (percentDiff(sum[r][q][p], sum_outputFromGpu[r][q][p]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t\t{\n\t\t\t\t\tfail++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Number of misses: %d\\n\", fail);\n}\n\n\n\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"doitgen.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\n\n\nvoid cl_initialization()\n{\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"device id is %d\\n\",device_id);\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_3D(A,NR,NQ,NP,nr,nq,np),\n\t\t    DATA_TYPE POLYBENCH_2D(C4,NP,NP,np,np),\n\t\t    DATA_TYPE POLYBENCH_3D(sum,NR,NQ,NP,nr,nq,np))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, NR * NQ * NP * sizeof(DATA_TYPE), NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, NP * NP * sizeof(DATA_TYPE), NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\tc_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, NR * NQ * NP * sizeof(DATA_TYPE), NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, NR * NQ * NP * sizeof(DATA_TYPE), A, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n\terrcode = clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, NP * NP * sizeof(DATA_TYPE), C4, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n\terrcode = clEnqueueWriteBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, NR * NQ * NP * sizeof(DATA_TYPE), sum, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"doitgen_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\tclKernel2 = clCreateKernel(clProgram, \"doitgen_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel2\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel1(int nr, int nq, int np, int r)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NP) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NQ) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(int), (void *)&nr);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(int), (void *)&nq);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(int), (void *)&np);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 5, sizeof(cl_mem), (void *)&c_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 6, sizeof(int), (void *)&r);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel2(int nr, int nq, int np, int r)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NP) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NQ) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(int), (void *)&nr);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(int), (void *)&nq);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(int), (void *)&np);\n\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 4, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 5, sizeof(cl_mem), (void *)&c_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 6, sizeof(int), (void *)&r);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseMemObject(c_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int nr, int nq, int np,\n\t\t DATA_TYPE POLYBENCH_3D(A,NR,NQ,NP,nr,nq,np))\n{\n\tint i, j, k;\n\n\tfor (i = 0; i < nr; i++)\n\t{\n\t\tfor (j = 0; j < nq; j++)\n\t\t{\n\t\t\tfor (k = 0; k < np; k++) \n\t\t\t{\n\t\t\t\tfprintf (stderr, DATA_PRINTF_MODIFIER, A[i][j][k]);\n\t\t\t\tif (i % 20 == 0) fprintf (stderr, \"\\n\");\n\t\t\t}\n\t\t}\n\t}\n\tfprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint nr = NR;\n\tint nq = NQ;\n\tint np = NP;\n\n\t/* Variable declaration/allocation. */\n\tPOLYBENCH_3D_ARRAY_DECL(A,DATA_TYPE,NR,NQ,NP,nr,nq,np);\n\tPOLYBENCH_3D_ARRAY_DECL(sum,DATA_TYPE,NR,NQ,NP,nr,nq,np);\n\tPOLYBENCH_3D_ARRAY_DECL(sum_outputFromGpu,DATA_TYPE,NR,NQ,NP,nr,nq,np);\n\tPOLYBENCH_2D_ARRAY_DECL(C4,DATA_TYPE,NP,NP,np,np);\n\n\t/* Initialize array(s). */\n\tinit_array (nr, nq, np,\n\t      POLYBENCH_ARRAY(A),\n\t      POLYBENCH_ARRAY(C4));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(C4), POLYBENCH_ARRAY(sum));\n\tcl_load_prog();\n\n\t/* Start timer. */\n\tpolybench_start_instruments;\n\n\n\tint r;\n\tfor (r = 0; r < NR; r++)\n\t{\n\t\tcl_launch_kernel1(nr, nq, np, r);\n\t\tcl_launch_kernel2(nr, nq, np, r);\n\t}\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n\tpolybench_stop_instruments;\n\tpolybench_print_instruments;\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, NR * NQ * NP * sizeof(DATA_TYPE), sum_outputFromGpu, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\t/* Run kernel on CPU */\n\t\tkernel_doitgenCpu(nr, nq, np,\n\t\t  POLYBENCH_ARRAY(A),\n\t\t  POLYBENCH_ARRAY(C4),\n\t\t  POLYBENCH_ARRAY(sum));\t\n\t\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n  \t\tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(nr, nq, np, POLYBENCH_ARRAY(sum), POLYBENCH_ARRAY(sum_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(nr, nq, np, POLYBENCH_ARRAY(sum_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tcl_clean_up();\n\n\t/* Garbage collection */\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(sum);\n\tPOLYBENCH_FREE_ARRAY(sum_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(C4);\t\n\n\treturn 0;\n}\n\n#include <polybench.c>\n", "doitgen.cl": "/**\n * doitgen.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n/* Can switch DATA_TYPE between float and double */\ntypedef float DATA_TYPE;\n\n\n__kernel void doitgen_kernel1(int nr, int nq, int np, __global DATA_TYPE *A, __global DATA_TYPE *C4, __global DATA_TYPE *sum, int r)\n{\n\tint p = get_global_id(0);\n\tint q = get_global_id(1);\n\n\tif ((p < np) && (q < nq))\n\t{\n\t\tsum[r * (nq * np) + q * np + p] = (DATA_TYPE)0.0;\n\t\n\t\tfor (int s = 0; s < np; s++)\n\t\t{\n\t\t\tsum[r * (nq * np) + q * np + p] = sum[r * (nq * np) + q * np + p] + A[r * (nq * np) + q * np + s] * C4[s * np + p];\n\t\t}\n\t}\n}\n\n__kernel void doitgen_kernel2(int nr, int nq, int np, __global DATA_TYPE *A, __global DATA_TYPE *C4, __global DATA_TYPE *sum, int r)\n{\n\tint p = get_global_id(0);\n\tint q = get_global_id(1);\n\n\tif ((p < np) && (q < nq))\n\t{\n\t\tA[r * (nq * np) + q * np + p] = sum[r * (nq * np) + q * np + p];\n\t}\n}\n"}, "code_dirs": {"doitgen.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/doitgen", "doitgen.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/doitgen"}}
{"kernel_name": "gemm", "parallel_api": "cuda", "code": {"gemm.cu": "/**\n * gemm.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"gemm.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n#define GPU_DEVICE 0\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define RUN_ON_CPU\n\n\nvoid gemm(int ni, int nj, int nk, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk), \n\t DATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj), DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj))\n{\n\tint i,j,k;\n\t\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n    \t\tfor (j = 0; j < _PB_NJ; j++)\n    \t\t{\n\t\t\tC[i][j] *= beta;\n\t\n\t\t\tfor (k = 0; k < _PB_NK; ++k)\n\t\t\t{\n\t  \t\t\tC[i][j] += alpha * A[i][k] * B[k][j];\n\t\t\t}\n      \t\t}\n\t}\n}\n\n\nvoid init(int ni, int nj, int nk, DATA_TYPE* alpha, DATA_TYPE* beta, DATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk), \n\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj), DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj))\n{\n\tint i, j;\n\n\t*alpha = 32412;\n\t*beta = 2123;\n\n  \tfor (i = 0; i < ni; i++)\n\t{\n    \t\tfor (j = 0; j < nk; j++)\n\t\t{\n      \t\t\tA[i][j] = ((DATA_TYPE) i*j) / NI;\n\t\t}\n\t}\n\n  \tfor (i = 0; i < nk; i++)\n\t{\n    \t\tfor (j = 0; j < nj; j++)\n\t\t{\n      \t\t\tB[i][j] = ((DATA_TYPE) i*j) / NI;\n\t\t}\n\t}\n\n  \tfor (i = 0; i < ni; i++)\n\t{\n    \t\tfor (j = 0; j < nj; j++)\n\t\t{\n      \t\t\tC[i][j] = ((DATA_TYPE) i*j) / NI;\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int ni, int nj, DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(C_outputFromGpu,NI,NJ,ni,nj))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\t// Compare CPU and GPU outputs\n\tfor (i=0; i < ni; i++) \n\t{\n\t\tfor (j=0; j < nj; j++) \n\t\t{\n\t\t\tif (percentDiff(C[i][j], C_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void gemm_kernel(int ni, int nj, int nk, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *a, DATA_TYPE *b, DATA_TYPE *c)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < _PB_NI) && (j < _PB_NJ))\n\t{\t\n\t\tc[i * NJ + j] *= beta;\n\t\tint k;\n\t\tfor(k=0; k < _PB_NK; k++)\n\t\t{\n\t\t\tc[i * NJ + j] += alpha * a[i * NK + k] * b[k * NJ +j];\n\t\t}\n\t}\n}\n\n\nvoid gemmCuda(int ni, int nj, int nk, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk), \n\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj), DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(C_outputFromGpu,NI,NJ,ni,nj))\n{\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *B_gpu;\n\tDATA_TYPE *C_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NI * NK);\n\tcudaMalloc((void **)&B_gpu, sizeof(DATA_TYPE) * NK * NJ);\n\tcudaMalloc((void **)&C_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\t\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NI * NK, cudaMemcpyHostToDevice);\n\tcudaMemcpy(B_gpu, B, sizeof(DATA_TYPE) * NK * NJ, cudaMemcpyHostToDevice);\n\tcudaMemcpy(C_gpu, C, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyHostToDevice);\n\t\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((size_t)(ceil( ((float)NI)/ ((float)block.x) )),(size_t)(ceil( ((float)NJ)/ ((float)block.y) )));\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tgemm_kernel<<< grid, block >>>(ni, nj, nk, alpha, beta, A_gpu, B_gpu, C_gpu);\n\tcudaThreadSynchronize();\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tcudaMemcpy(C_outputFromGpu, C_gpu, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyDeviceToHost);    \n\t\n\tcudaFree(A_gpu);\n\tcudaFree(B_gpu);\n\tcudaFree(C_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nj,\n\t\t DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nj; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, C[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\tint nk = NK;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NK,ni,nk);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,NK,NJ,nk,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(C,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(C_outputFromGpu,DATA_TYPE,NI,NJ,ni,nj);\n\n\tinit(ni, nj, nk, &alpha, &beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n\t\n\tGPU_argv_init();\n\t\n\tgemmCuda(ni, nj, nk, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(C_outputFromGpu));\n\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tgemm(ni, nj, nk, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n\t\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n  \t\tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(ni, nj, POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(C_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nj, POLYBENCH_ARRAY(C_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);  \n\tPOLYBENCH_FREE_ARRAY(C);  \n\tPOLYBENCH_FREE_ARRAY(C_outputFromGpu); \n\n    \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"gemm.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/gemm"}}
{"kernel_name": "gemm", "parallel_api": "ocl", "code": {"gemm.c": "/**\n * gemm.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"gemm.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\ncl_mem c_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int ni, int nj, DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(C_outputFromGpu,NI,NJ,ni,nj))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\t// Compare CPU and GPU outputs\n\tfor (i=0; i < ni; i++) \n\t{\n\t\tfor (j=0; j < nj; j++) \n\t\t{\n\t\t\tif (percentDiff(C[i][j], C_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"gemm.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init(int ni, int nj, int nk, DATA_TYPE* alpha, DATA_TYPE* beta, DATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk), \n\tDATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj), DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj))\n{\n\tint i, j;\n\n\t*alpha = 32412;\n\t*beta = 2123;\n\n  \tfor (i = 0; i < ni; i++)\n\t{\n    \t\tfor (j = 0; j < nk; j++)\n\t\t{\n      \t\t\tA[i][j] = ((DATA_TYPE) i*j) / NI;\n\t\t}\n\t}\n\n  \tfor (i = 0; i < nk; i++)\n\t{\n    \t\tfor (j = 0; j < nj; j++)\n\t\t{\n      \t\t\tB[i][j] = ((DATA_TYPE) i*j) / NI;\n\t\t}\n\t}\n\n  \tfor (i = 0; i < ni; i++)\n\t{\n    \t\tfor (j = 0; j < nj; j++)\n\t\t{\n      \t\t\tC[i][j] = ((DATA_TYPE) i*j) / NI;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk), DATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj), DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NK, NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NK * NJ, NULL, &errcode);\n\tc_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NK, A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NK * NJ, B, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NJ, C, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel = clCreateKernel(clProgram, \"gemm\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int ni, int nj, int nk, DATA_TYPE alpha, DATA_TYPE beta)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NJ) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NI) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel, 2, sizeof(cl_mem), (void *)&c_mem_obj);\n\terrcode |= clSetKernelArg(clKernel, 3, sizeof(DATA_TYPE), (void *)&alpha);\n\terrcode |= clSetKernelArg(clKernel, 4, sizeof(DATA_TYPE), (void *)&beta);\n\terrcode |= clSetKernelArg(clKernel, 5, sizeof(int), (void *)&ni);\n\terrcode |= clSetKernelArg(clKernel, 6, sizeof(int), (void *)&nj);\n\terrcode |= clSetKernelArg(clKernel, 7, sizeof(int), (void *)&nk);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseMemObject(c_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid gemm(int ni, int nj, int nk, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A,NI,NK,ni,nk), \n\t DATA_TYPE POLYBENCH_2D(B,NK,NJ,nk,nj), DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj))\n{\n\tint i,j,k;\n\t\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n    \t\tfor (j = 0; j < _PB_NJ; j++)\n    \t\t{\n\t\t\tC[i][j] *= beta;\n\t\n\t\t\tfor (k = 0; k < _PB_NK; ++k)\n\t\t\t{\n\t  \t\t\tC[i][j] += alpha * A[i][k] * B[k][j];\n\t\t\t}\n      \t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nj,\n\t\t DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nj; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, C[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\tint nk = NK;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NK,ni,nk);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,NK,NJ,nk,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(C,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(C_outputFromGpu,DATA_TYPE,NI,NJ,ni,nj);\n\n\tinit(ni, nj, nk, &alpha, &beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n\tcl_load_prog();\n\n\tcl_launch_kernel(ni, nj, nk, alpha, beta);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, NI*NJ*sizeof(DATA_TYPE), POLYBENCH_ARRAY(C_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tgemm(ni, nj, nk, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ni, nj, POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(C_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nj, POLYBENCH_ARRAY(C_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);  \n\tPOLYBENCH_FREE_ARRAY(C);  \n\tPOLYBENCH_FREE_ARRAY(C_outputFromGpu); \n\n\treturn 0;\n}\n\n#include <polybench.c>", "gemm.cl": "/**\n * gemm.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n\t\n__kernel void gemm(__global DATA_TYPE *a, __global DATA_TYPE *b, __global DATA_TYPE *c, DATA_TYPE alpha, DATA_TYPE beta, int ni, int nj, int nk) \n{\n    \tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\n\tif ((i < ni) && (j < nj))\n\t{\t\n\t\tc[i * nj + j] *= beta;\n\t\tint k;\n\t\tfor(k=0; k < nk; k++)\n\t\t{\n\t\t\tc[i * nj + j] += alpha * a[i * nk + k] * b[k * nj +j];\n\t\t}\n\t}\n}\n\n"}, "code_dirs": {"gemm.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/gemm", "gemm.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/gemm"}}
{"kernel_name": "gemver", "parallel_api": "cuda", "code": {"gemver.cu": "/**\n * gemver.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"gemver.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid gemver(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A, N, N, n, n), DATA_TYPE POLYBENCH_1D(u1, N, n), DATA_TYPE POLYBENCH_1D(v1, N, n), \n\tDATA_TYPE POLYBENCH_1D(u2, N, n), DATA_TYPE POLYBENCH_1D(v2, N, n), DATA_TYPE POLYBENCH_1D(w, N, n), DATA_TYPE POLYBENCH_1D(x, N, n), DATA_TYPE POLYBENCH_1D(y, N, n), \n\tDATA_TYPE POLYBENCH_1D(z, N, n))\n{\n\tint i,j;\n\t\n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n    \t\tfor (j = 0; j < _PB_N; j++)\n\t\t{\n      \t\t\tA[i][j] = A[i][j] + u1[i] * v1[j] + u2[i] * v2[j];\n\t\t}\n\t}\n\n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n    \t\tfor (j = 0; j < _PB_N; j++)\n\t\t{\n      \t\t\tx[i] = x[i] + beta * A[j][i] * y[j];\n\t\t}\n\t}\n\n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n    \t\tx[i] = x[i] + z[i];\n\t}\n\n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n    \t\tfor (j = 0; j < _PB_N; j++)\n\t\t{\n      \t\t\tw[i] = w[i] +  alpha * A[i][j] * x[j];\n\t\t}\n\t}\n}\n\n\nvoid init(int n, DATA_TYPE *alpha,\n\tDATA_TYPE *beta,\n\tDATA_TYPE POLYBENCH_2D(A,N,N,n,n),\n\tDATA_TYPE POLYBENCH_1D(u1,N,n),\n\tDATA_TYPE POLYBENCH_1D(v1,N,n),\n\tDATA_TYPE POLYBENCH_1D(u2,N,n),\n\tDATA_TYPE POLYBENCH_1D(v2,N,n),\n\tDATA_TYPE POLYBENCH_1D(w,N,n),\n\tDATA_TYPE POLYBENCH_1D(x,N,n),\n\tDATA_TYPE POLYBENCH_1D(y,N,n),\n\tDATA_TYPE POLYBENCH_1D(z,N,n))\n{\n\tint i, j;\n\n\t*alpha = 43532;\n\t*beta = 12313;\n\n  \tfor (i = 0; i < N; i++)\n\t{\n\t    \tu1[i] = i;\n\t    \tu2[i] = (i+1)/N/2.0;\n\t    \tv1[i] = (i+1)/N/4.0;\n\t    \tv2[i] = (i+1)/N/6.0;\n\t    \ty[i] = (i+1)/N/8.0;\n\t    \tz[i] = (i+1)/N/9.0;\n\t    \tx[i] = 0.0;\n\t    \tw[i] = 0.0;\n\n    \t\tfor (j = 0; j < N; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / N;\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_1D(w1, N, n), DATA_TYPE POLYBENCH_1D(w2, N, n))\n{\n\tint i, fail;\n\tfail = 0;\n\t\n\tfor (i=0; i < N; i++) \n\t{\n\t\tif (percentDiff(w1[i], w2[i]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\t\t\n\t// Print results\n\tprintf(\"Number of misses: %d\\n\", fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void gemver_kernel1(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *a, DATA_TYPE *v1, DATA_TYPE *v2, DATA_TYPE *u1, DATA_TYPE *u2)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < _PB_N) && (j < _PB_N))\n\t{\n\t\ta[i * N + j] += u1[i] * v1[j] + u2[i] * v2[j];\n\t}\n}\n\n\n__global__ void gemver_kernel2(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *a, DATA_TYPE *x, DATA_TYPE *y, DATA_TYPE *z)\n{\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i < _PB_N)\n\t{\n\t\tint j;\n\t\tfor(j = 0; j < _PB_N; j++) \n\t\t{\n\t\t\tx[i] += beta * a[j * N + i] * y[j];\n\t\t}\n\t\tx[i] += z[i];\n\t}\n}\n\n\n__global__ void gemver_kernel3(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *a, DATA_TYPE *x, DATA_TYPE *w)\n{\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif ((i >= 0) && (i < _PB_N))\n\t{\n\t\tint j;\n\t\tfor(j = 0; j < _PB_N; j++)\n\t\t{ \n\t\t\tw[i] += alpha * a[i*N + j] * x[j];\n\t\t}\n\t}\n}\n\n\nvoid gemverCuda(int n, DATA_TYPE alpha, DATA_TYPE beta,\n\t\tDATA_TYPE POLYBENCH_2D(A,N,N,n,n),\n\t\tDATA_TYPE POLYBENCH_1D(u1,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(v1,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(u2,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(v2,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(w,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(w_outputFromGpu,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(x,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(y,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(z,N,n))\n{\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *x_gpu;\n\tDATA_TYPE *y_gpu;\n\tDATA_TYPE *z_gpu;\n\tDATA_TYPE *v1_gpu;\n\tDATA_TYPE *v2_gpu;\n\tDATA_TYPE *u1_gpu;\n\tDATA_TYPE *u2_gpu;\n\tDATA_TYPE *w_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * N * N);\n\tcudaMalloc((void **)&x_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&y_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&z_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&w_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&v1_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&v2_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&u1_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&u2_gpu, sizeof(DATA_TYPE) * N);\n\t\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * N * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(x_gpu, x, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(y_gpu, y, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(z_gpu, z, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(w_gpu, w, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(v1_gpu, v1, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(v2_gpu, v2, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(u1_gpu, u1, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(u2_gpu, u2, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\n\tdim3 block1(DIM_THREAD_BLOCK_KERNEL_1_X, DIM_THREAD_BLOCK_KERNEL_1_Y);\n\tdim3 grid1((size_t)(ceil((float)N) / ((float)DIM_THREAD_BLOCK_KERNEL_1_X)), (size_t)(ceil((float)N) / ((float)DIM_THREAD_BLOCK_KERNEL_1_Y)));\n\n\tdim3 block2(DIM_THREAD_BLOCK_KERNEL_2_X, DIM_THREAD_BLOCK_KERNEL_2_Y);\n\tdim3 grid2((size_t)(ceil((float)N) / ((float)DIM_THREAD_BLOCK_KERNEL_2_X)), 1);\n\t\n\tdim3 block3(DIM_THREAD_BLOCK_KERNEL_3_X, DIM_THREAD_BLOCK_KERNEL_3_Y);\n\tdim3 grid3((size_t)(ceil((float)N) / ((float)DIM_THREAD_BLOCK_KERNEL_3_X)), 1);\n\t\n \t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tgemver_kernel1<<< grid1, block1 >>>(n, alpha, beta, A_gpu,v1_gpu,v2_gpu, u1_gpu, u2_gpu);\n\tcudaThreadSynchronize();\n\tgemver_kernel2<<< grid2, block2 >>>(n, alpha, beta, A_gpu,x_gpu,y_gpu, z_gpu);\n\tcudaThreadSynchronize();\n\tgemver_kernel3<<< grid3, block3 >>>(n, alpha, beta, A_gpu,x_gpu,w_gpu);\n\tcudaThreadSynchronize();\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tcudaMemcpy(w_outputFromGpu, w_gpu, sizeof(DATA_TYPE) * N, cudaMemcpyDeviceToHost);\n\t\n\tcudaFree(A_gpu);\n\tcudaFree(x_gpu);\n\tcudaFree(y_gpu);\n\tcudaFree(z_gpu);\n\tcudaFree(w_gpu);\n\tcudaFree(v1_gpu);\n\tcudaFree(v2_gpu);\n\tcudaFree(u1_gpu);\n\tcudaFree(u2_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_1D(w,N,n))\n{\n  int i;\n\n  for (i = 0; i < n; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, w[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n}\n\t\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint n = N;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_1D_ARRAY_DECL(u1,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(v1,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(u2,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(v2,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(w,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(w_outputFromGpu,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(x,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(y,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(z,DATA_TYPE,N,n);\n  \t\n\t\n\tinit(n, &alpha, &beta,\n\t      POLYBENCH_ARRAY(A),\n\t      POLYBENCH_ARRAY(u1),\n\t      POLYBENCH_ARRAY(v1),\n\t      POLYBENCH_ARRAY(u2),\n\t      POLYBENCH_ARRAY(v2),\n\t      POLYBENCH_ARRAY(w),\n\t      POLYBENCH_ARRAY(x),\n\t      POLYBENCH_ARRAY(y),\n\t      POLYBENCH_ARRAY(z));\n\t\n\tGPU_argv_init();\n\n\tgemverCuda(n, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(u1), POLYBENCH_ARRAY(v1), POLYBENCH_ARRAY(u2), POLYBENCH_ARRAY(v2), \n\t\tPOLYBENCH_ARRAY(w), POLYBENCH_ARRAY(w_outputFromGpu), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(z));\n\n\t#ifdef RUN_ON_CPU\n\n\t \t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\t\n\t\tgemver(n, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(u1), POLYBENCH_ARRAY(v1), POLYBENCH_ARRAY(u2), POLYBENCH_ARRAY(v2), \n\t\t\tPOLYBENCH_ARRAY(w), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(z));\n\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n  \t\tpolybench_stop_instruments;\n \t\tpolybench_print_instruments;\n\t\t\n\t\tcompareResults(n, POLYBENCH_ARRAY(w), POLYBENCH_ARRAY(w_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(w_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(w);  \n\tPOLYBENCH_FREE_ARRAY(w_outputFromGpu);  \n\tPOLYBENCH_FREE_ARRAY(x);  \n\tPOLYBENCH_FREE_ARRAY(y);\n\tPOLYBENCH_FREE_ARRAY(z);\n\tPOLYBENCH_FREE_ARRAY(u1);\n\tPOLYBENCH_FREE_ARRAY(u2);\n\tPOLYBENCH_FREE_ARRAY(v1);\n\tPOLYBENCH_FREE_ARRAY(v2);\n\n \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"gemver.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/gemver"}}
{"kernel_name": "gemver", "parallel_api": "ocl", "code": {"gemver.c": "/**\n * gemver.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"gemver.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_kernel clKernel3;\ncl_command_queue clCommandQue;\ncl_program clProgram;\n\ncl_mem a_mem_obj;\ncl_mem u1_mem_obj;\ncl_mem v1_mem_obj;\ncl_mem u2_mem_obj;\ncl_mem v2_mem_obj;\ncl_mem w_mem_obj;\ncl_mem x_mem_obj;\ncl_mem y_mem_obj;\ncl_mem z_mem_obj;\n\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_1D(w1, N, n), DATA_TYPE POLYBENCH_1D(w2, N, n))\n{\n\tint i, fail;\n\tfail = 0;\n\t\n\tfor (i=0; i < N; i++) \n\t{\n\t\tif (percentDiff(w1[i], w2[i]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\t\t\n\t// Print results\n\tprintf(\"Number of misses: %d\\n\", fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"gemver.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init(int n, DATA_TYPE *alpha,\n\tDATA_TYPE *beta,\n\tDATA_TYPE POLYBENCH_2D(A,N,N,n,n),\n\tDATA_TYPE POLYBENCH_1D(u1,N,n),\n\tDATA_TYPE POLYBENCH_1D(v1,N,n),\n\tDATA_TYPE POLYBENCH_1D(u2,N,n),\n\tDATA_TYPE POLYBENCH_1D(v2,N,n),\n\tDATA_TYPE POLYBENCH_1D(w,N,n),\n\tDATA_TYPE POLYBENCH_1D(x,N,n),\n\tDATA_TYPE POLYBENCH_1D(y,N,n),\n\tDATA_TYPE POLYBENCH_1D(z,N,n))\n{\n\tint i, j;\n\n\t*alpha = 43532;\n\t*beta = 12313;\n\n  \tfor (i = 0; i < N; i++)\n\t{\n\t    \tu1[i] = i;\n\t    \tu2[i] = (i+1)/N/2.0;\n\t    \tv1[i] = (i+1)/N/4.0;\n\t    \tv2[i] = (i+1)/N/6.0;\n\t    \ty[i] = (i+1)/N/8.0;\n\t    \tz[i] = (i+1)/N/9.0;\n\t    \tx[i] = 0.0;\n\t    \tw[i] = 0.0;\n\n    \t\tfor (j = 0; j < N; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / N;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\n\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"device id is %d\\n\",device_id);\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_1D(u1,N,n), DATA_TYPE POLYBENCH_1D(v1,N,n), DATA_TYPE POLYBENCH_1D(u2,N,n), \n\tDATA_TYPE POLYBENCH_1D(v2,N,n), DATA_TYPE POLYBENCH_1D(w,N,n), DATA_TYPE POLYBENCH_1D(x,N,n), DATA_TYPE POLYBENCH_1D(y,N,n), \n\tDATA_TYPE POLYBENCH_1D(z,N,n))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N * N, NULL, &errcode);\n\tu1_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\tv1_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\tu2_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\tv2_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\tw_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\tx_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\ty_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\tz_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N * N, A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, u1_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, u1, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, v1_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, v1, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, u2_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, u2, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, v2_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, v2, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, w_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, w, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, x_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, x, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, y_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, y, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, z_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, z, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"gemver_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\n\t// Create the OpenCL kernel\n\tclKernel2 = clCreateKernel(clProgram, \"gemver_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel2\\n\");\n\n\t// Create the OpenCL kernel\n\tclKernel3 = clCreateKernel(clProgram, \"gemver_kernel3\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel3\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int n, DATA_TYPE alpha, DATA_TYPE beta)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_KERNEL_1_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_KERNEL_1_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_1_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_1_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_1_Y)) * DIM_LOCAL_WORK_GROUP_KERNEL_1_Y;\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&v1_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&v2_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(cl_mem), (void *)&u1_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(cl_mem), (void *)&u2_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 5, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\tsize_t global_item_size = sizeof(DATA_TYPE) * N; \n\tsize_t local_item_size = 64; \n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\n\tint dim = N;\n\t\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_KERNEL_2_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_KERNEL_2_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_2_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_2_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_2_Y)) * DIM_LOCAL_WORK_GROUP_KERNEL_2_Y;\n\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(cl_mem), (void *)&y_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(cl_mem), (void *)&z_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 4, sizeof(DATA_TYPE), (void *)&beta);\n\terrcode |= clSetKernelArg(clKernel2, 5, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments2\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel2\\n\");\n\tclEnqueueBarrier(clCommandQue);\n\t\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_KERNEL_3_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_KERNEL_3_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_3_X)) * DIM_LOCAL_WORK_GROUP_KERNEL_3_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_KERNEL_3_Y)) * DIM_LOCAL_WORK_GROUP_KERNEL_3_Y;\n\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel3, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel3, 1, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel3, 2, sizeof(cl_mem), (void *)&w_mem_obj);\n\terrcode |= clSetKernelArg(clKernel3, 3, sizeof(DATA_TYPE), (void *)&alpha);\n\terrcode |= clSetKernelArg(clKernel3, 4, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments3\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel3, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel3\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseKernel(clKernel3);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(u1_mem_obj);\n\terrcode = clReleaseMemObject(v1_mem_obj);\n\terrcode = clReleaseMemObject(u2_mem_obj);\n\terrcode = clReleaseMemObject(v2_mem_obj);\n\terrcode = clReleaseMemObject(w_mem_obj);\n\terrcode = clReleaseMemObject(x_mem_obj);\n\terrcode = clReleaseMemObject(y_mem_obj);\n\terrcode = clReleaseMemObject(z_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid gemver(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A, N, N, n, n), DATA_TYPE POLYBENCH_1D(u1, N, n), DATA_TYPE POLYBENCH_1D(v1, N, n), \n\tDATA_TYPE POLYBENCH_1D(u2, N, n), DATA_TYPE POLYBENCH_1D(v2, N, n), DATA_TYPE POLYBENCH_1D(w, N, n), DATA_TYPE POLYBENCH_1D(x, N, n), DATA_TYPE POLYBENCH_1D(y, N, n), \n\tDATA_TYPE POLYBENCH_1D(z, N, n))\n{\n\tint i,j;\n\t\n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n    \t\tfor (j = 0; j < _PB_N; j++)\n\t\t{\n      \t\t\tA[i][j] = A[i][j] + u1[i] * v1[j] + u2[i] * v2[j];\n\t\t}\n\t}\n\n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n    \t\tfor (j = 0; j < _PB_N; j++)\n\t\t{\n      \t\t\tx[i] = x[i] + beta * A[j][i] * y[j];\n\t\t}\n\t}\n\n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n    \t\tx[i] = x[i] + z[i];\n\t}\n\n  \tfor (i = 0; i < _PB_N; i++)\n\t{\n    \t\tfor (j = 0; j < _PB_N; j++)\n\t\t{\n      \t\t\tw[i] = w[i] +  alpha * A[i][j] * x[j];\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_1D(w,N,n))\n{\n  int i;\n\n  for (i = 0; i < n; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, w[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint n = N;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_1D_ARRAY_DECL(u1,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(v1,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(u2,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(v2,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(w,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(w_outputFromGpu,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(x,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(y,DATA_TYPE,N,n);\n  \tPOLYBENCH_1D_ARRAY_DECL(z,DATA_TYPE,N,n);\n\t\n\tinit(n, &alpha, &beta,\n\t      POLYBENCH_ARRAY(A),\n\t      POLYBENCH_ARRAY(u1),\n\t      POLYBENCH_ARRAY(v1),\n\t      POLYBENCH_ARRAY(u2),\n\t      POLYBENCH_ARRAY(v2),\n\t      POLYBENCH_ARRAY(w),\n\t      POLYBENCH_ARRAY(x),\n\t      POLYBENCH_ARRAY(y),\n\t      POLYBENCH_ARRAY(z));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(u1), POLYBENCH_ARRAY(v1), POLYBENCH_ARRAY(u2), POLYBENCH_ARRAY(v2),\n\t      POLYBENCH_ARRAY(w), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(z));\n\n\tcl_load_prog();\n\tcl_launch_kernel(n, alpha, beta);\n\terrcode = clEnqueueReadBuffer(clCommandQue, w_mem_obj, CL_TRUE, 0, N*sizeof(DATA_TYPE), POLYBENCH_ARRAY(w_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\t#if RUN_ON_CPU\n\t\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tgemver(n, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(u1), POLYBENCH_ARRAY(v1), POLYBENCH_ARRAY(u2), POLYBENCH_ARRAY(v2), \n\t\t\tPOLYBENCH_ARRAY(w), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(z));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n  \t\tpolybench_stop_instruments;\n \t\tpolybench_print_instruments;\n\n\t\tcompareResults(n, POLYBENCH_ARRAY(w), POLYBENCH_ARRAY(w_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(w_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\t\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(u1);\n\tPOLYBENCH_FREE_ARRAY(v1);\n\tPOLYBENCH_FREE_ARRAY(u2);\n\tPOLYBENCH_FREE_ARRAY(v2);\n\tPOLYBENCH_FREE_ARRAY(w);  \n\tPOLYBENCH_FREE_ARRAY(w_outputFromGpu);  \n\tPOLYBENCH_FREE_ARRAY(x);  \n\tPOLYBENCH_FREE_ARRAY(y);\n\tPOLYBENCH_FREE_ARRAY(z);\n\t\n\t\n    return 0;\n}\n\n#include <polybench.c>", "gemver.cl": "/**\n * gemver.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n\t\n__kernel void gemver_kernel1(__global DATA_TYPE *A, __global DATA_TYPE *V1, __global DATA_TYPE *V2, __global DATA_TYPE *U1, __global DATA_TYPE *U2, int n) \n{    \n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < n) && (j < n))\n\t{\n\t\tA[i*n + j] += U1[i] * V1[j] + U2[i] * V2[j];\n\t}\n}\n\n\n__kernel void gemver_kernel2(__global DATA_TYPE *A, __global DATA_TYPE *X, __global DATA_TYPE *Y, __global DATA_TYPE *Z, DATA_TYPE beta, int n) \n{    \n\tint i = get_global_id(0);\n\n\tif (i < n)\n\t{\n\t\tint j;\n\t\tfor(j = 0; j < n; j++) \n\t\t{\n\t\t\tX[i] += beta * A[j * n + i] * Y[j];\n\t\t}\n\t\tX[i] += Z[i];\n\t}\n}\n\n\n__kernel void gemver_kernel3(__global DATA_TYPE *A, __global DATA_TYPE *X, __global DATA_TYPE *w, DATA_TYPE alpha, int n) \n{    \n\tint i = get_global_id(0);\n\t\n\tif (i < n)\n\t{\n\t\tint j;\n\t\tfor(j = 0; j < n; j++)\n\t\t{ \n\t\t\tw[i] += alpha * A[i*n + j] * X[j];\n\t\t}\n\t}\n}\n"}, "code_dirs": {"gemver.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/gemver", "gemver.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/gemver"}}
{"kernel_name": "gesummv", "parallel_api": "cuda", "code": {"gesummv.cu": "/**\n * gesummv.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"gesummv.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n/* Declared constant values for ALPHA and BETA (same as values in PolyBench 2.0) */\n#define ALPHA 43532.0f\n#define BETA 12313.0f\n\n#define RUN_ON_CPU\n\n\nvoid gesummv(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_1D(tmp,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(x,N,n), DATA_TYPE POLYBENCH_1D(y,N,n))\n{\n\tint i, j;\n\t\n\tfor (i = 0; i < _PB_N; i++)\n\t{\n\t\ttmp[i] = 0;\n\t\ty[i] = 0;\n\t\tfor (j = 0; j < _PB_N; j++)\n\t\t{\n\t\t\ttmp[i] = A[i][j] * x[j] + tmp[i];\n\t\t\ty[i] = B[i][j] * x[j] + y[i];\n\t\t}\n\t\t\n\t\ty[i] = alpha * tmp[i] + beta * y[i];\n\t}\n}\n\n\nvoid init(int n, DATA_TYPE *alpha, DATA_TYPE *beta, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), \n\tDATA_TYPE POLYBENCH_1D(x,N,n))\n{\n  \tint i, j;\n\n\t*alpha = 43532;\n\t*beta = 12313;\n\n \tfor (i = 0; i < n; i++)\n    \t{\n    \t\tx[i] = ((DATA_TYPE) i) / N;\n      \t\n\t\tfor (j = 0; j < n; j++) \n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / N;\n\t\t\tB[i][j] = ((DATA_TYPE) i*j) / n;\n\t\t}\n    }\n}\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_1D(y,N,n), DATA_TYPE POLYBENCH_1D(y_outputFromGpu,N,n))\n{\n\tint i, fail;\n\tfail = 0;\n\t\n\tfor (i=0; i<n; i++) \n\t{\n\t\tif (percentDiff(y[i], y_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void gesummv_kernel(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE* A, DATA_TYPE* B, DATA_TYPE* tmp, DATA_TYPE* x, DATA_TYPE* y)\n{\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i < _PB_N)\n\t{\n\t\tint j;\n\t\tfor(j = 0; j < _PB_N; j++)\n\t\t{\t\n\t\t\ttmp[i] += A[i * N + j] * x[j];\n\t\t\ty[i] += B[i * N + j] * x[j];\n\t\t}\n\t\ty[i] = alpha * tmp[i] + beta  * y[i];\n\t}\n}\n\nvoid gesummvCuda(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), \n\t\tDATA_TYPE POLYBENCH_1D(tmp,N,n), DATA_TYPE POLYBENCH_1D(x,N,n), DATA_TYPE POLYBENCH_1D(y,N,n),  \n\t\tDATA_TYPE POLYBENCH_1D(y_outputFromGpu,N,n))\n{\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *B_gpu;\n\tDATA_TYPE *x_gpu;\n\tDATA_TYPE *y_gpu;\n\tDATA_TYPE *tmp_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * N * N);\n\tcudaMalloc((void **)&B_gpu, sizeof(DATA_TYPE) * N * N);\n\tcudaMalloc((void **)&x_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&y_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&tmp_gpu, sizeof(DATA_TYPE) * N);\n\t\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * N * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(B_gpu, B, sizeof(DATA_TYPE) * N * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(x_gpu, x, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(y_gpu, y, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(tmp_gpu, tmp, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((unsigned int)ceil( ((float)N) / ((float)block.x) ), 1);\n\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tgesummv_kernel<<< grid, block>>>(n, alpha, beta, A_gpu, B_gpu, tmp_gpu, x_gpu, y_gpu);\n\tcudaThreadSynchronize();\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tcudaMemcpy(y_outputFromGpu, y_gpu, sizeof(DATA_TYPE) * N, cudaMemcpyDeviceToHost);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_1D(y,N,n))\n\n{\n  int i;\n\n  for (i = 0; i < n; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, y[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint n = N;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_1D_ARRAY_DECL(tmp,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(y,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(y_outputFromGpu,DATA_TYPE,N,n);\n\n\tinit(n, &alpha, &beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(x));\n\t\n\tGPU_argv_init();\n\tgesummvCuda(n, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(tmp), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y),  \n\t\tPOLYBENCH_ARRAY(y_outputFromGpu));\n\t\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tgesummv(n, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(tmp), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y));\n\t\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(n, POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(y_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(y_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);  \n\tPOLYBENCH_FREE_ARRAY(tmp);\n\tPOLYBENCH_FREE_ARRAY(x);  \n\tPOLYBENCH_FREE_ARRAY(y);\n\tPOLYBENCH_FREE_ARRAY(y_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"gesummv.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/gesummv"}}
{"kernel_name": "gesummv", "parallel_api": "ocl", "code": {"gesummv.c": "/**\n * gesummv.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"gesummv.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_kernel clKernel3;\ncl_command_queue clCommandQue;\ncl_program clProgram;\n\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\ncl_mem x_mem_obj;\ncl_mem y_mem_obj;\ncl_mem tmp_mem_obj;\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_1D(y,N,n), DATA_TYPE POLYBENCH_1D(y_outputFromGpu,N,n))\n{\n\tint i, fail;\n\tfail = 0;\n\t\n\tfor (i=0; i<n; i++) \n\t{\n\t\tif (percentDiff(y[i], y_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid init(int n, DATA_TYPE *alpha, DATA_TYPE *beta, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), \n\tDATA_TYPE POLYBENCH_1D(x,N,n))\n{\n  \tint i, j;\n\n\t*alpha = 43532;\n\t*beta = 12313;\n\n \tfor (i = 0; i < n; i++)\n    \t{\n    \t\tx[i] = ((DATA_TYPE) i) / N;\n      \t\n\t\tfor (j = 0; j < n; j++) \n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / N;\n\t\t\tB[i][j] = ((DATA_TYPE) i*j) / n;\n\t\t}\n\t}\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"gesummv.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid gesummv(int n, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_1D(tmp,N,n),\n\t\tDATA_TYPE POLYBENCH_1D(x,N,n), DATA_TYPE POLYBENCH_1D(y,N,n))\n{\n\tint i, j;\n\t\n\tfor (i = 0; i < _PB_N; i++)\n\t{\n\t\ttmp[i] = 0;\n\t\ty[i] = 0;\n\t\tfor (j = 0; j < _PB_N; j++)\n\t\t{\n\t\t\ttmp[i] = A[i][j] * x[j] + tmp[i];\n\t\t\ty[i] = B[i][j] * x[j] + y[i];\n\t\t}\n\t\t\n\t\ty[i] = alpha * tmp[i] + beta * y[i];\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_1D(x,N,n), \n\tDATA_TYPE POLYBENCH_1D(y,N,n), DATA_TYPE POLYBENCH_1D(tmp,N,n))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N * N, NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N * N, NULL, &errcode);\n\tx_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\ty_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\ttmp_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N * N, A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N * N, B, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, x_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, x, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, y_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, y, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, tmp_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, tmp, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"gesummv_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int n, DATA_TYPE alpha, DATA_TYPE beta)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(cl_mem), (void *)&y_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(cl_mem), (void *)&tmp_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 5, sizeof(DATA_TYPE), (void *)&alpha);\n\terrcode |= clSetKernelArg(clKernel1, 6, sizeof(DATA_TYPE), (void *)&beta);\n\terrcode |= clSetKernelArg(clKernel1, 7, sizeof(int), (void *)&n);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseMemObject(x_mem_obj);\n\terrcode = clReleaseMemObject(y_mem_obj);\n\terrcode = clReleaseMemObject(tmp_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_1D(y,N,n))\n\n{\n  int i;\n\n  for (i = 0; i < n; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, y[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint n = N;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_1D_ARRAY_DECL(tmp,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(y,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(y_outputFromGpu,DATA_TYPE,N,n);\n\n\tinit(n, &alpha, &beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(x));\n\t\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(tmp));\n\tcl_load_prog();\n\n\tcl_launch_kernel(n, alpha, beta);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, y_mem_obj, CL_TRUE, 0, N*sizeof(DATA_TYPE), POLYBENCH_ARRAY(y_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tgesummv(n, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(tmp), POLYBENCH_ARRAY(x), POLYBENCH_ARRAY(y));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(n, POLYBENCH_ARRAY(y), POLYBENCH_ARRAY(y_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(y_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tcl_clean_up();\n\t\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);  \n\tPOLYBENCH_FREE_ARRAY(tmp);\n\tPOLYBENCH_FREE_ARRAY(x);  \n\tPOLYBENCH_FREE_ARRAY(y);\n\tPOLYBENCH_FREE_ARRAY(y_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>", "gesummv.cl": "/**\n * gesummv.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n\t\n__kernel void gesummv_kernel(__global DATA_TYPE *a, __global DATA_TYPE *b, __global DATA_TYPE *x, __global DATA_TYPE *y, __global DATA_TYPE *tmp, DATA_TYPE alpha, DATA_TYPE beta, int n) \n{    \n\tint i = get_global_id(0);\n\n\tif (i < n)\n\t{\n\t\tint j;\n\t\tfor(j = 0; j < n; j++)\n\t\t{\t\n\t\t\ttmp[i] += a[i * n + j] * x[j];\n\t\t\ty[i] += b[i * n + j] * x[j];\n\t\t}\n\t\ty[i] = alpha * tmp[i] + beta * y[i];\n\t}\n}\n\n"}, "code_dirs": {"gesummv.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/gesummv", "gesummv.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/gesummv"}}
{"kernel_name": "mvt", "parallel_api": "cuda", "code": {"mvt.cu": "/**\n * mvt.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <unistd.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"mvt.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_2D(A, N, N, n, n), DATA_TYPE POLYBENCH_1D(x1, N, n), DATA_TYPE POLYBENCH_1D(x2, N, n), DATA_TYPE POLYBENCH_1D(y1, N, n), DATA_TYPE POLYBENCH_1D(y2, N, n))\n{\n\tint i, j;\n\n\tfor (i = 0; i < n; i++)\n\t{\n\t\tx1[i] = ((DATA_TYPE) i) / N;\n\t\tx2[i] = ((DATA_TYPE) i + 1) / N;\n\t\ty1[i] = ((DATA_TYPE) i + 3) / N;\n\t\ty2[i] = ((DATA_TYPE) i + 4) / N;\n\t\tfor (j = 0; j < n; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / N;\n\t\t}\n\t}\n}\n\n\n\nvoid runMvt(int n, DATA_TYPE POLYBENCH_2D(a, N, N, n, n), DATA_TYPE POLYBENCH_1D(x1, N, n), DATA_TYPE POLYBENCH_1D(x2, N, n), DATA_TYPE POLYBENCH_1D(y1, N, n), DATA_TYPE POLYBENCH_1D(y2, N, n))\n{\n\tint i, j;\n\t\n\tfor (i=0; i<_PB_N; i++) \n\t{\n\t\tfor (j=0; j<N; j++) \n\t\t{\n       \t\tx1[i] = x1[i] + a[i][j] * y1[j];\n        \t}\n    \t}\n\t\n\tfor (i=0; i<_PB_N; i++) \n\t{\n\t\tfor (j=0; j<_PB_N; j++) \n\t\t{\n \t\t      \tx2[i] = x2[i] + a[j][i] * y2[j];\n      \t\t}\n    \t}\n}\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_1D(x1, N, n), DATA_TYPE POLYBENCH_1D(x1_outputFromGpu, N, n), DATA_TYPE POLYBENCH_1D(x2, N, n), DATA_TYPE POLYBENCH_1D(x2_outputFromGpu, N, n))\n{\n\tint i, fail;\n\tfail = 0;\n\t\n\tfor (i=0; i<n; i++) \n\t{\n\t\tif (percentDiff(x1[i], x1_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\n\n\t\tif (percentDiff(x2[i], x2_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void mvt_kernel1(int n, DATA_TYPE *a, DATA_TYPE *x1, DATA_TYPE *y_1)\n{\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i < _PB_N)\n\t{\n\t\tint j;\n\t\tfor(j=0; j < _PB_N; j++)\n\t\t{\n\t\t\tx1[i] += a[i * N + j] * y_1[j];\n\t\t}\n\t}\n}\n\n\n__global__ void mvt_kernel2(int n, DATA_TYPE *a, DATA_TYPE *x2, DATA_TYPE *y_2)\n{\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i < _PB_N)\n\t{\n\t\tint j;\n\t\tfor(j=0; j < _PB_N; j++)\n\t\t{\n\t\t\tx2[i] += a[j * N + i] * y_2[j];\t\n\t\t}\n\t}\n}\n\nvoid mvtCuda(int n, DATA_TYPE POLYBENCH_2D(a, N, N, n, n), DATA_TYPE POLYBENCH_1D(x1, N, n), DATA_TYPE POLYBENCH_1D(x2, N, n), DATA_TYPE POLYBENCH_1D(y_1, N, n), DATA_TYPE POLYBENCH_1D(y_2, N, n), \n\t\t\tDATA_TYPE POLYBENCH_1D(x1_outputFromGpu, N, n), DATA_TYPE POLYBENCH_1D(x2_outputFromGpu, N, n))\n{\n\tDATA_TYPE* a_gpu;\n\tDATA_TYPE* x1_gpu;\n\tDATA_TYPE* x2_gpu;\n\tDATA_TYPE* y_1_gpu;\n\tDATA_TYPE* y_2_gpu;\n\n\tcudaMalloc((void **)&a_gpu, sizeof(DATA_TYPE) * N * N);\n\tcudaMalloc((void **)&x1_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&x2_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&y_1_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMalloc((void **)&y_2_gpu, sizeof(DATA_TYPE) * N);\n\tcudaMemcpy(a_gpu, a, sizeof(DATA_TYPE) * N * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(x1_gpu, x1, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(x2_gpu, x2, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(y_1_gpu, y_1, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\tcudaMemcpy(y_2_gpu, y_2, sizeof(DATA_TYPE) * N, cudaMemcpyHostToDevice);\n\t\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((size_t)ceil((float)N/ ((float)DIM_THREAD_BLOCK_X)), 1);\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\tmvt_kernel1<<<grid,block>>>(n, a_gpu,x1_gpu,y_1_gpu);\n\tmvt_kernel2<<<grid,block>>>(n, a_gpu,x2_gpu,y_2_gpu);\n\tcudaThreadSynchronize();\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\t\n\tcudaMemcpy(x1_outputFromGpu, x1_gpu, sizeof(DATA_TYPE) * N, cudaMemcpyDeviceToHost);\n\tcudaMemcpy(x2_outputFromGpu, x2_gpu, sizeof(DATA_TYPE) * N, cudaMemcpyDeviceToHost);    \n\t\n\tcudaFree(a_gpu);\n\tcudaFree(x1_gpu);\n\tcudaFree(x2_gpu);\n\tcudaFree(y_1_gpu);\n\tcudaFree(y_2_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_1D(x1,N,n),\n\t\t DATA_TYPE POLYBENCH_1D(x2,N,n))\n\n{\n  int i;\n\n  for (i = 0; i < n; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, x1[i]);\n    fprintf (stderr, DATA_PRINTF_MODIFIER, x2[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint n = N;\n\n\tPOLYBENCH_2D_ARRAY_DECL(a,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x1,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x2,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x1_outputFromGpu,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x2_outputFromGpu,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(y_1,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(y_2,DATA_TYPE,N,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(x1), POLYBENCH_ARRAY(x2), POLYBENCH_ARRAY(y_1), POLYBENCH_ARRAY(y_2));\n\t\n\tGPU_argv_init();\n\n\tmvtCuda(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(x1), POLYBENCH_ARRAY(x2), POLYBENCH_ARRAY(y_1), POLYBENCH_ARRAY(y_2), POLYBENCH_ARRAY(x1_outputFromGpu), POLYBENCH_ARRAY(x2_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\t\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\t//run the algorithm on the CPU\n\t\trunMvt(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(x1), POLYBENCH_ARRAY(x2), POLYBENCH_ARRAY(y_1), POLYBENCH_ARRAY(y_2));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(n, POLYBENCH_ARRAY(x1), POLYBENCH_ARRAY(x1_outputFromGpu), POLYBENCH_ARRAY(x2), POLYBENCH_ARRAY(x2_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(x1_outputFromGpu), POLYBENCH_ARRAY(x2_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tPOLYBENCH_FREE_ARRAY(a);\n\tPOLYBENCH_FREE_ARRAY(x1);\n\tPOLYBENCH_FREE_ARRAY(x2);\n\tPOLYBENCH_FREE_ARRAY(x1_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(x2_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(y_1);\n\tPOLYBENCH_FREE_ARRAY(y_2);\n\n  \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"mvt.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/mvt"}}
{"kernel_name": "mvt", "parallel_api": "ocl", "code": {"mvt.c": "/**\n * mvt.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"mvt.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_command_queue clCommandQue;\ncl_program clProgram;\n\ncl_mem a_mem_obj;\ncl_mem x1_mem_obj;\ncl_mem x2_mem_obj;\ncl_mem y1_mem_obj;\ncl_mem y2_mem_obj;\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\nconst int LIST_SIZE = N;\nchar str_temp[1024];\n\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_1D(x1, N, n), DATA_TYPE POLYBENCH_1D(x1_outputFromGpu, N, n), DATA_TYPE POLYBENCH_1D(x2, N, n), DATA_TYPE POLYBENCH_1D(x2_outputFromGpu, N, n))\n{\n\tint i, fail;\n\tfail = 0;\n\t\n\tfor (i=0; i<n; i++) \n\t{\n\t\tif (percentDiff(x1[i], x1_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\n\n\t\tif (percentDiff(x2[i], x2_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"mvt.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stdout, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_2D(A, N, N, n, n), DATA_TYPE POLYBENCH_1D(x1, N, n), DATA_TYPE POLYBENCH_1D(x2, N, n), DATA_TYPE POLYBENCH_1D(y1, N, n), DATA_TYPE POLYBENCH_1D(y2, N, n))\n{\n\tint i, j;\n\n\tfor (i = 0; i < n; i++)\n\t{\n\t\tx1[i] = ((DATA_TYPE) i) / N;\n\t\tx2[i] = ((DATA_TYPE) i + 1) / N;\n\t\ty1[i] = ((DATA_TYPE) i + 3) / N;\n\t\ty2[i] = ((DATA_TYPE) i + 4) / N;\n\t\tfor (j = 0; j < n; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / N;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(a,N,N,n,n), DATA_TYPE POLYBENCH_1D(x1,N,n), DATA_TYPE POLYBENCH_1D(x2,N,n), \n\tDATA_TYPE POLYBENCH_1D(y_1,N,n), DATA_TYPE POLYBENCH_1D(y_2,N,n))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N * N, NULL, &errcode);\n\tx1_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\tx2_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\ty1_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\ty2_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * N, NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N * N, a, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, x1_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, x1, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, x2_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, x2, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, y1_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, y_1, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, y2_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * N, y_2, 0, NULL, NULL);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program %d\\n\",errcode);\n\t\t\n\t// Create the 1st OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"mvt_kernel1\", &errcode);\n\t// Create the 2nd OpenCL kernel\n\tclKernel2 = clCreateKernel(clProgram, \"mvt_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&x1_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&y1_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n \n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&x2_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(cl_mem), (void *)&y2_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\n\tclFinish(clCommandQue);\n\t\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(x1_mem_obj);\n\terrcode = clReleaseMemObject(x2_mem_obj);\n\terrcode = clReleaseMemObject(y1_mem_obj);\n\terrcode = clReleaseMemObject(y2_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid runMvt(int n, DATA_TYPE POLYBENCH_2D(a, N, N, n, n), DATA_TYPE POLYBENCH_1D(x1, N, n), DATA_TYPE POLYBENCH_1D(x2, N, n), DATA_TYPE POLYBENCH_1D(y1, N, n), DATA_TYPE POLYBENCH_1D(y2, N, n))\n{\n\tint i, j;\n\t\n\tfor (i=0; i<_PB_N; i++) \n\t{\n\t\tfor (j=0; j<N; j++) \n\t\t{\n       \t\tx1[i] = x1[i] + a[i][j] * y1[j];\n        \t}\n    \t}\n\t\n\tfor (i=0; i<_PB_N; i++) \n\t{\n\t\tfor (j=0; j<_PB_N; j++) \n\t\t{\n \t\t      \tx2[i] = x2[i] + a[j][i] * y2[j];\n      \t\t}\n    \t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_1D(x1,N,n),\n\t\t DATA_TYPE POLYBENCH_1D(x2,N,n))\n\n{\n  int i;\n\n  for (i = 0; i < n; i++) {\n    fprintf (stderr, DATA_PRINTF_MODIFIER, x1[i]);\n    fprintf (stderr, DATA_PRINTF_MODIFIER, x2[i]);\n    if (i % 20 == 0) fprintf (stderr, \"\\n\");\n  }\n}\n\n\n\nint main(int argc, char *argv[])\n{\n\tint n = N;\n\n\tPOLYBENCH_2D_ARRAY_DECL(a,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x1,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x2,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x1_outputFromGpu,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(x2_outputFromGpu,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(y_1,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(y_2,DATA_TYPE,N,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(x1), POLYBENCH_ARRAY(x2), POLYBENCH_ARRAY(y_1), POLYBENCH_ARRAY(y_2));\n\t\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(x1), POLYBENCH_ARRAY(x2), POLYBENCH_ARRAY(y_1), POLYBENCH_ARRAY(y_2));\n\tcl_load_prog();\n\n\tcl_launch_kernel(n);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, x1_mem_obj, CL_TRUE, 0, N*sizeof(DATA_TYPE), POLYBENCH_ARRAY(x1_outputFromGpu), 0, NULL, NULL);\n\terrcode = clEnqueueReadBuffer(clCommandQue, x2_mem_obj, CL_TRUE, 0, N*sizeof(DATA_TYPE), POLYBENCH_ARRAY(x2_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");   \n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\trunMvt(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(x1), POLYBENCH_ARRAY(x2), POLYBENCH_ARRAY(y_1), POLYBENCH_ARRAY(y_2));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\t\n\n\t\tcompareResults(n, POLYBENCH_ARRAY(x1), POLYBENCH_ARRAY(x1_outputFromGpu), POLYBENCH_ARRAY(x2), POLYBENCH_ARRAY(x2_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(x1_outputFromGpu), POLYBENCH_ARRAY(x2_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(a);\n\tPOLYBENCH_FREE_ARRAY(x1);\n\tPOLYBENCH_FREE_ARRAY(x2);\n\tPOLYBENCH_FREE_ARRAY(x1_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(x2_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(y_1);\n\tPOLYBENCH_FREE_ARRAY(y_2);\n\n\treturn 0;\n}\n\n#include <polybench.c>", "mvt.cl": "/**\n * mvt.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n\n__kernel void mvt_kernel1(__global DATA_TYPE *a, __global DATA_TYPE *x1, __global DATA_TYPE *y1, int n) \n{    \n\tint i = get_global_id(0);\n\n\tif (i < n)\n\t{\n\t\tint j;\t\n\t\tfor (j=0; j < n; j++)\n\t\t{\n\t\t\tx1[i] += a[i * n + j] * y1[j];\n\t\t}\n\t}\n}\n\n__kernel void mvt_kernel2(__global DATA_TYPE *a, __global DATA_TYPE *x2, __global DATA_TYPE *y2, int n) \n{    \n\tint i = get_global_id(0);\n\n\tif (i < n)\n\t{\n\t\tint j;\t\n\t\tfor (j=0; j < n; j++)\n\t\t{\n\t\t\tx2[i] += a[j * n + i] * y2[j];\t\n\t\t}\n\t}\n}\n"}, "code_dirs": {"mvt.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/mvt", "mvt.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/mvt"}}
{"kernel_name": "syr2k", "parallel_api": "cuda", "code": {"syr2k.cu": "/**\n * syr2k.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <unistd.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"syr2k.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid init_arrays(int ni, int nj,\n\t\tDATA_TYPE *alpha,\n\t\tDATA_TYPE *beta,\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(B,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni))\n{\n\tint i, j;\n\n\t*alpha = 32412;\n\t*beta = 2123;\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++) \n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t\tB[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < ni; j++)\n\t\t{\n\t\t\tC[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n}\n\n\nvoid syr2kCpu(int ni, int nj,\n\t\t  DATA_TYPE alpha,\n\t\t  DATA_TYPE beta,\n\t\t  DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj),\n\t\t  DATA_TYPE POLYBENCH_2D(B,NI,NJ,ni,nj),\n\t\t  DATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni))\n{\n\tint i, j, k;\n\n\t/*    C := alpha*A*B' + alpha*B*A' + beta*C */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NI; j++)\n\t\t{\n\t\t\tC[i][j] *= beta;\n\t\t}\n\t}\n\t\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NI; j++)\n\t\t{\n\t\t\tfor (k = 0; k < _PB_NJ; k++)\n\t\t\t{\n\t\t\t\tC[i][j] += alpha * A[i][k] * B[j][k];\n\t\t\t\tC[i][j] += alpha * B[i][k] * A[j][k];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int ni, DATA_TYPE POLYBENCH_2D(C, NI, NI, ni, ni), DATA_TYPE POLYBENCH_2D(C_outputFromGpu, NI, NI, ni, ni))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\t// Compare C with D\n\tfor (i=0; i<ni; i++)\n\t{\n\t\tfor (j=0; j<ni; j++)\n\t\t{\n\t\t\tif (percentDiff(C[i][j], C_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{ \n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void syr2k_kernel(int ni, int nj, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *a, DATA_TYPE *b, DATA_TYPE *c)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < NI) && (j < NI))\n\t{\n\t\tc[i * NI + j] *= beta;\n\t\t\n\t\tint k;\n\t\tfor(k = 0; k < NJ; k++)\n\t\t{\n\t\t\tc[i * NI + j] += alpha * a[i * NJ + k] * b[j * NJ + k] + alpha * b[i * NJ + k] * a[j * NJ + k];\n\t\t}\n\t}\n}\n\n\nvoid syr2kCuda(int ni, int nj, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(B, NI, NJ, ni, nj), \n\t\tDATA_TYPE POLYBENCH_2D(C, NI, NI, ni, ni), DATA_TYPE POLYBENCH_2D(C_outputFromGpu, NI, NI, ni, ni)) \n{\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *B_gpu;\n\tDATA_TYPE *C_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\tcudaMalloc((void **)&B_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\tcudaMalloc((void **)&C_gpu, sizeof(DATA_TYPE) * NI * NI);\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyHostToDevice);\n\tcudaMemcpy(B_gpu, B, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyHostToDevice);\n\tcudaMemcpy(C_gpu, C, sizeof(DATA_TYPE) * NI * NI, cudaMemcpyHostToDevice);\n\t\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((size_t)ceil( ((float)NI) / ((float)DIM_THREAD_BLOCK_X) ), (size_t)(ceil( ((float)NI) / ((float)DIM_THREAD_BLOCK_Y) )));\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tsyr2k_kernel<<<grid,block>>>(ni, nj, alpha, beta, A_gpu, B_gpu, C_gpu);\n\tcudaThreadSynchronize();\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\t\t\n\tcudaMemcpy(C_outputFromGpu, C_gpu, sizeof(DATA_TYPE) * NI * NI, cudaMemcpyDeviceToHost);\n\n\tcudaFree(A_gpu);\n\tcudaFree(B_gpu);\n\tcudaFree(C_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, DATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < ni; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, C[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(C,DATA_TYPE,NI,NI,ni,ni);\n\tPOLYBENCH_2D_ARRAY_DECL(C_outputFromGpu,DATA_TYPE,NI,NI,ni,ni);\n\n\tinit_arrays(ni, nj, &alpha, &beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n    \n\tGPU_argv_init();\n\t\n\tsyr2kCuda(ni, nj, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(C_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start time for CPU */\n\t  \tpolybench_start_instruments;\n\n\t\tsyr2kCpu(ni, nj, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(ni, POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(C_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, POLYBENCH_ARRAY(C_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(C);\n\tPOLYBENCH_FREE_ARRAY(C_outputFromGpu);\n\n  \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"syr2k.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/syr2k"}}
{"kernel_name": "syr2k", "parallel_api": "ocl", "code": {"syr2k.c": "/**\n * syr2k.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"syr2k.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\nDATA_TYPE acc;\n\nDATA_TYPE ALPHA = 1;\nDATA_TYPE BETA = 1;\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_kernel clKernel3;\ncl_command_queue clCommandQue;\ncl_program clProgram;\n\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\ncl_mem c_mem_obj;\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int ni, DATA_TYPE POLYBENCH_2D(C, NI, NI, ni, ni), DATA_TYPE POLYBENCH_2D(C_outputFromGpu, NI, NI, ni, ni))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\t// Compare C with D\n\tfor (i=0; i<ni; i++)\n\t{\n\t\tfor (j=0; j<ni; j++)\n\t\t{\n\t\t\tif (percentDiff(C[i][j], C_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{ \n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"syr2k.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_arrays(int ni, int nj,\n\t\tDATA_TYPE *alpha,\n\t\tDATA_TYPE *beta,\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(B,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni))\n{\n\tint i, j;\n\n\t*alpha = 32412;\n\t*beta = 2123;\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++) \n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t\tB[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < ni; j++)\n\t\t{\n\t\t\tC[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(B,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(C,NI,NJ,ni,nj))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, NI*NJ*sizeof(DATA_TYPE), NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, NI*NJ*sizeof(DATA_TYPE), NULL, &errcode);\n\tc_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, NI*NI*sizeof(DATA_TYPE), NULL, &errcode);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, NI*NJ*sizeof(DATA_TYPE), A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, NI*NJ*sizeof(DATA_TYPE), B, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, NI*NI*sizeof(DATA_TYPE), C, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"syr2k_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int ni, int nj, DATA_TYPE alpha, DATA_TYPE beta)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NI) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NJ) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode =  clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&c_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(DATA_TYPE), (void *)&alpha);\n\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(DATA_TYPE), (void *)&beta);\n\terrcode |= clSetKernelArg(clKernel1, 5, sizeof(int), (void *)&ni);\n\terrcode |= clSetKernelArg(clKernel1, 6, sizeof(int), (void *)&nj);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in setting arguments1\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\tclFinish(clCommandQue);\n\t\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseMemObject(c_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid syr2kCpu(int ni, int nj,\n\t\t  DATA_TYPE alpha,\n\t\t  DATA_TYPE beta,\n\t\t  DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj),\n\t\t  DATA_TYPE POLYBENCH_2D(B,NI,NJ,ni,nj),\n\t\t  DATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni))\n{\n\tint i, j, k;\n\n\t/*    C := alpha*A*B' + alpha*B*A' + beta*C */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NI; j++)\n\t\t{\n\t\t\tC[i][j] *= beta;\n\t\t}\n\t}\n\t\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NI; j++)\n\t\t{\n\t\t\tfor (k = 0; k < _PB_NJ; k++)\n\t\t\t{\n\t\t\t\tC[i][j] += alpha * A[i][k] * B[j][k];\n\t\t\t\tC[i][j] += alpha * B[i][k] * A[j][k];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, DATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < ni; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, C[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(C,DATA_TYPE,NI,NI,ni,ni);\n\tPOLYBENCH_2D_ARRAY_DECL(C_outputFromGpu,DATA_TYPE,NI,NI,ni,ni);\n\n\tinit_arrays(ni, nj, &alpha, &beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n\tcl_load_prog();\n\n\tcl_launch_kernel(ni, nj, alpha, beta);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, NI*NJ*sizeof(DATA_TYPE), POLYBENCH_ARRAY(C_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tsyr2kCpu(ni, nj, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(C));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ni, POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(C_outputFromGpu));\n\t\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, POLYBENCH_ARRAY(C_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(C);\n\tPOLYBENCH_FREE_ARRAY(C_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>", "syr2k.cl": "/**\n * syr2k.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n__kernel void syr2k_kernel(__global DATA_TYPE *a, __global DATA_TYPE *b, __global DATA_TYPE *c, DATA_TYPE alpha, DATA_TYPE beta, int ni, int nj) \n{    \n   \tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\n\tif ((i < nj) && (j < nj))\n\t{\n\t\tc[i * nj + j] *= beta;\n\t\t\n\t\tint k;\n\t\tfor(k = 0; k < ni; k++)\n\t\t{\n\t\t\tc[i * nj + j] += alpha * a[i * ni + k] * b[j * ni + k] + alpha * b[i * ni + k] * a[j * ni + k];\n\t\t}\n\t}\n}\n\n\n"}, "code_dirs": {"syr2k.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/syr2k", "syr2k.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/syr2k"}}
{"kernel_name": "syrk", "parallel_api": "cuda", "code": {"syrk.cu": "/**\n * syrk.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <unistd.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"syrk.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid init_arrays(int ni, int nj,\n\t\tDATA_TYPE *alpha,\n\t\tDATA_TYPE *beta,\n\t\tDATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni),\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj))\n{\n\tint i, j;\n\n\t*alpha = 32412;\n\t*beta = 2123;\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < ni; j++)\n\t\t{\n\t\t\tC[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n}\n\n\nvoid syrk(int ni, int nj, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(C, NI, NI, ni, ni))\n{\n\tint i, j, k;\n\t\n\t/*  C := alpha*A*A' + beta*C */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NI; j++)\n\t\t{\n\t\t\tC[i][j] *= beta;\n\t\t}\n\t}\n\t\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NI; j++)\n\t\t{\n\t\t\tfor (k = 0; k < _PB_NJ; k++)\n\t\t\t{\n\t\t\t\tC[i][j] += alpha * A[i][k] * A[j][k];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int ni, DATA_TYPE POLYBENCH_2D(C, NI, NI, ni, ni), DATA_TYPE POLYBENCH_2D(C_outputFromGpu, NI, NI, ni, ni))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\t// Compare C with D\n\tfor (i=0; i<ni; i++)\n\t{\n\t\tfor (j=0; j<ni; j++)\n\t\t{\n\t\t\tif (percentDiff(C[i][j], C_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n\t\n\treturn;\n}\n\n\n__global__ void syrk_kernel(int ni, int nj, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE *a, DATA_TYPE *c)\n{\n\t/*  C := alpha*A*A' + beta*C */\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < _PB_NI) && (j < _PB_NI))\n\t{\n\t\tc[i * NI + j] *= beta;\n\t\tint k;\t\t\n\t\tfor(k=0; k < _PB_NJ; k++)\n\t\t{\n\t\t\tc[i * NI + j] += alpha * a[i * NJ + k] * a[j * NJ + k];\n\t\t}\n\t}\n}\n\n\nvoid syrkCuda(int ni, int nj, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(C, NI, NI, ni, ni), \n\t\tDATA_TYPE POLYBENCH_2D(C_outputFromGpu, NI, NI, ni, ni))\n{\n\tDATA_TYPE* A_gpu;\n\tDATA_TYPE* C_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\tcudaMalloc((void **)&C_gpu, sizeof(DATA_TYPE) * NI * NI);\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyHostToDevice);\n\tcudaMemcpy(C_gpu, C, sizeof(DATA_TYPE) * NI * NI, cudaMemcpyHostToDevice);\n\t\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((size_t)(ceil(((float)NI) / ((float)DIM_THREAD_BLOCK_X))), (size_t)ceil(((float)NI) / ((float)DIM_THREAD_BLOCK_Y)));\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tsyrk_kernel<<<grid,block>>>(ni, nj, alpha, beta, A_gpu,C_gpu);\n\tcudaThreadSynchronize();\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tcudaMemcpy(C_outputFromGpu, C_gpu, sizeof(DATA_TYPE) * NI * NI, cudaMemcpyDeviceToHost);\n\n\tcudaFree(A_gpu);\n\tcudaFree(C_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, DATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < ni; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, C[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,ni,nj);\n  \tPOLYBENCH_2D_ARRAY_DECL(C,DATA_TYPE,NI,NI,ni,ni);\n  \tPOLYBENCH_2D_ARRAY_DECL(C_outputFromGpu,DATA_TYPE,NI,NI,ni,ni);\n\n\tinit_arrays(ni, nj, &alpha, &beta, POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(A));\n\t\n\tGPU_argv_init();\t\n\tsyrkCuda(ni, nj, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(C_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tsyrk(ni, nj, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(C));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n  \t\tpolybench_stop_instruments;\n \t\tpolybench_print_instruments;\n\n\t\tcompareResults(ni, POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(C_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, POLYBENCH_ARRAY(C_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(A);\n  \tPOLYBENCH_FREE_ARRAY(C);\n\tPOLYBENCH_FREE_ARRAY(C_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"syrk.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/kernels/syrk"}}
{"kernel_name": "syrk", "parallel_api": "ocl", "code": {"syrk.c": "/**\n * syrk.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"syrk.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 1.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\nDATA_TYPE acc;\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_kernel clKernel3;\ncl_command_queue clCommandQue;\ncl_program clProgram;\n\ncl_mem a_mem_obj;\ncl_mem c_mem_obj;\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int ni, DATA_TYPE POLYBENCH_2D(C, NI, NI, ni, ni), DATA_TYPE POLYBENCH_2D(C_outputFromGpu, NI, NI, ni, ni))\n{\n\tint i,j,fail;\n\tfail = 0;\n\n\t// Compare C with D\n\tfor (i=0; i<ni; i++)\n\t{\n\t\tfor (j=0; j<ni; j++)\n\t\t{\n\t\t\tif (percentDiff(C[i][j], C_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"syrk.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_arrays(int ni, int nj,\n\t\tDATA_TYPE *alpha,\n\t\tDATA_TYPE *beta,\n\t\tDATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni),\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj))\n{\n\tint i, j;\n\n\t*alpha = 32412;\n\t*beta = 2123;\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < ni; j++)\n\t\t{\n\t\t\tC[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,NJ,NI,nj,ni), DATA_TYPE POLYBENCH_2D(C,NJ,NI,nj,ni))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\tc_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NJ, A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NJ, C, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"syrk_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int ni, int nj, DATA_TYPE alpha, DATA_TYPE beta)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NJ) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NI) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&c_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(DATA_TYPE), (void *)&alpha);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(DATA_TYPE), (void *)&beta);\n\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(int), (void *)&ni);\n\terrcode |= clSetKernelArg(clKernel1, 5, sizeof(int), (void *)&nj);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(c_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid syrk(int ni, int nj, DATA_TYPE alpha, DATA_TYPE beta, DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(C, NI, NI, ni, ni))\n{\n\tint i, j, k;\n\t\n\t/*  C := alpha*A*A' + beta*C */\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NI; j++)\n\t\t{\n\t\t\tC[i][j] *= beta;\n\t\t}\n\t}\n\t\n\tfor (i = 0; i < _PB_NI; i++)\n\t{\n\t\tfor (j = 0; j < _PB_NI; j++)\n\t\t{\n\t\t\tfor (k = 0; k < _PB_NJ; k++)\n\t\t\t{\n\t\t\t\tC[i][j] += alpha * A[i][k] * A[j][k];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, DATA_TYPE POLYBENCH_2D(C,NI,NI,ni,ni))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < ni; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, C[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\n\t/* Variable declaration/allocation. */\n\tDATA_TYPE alpha;\n\tDATA_TYPE beta;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,ni,nj);\n  \tPOLYBENCH_2D_ARRAY_DECL(C,DATA_TYPE,NI,NI,ni,ni);\n  \tPOLYBENCH_2D_ARRAY_DECL(C_outputFromGpu,DATA_TYPE,NI,NI,ni,ni);\n\n\tinit_arrays(ni, nj, &alpha, &beta, POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(A));\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(C));\n\tcl_load_prog();\n\n\tcl_launch_kernel(ni, nj, alpha, beta);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, c_mem_obj, CL_TRUE, 0, NI * NJ * sizeof(DATA_TYPE), POLYBENCH_ARRAY(C_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");  \n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tsyrk(ni, nj, alpha, beta, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(C));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ni, POLYBENCH_ARRAY(C), POLYBENCH_ARRAY(C_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, POLYBENCH_ARRAY(C_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tcl_clean_up();\n\t\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(C);\n\tPOLYBENCH_FREE_ARRAY(C_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>", "syrk.cl": "/**\n * syrk.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n/*  C := alpha*A*A' + beta*C */\n__kernel void syrk_kernel(__global DATA_TYPE *a, __global DATA_TYPE *c, DATA_TYPE alpha, DATA_TYPE beta, int ni, int nj) \n{\n   \tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < nj) && (j < nj))\n\t{\n\t\tc[i * nj + j] *= beta;\n\t\tint k;\t\t\n\t\tfor(k=0; k< ni; k++)\n\t\t{\n\t\t\tc[i * nj + j] += alpha * a[i * ni + k] * a[j * ni + k];\n\t\t}\n\t}\n}\n"}, "code_dirs": {"syrk.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/syrk", "syrk.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/kernels/syrk"}}
{"kernel_name": "lu", "parallel_api": "cuda", "code": {"lu.cu": "/**\n * lu.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"lu.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid lu(int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n))\n{\n\tfor (int k = 0; k < _PB_N; k++)\n    {\n\t\tfor (int j = k + 1; j < _PB_N; j++)\n\t\t{\n\t\t\tA[k][j] = A[k][j] / A[k][k];\n\t\t}\n\n\t\tfor (int i = k + 1; i < _PB_N; i++)\n\t\t{\n\t\t\tfor (int j = k + 1; j < _PB_N; j++)\n\t\t\t{\n\t\t\t\tA[i][j] = A[i][j] - A[i][k] * A[k][j];\n\t\t\t}\n\t\t}\n    }\n}\n\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n))\n{\n\tint i, j;\n\n\tfor (i = 0; i < n; i++)\n\t{\n\t\tfor (j = 0; j < n; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j + 1) / N;\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_2D(A_cpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(A_outputFromGpu,N,N,n,n))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\t// Compare a and b\n\tfor (i=0; i<n; i++) \n\t{\n\t\tfor (j=0; j<n; j++) \n\t\t{\n\t\t\tif (percentDiff(A_cpu[i][j], A_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void lu_kernel1(int n, DATA_TYPE *A, int k)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif ((j > k) && (j < _PB_N))\n\t{\n\t\tA[k*N + j] = A[k*N + j] / A[k*N + k];\n\t}\n}\n\n\n__global__ void lu_kernel2(int n, DATA_TYPE *A, int k)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\tif ((i > k) && (j > k) && (i < _PB_N) && (j < _PB_N))\n\t{\n\t\tA[i*N + j] = A[i*N + j] - A[i*N + k] * A[k*N + j];\n\t}\n}\n\n\nvoid luCuda(int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(A_outputFromGpu,N,N,n,n))\n{\n\tDATA_TYPE* AGpu;\n\n\tcudaMalloc(&AGpu, N * N * sizeof(DATA_TYPE));\n\tcudaMemcpy(AGpu, A, N * N * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\n\tdim3 block1(DIM_THREAD_BLOCK_KERNEL_1_X, DIM_THREAD_BLOCK_KERNEL_1_Y);\n\tdim3 block2(DIM_THREAD_BLOCK_KERNEL_2_X, DIM_THREAD_BLOCK_KERNEL_2_Y);\n\tdim3 grid1(1, 1, 1);\n\tdim3 grid2(1, 1, 1);\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tfor (int k = 0; k < N; k++)\n\t{\n\t\tgrid1.x = (unsigned int)(ceil((float)(N - (k + 1)) / ((float)block1.x)));\n\t\tlu_kernel1<<<grid1, block1>>>(n, AGpu, k);\n\t\tcudaThreadSynchronize();\n\n\t\tgrid2.x = (unsigned int)(ceil((float)(N - (k + 1)) / ((float)block2.x)));\n\t\tgrid2.y = (unsigned int)(ceil((float)(N - (k + 1)) / ((float)block2.y)));\n\t\tlu_kernel2<<<grid2, block2>>>(n, AGpu, k);\n\t\tcudaThreadSynchronize();\n\t}\n\t\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tcudaMemcpy(A_outputFromGpu, AGpu, N * N * sizeof(DATA_TYPE), cudaMemcpyDeviceToHost);\n\tcudaFree(AGpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_2D(A,N,N,n,n))\n\n{\n  int i, j;\n\n  for (i = 0; i < n; i++)\n    for (j = 0; j < n; j++) {\n      fprintf (stderr, DATA_PRINTF_MODIFIER, A[i][j]);\n      if ((i * n + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\t\n\nint main(int argc, char *argv[])\n{\n\tint n = N;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,N,N,n,n);\n  \tPOLYBENCH_2D_ARRAY_DECL(A_outputFromGpu,DATA_TYPE,N,N,n,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(A));\n\n\tGPU_argv_init();\n\tluCuda(n, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(A_outputFromGpu));\n\t\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tlu(n, POLYBENCH_ARRAY(A));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(n, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(A_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(A_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(A_outputFromGpu);\n\n   \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"lu.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/solvers/lu"}}
{"kernel_name": "lu", "parallel_api": "ocl", "code": {"lu.c": "/**\n * lu.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"lu.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_2D(A_cpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(A_outputFromGpu,N,N,n,n))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\t// Compare a and b\n\tfor (i=0; i<n; i++) \n\t{\n\t\tfor (j=0; j<n; j++) \n\t\t{\n\t\t\tif (percentDiff(A_cpu[i][j], A_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"lu.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n))\n{\n\tint i, j;\n\n\tfor (i = 0; i < n; i++)\n\t{\n\t\tfor (j = 0; j < n; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j + 1) / N;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"device id is %d\\n\",device_id);\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,N,N,n,n))\n{\n\tsize_t mem_size_A = N*N*sizeof(DATA_TYPE);\n\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, mem_size_A, NULL, &errcode);\n\t\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, mem_size_A, A, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"lu_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\tclKernel2 = clCreateKernel(clProgram, \"lu_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel2\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel1(int k, int n)\n{\n\tif (k < (_PB_N-1))\n\t{\n\t\tsize_t localWorkSize[2], globalWorkSize[2];\n\t\tlocalWorkSize[0] = 256;\n\t\tlocalWorkSize[1] = 1;\n\t\tglobalWorkSize[0] = (size_t)ceil(((double)N - (double)(k + 1)) / 256.0) * 256;\n\t\tglobalWorkSize[1] = 1;\n\t\n\t\t// Set the arguments of the kernel\n\t\terrcode = clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(int), (void *)&k);\n\t\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(int), (void *)&n);\n\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\t\tclFinish(clCommandQue);\n\t}\n}\n\n\nvoid cl_launch_kernel2(int k, int n)\n{\n\tif (k < (_PB_N-1))\n\t{\n\t\tsize_t localWorkSize[2], globalWorkSize[2];\n\t\tlocalWorkSize[0] = 32;\n\t\tlocalWorkSize[1] = 8;\n\t\tglobalWorkSize[0] = (size_t)ceil(((double)N - (double)(k + 1)) / 32.0) * 32;\n\t\tglobalWorkSize[1] = (size_t)ceil(((double)N - (double)(k + 1)) / 8.0) * 8;\n\t\n\t\t// Set the arguments of the kernel\n\t\terrcode = clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(int), (void *)&k);\n\t\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(int), (void *)&n);\n\t\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\t\tif(errcode != CL_SUCCESS) \n\t\t{\n\t\t\tprintf(\"Error in launching kernel\\n\");\n\t\t\tprintf(\"Nums: %d %d\\n\", globalWorkSize[0], globalWorkSize[1]);\n\t\t}\n\t\tclFinish(clCommandQue);\n\t}\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid lu(int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n))\n{\n\tint i, j, k;\n\tfor (k = 0; k < _PB_N; k++)\n    \t{\n\t\tfor (j = k + 1; j < _PB_N; j++)\n\t\t{\n\t\t\tA[k][j] = A[k][j] / A[k][k];\n\t\t}\n\n\t\tfor (i = k + 1; i < _PB_N; i++)\n\t\t{\n\t\t\tfor (j = k + 1; j < _PB_N; j++)\n\t\t\t{\n\t\t\t\tA[i][j] = A[i][j] - A[i][k] * A[k][j];\n\t\t\t}\n\t\t}\n    }\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_2D(A,N,N,n,n))\n\n{\n  int i, j;\n\n  for (i = 0; i < n; i++)\n    for (j = 0; j < n; j++) {\n      fprintf (stderr, DATA_PRINTF_MODIFIER, A[i][j]);\n      if ((i * n + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint n = N;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,N,N,n,n);\n  \tPOLYBENCH_2D_ARRAY_DECL(A_outputFromGpu,DATA_TYPE,N,N,n,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(A));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A));\n\tcl_load_prog();\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tint k;\n\tfor (k = 0; k < _PB_N; k++)\n    \t{\n\t\tcl_launch_kernel1(k, n);\n\t\tcl_launch_kernel2(k, n);\n\t}\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, N*N*sizeof(DATA_TYPE), POLYBENCH_ARRAY(A_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\t\n\t#if RUN_ON_CPU\n\t\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tlu(n, POLYBENCH_ARRAY(A));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(n, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(A_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(A_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(A_outputFromGpu);\n\n    return 0;\n}\n\n#include <polybench.c>", "lu.cl": "/**\n * lu.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n\ntypedef float DATA_TYPE;\n\n\n\n__kernel void lu_kernel1(__global DATA_TYPE *A, int k, int n)\n{\n\tint j = get_global_id(0) + (k + 1);\n\t\n\tif ((j < n))\n\t{\n\t\tA[k*n + j] = A[k*n + j] / A[k*n + k];\n\t}\n}\n\n__kernel void lu_kernel2(__global DATA_TYPE *A, int k, int n)\n{\n\tint j = get_global_id(0) + (k + 1);\n\tint i = get_global_id(1) + (k + 1);\n\t\n\tif ((i < n) && (j < n))\n\t{\n\t\tA[i*n + j] = A[i*n + j] - A[i*n + k] * A[k*n + j];\n\t}\n}\n"}, "code_dirs": {"lu.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/solvers/lu", "lu.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/solvers/lu"}}
{"kernel_name": "adi", "parallel_api": "cuda", "code": {"adi.cu": "/**\n * adi.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"adi.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 2.5\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid adi(int tsteps, int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_2D(X,N,N,n,n))\n{\n\tfor (int t = 0; t < _PB_TSTEPS; t++)\n    \t{\n    \t\tfor (int i1 = 0; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tfor (int i2 = 1; i2 < _PB_N; i2++)\n\t\t\t{\n\t\t\t\tX[i1][i2] = X[i1][i2] - X[i1][(i2-1)] * A[i1][i2] / B[i1][(i2-1)];\n\t\t\t\tB[i1][i2] = B[i1][i2] - A[i1][i2] * A[i1][i2] / B[i1][(i2-1)];\n\t\t\t}\n\t\t}\n\n\t   \tfor (int i1 = 0; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tX[i1][(N-1)] = X[i1][(N-1)] / B[i1][(N-1)];\n\t\t}\n\n\t   \tfor (int i1 = 0; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tfor (int i2 = 0; i2 < _PB_N-2; i2++)\n\t\t\t{\n\t\t\t\tX[i1][(N-i2-2)] = (X[i1][(N-2-i2)] - X[i1][(N-2-i2-1)] * A[i1][(N-i2-3)]) / B[i1][(N-3-i2)];\n\t\t\t}\n\t\t}\n\n\t   \tfor (int i1 = 1; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tfor (int i2 = 0; i2 < _PB_N; i2++) \n\t\t\t{\n\t\t  \t\tX[i1][i2] = X[i1][i2] - X[(i1-1)][i2] * A[i1][i2] / B[(i1-1)][i2];\n\t\t  \t\tB[i1][i2] = B[i1][i2] - A[i1][i2] * A[i1][i2] / B[(i1-1)][i2];\n\t\t\t}\n\t\t}\n\n\t   \tfor (int i2 = 0; i2 < _PB_N; i2++)\n\t\t{\n\t\t\tX[(N-1)][i2] = X[(N-1)][i2] / B[(N-1)][i2];\n\t\t}\n\n\t   \tfor (int i1 = 0; i1 < _PB_N-2; i1++)\n\t\t{\n\t\t\tfor (int i2 = 0; i2 < _PB_N; i2++)\n\t\t\t{\n\t\t \t \tX[(N-2-i1)][i2] = (X[(N-2-i1)][i2] - X[(N-i1-3)][i2] * A[(N-3-i1)][i2]) / B[(N-2-i1)][i2];\n\t\t\t}\n\t\t}\n    }\n}\n\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_2D(X,N,N,n,n))\n{\n  \tint i, j;\n\n  \tfor (i = 0; i < n; i++)\n\t{\n    \t\tfor (j = 0; j < n; j++)\n      \t\t{\n\t\t\tX[i][j] = ((DATA_TYPE) i*(j+1) + 1) / N;\n\t\t\tA[i][j] = ((DATA_TYPE) (i-1)*(j+4) + 2) / N;\n\t\t\tB[i][j] = ((DATA_TYPE) (i+3)*(j+7) + 3) / N;\n      \t\t}\n\t}\n}\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_2D(B_cpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(B_fromGpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(X_cpu,N,N,n,n), \n\t\t\tDATA_TYPE POLYBENCH_2D(X_fromGpu,N,N,n,n))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\t// Compare b and x output on cpu and gpu\n\tfor (i=0; i < n; i++) \n\t{\n\t\tfor (j=0; j < n; j++) \n\t\t{\n\t\t\tif (percentDiff(B_cpu[i][j], B_fromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\tfor (i=0; i<n; i++) \n\t{\n\t\tfor (j=0; j<n; j++) \n\t\t{\n\t\t\tif (percentDiff(X_cpu[i][j], X_fromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void adi_kernel1(int n, DATA_TYPE* A, DATA_TYPE* B, DATA_TYPE* X)\n{\n\tint i1 = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif ((i1 < _PB_N))\n\t{\n\t\tfor (int i2 = 1; i2 < _PB_N; i2++)\n\t\t{\n\t\t\tX[i1*N + i2] = X[i1*N + i2] - X[i1*N + (i2-1)] * A[i1*N + i2] / B[i1*N + (i2-1)];\n\t\t\tB[i1*N + i2] = B[i1*N + i2] - A[i1*N + i2] * A[i1*N + i2] / B[i1*N + (i2-1)];\n\t\t}\n\t}\n}\n\n\n__global__ void adi_kernel2(int n, DATA_TYPE* A, DATA_TYPE* B, DATA_TYPE* X)\n{\n\tint i1 = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif ((i1 < _PB_N))\n\t{\n\t\tX[i1*N + (N-1)] = X[i1*N + (N-1)] / B[i1*N + (N-1)];\n\t}\n}\n\t\n\n__global__ void adi_kernel3(int n, DATA_TYPE* A, DATA_TYPE* B, DATA_TYPE* X)\n{\n\tint i1 = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif (i1 < _PB_N)\n\t{\n\t\tfor (int i2 = 0; i2 < _PB_N-2; i2++)\n\t\t{\n\t\t\tX[i1*N + (N-i2-2)] = (X[i1*N + (N-2-i2)] - X[i1*N + (N-2-i2-1)] * A[i1*N + (N-i2-3)]) / B[i1*N + (N-3-i2)];\n\t\t}\n\t}\n}\n\n\n__global__ void adi_kernel4(int n, DATA_TYPE* A, DATA_TYPE* B, DATA_TYPE* X, int i1)\n{\n\tint i2 = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif (i2 < _PB_N)\n\t{\n\t\tX[i1*N + i2] = X[i1*N + i2] - X[(i1-1)*N + i2] * A[i1*N + i2] / B[(i1-1)*N + i2];\n\t\tB[i1*N + i2] = B[i1*N + i2] - A[i1*N + i2] * A[i1*N + i2] / B[(i1-1)*N + i2];\n\t}\n}\n\n\n__global__ void adi_kernel5(int n, DATA_TYPE* A, DATA_TYPE* B, DATA_TYPE* X)\n{\n\tint i2 = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif (i2 < _PB_N)\n\t{\n\t\tX[(N-1)*N + i2] = X[(N-1)*N + i2] / B[(N-1)*N + i2];\n\t}\n}\n\n\n__global__ void adi_kernel6(int n, DATA_TYPE* A, DATA_TYPE* B, DATA_TYPE* X, int i1)\n{\n\tint i2 = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif (i2 < _PB_N)\n\t{\n\t\tX[(N-2-i1)*N + i2] = (X[(N-2-i1)*N + i2] - X[(N-i1-3)*N + i2] * A[(N-3-i1)*N + i2]) / B[(N-2-i1)*N + i2];\n\t}\n}\n\n\nvoid adiCuda(int tsteps, int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_2D(X,N,N,n,n), \n\tDATA_TYPE POLYBENCH_2D(B_outputFromGpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(X_outputFromGpu,N,N,n,n))\n{\n\tDATA_TYPE* A_gpu;\n\tDATA_TYPE* B_gpu;\n\tDATA_TYPE* X_gpu;\n\n\tcudaMalloc(&A_gpu, N * N * sizeof(DATA_TYPE));\n\tcudaMalloc(&B_gpu, N * N * sizeof(DATA_TYPE));\n\tcudaMalloc(&X_gpu, N * N * sizeof(DATA_TYPE));\n\tcudaMemcpy(A_gpu, A, N * N * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\tcudaMemcpy(B_gpu, B, N * N * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\tcudaMemcpy(X_gpu, X, N * N * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\n\tdim3 block1(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y, 1);\n\tdim3 grid1(1, 1, 1);\n\tgrid1.x = (size_t)(ceil( ((float)N) / ((float)block1.x) ));\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tfor (int t = 0; t < _PB_TSTEPS; t++)\n\t{\n\t\t\n\t\tadi_kernel1<<<grid1, block1>>>(n, A_gpu, B_gpu, X_gpu);\n\t\tcudaThreadSynchronize();\n\t\tadi_kernel2<<<grid1, block1>>>(n, A_gpu, B_gpu, X_gpu);\n\t\tcudaThreadSynchronize();\n\t\tadi_kernel3<<<grid1, block1>>>(n, A_gpu, B_gpu, X_gpu);\n\t\tcudaThreadSynchronize();\n\t\n\t\tfor (int i1 = 1; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tadi_kernel4<<<grid1, block1>>>(n, A_gpu, B_gpu, X_gpu, i1);\n\t\t\tcudaThreadSynchronize();\n\t\t}\n\n\t\tadi_kernel5<<<grid1, block1>>>(n, A_gpu, B_gpu, X_gpu);\n\t\tcudaThreadSynchronize();\n\t\t\n\t\tfor (int i1 = 0; i1 < _PB_N-2; i1++)\n\t\t{\n\t\t\tadi_kernel6<<<grid1, block1>>>(n, A_gpu, B_gpu, X_gpu, i1);\n\t\t\tcudaThreadSynchronize();\n\t\t}\n\t}\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tcudaMemcpy(B_outputFromGpu, B_gpu, N * N * sizeof(DATA_TYPE), cudaMemcpyDeviceToHost);\n\tcudaMemcpy(X_outputFromGpu, X_gpu, N * N * sizeof(DATA_TYPE), cudaMemcpyDeviceToHost);\n\n\tcudaFree(A_gpu);\n\tcudaFree(B_gpu);\n\tcudaFree(X_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_2D(X,N,N,n,n))\n\n{\n  int i, j;\n\n  for (i = 0; i < n; i++)\n    for (j = 0; j < n; j++) {\n      fprintf(stderr, DATA_PRINTF_MODIFIER, X[i][j]);\n      if ((i * N + j) % 20 == 0) fprintf(stderr, \"\\n\");\n    }\n  fprintf(stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint tsteps = TSTEPS;\n\tint n = N;\n\n\tGPU_argv_init();\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(B_outputFromGpu,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(X,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(X_outputFromGpu,DATA_TYPE,N,N,n,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(X));\n\n\tadiCuda(tsteps, n, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(X), POLYBENCH_ARRAY(B_outputFromGpu), \n\t\tPOLYBENCH_ARRAY(X_outputFromGpu));\n\t\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tadi(tsteps, n, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(X));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(n, POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(B_outputFromGpu), POLYBENCH_ARRAY(X), POLYBENCH_ARRAY(X_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(X_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(B_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(X);\n\tPOLYBENCH_FREE_ARRAY(X_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"adi.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/stencils/adi"}}
{"kernel_name": "adi", "parallel_api": "ocl", "code": {"adi.c": "/**\n * adi.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"adi.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 10.05\n\n#define GPU_DEVICE 0\n\n#define MAX_SOURCE_SIZE (0x10000000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_kernel clKernel3;\ncl_kernel clKernel4;\ncl_kernel clKernel5;\ncl_kernel clKernel6;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\ncl_mem x_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\nunsigned int mem_size_A;\nunsigned int mem_size_B;\nunsigned int mem_size_X;\n\n\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_2D(X,N,N,n,n))\n{\n  \tint i, j;\n\n  \tfor (i = 0; i < n; i++)\n\t{\n    \t\tfor (j = 0; j < n; j++)\n      \t\t{\n\t\t\tX[i][j] = ((DATA_TYPE) i*(j+1) + 1) / N;\n\t\t\tA[i][j] = ((DATA_TYPE) (i-1)*(j+4) + 2) / N;\n\t\t\tB[i][j] = ((DATA_TYPE) (i+3)*(j+7) + 3) / N;\n      \t\t}\n\t}\n}\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_2D(B_cpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(B_fromGpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(X_cpu,N,N,n,n), \n\t\t\tDATA_TYPE POLYBENCH_2D(X_fromGpu,N,N,n,n))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\t// Compare b and x output on cpu and gpu\n\tfor (i=0; i < n; i++) \n\t{\n\t\tfor (j=0; j < n; j++) \n\t\t{\n\t\t\tif (percentDiff(B_cpu[i][j], B_fromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\tfor (i=0; i<n; i++) \n\t{\n\t\tfor (j=0; j<n; j++) \n\t\t{\n\t\t\tif (percentDiff(X_cpu[i][j], X_fromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"adi.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid cl_initialization()\n{\n\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"device id is %d\\n\",device_id);\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_2D(X,N,N,n,n))\n{\n\tmem_size_A = N*N*sizeof(DATA_TYPE);\n\tmem_size_B = N*N*sizeof(DATA_TYPE);\n\tmem_size_X = N*N*sizeof(DATA_TYPE);\n\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, mem_size_A, NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, mem_size_B, NULL, &errcode);\n\tx_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, mem_size_X, NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, mem_size_A, A, 0, NULL, NULL);\n\terrcode |= clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, mem_size_B, B, 0, NULL, NULL);\n\terrcode |= clEnqueueWriteBuffer(clCommandQue, x_mem_obj, CL_TRUE, 0, mem_size_X, X, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n }\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"adi_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\tclKernel2 = clCreateKernel(clProgram, \"adi_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel2\\n\");\n\tclKernel3 = clCreateKernel(clProgram, \"adi_kernel3\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel3\\n\");\n\tclKernel4 = clCreateKernel(clProgram, \"adi_kernel4\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel4\\n\");\n\tclKernel5 = clCreateKernel(clProgram, \"adi_kernel5\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel5\\n\");\n\tclKernel6 = clCreateKernel(clProgram, \"adi_kernel6\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel6\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel1(int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel2(int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = 1;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel3(int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = 1;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel3, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel3, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel3, 2, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel3, 3, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel3, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel4(int i, int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = 1;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel4, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel4, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel4, 2, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel4, 3, sizeof(int), (void *)&i);\n\terrcode |= clSetKernelArg(clKernel4, 4, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel4, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel5(int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = 1;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel5, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel5, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel5, 2, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel5, 3, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel5, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel6(int i, int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = 1;\n\tglobalWorkSize[0] = (size_t)ceil(((float)N) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = 1;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel6, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel6, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel6, 2, sizeof(cl_mem), (void *)&x_mem_obj);\n\terrcode |= clSetKernelArg(clKernel6, 3, sizeof(int), (void *)&i);\n\terrcode |= clSetKernelArg(clKernel6, 4, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel6, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseKernel(clKernel3);\n\terrcode = clReleaseKernel(clKernel4);\n\terrcode = clReleaseKernel(clKernel5);\n\terrcode = clReleaseKernel(clKernel6);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseMemObject(x_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid adi(int tsteps, int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_2D(X,N,N,n,n))\n{\n\tint t, i1, i2;\n\tfor (t = 0; t < _PB_TSTEPS; t++)\n    \t{\n    \t\tfor (i1 = 0; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tfor (i2 = 1; i2 < _PB_N; i2++)\n\t\t\t{\n\t\t\t\tX[i1][i2] = X[i1][i2] - X[i1][(i2-1)] * A[i1][i2] / B[i1][(i2-1)];\n\t\t\t\tB[i1][i2] = B[i1][i2] - A[i1][i2] * A[i1][i2] / B[i1][(i2-1)];\n\t\t\t}\n\t\t}\n\n\t   \tfor (i1 = 0; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tX[i1][(N-1)] = X[i1][(N-1)] / B[i1][(N-1)];\n\t\t}\n\n\t   \tfor (i1 = 0; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tfor (i2 = 0; i2 < _PB_N-2; i2++)\n\t\t\t{\n\t\t\t\tX[i1][(N-i2-2)] = (X[i1][(N-2-i2)] - X[i1][(N-2-i2-1)] * A[i1][(N-i2-3)]) / B[i1][(N-3-i2)];\n\t\t\t}\n\t\t}\n\n\t   \tfor (i1 = 1; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tfor (i2 = 0; i2 < _PB_N; i2++) \n\t\t\t{\n\t\t  \t\tX[i1][i2] = X[i1][i2] - X[(i1-1)][i2] * A[i1][i2] / B[(i1-1)][i2];\n\t\t  \t\tB[i1][i2] = B[i1][i2] - A[i1][i2] * A[i1][i2] / B[(i1-1)][i2];\n\t\t\t}\n\t\t}\n\n\t   \tfor (i2 = 0; i2 < _PB_N; i2++)\n\t\t{\n\t\t\tX[(N-1)][i2] = X[(N-1)][i2] / B[(N-1)][i2];\n\t\t}\n\n\t   \tfor (i1 = 0; i1 < _PB_N-2; i1++)\n\t\t{\n\t\t\tfor (i2 = 0; i2 < _PB_N; i2++)\n\t\t\t{\n\t\t \t \tX[(N-2-i1)][i2] = (X[(N-2-i1)][i2] - X[(N-i1-3)][i2] * A[(N-3-i1)][i2]) / B[(N-2-i1)][i2];\n\t\t\t}\n\t\t}\n    }\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_2D(X,N,N,n,n))\n\n{\n  int i, j;\n\n  for (i = 0; i < n; i++)\n    for (j = 0; j < n; j++) {\n      fprintf(stderr, DATA_PRINTF_MODIFIER, X[i][j]);\n      if ((i * N + j) % 20 == 0) fprintf(stderr, \"\\n\");\n    }\n  fprintf(stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint tsteps = TSTEPS;\n\tint n = N;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(B_outputFromGpu,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(X,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(X_outputFromGpu,DATA_TYPE,N,N,n,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(X));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(X));\n\tcl_load_prog();\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tint t, i1;\n\n\tfor (t = 0; t < _PB_TSTEPS; t++)\n\t{\n\t\tcl_launch_kernel1(n);\n\n\t\tcl_launch_kernel2(n);\n\n\t\tcl_launch_kernel3(n);\n\t\n\t\tfor (i1 = 1; i1 < _PB_N; i1++)\n\t\t{\n\t\t\tcl_launch_kernel4(i1, n);\n\t\t}\n\n\t\tcl_launch_kernel5(n);\n\t\t\n\t\tfor (i1 = 0; i1 < _PB_N-2; i1++)\n\t\t{\n\t\t\tcl_launch_kernel6(i1, n);\n\t\t}\n\t}\t\n\t\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, mem_size_B, POLYBENCH_ARRAY(B_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\terrcode = clEnqueueReadBuffer(clCommandQue, x_mem_obj, CL_TRUE, 0, mem_size_X, POLYBENCH_ARRAY(X_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\t\n\t#if RUN_ON_CPU\n\t\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tadi(tsteps, n, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(X));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(n, POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(B_outputFromGpu), POLYBENCH_ARRAY(X), POLYBENCH_ARRAY(X_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(X_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(B_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(X);\n\tPOLYBENCH_FREE_ARRAY(X_outputFromGpu);\n\n    return 0;\n}\n\n#include <polybench.c>", "adi.cl": "/**\n * adi.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n\n__kernel void adi_kernel1(__global DATA_TYPE* A, __global DATA_TYPE* B, __global DATA_TYPE* X, int n)\n{\n\tint i1 = get_global_id(0);\n\tint i2;\t\n\n\tif ((i1 < n))\n\t{\n\t\tfor (i2 = 1; i2 < n; i2++)\n\t\t{\n\t\t\tX[i1*n + i2] = X[i1*n + i2] - X[i1*n + (i2-1)] * A[i1*n + i2] / B[i1*n + (i2-1)];\n\t\t\tB[i1*n + i2] = B[i1*n + i2] - A[i1*n + i2] * A[i1*n + i2] / B[i1*n + (i2-1)];\n\t\t}\n\t}\n}\n\n__kernel void adi_kernel2(__global DATA_TYPE* A, __global DATA_TYPE* B, __global DATA_TYPE* X, int n)\n{\n\tint i1 = get_global_id(0);\n\t\n\tif ((i1 < n))\n\t{\n\t\tX[i1*n + (n-1)] = X[i1*n + (n-1)] / B[i1*n + (n-1)];\n\t}\n}\n\t\n__kernel void adi_kernel3(__global DATA_TYPE* A, __global DATA_TYPE* B, __global DATA_TYPE* X, int n)\n{\n\tint i1 = get_global_id(0);\n\tint i2;\t\n\n\tif ((i1 < n))\n\t{\n\t\tfor (i2 = 0; i2 < n-2; i2++)\n\t\t{\n\t\t\tX[i1*n + (n-i2-2)] = (X[i1*n + (n-2-i2)] - X[i1*n + (n-2-i2-1)] * A[i1*n + (n-i2-3)]) / B[i1*n + (n-3-i2)];\n\t\t}\n\t}\n}\n\n\n\n__kernel void adi_kernel4(__global DATA_TYPE* A, __global DATA_TYPE* B, __global DATA_TYPE* X, int i1, int n)\n{\n\tint i2 = get_global_id(0);\n\t\n\tif ((i2 < n))\n\t{\n\t\tX[i1*n + i2] = X[i1*n + i2] - X[(i1-1)*n + i2] * A[i1*n + i2] / B[(i1-1)*n + i2];\n\t\tB[i1*n + i2] = B[i1*n + i2] - A[i1*n + i2] * A[i1*n + i2] / B[(i1-1)*n + i2];\n\t}\n}\n\n__kernel void adi_kernel5(__global DATA_TYPE* A, __global DATA_TYPE* B, __global DATA_TYPE* X, int n)\n{\n\tint i2 = get_global_id(0);\n\t\n\tif ((i2 < n))\n\t{\n\t\tX[(n-1)*n + i2] = X[(n-1)*n + i2] / B[(n-1)*n + i2];\n\t}\n}\n\n__kernel void adi_kernel6(__global DATA_TYPE* A, __global DATA_TYPE* B, __global DATA_TYPE* X, int i1, int n)\n{\n\tint i2 = get_global_id(0);\n\t\n\tif ((i2 < n))\n\t{\n\t     X[(n-2-i1)*n + i2] = (X[(n-2-i1)*n + i2] - X[(n-i1-3)*n + i2] * A[(n-3-i1)*n + i2]) / B[(n-2-i1)*n + i2];\n\t}\n}\n\n"}, "code_dirs": {"adi.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/adi", "adi.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/adi"}}
{"kernel_name": "fdtd-2d", "parallel_api": "cuda", "code": {"fdtd2d.cu": "/**\n * fdtd2d.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <assert.h>\n#include <unistd.h>\n#include <sys/time.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"fdtd2d.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 10.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid init_arrays(int tmax, int nx, int ny, DATA_TYPE POLYBENCH_1D(_fict_, TMAX, TMAX), DATA_TYPE POLYBENCH_2D(ex,NX,NY,nx,ny), \n\t\tDATA_TYPE POLYBENCH_2D(ey,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(hz,NX,NY,nx,ny))\n{\n\tint i, j;\n\n  \tfor (i = 0; i < tmax; i++)\n\t{\n\t\t_fict_[i] = (DATA_TYPE) i;\n\t}\n\t\n\tfor (i = 0; i < nx; i++)\n\t{\n\t\tfor (j = 0; j < ny; j++)\n\t\t{\n\t\t\tex[i][j] = ((DATA_TYPE) i*(j+1) + 1) / NX;\n\t\t\tey[i][j] = ((DATA_TYPE) (i-1)*(j+2) + 2) / NX;\n\t\t\thz[i][j] = ((DATA_TYPE) (i-9)*(j+4) + 3) / NX;\n\t\t}\n\t}\n}\n\n\nvoid runFdtd(int tmax, int nx, int ny, DATA_TYPE POLYBENCH_1D(_fict_, TMAX, TMAX), DATA_TYPE POLYBENCH_2D(ex,NX,NY,nx,ny), \n\tDATA_TYPE POLYBENCH_2D(ey,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(hz,NX,NY,nx,ny))\n{\n\tint t, i, j;\n\t\n\tfor (t=0; t < _PB_TMAX; t++)  \n\t{\n\t\tfor (j=0; j < _PB_NY; j++)\n\t\t{\n\t\t\tey[0][j] = _fict_[t];\n\t\t}\n\t\n\t\tfor (i = 1; i < _PB_NX; i++)\n\t\t{\n       \t\tfor (j = 0; j < _PB_NY; j++)\n\t\t\t{\n       \t\t\tey[i][j] = ey[i][j] - 0.5*(hz[i][j] - hz[(i-1)][j]);\n        \t\t}\n\t\t}\n\n\t\tfor (i = 0; i < _PB_NX; i++)\n\t\t{\n       \t\tfor (j = 1; j < _PB_NY; j++)\n\t\t\t{\n\t\t\t\tex[i][j] = ex[i][j] - 0.5*(hz[i][j] - hz[i][(j-1)]);\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0; i < _PB_NX-1; i++)\n\t\t{\n\t\t\tfor (j = 0; j < _PB_NY-1; j++)\n\t\t\t{\n\t\t\t\thz[i][j] = hz[i][j] - 0.7*(ex[i][(j+1)] - ex[i][j] + ey[(i+1)][j] - ey[i][j]);\n\t\t\t}\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int nx, int ny, DATA_TYPE POLYBENCH_2D(hz1,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(hz2,NX,NY,nx,ny))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\tfor (i=0; i < nx; i++) \n\t{\n\t\tfor (j=0; j < ny; j++) \n\t\t{\n\t\t\tif (percentDiff(hz1[i][j], hz2[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n\n__global__ void fdtd_step1_kernel(int nx, int ny, DATA_TYPE* _fict_, DATA_TYPE *ex, DATA_TYPE *ey, DATA_TYPE *hz, int t)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif ((i < _PB_NX) && (j < _PB_NY))\n\t{\n\t\tif (i == 0) \n\t\t{\n\t\t\tey[i * NY + j] = _fict_[t];\n\t\t}\n\t\telse\n\t\t{ \n\t\t\tey[i * NY + j] = ey[i * NY + j] - 0.5f*(hz[i * NY + j] - hz[(i-1) * NY + j]);\n\t\t}\n\t}\n}\n\n\n\n__global__ void fdtd_step2_kernel(int nx, int ny, DATA_TYPE *ex, DATA_TYPE *ey, DATA_TYPE *hz, int t)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\tif ((i < _PB_NX) && (j < _PB_NY) && (j > 0))\n\t{\n\t\tex[i * NY + j] = ex[i * NY + j] - 0.5f*(hz[i * NY + j] - hz[i * NY + (j-1)]);\n\t}\n}\n\n\n__global__ void fdtd_step3_kernel(int nx, int ny, DATA_TYPE *ex, DATA_TYPE *ey, DATA_TYPE *hz, int t)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\tif ((i < (_PB_NX-1)) && (j < (_PB_NY-1)))\n\t{\t\n\t\thz[i * NY + j] = hz[i * NY + j] - 0.7f*(ex[i * NY + (j+1)] - ex[i * NY + j] + ey[(i + 1) * NY + j] - ey[i * NY + j]);\n\t}\n}\n\n\nvoid fdtdCuda(int tmax, int nx, int ny, DATA_TYPE POLYBENCH_1D(_fict_, TMAX, TMAX), DATA_TYPE POLYBENCH_2D(ex,NX,NY,nx,ny), \n\tDATA_TYPE POLYBENCH_2D(ey,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(hz,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(hz_outputFromGpu,NX,NY,nx,ny))\n{\n\tDATA_TYPE *_fict_gpu;\n\tDATA_TYPE *ex_gpu;\n\tDATA_TYPE *ey_gpu;\n\tDATA_TYPE *hz_gpu;\n\n\tcudaMalloc((void **)&_fict_gpu, sizeof(DATA_TYPE) * TMAX);\n\tcudaMalloc((void **)&ex_gpu, sizeof(DATA_TYPE) * NX * NY);\n\tcudaMalloc((void **)&ey_gpu, sizeof(DATA_TYPE) * NX * NY);\n\tcudaMalloc((void **)&hz_gpu, sizeof(DATA_TYPE) * NX * NY);\n\n\tcudaMemcpy(_fict_gpu, _fict_, sizeof(DATA_TYPE) * TMAX, cudaMemcpyHostToDevice);\n\tcudaMemcpy(ex_gpu, ex, sizeof(DATA_TYPE) * NX * NY, cudaMemcpyHostToDevice);\n\tcudaMemcpy(ey_gpu, ey, sizeof(DATA_TYPE) * NX * NY, cudaMemcpyHostToDevice);\n\tcudaMemcpy(hz_gpu, hz, sizeof(DATA_TYPE) * NX * NY, cudaMemcpyHostToDevice);\n\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid( (size_t)ceil(((float)NY) / ((float)block.x)), (size_t)ceil(((float)NX) / ((float)block.y)));\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tfor(int t = 0; t < _PB_TMAX; t++)\n\t{\n\t\tfdtd_step1_kernel<<<grid,block>>>(nx, ny, _fict_gpu, ex_gpu, ey_gpu, hz_gpu, t);\n\t\tcudaThreadSynchronize();\n\t\tfdtd_step2_kernel<<<grid,block>>>(nx, ny, ex_gpu, ey_gpu, hz_gpu, t);\n\t\tcudaThreadSynchronize();\n\t\tfdtd_step3_kernel<<<grid,block>>>(nx, ny, ex_gpu, ey_gpu, hz_gpu, t);\n\t\tcudaThreadSynchronize();\n\t}\n\t\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\n\tcudaMemcpy(hz_outputFromGpu, hz_gpu, sizeof(DATA_TYPE) * NX * NY, cudaMemcpyDeviceToHost);\t\n\t\t\n\tcudaFree(_fict_gpu);\n\tcudaFree(ex_gpu);\n\tcudaFree(ey_gpu);\n\tcudaFree(hz_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int nx,\n\t\t int ny,\n\t\t DATA_TYPE POLYBENCH_2D(hz,NX,NY,nx,ny))\n{\n  int i, j;\n\n  for (i = 0; i < nx; i++)\n    for (j = 0; j < ny; j++) {\n         fprintf(stderr, DATA_PRINTF_MODIFIER, hz[i][j]);\n      if ((i * nx + j) % 20 == 0) fprintf(stderr, \"\\n\");\n    }\n  fprintf(stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint tmax = TMAX;\n\tint nx = NX;\n\tint ny = NY;\n\n\tPOLYBENCH_1D_ARRAY_DECL(_fict_,DATA_TYPE,TMAX,TMAX);\n\tPOLYBENCH_2D_ARRAY_DECL(ex,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_2D_ARRAY_DECL(ey,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_2D_ARRAY_DECL(hz,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_2D_ARRAY_DECL(hz_outputFromGpu,DATA_TYPE,NX,NY,nx,ny);\n\n\tinit_arrays(tmax, nx, ny, POLYBENCH_ARRAY(_fict_), POLYBENCH_ARRAY(ex), POLYBENCH_ARRAY(ey), POLYBENCH_ARRAY(hz));\n\n\tGPU_argv_init();\n\tfdtdCuda(tmax, nx, ny, POLYBENCH_ARRAY(_fict_), POLYBENCH_ARRAY(ex), POLYBENCH_ARRAY(ey), POLYBENCH_ARRAY(hz), POLYBENCH_ARRAY(hz_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\trunFdtd(tmax, nx, ny, POLYBENCH_ARRAY(_fict_), POLYBENCH_ARRAY(ex), POLYBENCH_ARRAY(ey), POLYBENCH_ARRAY(hz));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\t\n\t\tcompareResults(nx, ny, POLYBENCH_ARRAY(hz), POLYBENCH_ARRAY(hz_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(nx, ny, POLYBENCH_ARRAY(hz_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(_fict_);\n\tPOLYBENCH_FREE_ARRAY(ex);\n\tPOLYBENCH_FREE_ARRAY(ey);\n\tPOLYBENCH_FREE_ARRAY(hz);\n\tPOLYBENCH_FREE_ARRAY(hz_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"fdtd2d.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/stencils/fdtd-2d"}}
{"kernel_name": "fdtd-2d", "parallel_api": "ocl", "code": {"fdtd2d.c": "/**\n * fdtd2d.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"fdtd2d.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 1.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_kernel clKernel3;\ncl_command_queue clCommandQue;\ncl_program clProgram;\n\ncl_mem fict_mem_obj;\ncl_mem ex_mem_obj;\ncl_mem ey_mem_obj;\ncl_mem hz_mem_obj;\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int nx, int ny, DATA_TYPE POLYBENCH_2D(hz1,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(hz2,NX,NY,nx,ny))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\tfor (i=0; i < nx; i++) \n\t{\n\t\tfor (j=0; j < ny; j++) \n\t\t{\n\t\t\tif (percentDiff(hz1[i][j], hz2[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"fdtd2d.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_arrays(int tmax, int nx, int ny, DATA_TYPE POLYBENCH_1D(_fict_, TMAX, TMAX), DATA_TYPE POLYBENCH_2D(ex,NX,NY,nx,ny), \n\t\tDATA_TYPE POLYBENCH_2D(ey,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(hz,NX,NY,nx,ny))\n{\n\tint i, j;\n\n  \tfor (i = 0; i < tmax; i++)\n\t{\n\t\t_fict_[i] = (DATA_TYPE) i;\n\t}\n\t\n\tfor (i = 0; i < nx; i++)\n\t{\n\t\tfor (j = 0; j < ny; j++)\n\t\t{\n\t\t\tex[i][j] = ((DATA_TYPE) i*(j+1) + 1) / NX;\n\t\t\tey[i][j] = ((DATA_TYPE) (i-1)*(j+2) + 2) / NX;\n\t\t\thz[i][j] = ((DATA_TYPE) (i-9)*(j+4) + 3) / NX;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_1D(_fict_,TMAX,tmax), DATA_TYPE POLYBENCH_2D(ex,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(ey,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(hz,NX,NY,nx,ny))\n{\n\tfict_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * TMAX, NULL, &errcode);\n\tex_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX * NY, NULL, &errcode);\n\tey_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX * NY, NULL, &errcode);\n\thz_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NX * NY, NULL, &errcode);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, fict_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * TMAX, _fict_, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, ex_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX * NY, ex, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, ey_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX * NY, ey, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, hz_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NX * NY, hz, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n \nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"fdtd_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\t\n\t// Create the OpenCL kernel\n\tclKernel2 = clCreateKernel(clProgram, \"fdtd_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\n\t// Create the OpenCL kernel\n\tclKernel3 = clCreateKernel(clProgram, \"fdtd_kernel3\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int tmax, int nx, int ny)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NY) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NX) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tint t;\n\tfor(t=0;t<_PB_TMAX;t++)\n\t{\n\t\t// Set the arguments of the kernel\n\t\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&fict_mem_obj);\n\t\terrcode =  clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&ex_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&ey_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(cl_mem), (void *)&hz_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(int), (void *)&t);\n\t\terrcode |= clSetKernelArg(clKernel1, 5, sizeof(int), (void *)&nx);\n\t\terrcode |= clSetKernelArg(clKernel1, 6, sizeof(int), (void *)&ny);\n\t\t\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\t\tclEnqueueBarrier(clCommandQue);\n\n\t\t// Set the arguments of the kernel\n\t\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&ex_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&ey_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(cl_mem), (void *)&hz_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(int), (void *)&nx);\n\t\terrcode |= clSetKernelArg(clKernel2, 4, sizeof(int), (void *)&ny);\n\t\t\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\t\tclEnqueueBarrier(clCommandQue);\n\n\t\t// Set the arguments of the kernel\n\t\terrcode =  clSetKernelArg(clKernel3, 0, sizeof(cl_mem), (void *)&ex_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel3, 1, sizeof(cl_mem), (void *)&ey_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel3, 2, sizeof(cl_mem), (void *)&hz_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel3, 3, sizeof(int), (void *)&nx);\n\t\terrcode |= clSetKernelArg(clKernel3, 4, sizeof(int), (void *)&ny);\n\t\t\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel3, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\t\tclFinish(clCommandQue);\n\t}\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseKernel(clKernel3);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(fict_mem_obj);\n\terrcode = clReleaseMemObject(ex_mem_obj);\n\terrcode = clReleaseMemObject(ey_mem_obj);\n\terrcode = clReleaseMemObject(hz_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid runFdtd(int tmax, int nx, int ny, DATA_TYPE POLYBENCH_1D(_fict_, TMAX, TMAX), DATA_TYPE POLYBENCH_2D(ex,NX,NY,nx,ny), \n\tDATA_TYPE POLYBENCH_2D(ey,NX,NY,nx,ny), DATA_TYPE POLYBENCH_2D(hz,NX,NY,nx,ny))\n{\n\tint t, i, j;\n\t\n\tfor (t=0; t < _PB_TMAX; t++)  \n\t{\n\t\tfor (j=0; j < _PB_NY; j++)\n\t\t{\n\t\t\tey[0][j] = _fict_[t];\n\t\t}\n\t\n\t\tfor (i = 1; i < _PB_NX; i++)\n\t\t{\n       \t\tfor (j = 0; j < _PB_NY; j++)\n\t\t\t{\n       \t\t\tey[i][j] = ey[i][j] - 0.5*(hz[i][j] - hz[(i-1)][j]);\n        \t\t}\n\t\t}\n\n\t\tfor (i = 0; i < _PB_NX; i++)\n\t\t{\n       \t\tfor (j = 1; j < _PB_NY; j++)\n\t\t\t{\n\t\t\t\tex[i][j] = ex[i][j] - 0.5*(hz[i][j] - hz[i][(j-1)]);\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0; i < _PB_NX-1; i++)\n\t\t{\n\t\t\tfor (j = 0; j < _PB_NY-1; j++)\n\t\t\t{\n\t\t\t\thz[i][j] = hz[i][j] - 0.7*(ex[i][(j+1)] - ex[i][j] + ey[(i+1)][j] - ey[i][j]);\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int nx,\n\t\t int ny,\n\t\t DATA_TYPE POLYBENCH_2D(hz,NX,NY,nx,ny))\n{\n  int i, j;\n\n  for (i = 0; i < nx; i++)\n    for (j = 0; j < ny; j++) {\n         fprintf(stderr, DATA_PRINTF_MODIFIER, hz[i][j]);\n      if ((i * nx + j) % 20 == 0) fprintf(stderr, \"\\n\");\n    }\n  fprintf(stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint tmax = TMAX;\n\tint nx = NX;\n\tint ny = NY;\n\n\tPOLYBENCH_1D_ARRAY_DECL(_fict_,DATA_TYPE,TMAX,TMAX);\n\tPOLYBENCH_2D_ARRAY_DECL(ex,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_2D_ARRAY_DECL(ey,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_2D_ARRAY_DECL(hz,DATA_TYPE,NX,NY,nx,ny);\n\tPOLYBENCH_2D_ARRAY_DECL(hz_outputFromGpu,DATA_TYPE,NX,NY,nx,ny);\n\t\n\tinit_arrays(tmax, nx, ny, POLYBENCH_ARRAY(_fict_), POLYBENCH_ARRAY(ex), POLYBENCH_ARRAY(ey), POLYBENCH_ARRAY(hz));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(_fict_), POLYBENCH_ARRAY(ex), POLYBENCH_ARRAY(ey), POLYBENCH_ARRAY(hz));\n\tcl_load_prog();\n\n\tcl_launch_kernel(tmax, nx, ny);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, hz_mem_obj, CL_TRUE, 0, NX * NY * sizeof(DATA_TYPE), POLYBENCH_ARRAY(hz_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\t\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\trunFdtd(tmax, nx, ny, POLYBENCH_ARRAY(_fict_), POLYBENCH_ARRAY(ex), POLYBENCH_ARRAY(ey), POLYBENCH_ARRAY(hz));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(nx, ny, POLYBENCH_ARRAY(hz), POLYBENCH_ARRAY(hz_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(nx, ny, POLYBENCH_ARRAY(hz_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tPOLYBENCH_FREE_ARRAY(_fict_);\n\tPOLYBENCH_FREE_ARRAY(ex);\n\tPOLYBENCH_FREE_ARRAY(ey);\n\tPOLYBENCH_FREE_ARRAY(hz);\n\tPOLYBENCH_FREE_ARRAY(hz_outputFromGpu);\n\n\tcl_clean_up();\n\t\n    return 0;\n}\n\n#include <polybench.c>", "fdtd2d.cl": "/**\n * fdtd2d.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n\t\n__kernel void fdtd_kernel1(__global DATA_TYPE *_fict_, __global DATA_TYPE *ex, __global DATA_TYPE *ey, __global DATA_TYPE *hz, int t, int nx, int ny) \n{    \n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\n\tif ((i < nx) && (j < ny))\n\t{\n\t\tint tid = i * ny + j;\n\n\t\tif (i == 0) \n\t\t{\n\t\t\tey[i * ny + j] = _fict_[t];\n\t\t}\n\t\telse\n\t\t{ \n\t\t\tey[i * ny + j] = ey[i * ny + j] - 0.5*(hz[i * ny + j] - hz[(i-1) * ny + j]);\n\t\t}\n\t}\n}\n\n\n__kernel void fdtd_kernel2(__global DATA_TYPE *ex, __global DATA_TYPE *ey, __global DATA_TYPE *hz, int nx, int ny) \n{    \n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < nx) && (j < ny) && (j > 0))\n\t{\n\t\tex[i * ny + j] = ex[i * ny + j] - 0.5*(hz[i * ny + j] - hz[i * ny + (j-1)]);\n\t}\n}\n\n\n__kernel void fdtd_kernel3(__global DATA_TYPE *ex, __global DATA_TYPE *ey, __global DATA_TYPE *hz, int nx, int ny) \n{    \n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\t\n\tif ((i < (nx-1)) && (j < (ny-1)))\n\t{\n\t\thz[i * ny + j] = hz[i * ny + j] - 0.7*(ex[i * ny + (j+1)] - ex[i * ny + j] + ey[(i + 1) * ny + j] - ey[i * ny + j]);\n\t}\n}\n\n"}, "code_dirs": {"fdtd2d.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/fdtd-2d", "fdtd2d.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/fdtd-2d"}}
{"kernel_name": "convolution-2d", "parallel_api": "cuda", "code": {"2DConvolution.cu": "/**\n * 2DConvolution.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"2DConvolution.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid conv2D(int ni, int nj, DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(B, NI, NJ, ni, nj))\n{\n\tint i, j;\n\tDATA_TYPE c11, c12, c13, c21, c22, c23, c31, c32, c33;\n\n\tc11 = +0.2;  c21 = +0.5;  c31 = -0.8;\n\tc12 = -0.3;  c22 = +0.6;  c32 = -0.9;\n\tc13 = +0.4;  c23 = +0.7;  c33 = +0.10;\n\n\n\tfor (i = 1; i < _PB_NI - 1; ++i) // 0\n\t{\n\t\tfor (j = 1; j < _PB_NJ - 1; ++j) // 1\n\t\t{\n\t\t\tB[i][j] = c11 * A[(i - 1)][(j - 1)]  +  c12 * A[(i + 0)][(j - 1)]  +  c13 * A[(i + 1)][(j - 1)]\n\t\t\t\t+ c21 * A[(i - 1)][(j + 0)]  +  c22 * A[(i + 0)][(j + 0)]  +  c23 * A[(i + 1)][(j + 0)] \n\t\t\t\t+ c31 * A[(i - 1)][(j + 1)]  +  c32 * A[(i + 0)][(j + 1)]  +  c33 * A[(i + 1)][(j + 1)];\n\t\t}\n\t}\n}\n\n\n\nvoid init(int ni, int nj, DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj))\n{\n\tint i, j;\n\n\tfor (i = 0; i < ni; ++i)\n    \t{\n\t\tfor (j = 0; j < nj; ++j)\n\t\t{\n\t\t\tA[i][j] = (float)rand()/RAND_MAX;\n        \t}\n    \t}\n}\n\n\nvoid compareResults(int ni, int nj, DATA_TYPE POLYBENCH_2D(B, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(B_outputFromGpu, NI, NJ, ni, nj))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\t// Compare outputs from CPU and GPU\n\tfor (i=1; i < (ni-1); i++) \n\t{\n\t\tfor (j=1; j < (nj-1); j++) \n\t\t{\n\t\t\tif (percentDiff(B[i][j], B_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n\t\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void convolution2D_kernel(int ni, int nj, DATA_TYPE *A, DATA_TYPE *B)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tDATA_TYPE c11, c12, c13, c21, c22, c23, c31, c32, c33;\n\n\tc11 = +0.2;  c21 = +0.5;  c31 = -0.8;\n\tc12 = -0.3;  c22 = +0.6;  c32 = -0.9;\n\tc13 = +0.4;  c23 = +0.7;  c33 = +0.10;\n\n\tif ((i < _PB_NI-1) && (j < _PB_NJ-1) && (i > 0) && (j > 0))\n\t{\n\t\tB[i * NJ + j] =  c11 * A[(i - 1) * NJ + (j - 1)]  + c21 * A[(i - 1) * NJ + (j + 0)] + c31 * A[(i - 1) * NJ + (j + 1)] \n\t\t\t+ c12 * A[(i + 0) * NJ + (j - 1)]  + c22 * A[(i + 0) * NJ + (j + 0)] +  c32 * A[(i + 0) * NJ + (j + 1)]\n\t\t\t+ c13 * A[(i + 1) * NJ + (j - 1)]  + c23 * A[(i + 1) * NJ + (j + 0)] +  c33 * A[(i + 1) * NJ + (j + 1)];\n\t}\n}\n\n\nvoid convolution2DCuda(int ni, int nj, DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(B, NI, NJ, ni, nj), \n\t\t\tDATA_TYPE POLYBENCH_2D(B_outputFromGpu, NI, NJ, ni, nj))\n{\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *B_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\tcudaMalloc((void **)&B_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyHostToDevice);\n\t\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((size_t)ceil( ((float)NI) / ((float)block.x) ), (size_t)ceil( ((float)NJ) / ((float)block.y)) );\n\n  \tpolybench_start_instruments;\n\n\tconvolution2D_kernel <<< grid,block >>> (ni, nj, A_gpu,B_gpu);\n\tcudaThreadSynchronize();\n\t\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n\n  \tpolybench_stop_instruments;\n  \tpolybench_print_instruments;\n\n\tcudaMemcpy(B_outputFromGpu, B_gpu, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyDeviceToHost);\n\t\n\tcudaFree(A_gpu);\n\tcudaFree(B_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nj,\n\t\t DATA_TYPE POLYBENCH_2D(B,NI,NJ,ni,nj))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nj; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, B[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size */\n\tint ni = NI;\n\tint nj = NJ;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,ni,nj);\n  \tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,NI,NJ,ni,nj);\n  \tPOLYBENCH_2D_ARRAY_DECL(B_outputFromGpu,DATA_TYPE,NI,NJ,ni,nj);\n\n\t//initialize the arrays\n\tinit(ni, nj, POLYBENCH_ARRAY(A));\n\t\n\tGPU_argv_init();\n\n\tconvolution2DCuda(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(B_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\t\n\t \t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tconv2D(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B));\n\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(ni, nj, POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(B_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nj, POLYBENCH_ARRAY(B_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(A);\n  \tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(B_outputFromGpu);\n\t\n\treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"2DConvolution.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/stencils/convolution-2d"}}
{"kernel_name": "convolution-2d", "parallel_api": "ocl", "code": {"2DConvolution.c": "/**\n * 2DConvolution.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"2DConvolution.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 1.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\ncl_mem c_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int ni, int nj, DATA_TYPE POLYBENCH_2D(B, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(B_outputFromGpu, NI, NJ, ni, nj))\n{\n\tint i, j, fail;\n\tfail = 0;\n\t\n\t// Compare outputs from CPU and GPU\n\tfor (i=1; i < (ni-1); i++) \n\t{\n\t\tfor (j=1; j < (nj-1); j++) \n\t\t{\n\t\t\tif (percentDiff(B[i][j], B_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"2DConvolution.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stdout, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init(int ni, int nj, DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj))\n{\n\tint i, j;\n\n\tfor (i = 0; i < ni; ++i)\n    \t{\n\t\tfor (j = 0; j < nj; ++j)\n\t\t{\n\t\t\tA[i][j] = (float)rand()/RAND_MAX;\n        \t}\n    \t}\n}\n\n\nvoid cl_initialization()\n{\n\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_ONLY, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NJ, A, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n }\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel = clCreateKernel(clProgram, \"Convolution2D_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int ni, int nj)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NI) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NJ) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode =  clSetKernelArg(clKernel, 2, sizeof(int), &ni);\n\terrcode |= clSetKernelArg(clKernel, 3, sizeof(int), &nj);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\nvoid conv2D(int ni, int nj, DATA_TYPE POLYBENCH_2D(A, NI, NJ, ni, nj), DATA_TYPE POLYBENCH_2D(B, NI, NJ, ni, nj))\n{\n\tint i, j;\n\tDATA_TYPE c11, c12, c13, c21, c22, c23, c31, c32, c33;\n\n\tc11 = +0.2;  c21 = +0.5;  c31 = -0.8;\n\tc12 = -0.3;  c22 = +0.6;  c32 = -0.9;\n\tc13 = +0.4;  c23 = +0.7;  c33 = +0.10;\n\n\n\tfor (i = 1; i < _PB_NI - 1; ++i) // 0\n\t{\n\t\tfor (j = 1; j < _PB_NJ - 1; ++j) // 1\n\t\t{\n\t\t\tB[i][j] = c11 * A[(i - 1)][(j - 1)]  +  c12 * A[(i + 0)][(j - 1)]  +  c13 * A[(i + 1)][(j - 1)]\n\t\t\t\t+ c21 * A[(i - 1)][(j + 0)]  +  c22 * A[(i + 0)][(j + 0)]  +  c23 * A[(i + 1)][(j + 0)] \n\t\t\t\t+ c31 * A[(i - 1)][(j + 1)]  +  c32 * A[(i + 0)][(j + 1)]  +  c33 * A[(i + 1)][(j + 1)];\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nj,\n\t\t DATA_TYPE POLYBENCH_2D(B,NI,NJ,ni,nj))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nj; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, B[i][j]);\n\tif ((i * ni + j) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size */\n\tint ni = NI;\n\tint nj = NJ;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,ni,nj);\n  \tPOLYBENCH_2D_ARRAY_DECL(B,DATA_TYPE,NI,NJ,ni,nj);\n  \tPOLYBENCH_2D_ARRAY_DECL(B_outputFromGpu,DATA_TYPE,NI,NJ,ni,nj);\n\n\tinit(ni, nj, POLYBENCH_ARRAY(A));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A));\n\tcl_load_prog();\n\n\tcl_launch_kernel(ni, nj);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, NI*NJ*sizeof(DATA_TYPE), POLYBENCH_ARRAY(B_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n  \t\tpolybench_start_instruments;\n\n\t\tconv2D(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n  \t\tpolybench_stop_instruments;\n \t\tpolybench_print_instruments;\n\n\t\tcompareResults(ni, nj, POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(B_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nj, POLYBENCH_ARRAY(B_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(B_outputFromGpu);\n\n    \treturn 0;\n}\n\n#include <polybench.c>", "2DConvolution.cl": "/**\n * 2DConvolution.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n/* Can switch DATA_TYPE between float and double */\ntypedef float DATA_TYPE;\n\n__kernel void Convolution2D_kernel(__global DATA_TYPE *A, __global DATA_TYPE *B, int ni, int nj) \n{\n\tint j = get_global_id(0);\n\tint i = get_global_id(1);\n\n\tDATA_TYPE c11, c12, c13, c21, c22, c23, c31, c32, c33;\n\tc11 = +0.2;  c21 = +0.5;  c31 = -0.8;\n\tc12 = -0.3;  c22 = +0.6;  c32 = -0.9;\n\tc13 = +0.4;  c23 = +0.7;  c33 = +0.10;\n\tif ((i < (ni-1)) && (j < (nj - 1)) && (i > 0) && (j > 0))\n\t{\n\t\tB[i*nj + j] =  c11 * A[(i - 1) * nj + (j - 1)]  + c21 * A[(i - 1) * nj + (j + 0)] + c31 * A[(i - 1) * nj + (j + 1)] \n\t\t      + c12 * A[(i + 0) * nj + (j - 1)]  + c22 * A[(i + 0) * nj + (j + 0)] + c32 * A[(i + 0) * nj + (j + 1)]\n\t\t      + c13 * A[(i + 1) * nj + (j - 1)]  + c23 * A[(i + 1) * nj + (j + 0)] + c33 * A[(i + 1) * nj + (j + 1)];\n\t}\n}\n"}, "code_dirs": {"2DConvolution.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/convolution-2d", "2DConvolution.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/convolution-2d"}}
{"kernel_name": "convolution-3d", "parallel_api": "cuda", "code": {"3DConvolution.cu": "/**\n * 3DConvolution.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"3DConvolution.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.5\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid conv3D(int ni, int nj, int nk, DATA_TYPE POLYBENCH_3D(A, NI, NJ, NK, ni, nj, nk), DATA_TYPE POLYBENCH_3D(B, NI, NJ, NK, ni, nj, nk))\n{\n\tint i, j, k;\n\tDATA_TYPE c11, c12, c13, c21, c22, c23, c31, c32, c33;\n\n\tc11 = +2;  c21 = +5;  c31 = -8;\n\tc12 = -3;  c22 = +6;  c32 = -9;\n\tc13 = +4;  c23 = +7;  c33 = +10;\n\n\tfor (i = 1; i < _PB_NI - 1; ++i) // 0\n\t{\n\t\tfor (j = 1; j < _PB_NJ - 1; ++j) // 1\n\t\t{\n\t\t\tfor (k = 1; k < _PB_NK -1; ++k) // 2\n\t\t\t{\n\t\t\t\tB[i][j][k] = c11 * A[(i - 1)][(j - 1)][(k - 1)]  +  c13 * A[(i + 1)][(j - 1)][(k - 1)]\n\t\t\t\t\t     +   c21 * A[(i - 1)][(j - 1)][(k - 1)]  +  c23 * A[(i + 1)][(j - 1)][(k - 1)]\n\t\t\t\t\t     +   c31 * A[(i - 1)][(j - 1)][(k - 1)]  +  c33 * A[(i + 1)][(j - 1)][(k - 1)]\n\t\t\t\t\t     +   c12 * A[(i + 0)][(j - 1)][(k + 0)]  +  c22 * A[(i + 0)][(j + 0)][(k + 0)]   \n\t\t\t\t\t     +   c32 * A[(i + 0)][(j + 1)][(k + 0)]  +  c11 * A[(i - 1)][(j - 1)][(k + 1)]  \n\t\t\t\t\t     +   c13 * A[(i + 1)][(j - 1)][(k + 1)]  +  c21 * A[(i - 1)][(j + 0)][(k + 1)]  \n\t\t\t\t\t     +   c23 * A[(i + 1)][(j + 0)][(k + 1)]  +  c31 * A[(i - 1)][(j + 1)][(k + 1)]  \n\t\t\t\t\t     +   c33 * A[(i + 1)][(j + 1)][(k + 1)];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\nvoid init(int ni, int nj, int nk, DATA_TYPE POLYBENCH_3D(A, NI, NJ, NK, ni, nj, nk))\n{\n\tint i, j, k;\n\n\tfor (i = 0; i < ni; ++i)\n    \t{\n\t\tfor (j = 0; j < nj; ++j)\n\t\t{\n\t\t\tfor (k = 0; k < nk; ++k)\n\t\t\t{\n\t\t\t\tA[i][j][k] = i % 12 + 2 * (j % 7) + 3 * (k % 13);\n\t\t\t}\n\t\t}\n\t}\n}\n\n\nvoid compareResults(int ni, int nj, int nk, DATA_TYPE POLYBENCH_3D(B, NI, NJ, NK, ni, nj, nk), DATA_TYPE POLYBENCH_3D(B_outputFromGpu, NI, NJ, NK, ni, nj, nk))\n{\n\tint i, j, k, fail;\n\tfail = 0;\n\t\n\t// Compare result from cpu and gpu\n\tfor (i = 1; i < ni - 1; ++i) // 0\n\t{\n\t\tfor (j = 1; j < nj - 1; ++j) // 1\n\t\t{\n\t\t\tfor (k = 1; k < nk - 1; ++k) // 2\n\t\t\t{\n\t\t\t\tif (percentDiff(B[i][j][k], B_outputFromGpu[i][j][k]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t\t{\n\t\t\t\t\tfail++;\n\t\t\t\t}\n\t\t\t}\t\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\n}\n\n\n__global__ void convolution3D_kernel(int ni, int nj, int nk, DATA_TYPE* A, DATA_TYPE* B, int i)\n{\n\tint k = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tDATA_TYPE c11, c12, c13, c21, c22, c23, c31, c32, c33;\n\n\tc11 = +2;  c21 = +5;  c31 = -8;\n\tc12 = -3;  c22 = +6;  c32 = -9;\n\tc13 = +4;  c23 = +7;  c33 = +10;\n\n\n\tif ((i < (_PB_NI-1)) && (j < (_PB_NJ-1)) &&  (k < (_PB_NK-1)) && (i > 0) && (j > 0) && (k > 0))\n\t{\n\t\tB[i*(NK * NJ) + j*NK + k] = c11 * A[(i - 1)*(NK * NJ) + (j - 1)*NK + (k - 1)]  +  c13 * A[(i + 1)*(NK * NJ) + (j - 1)*NK + (k - 1)]\n\t\t\t\t\t     +   c21 * A[(i - 1)*(NK * NJ) + (j - 1)*NK + (k - 1)]  +  c23 * A[(i + 1)*(NK * NJ) + (j - 1)*NK + (k - 1)]\n\t\t\t\t\t     +   c31 * A[(i - 1)*(NK * NJ) + (j - 1)*NK + (k - 1)]  +  c33 * A[(i + 1)*(NK * NJ) + (j - 1)*NK + (k - 1)]\n\t\t\t\t\t     +   c12 * A[(i + 0)*(NK * NJ) + (j - 1)*NK + (k + 0)]  +  c22 * A[(i + 0)*(NK * NJ) + (j + 0)*NK + (k + 0)]   \n\t\t\t\t\t     +   c32 * A[(i + 0)*(NK * NJ) + (j + 1)*NK + (k + 0)]  +  c11 * A[(i - 1)*(NK * NJ) + (j - 1)*NK + (k + 1)]  \n\t\t\t\t\t     +   c13 * A[(i + 1)*(NK * NJ) + (j - 1)*NK + (k + 1)]  +  c21 * A[(i - 1)*(NK * NJ) + (j + 0)*NK + (k + 1)]  \n\t\t\t\t\t     +   c23 * A[(i + 1)*(NK * NJ) + (j + 0)*NK + (k + 1)]  +  c31 * A[(i - 1)*(NK * NJ) + (j + 1)*NK + (k + 1)]  \n\t\t\t\t\t     +   c33 * A[(i + 1)*(NK * NJ) + (j + 1)*NK + (k + 1)];\n\t}\n}\n\n\nvoid convolution3DCuda(int ni, int nj, int nk, DATA_TYPE POLYBENCH_3D(A, NI, NJ, NK, ni, nj, nk), DATA_TYPE POLYBENCH_3D(B, NI, NJ, NK, ni, nj, nk), DATA_TYPE POLYBENCH_3D(B_outputFromGpu, NI, NJ, NK, ni, nj, nk))\n{\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *B_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NI * NJ * NK);\n\tcudaMalloc((void **)&B_gpu, sizeof(DATA_TYPE) * NI * NJ * NK);\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NI * NJ * NK, cudaMemcpyHostToDevice);\n\tcudaMemcpy(B_gpu, B, sizeof(DATA_TYPE) * NI * NJ * NK, cudaMemcpyHostToDevice);\n\t\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((size_t)(ceil( ((float)NK) / ((float)block.x) )), (size_t)(ceil( ((float)NJ) / ((float)block.y) )));\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tint i;\n\tfor (i = 1; i < _PB_NI - 1; ++i) // 0\n\t{\n\t\tconvolution3D_kernel<<< grid, block >>>(ni, nj, nk, A_gpu, B_gpu, i);\n\t}\n\n\tcudaThreadSynchronize();\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\t\n\tcudaMemcpy(B_outputFromGpu, B_gpu, sizeof(DATA_TYPE) * NI * NJ * NK, cudaMemcpyDeviceToHost);\n\t\n\tcudaFree(A_gpu);\n\tcudaFree(B_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nj, int nk,\n\t\t DATA_TYPE POLYBENCH_3D(B,NI,NJ,NK,ni,nj,nk))\n{\n  int i, j, k;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nj; j++) \n\tfor (k = 0; k < nk; k++)\n\t{\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, B[i][j][k]);\n\tif ((i * (nj*nk) + j*nk + k) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\tint ni = NI;\n\tint nj = NJ;\n\tint nk = NK;\n\n\tPOLYBENCH_3D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,NK,ni,nj,nk);\n\tPOLYBENCH_3D_ARRAY_DECL(B,DATA_TYPE,NI,NJ,NK,ni,nj,nk);\n\tPOLYBENCH_3D_ARRAY_DECL(B_outputFromGpu,DATA_TYPE,NI,NJ,NK,ni,nj,nk);\n\n\tinit(ni, nj, nk, POLYBENCH_ARRAY(A));\n\t\n\tGPU_argv_init();\n\n\tconvolution3DCuda(ni, nj, nk, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(B_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tconv3D(ni, nj, nk, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B));\n\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(ni, nj, nk, POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(B_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(NI, NJ, NK, POLYBENCH_ARRAY(B_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(B_outputFromGpu);\n\n    \treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"3DConvolution.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/stencils/convolution-3d"}}
{"kernel_name": "convolution-3d", "parallel_api": "ocl", "code": {"3DConvolution.c": "/**\n * 3DConvolution.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"3DConvolution.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 1.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"3DConvolution.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init(int ni, int nj, int nk, DATA_TYPE POLYBENCH_3D(A, NI, NJ, NK, ni, nj, nk))\n{\n\tint i, j, k;\n\n\tfor (i = 0; i < ni; ++i)\n    \t{\n\t\tfor (j = 0; j < nj; ++j)\n\t\t{\n\t\t\tfor (k = 0; k < nk; ++k)\n\t\t\t{\n\t\t\t\tA[i][j][k] = i % 12 + 2 * (j % 7) + 3 * (k % 13);\n\t\t\t}\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_3D(A, NI, NJ, NK, ni, nj, nk), DATA_TYPE POLYBENCH_3D(B, NI, NJ, NK, ni, nj, nk))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_ONLY, sizeof(DATA_TYPE) * NI * NJ * NK, NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ * NK, NULL, &errcode);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NJ * NK, A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NJ * NK, B, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel = clCreateKernel(clProgram, \"Convolution3D_kernel\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int ni, int nj, int nk)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = (size_t)ceil(((float)NK) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSize[1] = (size_t)ceil(((float)NJ) / ((float)DIM_LOCAL_WORK_GROUP_Y)) * DIM_LOCAL_WORK_GROUP_Y;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel, 2, sizeof(int), &ni);\n\terrcode |= clSetKernelArg(clKernel, 3, sizeof(int), &nj);\n\terrcode |= clSetKernelArg(clKernel, 4, sizeof(int), &nk);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\t\n\tint i;\n\tfor (i = 1; i < NI - 1; ++i) // 0\n\t{\n\t\t// set the current value of 'i' for the argument in the kernel\n\t\terrcode |= clSetKernelArg(clKernel, 5, sizeof(int), &i);\n\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\t}\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid compareResults(int ni, int nj, int nk, DATA_TYPE POLYBENCH_3D(B, NI, NJ, NK, ni, nj, nk), DATA_TYPE POLYBENCH_3D(B_outputFromGpu, NI, NJ, NK, ni, nj, nk))\n{\n\tint i, j, k, fail;\n\tfail = 0;\n\t\n\t// Compare result from cpu and gpu\n\tfor (i = 1; i < ni - 1; ++i) // 0\n\t{\n\t\tfor (j = 1; j < nj - 1; ++j) // 1\n\t\t{\n\t\t\tfor (k = 1; k < nk - 1; ++k) // 2\n\t\t\t{\n\t\t\t\tif (percentDiff(B[i][j][k], B_outputFromGpu[i][j][k]) > PERCENT_DIFF_ERROR_THRESHOLD)\n\t\t\t\t{\n\t\t\t\t\tfail++;\n\t\t\t\t}\n\t\t\t}\t\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid conv3D(int ni, int nj, int nk, DATA_TYPE POLYBENCH_3D(A, NI, NJ, NK, ni, nj, nk), DATA_TYPE POLYBENCH_3D(B, NI, NJ, NK, ni, nj, nk))\n{\n\tint i, j, k;\n\tDATA_TYPE c11, c12, c13, c21, c22, c23, c31, c32, c33;\n\n\tc11 = +2;  c21 = +5;  c31 = -8;\n\tc12 = -3;  c22 = +6;  c32 = -9;\n\tc13 = +4;  c23 = +7;  c33 = +10;\n\n\tfor (i = 1; i < _PB_NI - 1; ++i) // 0\n\t{\n\t\tfor (j = 1; j < _PB_NJ - 1; ++j) // 1\n\t\t{\n\t\t\tfor (k = 1; k < _PB_NK -1; ++k) // 2\n\t\t\t{\n\t\t\t\tB[i][j][k] = c11 * A[(i - 1)][(j - 1)][(k - 1)]  +  c13 * A[(i + 1)][(j - 1)][(k - 1)]\n\t\t\t\t\t     +   c21 * A[(i - 1)][(j - 1)][(k - 1)]  +  c23 * A[(i + 1)][(j - 1)][(k - 1)]\n\t\t\t\t\t     +   c31 * A[(i - 1)][(j - 1)][(k - 1)]  +  c33 * A[(i + 1)][(j - 1)][(k - 1)]\n\t\t\t\t\t     +   c12 * A[(i + 0)][(j - 1)][(k + 0)]  +  c22 * A[(i + 0)][(j + 0)][(k + 0)]   \n\t\t\t\t\t     +   c32 * A[(i + 0)][(j + 1)][(k + 0)]  +  c11 * A[(i - 1)][(j - 1)][(k + 1)]  \n\t\t\t\t\t     +   c13 * A[(i + 1)][(j - 1)][(k + 1)]  +  c21 * A[(i - 1)][(j + 0)][(k + 1)]  \n\t\t\t\t\t     +   c23 * A[(i + 1)][(j + 0)][(k + 1)]  +  c31 * A[(i - 1)][(j + 1)][(k + 1)]  \n\t\t\t\t\t     +   c33 * A[(i + 1)][(j + 1)][(k + 1)];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nj, int nk,\n\t\t DATA_TYPE POLYBENCH_3D(B,NI,NJ,NK,ni,nj,nk))\n{\n  int i, j, k;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nj; j++) \n\tfor (k = 0; k < nk; k++)\n\t{\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, B[i][j][k]);\n\tif ((i * (nj*nk) + j*nk + k) % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\t\n\tint ni = NI;\n\tint nj = NJ;\n\tint nk = NK;\n\n\tPOLYBENCH_3D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,NK,ni,nj,nk);\n\tPOLYBENCH_3D_ARRAY_DECL(B,DATA_TYPE,NI,NJ,NK,ni,nj,nk);\n\tPOLYBENCH_3D_ARRAY_DECL(B_outputFromGpu,DATA_TYPE,NI,NJ,NK,ni,nj,nk);\n\n\tinit(ni, nj, nk, POLYBENCH_ARRAY(A));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B));\n\tcl_load_prog();\n\n\tcl_launch_kernel(ni, nj, nk);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, NI * NJ * NK * sizeof(DATA_TYPE), POLYBENCH_ARRAY(B_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tconv3D(ni, nj, nk, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(B));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(ni, nj, nk, POLYBENCH_ARRAY(B), POLYBENCH_ARRAY(B_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nj, nk, POLYBENCH_ARRAY(B_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(B);\n\tPOLYBENCH_FREE_ARRAY(B_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>", "3DConvolution.cl": "/**\n * 3DConvolution.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n__kernel void Convolution3D_kernel(__global DATA_TYPE *A, __global DATA_TYPE *B, int ni, int nj, int nk, int i)\n{\n    \n\tint k = get_global_id(0);\n\tint j = get_global_id(1);\n\t\n\tDATA_TYPE c11, c12, c13, c21, c22, c23, c31, c32, c33;\n\tc11 = +2;  c21 = +5;  c31 = -8;\n\tc12 = -3;  c22 = +6;  c32 = -9;\n\tc13 = +4;  c23 = +7;  c33 = +10;\n\t\n    \t// Do the operation\n    \tif ((i < (ni - 1)) && (j < (nj - 1)) &&  (k < (nk - 1)) && (i > 0) && (j > 0) && (k > 0))\n\t{\n\t\tB[i*(nk * nj) + j*nk + k] = c11 * A[(i - 1)*(nk * nj) + (j - 1)*nk + (k - 1)]  +  c13 * A[(i + 1)*(nk * nj) + (j - 1)*nk + (k - 1)]\n\t\t\t\t\t     +   c21 * A[(i - 1)*(nk * nj) + (j - 1)*nk + (k - 1)]  +  c23 * A[(i + 1)*(nk * nj) + (j - 1)*nk + (k - 1)]\n\t\t\t\t\t     +   c31 * A[(i - 1)*(nk * nj) + (j - 1)*nk + (k - 1)]  +  c33 * A[(i + 1)*(nk * nj) + (j - 1)*nk + (k - 1)]\n\t\t\t\t\t     +   c12 * A[(i + 0)*(nk * nj) + (j - 1)*nk + (k + 0)]  +  c22 * A[(i + 0)*(nk * nj) + (j + 0)*nk + (k + 0)]   \n\t\t\t\t\t     +   c32 * A[(i + 0)*(nk * nj) + (j + 1)*nk + (k + 0)]  +  c11 * A[(i - 1)*(nk * nj) + (j - 1)*nk + (k + 1)]  \n\t\t\t\t\t     +   c13 * A[(i + 1)*(nk * nj) + (j - 1)*nk + (k + 1)]  +  c21 * A[(i - 1)*(nk * nj) + (j + 0)*nk + (k + 1)]  \n\t\t\t\t\t     +   c23 * A[(i + 1)*(nk * nj) + (j + 0)*nk + (k + 1)]  +  c31 * A[(i - 1)*(nk * nj) + (j + 1)*nk + (k + 1)]  \n\t\t\t\t\t     +   c33 * A[(i + 1)*(nk * nj) + (j + 1)*nk + (k + 1)];\n\t}\n\telse \n\t{\n\t\tB[i*(nk * nj) + j*nk + k] = 0;\n\t}\n}\n"}, "code_dirs": {"3DConvolution.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/convolution-3d", "3DConvolution.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/convolution-3d"}}
{"kernel_name": "jacobi-1d-imper", "parallel_api": "cuda", "code": {"jacobi1D.cu": "/**\n * jacobi1D.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <unistd.h>\n#include <time.h>\n#include <sys/time.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <math.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"jacobi1D.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define RUN_ON_CPU\n\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_1D(A,N,n), DATA_TYPE POLYBENCH_1D(B,N,n))\n{\n\tint i;\n\n\tfor (i = 0; i < n; i++)\n    \t{\n\t\tA[i] = ((DATA_TYPE) 4 * i + 10) / N;\n\t\tB[i] = ((DATA_TYPE) 7 * i + 11) / N;\n    \t}\n}\n\n\nvoid runJacobi1DCpu(int tsteps, int n, DATA_TYPE POLYBENCH_1D(A,N,n), DATA_TYPE POLYBENCH_1D(B,N,n))\n{\n\tfor (int t = 0; t < _PB_TSTEPS; t++)\n    {\n\t\tfor (int i = 2; i < _PB_N - 1; i++)\n\t\t{\n\t\t\tB[i] = 0.33333 * (A[i-1] + A[i] + A[i + 1]);\n\t\t}\n\t\t\n\t\tfor (int j = 2; j < _PB_N - 1; j++)\n\t\t{\n\t\t\tA[j] = B[j];\n\t\t}\n    }\n}\n\n\n__global__ void runJacobiCUDA_kernel1(int n, DATA_TYPE* A, DATA_TYPE* B)\n{\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif ((i > 1) && (i < (_PB_N-1)))\n\t{\n\t\tB[i] = 0.33333f * (A[i-1] + A[i] + A[i + 1]);\n\t}\n}\n\n\n__global__ void runJacobiCUDA_kernel2(int n, DATA_TYPE* A, DATA_TYPE* B)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif ((j > 1) && (j < (_PB_N-1)))\n\t{\n\t\tA[j] = B[j];\n\t}\n}\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_1D(a,N,n), DATA_TYPE POLYBENCH_1D(a_outputFromGpu,N,n), DATA_TYPE POLYBENCH_1D(b,N,n), DATA_TYPE POLYBENCH_1D(b_outputFromGpu,N,n))\n{\n\tint i, fail;\n\tfail = 0;   \n\n\t// Compare a and c\n\tfor (i=0; i < n; i++) \n\t{\n\t\tif (percentDiff(a[i], a_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\n\tfor (i=0; i < n; i++) \n\t{\n\t\tif (percentDiff(b[i], b_outputFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t{\t\n\t\t\tfail++;\n\t\t}\n\t}\n\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid runJacobi1DCUDA(int tsteps, int n, DATA_TYPE POLYBENCH_1D(A,N,n), DATA_TYPE POLYBENCH_1D(B,N,n), DATA_TYPE POLYBENCH_1D(A_outputFromGpu,N,n), \n\t\t\tDATA_TYPE POLYBENCH_1D(B_outputFromGpu,N,n))\n{\n\tDATA_TYPE* Agpu;\n\tDATA_TYPE* Bgpu;\n\n\tcudaMalloc(&Agpu, N * sizeof(DATA_TYPE));\n\tcudaMalloc(&Bgpu, N * sizeof(DATA_TYPE));\n\n\tcudaMemcpy(Agpu, A, N * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\tcudaMemcpy(Bgpu, B, N * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\t\n\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((unsigned int)ceil( ((float)N) / ((float)block.x) ), 1);\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tfor (int t = 0; t < _PB_TSTEPS ; t++)\n\t{\n\t\trunJacobiCUDA_kernel1 <<< grid, block >>> (n, Agpu, Bgpu);\n\t\tcudaThreadSynchronize();\n\t\trunJacobiCUDA_kernel2 <<< grid, block>>> (n, Agpu, Bgpu);\n\t\tcudaThreadSynchronize();\n\t}\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\t\n\tcudaMemcpy(A_outputFromGpu, Agpu, sizeof(DATA_TYPE) * N, cudaMemcpyDeviceToHost);\n\tcudaMemcpy(B_outputFromGpu, Bgpu, sizeof(DATA_TYPE) * N, cudaMemcpyDeviceToHost);\n\n\tcudaFree(Agpu);\n\tcudaFree(Bgpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_1D(A,N,n))\n\n{\n  int i;\n\n  for (i = 0; i < n; i++)\n    {\n      fprintf(stderr, DATA_PRINTF_MODIFIER, A[i]);\n      if (i % 20 == 0) fprintf(stderr, \"\\n\");\n    }\n  fprintf(stderr, \"\\n\");\n}\n\n\nint main(int argc, char** argv)\n{\n\t/* Retrieve problem size. */\n\tint n = N;\n\tint tsteps = TSTEPS;\n\n\tPOLYBENCH_1D_ARRAY_DECL(a,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(b,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(a_outputFromGpu,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(b_outputFromGpu,DATA_TYPE,N,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\n\trunJacobi1DCUDA(tsteps, n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b), POLYBENCH_ARRAY(a_outputFromGpu), POLYBENCH_ARRAY(b_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\t\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\t\n\t\trunJacobi1DCpu(tsteps, n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(a_outputFromGpu), POLYBENCH_ARRAY(b), POLYBENCH_ARRAY(b_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(a_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(a);\n\tPOLYBENCH_FREE_ARRAY(a_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(b);\n\tPOLYBENCH_FREE_ARRAY(b_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"jacobi1D.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/stencils/jacobi-1d-imper"}}
{"kernel_name": "jacobi-1d-imper", "parallel_api": "ocl", "code": {"jacobi1D.c": "/**\n * jacobi1D.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"jacobi1D.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 10.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_1D(a,N,n), DATA_TYPE POLYBENCH_1D(a_outFromGpu,N,n), DATA_TYPE POLYBENCH_1D(b,N,n), \n\tDATA_TYPE POLYBENCH_1D(b_outFromGpu,N,n))\n{\n\tint i, j, fail;\n\tfail = 0;   \n\n\tfor (i=1; i<(n-1); i++) \n\t{\n\t\tif (percentDiff(a[i], a_outFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\n\tfor (i=1; i<(n-1); i++) \n\t{\n\t\tif (percentDiff(b[i], b_outFromGpu[i]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t{\n\t\t\tfail++;\n\t\t}\n\t}\n\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"jacobi1D.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_1D(A,N,n), DATA_TYPE POLYBENCH_1D(B,N,n))\n{\n\tint i;\n\n\tfor (i = 0; i < n; i++)\n    \t{\n\t\tA[i] = ((DATA_TYPE) 4 * i + 10) / N;\n\t\tB[i] = ((DATA_TYPE) 7 * i + 11) / N;\n    \t}\n}\n\n\nvoid cl_initialization()\n{\n\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"device id is %d\\n\",device_id);\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_1D(A,N,n), DATA_TYPE POLYBENCH_1D(B,N,n))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, N * sizeof(DATA_TYPE), NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, N * sizeof(DATA_TYPE), NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, N * sizeof(DATA_TYPE), A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, N * sizeof(DATA_TYPE), B, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"runJacobi1D_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclKernel2 = clCreateKernel(clProgram, \"runJacobi1D_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel1(int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = N;\n\tglobalWorkSize[1] = 1;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel2(int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = N;\n\tglobalWorkSize[1] = 1;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid runJacobi1DCpu(int tsteps, int n, DATA_TYPE POLYBENCH_1D(A,N,n), DATA_TYPE POLYBENCH_1D(B,N,n))\n{\n\tint t, i, j;\n\tfor (t = 0; t < _PB_TSTEPS; t++)\n\t{\n\t\tfor (i = 1; i < _PB_N - 1; i++)\n\t\t{\n\t\t\tB[i] = 0.33333 * (A[i-1] + A[i] + A[i + 1]);\n\t\t}\n\t\t\n\t\tfor (j = 1; j < _PB_N - 1; j++)\n\t\t{\n\t\t\tA[j] = B[j];\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_1D(A,N,n))\n\n{\n  int i;\n\n  for (i = 0; i < n; i++)\n    {\n      fprintf(stderr, DATA_PRINTF_MODIFIER, A[i]);\n      if (i % 20 == 0) fprintf(stderr, \"\\n\");\n    }\n  fprintf(stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\t\n\t/* Retrieve problem size. */\n\tint n = N;\n\tint tsteps = TSTEPS;\n\n\tPOLYBENCH_1D_ARRAY_DECL(a,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(b,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(a_outputFromGpu,DATA_TYPE,N,n);\n\tPOLYBENCH_1D_ARRAY_DECL(b_outputFromGpu,DATA_TYPE,N,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\tcl_load_prog();\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\tint t;\n\tfor (t = 0; t < _PB_TSTEPS ; t++)\n\t{\n\t\tcl_launch_kernel1(n);\n\t\tcl_launch_kernel2(n);\n\t}\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\t\n\terrcode = clEnqueueReadBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, N * sizeof(DATA_TYPE), POLYBENCH_ARRAY(a_outputFromGpu), 0, NULL, NULL);\n\terrcode = clEnqueueReadBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, N * sizeof(DATA_TYPE), POLYBENCH_ARRAY(b_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\t\t\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\trunJacobi1DCpu(tsteps, n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(a_outputFromGpu), POLYBENCH_ARRAY(b), POLYBENCH_ARRAY(b_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(a_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(a);\n\tPOLYBENCH_FREE_ARRAY(b);\n\tPOLYBENCH_FREE_ARRAY(a_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(b_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>", "jacobi1D.cl": "/**\n * jacobi1D.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n__kernel void runJacobi1D_kernel1(__global DATA_TYPE* A, __global DATA_TYPE* B, int n)\n{\n\tint i = get_global_id(0);\n\tif ((i >= 1) && (i < (n-1)))\n\t{\n\t\tB[i] = 0.33333f * (A[i-1] + A[i] + A[i + 1]);\n\t}\n}\n\n__kernel void runJacobi1D_kernel2(__global DATA_TYPE* A, __global DATA_TYPE* B, int n)\n{\n\tint j = get_global_id(0);\n\t\n\tif ((j >= 1) && (j < (n-1)))\n\t{\n\t\tA[j] = B[j];\n\t}\n}\n"}, "code_dirs": {"jacobi1D.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/jacobi-1d-imper", "jacobi1D.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/jacobi-1d-imper"}}
{"kernel_name": "jacobi-2d-imper", "parallel_api": "cuda", "code": {"jacobi2D.cu": "/**\n * jacobi2D.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <unistd.h>\n#include <time.h>\n#include <sys/time.h>\n#include <string.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <math.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"jacobi2D.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define RUN_ON_CPU\n\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n))\n{\n\tint i, j;\n\n\tfor (i = 0; i < n; i++)\n\t{\n\t\tfor (j = 0; j < n; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*(j+2) + 10) / N;\n\t\t\tB[i][j] = ((DATA_TYPE) (i-4)*(j-1) + 11) / N;\n\t\t}\n\t}\n}\n\n\nvoid runJacobi2DCpu(int tsteps, int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n))\n{\n\tfor (int t = 0; t < _PB_TSTEPS; t++)\n\t{\n    \t\tfor (int i = 1; i < _PB_N - 1; i++)\n\t\t{\n\t\t\tfor (int j = 1; j < _PB_N - 1; j++)\n\t\t\t{\n\t  \t\t\tB[i][j] = 0.2f * (A[i][j] + A[i][(j-1)] + A[i][(1+j)] + A[(1+i)][j] + A[(i-1)][j]);\n\t\t\t}\n\t\t}\n\t\t\n    \t\tfor (int i = 1; i < _PB_N-1; i++)\n\t\t{\n\t\t\tfor (int j = 1; j < _PB_N-1; j++)\n\t\t\t{\n\t  \t\t\tA[i][j] = B[i][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n__global__ void runJacobiCUDA_kernel1(int n, DATA_TYPE* A, DATA_TYPE* B)\n{\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif ((i >= 1) && (i < (_PB_N-1)) && (j >= 1) && (j < (_PB_N-1)))\n\t{\n\t\tB[i*N + j] = 0.2f * (A[i*N + j] + A[i*N + (j-1)] + A[i*N + (1 + j)] + A[(1 + i)*N + j] + A[(i-1)*N + j]);\t\n\t}\n}\n\n\n__global__ void runJacobiCUDA_kernel2(int n, DATA_TYPE* A, DATA_TYPE* B)\n{\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif ((i >= 1) && (i < (_PB_N-1)) && (j >= 1) && (j < (_PB_N-1)))\n\t{\n\t\tA[i*N + j] = B[i*N + j];\n\t}\n}\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_2D(a,N,N,n,n), DATA_TYPE POLYBENCH_2D(a_outputFromGpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(b,N,N,n,n), DATA_TYPE POLYBENCH_2D(b_outputFromGpu,N,N,n,n))\n{\n\tint i, j, fail;\n\tfail = 0;   \n\n\t// Compare output from CPU and GPU\n\tfor (i=0; i<n; i++) \n\t{\n\t\tfor (j=0; j<n; j++) \n\t\t{\n\t\t\tif (percentDiff(a[i][j], a_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n        }\n\t}\n  \n\tfor (i=0; i<n; i++) \n\t{\n       \tfor (j=0; j<n; j++) \n\t\t{\n        \t\tif (percentDiff(b[i][j], b_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n        \t\t\tfail++;\n        \t\t}\n       \t}\n\t}\n\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid runJacobi2DCUDA(int tsteps, int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n), DATA_TYPE POLYBENCH_2D(A_outputFromGpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(B_outputFromGpu,N,N,n,n))\n{\n\tDATA_TYPE* Agpu;\n\tDATA_TYPE* Bgpu;\n\n\tcudaMalloc(&Agpu, N * N * sizeof(DATA_TYPE));\n\tcudaMalloc(&Bgpu, N * N * sizeof(DATA_TYPE));\n\tcudaMemcpy(Agpu, A, N * N * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\tcudaMemcpy(Bgpu, B, N * N * sizeof(DATA_TYPE), cudaMemcpyHostToDevice);\n\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 grid((unsigned int)ceil( ((float)N) / ((float)block.x) ), (unsigned int)ceil( ((float)N) / ((float)block.y) ));\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tfor (int t = 0; t < _PB_TSTEPS; t++)\n\t{\n\t\trunJacobiCUDA_kernel1<<<grid,block>>>(n, Agpu, Bgpu);\n\t\tcudaThreadSynchronize();\n\t\trunJacobiCUDA_kernel2<<<grid,block>>>(n, Agpu, Bgpu);\n\t\tcudaThreadSynchronize();\n\t}\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n  \tpolybench_print_instruments;\n\t\n\tcudaMemcpy(A_outputFromGpu, Agpu, sizeof(DATA_TYPE) * N * N, cudaMemcpyDeviceToHost);\n\tcudaMemcpy(B_outputFromGpu, Bgpu, sizeof(DATA_TYPE) * N * N, cudaMemcpyDeviceToHost);\n\n\tcudaFree(Agpu);\n\tcudaFree(Bgpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_2D(A,N,N,n,n))\n\n{\n  int i, j;\n\n  for (i = 0; i < n; i++)\n    for (j = 0; j < n; j++) {\n      fprintf(stderr, DATA_PRINTF_MODIFIER, A[i][j]);\n      if ((i * n + j) % 20 == 0) fprintf(stderr, \"\\n\");\n    }\n  fprintf(stderr, \"\\n\");\n}\n\n\nint main(int argc, char** argv)\n{\n\t/* Retrieve problem size. */\n\tint n = N;\n\tint tsteps = TSTEPS;\n\n\tPOLYBENCH_2D_ARRAY_DECL(a,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(b,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(a_outputFromGpu,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(b_outputFromGpu,DATA_TYPE,N,N,n,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\trunJacobi2DCUDA(tsteps, n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b), POLYBENCH_ARRAY(a_outputFromGpu), POLYBENCH_ARRAY(b_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\trunJacobi2DCpu(tsteps, n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t  \tpolybench_print_instruments;\n\t\n\t\tcompareResults(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(a_outputFromGpu), POLYBENCH_ARRAY(b), POLYBENCH_ARRAY(b_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(a_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tPOLYBENCH_FREE_ARRAY(a);\n\tPOLYBENCH_FREE_ARRAY(a_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(b);\n\tPOLYBENCH_FREE_ARRAY(b_outputFromGpu);\n\n\treturn 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"jacobi2D.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/stencils/jacobi-2d-imper"}}
{"kernel_name": "jacobi-2d-imper", "parallel_api": "ocl", "code": {"jacobi2D.c": "/**\n * jacobi2D.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n\n#define POLYBENCH_TIME 1\n\n\n#include \"jacobi2D.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\nchar str_temp[1024];\n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_command_queue clCommandQue;\ncl_program clProgram;\ncl_mem a_mem_obj;\ncl_mem b_mem_obj;\ncl_mem c_mem_obj;\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int n, DATA_TYPE POLYBENCH_2D(a,N,N,n,n), DATA_TYPE POLYBENCH_2D(a_outputFromGpu,N,N,n,n), DATA_TYPE POLYBENCH_2D(b,N,N,n,n), DATA_TYPE POLYBENCH_2D(b_outputFromGpu,N,N,n,n))\n{\n\tint i, j, fail;\n\tfail = 0;   \n\n\t// Compare output from CPU and GPU\n\tfor (i=0; i<n; i++) \n\t{\n\t\tfor (j=0; j<n; j++) \n\t\t{\n\t\t\tif (percentDiff(a[i][j], a_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n\t\t\t\tfail++;\n\t\t\t}\n        }\n\t}\n  \n\tfor (i=0; i<n; i++) \n\t{\n       \tfor (j=0; j<n; j++) \n\t\t{\n        \t\tif (percentDiff(b[i][j], b_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\n        \t\t\tfail++;\n        \t\t}\n       \t}\n\t}\n\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"jacobi2D.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\nvoid init_array(int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n))\n{\n\tint i, j;\n\n\tfor (i = 0; i < n; i++)\n\t{\n\t\tfor (j = 0; j < n; j++)\n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*(j+2) + 10) / N;\n\t\t\tB[i][j] = ((DATA_TYPE) (i-4)*(j-1) + 11) / N;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"device id is %d\\n\",device_id);\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, N * N * sizeof(DATA_TYPE), NULL, &errcode);\n\tb_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, N * N * sizeof(DATA_TYPE), NULL, &errcode);\n\t\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, N * N * sizeof(DATA_TYPE), A, 0, NULL, NULL);\n\terrcode = clEnqueueWriteBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, N * N * sizeof(DATA_TYPE), B, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"runJacobi2D_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\tclKernel2 = clCreateKernel(clProgram, \"runJacobi2D_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel2\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel1(int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = N;\n\tglobalWorkSize[1] = N;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernel2(int n)\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = N;\n\tglobalWorkSize[1] = N;\n\t\n\t// Set the arguments of the kernel\n\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&b_mem_obj);\n\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(int), (void *)&n);\n\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments\\n\");\n\n\t// Execute the OpenCL kernel\n\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\tclFinish(clCommandQue);\n}\n\nvoid cl_launch_kernels()\n{\n\tsize_t localWorkSize[2], globalWorkSize[2];\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSize[0] = N;\n\tglobalWorkSize[1] = N;\n\tint t;\n\t\n\tfor (t = 0; t < TSTEPS ; t++)\n\t{\t\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\t\tclFinish(clCommandQue);\n\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel\\n\");\n\t\tclFinish(clCommandQue);\n\t}\n}\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(b_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid runJacobi2DCpu(int tsteps, int n, DATA_TYPE POLYBENCH_2D(A,N,N,n,n), DATA_TYPE POLYBENCH_2D(B,N,N,n,n))\n{\n\tint t, i, j;\n\tfor (t = 0; t < _PB_TSTEPS; t++)\n\t{\n    \t\tfor (i = 1; i < _PB_N - 1; i++)\n\t\t{\n\t\t\tfor (j = 1; j < _PB_N - 1; j++)\n\t\t\t{\n\t  \t\t\tB[i][j] = 0.2f * (A[i][j] + A[i][(j-1)] + A[i][(1+j)] + A[(1+i)][j] + A[(i-1)][j]);\n\t\t\t}\n\t\t}\n\t\t\n    \t\tfor (i = 1; i < _PB_N-1; i++)\n\t\t{\n\t\t\tfor (j = 1; j < _PB_N-1; j++)\n\t\t\t{\n\t  \t\t\tA[i][j] = B[i][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int n,\n\t\t DATA_TYPE POLYBENCH_2D(A,N,N,n,n))\n\n{\n  int i, j;\n\n  for (i = 0; i < n; i++)\n    for (j = 0; j < n; j++) {\n      fprintf(stderr, DATA_PRINTF_MODIFIER, A[i][j]);\n      if ((i * n + j) % 20 == 0) fprintf(stderr, \"\\n\");\n    }\n  fprintf(stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint n = N;\n\tint tsteps = TSTEPS;\n\n\tPOLYBENCH_2D_ARRAY_DECL(a,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(b,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(a_outputFromGpu,DATA_TYPE,N,N,n,n);\n\tPOLYBENCH_2D_ARRAY_DECL(b_outputFromGpu,DATA_TYPE,N,N,n,n);\n\n\tinit_array(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\tcl_load_prog();\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\n\tint t;\n\tfor (t = 0; t < _PB_TSTEPS ; t++)\n    \t{\n\t\tcl_launch_kernel1(n);\n\t\tcl_launch_kernel2(n);\n\t}\n\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\t\n\terrcode = clEnqueueReadBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, N * N * sizeof(DATA_TYPE), POLYBENCH_ARRAY(a_outputFromGpu), 0, NULL, NULL);\n\terrcode = clEnqueueReadBuffer(clCommandQue, b_mem_obj, CL_TRUE, 0, N * N * sizeof(DATA_TYPE), POLYBENCH_ARRAY(b_outputFromGpu), 0, NULL, NULL);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");\n\n\n\t#if RUN_ON_CPU\n\t\t\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\trunJacobi2DCpu(tsteps, n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(b));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\n\t\tcompareResults(n, POLYBENCH_ARRAY(a), POLYBENCH_ARRAY(a_outputFromGpu), POLYBENCH_ARRAY(b), POLYBENCH_ARRAY(b_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(n, POLYBENCH_ARRAY(a_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\tPOLYBENCH_FREE_ARRAY(a);\n\tPOLYBENCH_FREE_ARRAY(a_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(b);\n\tPOLYBENCH_FREE_ARRAY(b_outputFromGpu);\n    \n\treturn 0;\n}\n\n#include <polybench.c>", "jacobi2D.cl": "/**\n * jacobi2D.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n__kernel void runJacobi2D_kernel1(__global DATA_TYPE* A, __global DATA_TYPE* B, int n)\n{\n\tint i = get_global_id(1);\n\tint j = get_global_id(0);\n\n\tif ((i >= 1) && (i < (n-1)) && (j >= 1) && (j < (n-1)))\n\t{\n\t\tB[i*n + j] = 0.2f * (A[i*n + j] + A[i*n + (j-1)] + A[i*n + (1 + j)] + A[(1 + i)*n + j] \n\t\t\t\t+ A[(i-1)*n + j]);\t\n\t}\n}\n\n__kernel void runJacobi2D_kernel2(__global DATA_TYPE* A, __global DATA_TYPE* B, int n)\n{\n\tint i = get_global_id(1);\n\tint j = get_global_id(0);\n\t\n\tif ((i >= 1) && (i < (n-1)) && (j >= 1) && (j < (n-1)))\n\t{\n\t\tA[i*n + j] = B[i*n + j];\n\t}\n}\n"}, "code_dirs": {"jacobi2D.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/jacobi-2d-imper", "jacobi2D.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/stencils/jacobi-2d-imper"}}
{"kernel_name": "gramschmidt", "parallel_api": "cuda", "code": {"gramschmidt.cu": "/**\n * gramschmidt.cu: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <unistd.h>\n#include <stdio.h>\n#include <time.h>\n#include <sys/time.h>\n#include <stdlib.h>\n#include <stdarg.h>\n#include <string.h>\n#include <cuda.h>\n\n#define POLYBENCH_TIME 1\n\n#include \"gramschmidt.cuh\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define GPU_DEVICE 0\n\n#define RUN_ON_CPU\n\n\nvoid gramschmidt(int ni, int nj, DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(R,NJ,NJ,nj,nj), DATA_TYPE POLYBENCH_2D(Q,NI,NJ,ni,nj))\n{\n\tint i,j,k;\n\tDATA_TYPE nrm;\n\tfor (k = 0; k < _PB_NJ; k++)\n\t{\n\t\tnrm = 0;\n\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t{\n\t\t\tnrm += A[i][k] * A[i][k];\n\t\t}\n\t\t\n\t\tR[k][k] = sqrt(nrm);\n\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t{\n\t\t\tQ[i][k] = A[i][k] / R[k][k];\n\t\t}\n\t\t\n\t\tfor (j = k + 1; j < _PB_NJ; j++)\n\t\t{\n\t\t\tR[k][j] = 0;\n\t\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t\t{\n\t\t\t\tR[k][j] += Q[i][k] * A[i][j];\n\t\t\t}\n\t\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t\t{\n\t\t\t\tA[i][j] = A[i][j] - Q[i][k] * R[k][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n/* Array initialization. */\nvoid init_array(int ni, int nj,\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(R,NJ,NJ,nj,nj),\n\t\tDATA_TYPE POLYBENCH_2D(Q,NI,NJ,ni,nj))\n{\n\tint i, j;\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++) \n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t\tQ[i][j] = ((DATA_TYPE) i*(j+1)) / nj;\n\t\t}\n\t}\n\n\tfor (i = 0; i < nj; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tR[i][j] = ((DATA_TYPE) i*(j+2)) / nj;\n\t\t}\n\t}\n}\n\nvoid compareResults(int ni, int nj, DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(A_outputFromGpu,NI,NJ,ni,nj))\n{\n\tint i, j, fail;\n\tfail = 0;\n\n\tfor (i=0; i < ni; i++) \n\t{\n\t\tfor (j=0; j < nj; j++) \n\t\t{\n\t\t\tif (percentDiff(A[i][j], A_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\t\t\t\t\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid GPU_argv_init()\n{\n\tcudaDeviceProp deviceProp;\n\tcudaGetDeviceProperties(&deviceProp, GPU_DEVICE);\n\tprintf(\"setting device %d with name %s\\n\",GPU_DEVICE,deviceProp.name);\n\tcudaSetDevice( GPU_DEVICE );\t\n\treturn;\n}\n\n\n__global__ void gramschmidt_kernel1(int ni, int nj, DATA_TYPE *a, DATA_TYPE *r, DATA_TYPE *q, int k)\n{\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif(tid==0)\n\t{\n\t\tDATA_TYPE nrm = 0.0;\n\t\tint i;\n\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t{\n\t\t\tnrm += a[i * NJ + k] * a[i * NJ + k];\n\t\t}\n      \t\tr[k * NJ + k] = sqrt(nrm);\n\t}\n}\n\n\n__global__ void gramschmidt_kernel2(int ni, int nj, DATA_TYPE *a, DATA_TYPE *r, DATA_TYPE *q, int k)\n{\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\tif (i < _PB_NI)\n\t{\t\n\t\tq[i * NJ + k] = a[i * NJ + k] / r[k * NJ + k];\n\t}\n}\n\n\n__global__ void gramschmidt_kernel3(int ni, int nj, DATA_TYPE *a, DATA_TYPE *r, DATA_TYPE *q, int k)\n{\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif ((j > k) && (j < _PB_NJ))\n\t{\n\t\tr[k*NJ + j] = 0.0;\n\n\t\tint i;\n\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t{\n\t\t\tr[k*NJ + j] += q[i*NJ + k] * a[i*NJ + j];\n\t\t}\n\t\t\n\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t{\n\t\t\ta[i*NJ + j] -= q[i*NJ + k] * r[k*NJ + j];\n\t\t}\n\t}\n}\n\n\nvoid gramschmidtCuda(int ni, int nj, DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(R,NJ,NJ,nj,nj), DATA_TYPE POLYBENCH_2D(Q,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(A_outputFromGpu,NI,NJ,ni,nj))\n{\n\tdim3 block(DIM_THREAD_BLOCK_X, DIM_THREAD_BLOCK_Y);\n\tdim3 gridKernel1(1, 1);\n\tdim3 gridKernel2((size_t)ceil(((float)NJ) / ((float)DIM_THREAD_BLOCK_X)), 1);\n\tdim3 gridKernel3((size_t)ceil(((float)NJ) / ((float)DIM_THREAD_BLOCK_X)), 1);\n\t\n\tDATA_TYPE *A_gpu;\n\tDATA_TYPE *R_gpu;\n\tDATA_TYPE *Q_gpu;\n\n\tcudaMalloc((void **)&A_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\tcudaMalloc((void **)&R_gpu, sizeof(DATA_TYPE) * NJ * NJ);\n\tcudaMalloc((void **)&Q_gpu, sizeof(DATA_TYPE) * NI * NJ);\n\tcudaMemcpy(A_gpu, A, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyHostToDevice);\n\t\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\tint k;\n\tfor (k = 0; k < _PB_NJ; k++)\n\t{\n\t\tgramschmidt_kernel1<<<gridKernel1,block>>>(ni, nj, A_gpu, R_gpu, Q_gpu, k);\n\t\tcudaThreadSynchronize();\n\t\tgramschmidt_kernel2<<<gridKernel2,block>>>(ni, nj, A_gpu, R_gpu, Q_gpu, k);\n\t\tcudaThreadSynchronize();\n\t\tgramschmidt_kernel3<<<gridKernel3,block>>>(ni, nj, A_gpu, R_gpu, Q_gpu, k);\n\t\tcudaThreadSynchronize();\n\t}\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n\t\n\tcudaMemcpy(A_outputFromGpu, A_gpu, sizeof(DATA_TYPE) * NI * NJ, cudaMemcpyDeviceToHost);    \n\n\tcudaFree(A_gpu);\n\tcudaFree(R_gpu);\n\tcudaFree(Q_gpu);\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nj, DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nj; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, A[i][j]);\n\tif (i % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,ni,nj);\n  \tPOLYBENCH_2D_ARRAY_DECL(A_outputFromGpu,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(R,DATA_TYPE,NJ,NJ,nj,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(Q,DATA_TYPE,NI,NJ,ni,nj);\n\t\n\tinit_array(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(R), POLYBENCH_ARRAY(Q));\n\t\n\tGPU_argv_init();\n\n\tgramschmidtCuda(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(R), POLYBENCH_ARRAY(Q), POLYBENCH_ARRAY(A_outputFromGpu));\n\n\t#ifdef RUN_ON_CPU\n\t\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tgramschmidt(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(R), POLYBENCH_ARRAY(Q));\n\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(A_outputFromGpu));\n\t\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nj, POLYBENCH_ARRAY(A_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(A_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(R);\n\tPOLYBENCH_FREE_ARRAY(Q);  \n\n    return 0;\n}\n\n#include <polybench.c>"}, "code_dirs": {"gramschmidt.cu": "/home/erel.kaplan/atca_proj/data/polybench/CUDA/linear-algebra/solvers/gramschmidt"}}
{"kernel_name": "gramschmidt", "parallel_api": "ocl", "code": {"gramschmidt.c": "/**\n * gramschmidt.c: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <sys/time.h>\n#include <math.h>\n\n#ifdef __APPLE__\n#include <OpenCL/opencl.h>\n#else\n#include <CL/cl.h>\n#endif\n\n#define POLYBENCH_TIME 1\n\n\n#include \"gramschmidt.h\"\n#include <polybench.h>\n#include <polybenchUtilFuncts.h>\n\n//define the error threshold for the results \"not matching\"\n#define PERCENT_DIFF_ERROR_THRESHOLD 0.05\n\n#define MAX_SOURCE_SIZE (0x100000)\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\n\nchar str_temp[1024];\n \n\ncl_platform_id platform_id;\ncl_device_id device_id;   \ncl_uint num_devices;\ncl_uint num_platforms;\ncl_int errcode;\ncl_context clGPUContext;\ncl_kernel clKernel1;\ncl_kernel clKernel2;\ncl_kernel clKernel3;\ncl_command_queue clCommandQue;\ncl_program clProgram;\n\ncl_mem a_mem_obj;\ncl_mem r_mem_obj;\ncl_mem q_mem_obj;\n\nFILE *fp;\nchar *source_str;\nsize_t source_size;\n\n\n\nvoid compareResults(int ni, int nj, DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(A_outputFromGpu,NI,NJ,ni,nj))\n{\n\tint i, j, fail;\n\tfail = 0;\n\n\tfor (i=0; i < ni; i++) \n\t{\n\t\tfor (j=0; j < nj; j++) \n\t\t{\n\t\t\tif (percentDiff(A[i][j], A_outputFromGpu[i][j]) > PERCENT_DIFF_ERROR_THRESHOLD) \n\t\t\t{\t\t\t\t\n\t\t\t\tfail++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Print results\n\tprintf(\"Non-Matching CPU-GPU Outputs Beyond Error Threshold of %4.2f Percent: %d\\n\", PERCENT_DIFF_ERROR_THRESHOLD, fail);\n}\n\n\nvoid read_cl_file()\n{\n\t// Load the kernel source code into the array source_str\n\tfp = fopen(\"gramschmidt.cl\", \"r\");\n\tif (!fp) {\n\t\tfprintf(stderr, \"Failed to load kernel.\\n\");\n\t\texit(1);\n\t}\n\tsource_str = (char*)malloc(MAX_SOURCE_SIZE);\n\tsource_size = fread( source_str, 1, MAX_SOURCE_SIZE, fp);\n\tfclose( fp );\n}\n\n\n/* Array initialization. */\nvoid init_array(int ni, int nj,\n\t\tDATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj),\n\t\tDATA_TYPE POLYBENCH_2D(R,NJ,NJ,nj,nj),\n\t\tDATA_TYPE POLYBENCH_2D(Q,NI,NJ,ni,nj))\n{\n\tint i, j;\n\n\tfor (i = 0; i < ni; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++) \n\t\t{\n\t\t\tA[i][j] = ((DATA_TYPE) i*j) / ni;\n\t\t\tQ[i][j] = ((DATA_TYPE) i*(j+1)) / nj;\n\t\t}\n\t}\n\n\tfor (i = 0; i < nj; i++)\n\t{\n\t\tfor (j = 0; j < nj; j++)\n\t\t{\n\t\t\tR[i][j] = ((DATA_TYPE) i*(j+2)) / nj;\n\t\t}\n\t}\n}\n\n\nvoid cl_initialization()\n{\t\n\t// Get platform and device information\n\terrcode = clGetPlatformIDs(1, &platform_id, &num_platforms);\n\tif(errcode == CL_SUCCESS) printf(\"number of platforms is %d\\n\",num_platforms);\n\telse printf(\"Error getting platform IDs\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id,CL_PLATFORM_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform name is %s\\n\",str_temp);\n\telse printf(\"Error getting platform name\\n\");\n\n\terrcode = clGetPlatformInfo(platform_id, CL_PLATFORM_VERSION, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"platform version is %s\\n\",str_temp);\n\telse printf(\"Error getting platform version\\n\");\n\n\terrcode = clGetDeviceIDs( platform_id, OPENCL_DEVICE_SELECTION, 1, &device_id, &num_devices);\n\tif(errcode == CL_SUCCESS) printf(\"number of devices is %d\\n\", num_devices);\n\telse printf(\"Error getting device IDs\\n\");\n\n\terrcode = clGetDeviceInfo(device_id,CL_DEVICE_NAME, sizeof(str_temp), str_temp,NULL);\n\tif(errcode == CL_SUCCESS) printf(\"device name is %s\\n\",str_temp);\n\telse printf(\"Error getting device name\\n\");\n\t\n\t// Create an OpenCL context\n\tclGPUContext = clCreateContext( NULL, 1, &device_id, NULL, NULL, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating context\\n\");\n \n\t//Create a command-queue\n\tclCommandQue = clCreateCommandQueue(clGPUContext, device_id, 0, &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating command queue\\n\");\n}\n\n\nvoid cl_mem_init(DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj))\n{\n\ta_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\tr_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\tq_mem_obj = clCreateBuffer(clGPUContext, CL_MEM_READ_WRITE, sizeof(DATA_TYPE) * NI * NJ, NULL, &errcode);\n\t\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating buffers\\n\");\n\n\terrcode = clEnqueueWriteBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, sizeof(DATA_TYPE) * NI * NJ, A, 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS)printf(\"Error in writing buffers\\n\");\n}\n\n\nvoid cl_load_prog()\n{\n\t// Create a program from the kernel source\n\tclProgram = clCreateProgramWithSource(clGPUContext, 1, (const char **)&source_str, (const size_t *)&source_size, &errcode);\n\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating program\\n\");\n\n\t// Build the program\n\terrcode = clBuildProgram(clProgram, 1, &device_id, NULL, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in building program\\n\");\n\t\t\n\t// Create the OpenCL kernel\n\tclKernel1 = clCreateKernel(clProgram, \"gramschmidt_kernel1\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel1\\n\");\n\n\tclKernel2 = clCreateKernel(clProgram, \"gramschmidt_kernel2\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel2\\n\");\n\n\tclKernel3 = clCreateKernel(clProgram, \"gramschmidt_kernel3\", &errcode);\n\tif(errcode != CL_SUCCESS) printf(\"Error in creating kernel3\\n\");\n\tclFinish(clCommandQue);\n}\n\n\nvoid cl_launch_kernel(int ni, int nj)\n{\n\tsize_t localWorkSize[2], globalWorkSizeKernel1[2], globalWorkSizeKernel2[2], globalWorkSizeKernel3[2];\n\n\tlocalWorkSize[0] = DIM_LOCAL_WORK_GROUP_X;\n\tlocalWorkSize[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSizeKernel1[0] = DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSizeKernel1[1] = DIM_LOCAL_WORK_GROUP_Y;\n\tglobalWorkSizeKernel2[0] = (size_t)ceil(((float)NJ) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSizeKernel2[1] = 1;\n\tglobalWorkSizeKernel3[0] = (size_t)ceil(((float)NJ) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\tglobalWorkSizeKernel3[1] = 1;\n\n\t/* Start timer. */\n  \tpolybench_start_instruments;\n\t\n\tint k;\n\tfor (k = 0; k < _PB_NJ; k++)\n\t{\n\t\t// Set the arguments of the kernel\n\t\terrcode =  clSetKernelArg(clKernel1, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\t\terrcode =  clSetKernelArg(clKernel1, 1, sizeof(cl_mem), (void *)&r_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel1, 2, sizeof(cl_mem), (void *)&q_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel1, 3, sizeof(int), (void *)&k);\n\t\terrcode |= clSetKernelArg(clKernel1, 4, sizeof(int), (void *)&ni);\n\t\terrcode |= clSetKernelArg(clKernel1, 5, sizeof(int), (void *)&nj);\n\t\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\t\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel1, 1, NULL, globalWorkSizeKernel1, localWorkSize, 0, NULL, NULL);\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel1\\n\");\n\t\tclEnqueueBarrier(clCommandQue);\n\n\n\t\terrcode =  clSetKernelArg(clKernel2, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\t\terrcode =  clSetKernelArg(clKernel2, 1, sizeof(cl_mem), (void *)&r_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel2, 2, sizeof(cl_mem), (void *)&q_mem_obj);\n\t\terrcode |= clSetKernelArg(clKernel2, 3, sizeof(int), (void *)&k);\n\t\terrcode |= clSetKernelArg(clKernel2, 4, sizeof(int), (void *)&ni);\n\t\terrcode |= clSetKernelArg(clKernel2, 5, sizeof(int), (void *)&nj);\n\t\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\t\n\t\t// Execute the OpenCL kernel\n\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel2, 1, NULL, globalWorkSizeKernel2, localWorkSize, 0, NULL, NULL);\n\t\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel2\\n\");\n\t\tclEnqueueBarrier(clCommandQue);\n\n\t\tglobalWorkSizeKernel3[0] = (size_t)ceil(((float)NJ - (float)(k+1)) / ((float)DIM_LOCAL_WORK_GROUP_X)) * DIM_LOCAL_WORK_GROUP_X;\n\t\tif (globalWorkSizeKernel3[0] > 1)\n\t\t{\n\t\t\terrcode =  clSetKernelArg(clKernel3, 0, sizeof(cl_mem), (void *)&a_mem_obj);\n\t\t\terrcode =  clSetKernelArg(clKernel3, 1, sizeof(cl_mem), (void *)&r_mem_obj);\n\t\t\terrcode |= clSetKernelArg(clKernel3, 2, sizeof(cl_mem), (void *)&q_mem_obj);\n\t\t\terrcode |= clSetKernelArg(clKernel3, 3, sizeof(int), (void *)&k);\n\t\t\terrcode |= clSetKernelArg(clKernel3, 4, sizeof(int), (void *)&ni);\n\t\t\terrcode |= clSetKernelArg(clKernel3, 5, sizeof(int), (void *)&nj);\n\t\n\t\t\tif(errcode != CL_SUCCESS) printf(\"Error in seting arguments1\\n\");\n\t\n\t\t\t// Execute the OpenCL kernel\n\t\t\terrcode = clEnqueueNDRangeKernel(clCommandQue, clKernel3, 1, NULL, globalWorkSizeKernel3, localWorkSize, 0, NULL, NULL);\n\t\t\tif(errcode != CL_SUCCESS) printf(\"Error in launching kernel3\\n\");\n\t\t\tclEnqueueBarrier(clCommandQue);\n\t\t}\n\n\t}\n\tclFinish(clCommandQue);\n\n\t/* Stop and print timer. */\n\tprintf(\"GPU Time in seconds:\\n\");\n  \tpolybench_stop_instruments;\n \tpolybench_print_instruments;\n}\n\n\nvoid cl_clean_up()\n{\n\t// Clean up\n\terrcode = clFlush(clCommandQue);\n\terrcode = clFinish(clCommandQue);\n\terrcode = clReleaseKernel(clKernel1);\n\terrcode = clReleaseKernel(clKernel2);\n\terrcode = clReleaseKernel(clKernel3);\n\terrcode = clReleaseProgram(clProgram);\n\terrcode = clReleaseMemObject(a_mem_obj);\n\terrcode = clReleaseMemObject(r_mem_obj);\n\terrcode = clReleaseMemObject(q_mem_obj);\n\terrcode = clReleaseCommandQueue(clCommandQue);\n\terrcode = clReleaseContext(clGPUContext);\n\tif(errcode != CL_SUCCESS) printf(\"Error in cleanup\\n\");\n}\n\n\nvoid gramschmidt(int ni, int nj, DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj), DATA_TYPE POLYBENCH_2D(R,NJ,NJ,nj,nj), DATA_TYPE POLYBENCH_2D(Q,NI,NJ,ni,nj))\n{\n\tint i,j,k;\n\tDATA_TYPE nrm;\n\tfor (k = 0; k < _PB_NJ; k++)\n\t{\n\t\tnrm = 0;\n\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t{\n\t\t\tnrm += A[i][k] * A[i][k];\n\t\t}\n\t\t\n\t\tR[k][k] = sqrt(nrm);\n\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t{\n\t\t\tQ[i][k] = A[i][k] / R[k][k];\n\t\t}\n\t\t\n\t\tfor (j = k + 1; j < _PB_NJ; j++)\n\t\t{\n\t\t\tR[k][j] = 0;\n\t\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t\t{\n\t\t\t\tR[k][j] += Q[i][k] * A[i][j];\n\t\t\t}\n\t\t\tfor (i = 0; i < _PB_NI; i++)\n\t\t\t{\n\t\t\t\tA[i][j] = A[i][j] - Q[i][k] * R[k][j];\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n/* DCE code. Must scan the entire live-out data.\n   Can be used also to check the correctness of the output. */\nstatic\nvoid print_array(int ni, int nj, DATA_TYPE POLYBENCH_2D(A,NI,NJ,ni,nj))\n{\n  int i, j;\n\n  for (i = 0; i < ni; i++)\n    for (j = 0; j < nj; j++) {\n\tfprintf (stderr, DATA_PRINTF_MODIFIER, A[i][j]);\n\tif (i % 20 == 0) fprintf (stderr, \"\\n\");\n    }\n\n  fprintf (stderr, \"\\n\");\n}\n\n\nint main(int argc, char *argv[])\n{\t\n\t/* Retrieve problem size. */\n\tint ni = NI;\n\tint nj = NJ;\n\n\tPOLYBENCH_2D_ARRAY_DECL(A,DATA_TYPE,NI,NJ,ni,nj);\n  \tPOLYBENCH_2D_ARRAY_DECL(A_outputFromGpu,DATA_TYPE,NI,NJ,ni,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(R,DATA_TYPE,NJ,NJ,nj,nj);\n\tPOLYBENCH_2D_ARRAY_DECL(Q,DATA_TYPE,NI,NJ,ni,nj);\n\t\n\tinit_array(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(R), POLYBENCH_ARRAY(Q));\n\t\n\tread_cl_file();\n\tcl_initialization();\n\tcl_mem_init(POLYBENCH_ARRAY(A));\n\tcl_load_prog();\n\n\tcl_launch_kernel(ni, nj);\n\n\terrcode = clEnqueueReadBuffer(clCommandQue, a_mem_obj, CL_TRUE, 0, NI*NJ*sizeof(DATA_TYPE), POLYBENCH_ARRAY(A_outputFromGpu), 0, NULL, NULL);\n\tif(errcode != CL_SUCCESS) printf(\"Error in reading GPU mem\\n\");   \n\n\n\t#if RUN_ON_CPU\n\n\t\t/* Start timer. */\n\t  \tpolybench_start_instruments;\n\n\t\tgramschmidt(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(R), POLYBENCH_ARRAY(Q));\n\t\n\t\t/* Stop and print timer. */\n\t\tprintf(\"CPU Time in seconds:\\n\");\n\t  \tpolybench_stop_instruments;\n\t \tpolybench_print_instruments;\n\t\n\t\tcompareResults(ni, nj, POLYBENCH_ARRAY(A), POLYBENCH_ARRAY(A_outputFromGpu));\n\n\t#else //prevent dead code elimination\n\n\t\tpolybench_prevent_dce(print_array(ni, nj, POLYBENCH_ARRAY(A_outputFromGpu)));\n\n\t#endif //RUN_ON_CPU\n\n\n\tcl_clean_up();\n\n\tPOLYBENCH_FREE_ARRAY(A);\n\tPOLYBENCH_FREE_ARRAY(A_outputFromGpu);\n\tPOLYBENCH_FREE_ARRAY(R);\n\tPOLYBENCH_FREE_ARRAY(Q);  \n\n\treturn 0;\n}\n\n#include <polybench.c>", "gramschmidt.cl": "/**\n * gramschmidt.cl: This file is part of the PolyBench/GPU 1.0 test suite.\n *\n *\n * Contact: Scott Grauer-Gray <sgrauerg@gmail.com>\n * Will Killian <killian@udel.edu>\n * Louis-Noel Pouchet <pouchet@cse.ohio-state.edu>\n * Web address: http://www.cse.ohio-state.edu/~pouchet/software/polybench/GPU\n */\n\n#if defined(cl_khr_fp64)  // Khronos extension available?\n#pragma OPENCL EXTENSION cl_khr_fp64 : enable\n#elif defined(cl_amd_fp64)  // AMD extension available?\n#pragma OPENCL EXTENSION cl_amd_fp64 : enable\n#endif\n\ntypedef float DATA_TYPE;\n\n\n__kernel void gramschmidt_kernel1(__global DATA_TYPE *a, __global DATA_TYPE *r, __global DATA_TYPE *q, int k, int ni, int nj)\n{\n\tint tid = get_global_id(0);\n\t\n\tif (tid == 0)\n\t{\n\t\tDATA_TYPE nrm = 0.0;\n\t\tint i;\n\t\tfor (i = 0; i < ni; i++)\n\t\t{\n\t\t\tnrm += a[i * nj + k] * a[i * nj + k];\n\t\t}\n      \t\tr[k * nj + k] = sqrt(nrm);\n\t}\n}\n\n\n__kernel void gramschmidt_kernel2(__global DATA_TYPE *a, __global DATA_TYPE *r, __global DATA_TYPE *q, int k, int ni, int nj)\n{\n\tint i = get_global_id(0);\n\n        if (i < ni)\n\t{\t\n\t\tq[i * nj + k] = a[i * nj + k] / r[k * nj + k];\n\t}\n}\n\n\n__kernel void gramschmidt_kernel3(__global DATA_TYPE *a, __global DATA_TYPE *r, __global DATA_TYPE *q, int k, int ni, int nj)\n{\n\tint j = get_global_id(0) + (k+1);\n\n\tif ((j < nj))\n\t{\n\t\tr[k*nj + j] = 0.0;\n\n\t\tint i;\n\t\tfor (i = 0; i < ni; i++)\n\t\t{\n\t\t\tr[k*nj + j] += q[i*nj + k] * a[i*nj + j];\n\t\t}\n\t\t\n\t\tfor (i = 0; i < ni; i++)\n\t\t{\n\t\t\ta[i*nj + j] -= q[i*nj + k] * r[k*nj + j];\n\t\t}\n\t}\n}\n\n"}, "code_dirs": {"gramschmidt.c": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/solvers/gramschmidt", "gramschmidt.cl": "/home/erel.kaplan/atca_proj/data/polybench/OpenCL/linear-algebra/solvers/gramschmidt"}}
