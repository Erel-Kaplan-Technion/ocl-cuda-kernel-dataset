{"kernel_name": "vectorAdd", "parallel_api": "cuda", "code": {"vectorAdd.cu": "#include <stdio.h>\n\n#include <cuda_runtime.h>\n#include <helper_cuda.h>\n\n__global__ void vectorAdd(const float *A, const float *B, float *C, int numElements)\n{\n    int i = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (i < numElements) {\n        C[i] = A[i] + B[i] + 0.0f;\n    }\n}\n\nint main(void)\n{\n    cudaError_t err = cudaSuccess;\n\n    int    numElements = 50000;\n    size_t size        = numElements * sizeof(float);\n    printf(\"[Vector addition of %d elements]\\n\", numElements);\n\n    float *h_A = (float *)malloc(size);\n\n    float *h_B = (float *)malloc(size);\n\n    float *h_C = (float *)malloc(size);\n\n    if (h_A == NULL || h_B == NULL || h_C == NULL) {\n        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    for (int i = 0; i < numElements; ++i) {\n        h_A[i] = rand() / (float)RAND_MAX;\n        h_B[i] = rand() / (float)RAND_MAX;\n    }\n\n    float *d_A = NULL;\n    err        = cudaMalloc((void **)&d_A, size);\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    float *d_B = NULL;\n    err        = cudaMalloc((void **)&d_B, size);\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    float *d_C = NULL;\n    err        = cudaMalloc((void **)&d_C, size);\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    int threadsPerBlock = 256;\n    int blocksPerGrid   = (numElements + threadsPerBlock - 1) / threadsPerBlock;\n    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n    err = cudaGetLastError();\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    for (int i = 0; i < numElements; ++i) {\n        if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5) {\n            fprintf(stderr, \"Result verification failed at element %d!\\n\", i);\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    printf(\"Test PASSED\\n\");\n\n    err = cudaFree(d_A);\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    err = cudaFree(d_B);\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    err = cudaFree(d_C);\n\n    if (err != cudaSuccess) {\n        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n\n    free(h_A);\n    free(h_B);\n    free(h_C);\n\n    printf(\"Done\\n\");\n    return 0;\n}\n"}, "code_dirs": {"vectorAdd.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/0_Introduction/vectorAdd"}}
{"kernel_name": "vectorAdd", "parallel_api": "ocl", "code": {"oclVectorAdd.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n\nconst char* cSourceFile = \"VectorAdd.cl\";\n\nvoid *srcA, *srcB, *dst;        // Host buffers for OpenCL test\nvoid* Golden;                   // Host buffer for host golden processing cross check\n\n// OpenCL Vars\ncl_context cxGPUContext;        // OpenCL context\ncl_command_queue cqCommandQueue;// OpenCL command que\ncl_platform_id cpPlatform;      // OpenCL platform\ncl_device_id cdDevice;          // OpenCL device\ncl_program cpProgram;           // OpenCL program\ncl_kernel ckKernel;             // OpenCL kernel\ncl_mem cmDevSrcA;               // OpenCL device source buffer A\ncl_mem cmDevSrcB;               // OpenCL device source buffer B \ncl_mem cmDevDst;                // OpenCL device destination buffer \nsize_t szGlobalWorkSize;        // 1D var for Total # of work items\nsize_t szLocalWorkSize;\t\t    // 1D var for # of work items in the work group\t\nsize_t szParmDataBytes;\t\t\t// Byte size of context information\nsize_t szKernelLength;\t\t\t// Byte size of kernel code\ncl_int ciErr1, ciErr2;\t\t\t// Error code var\nchar* cPathAndName = NULL;      // var for full paths to data, src, etc.\nchar* cSourceCL = NULL;         // Buffer to hold source for compilation\nconst char* cExecutableName = NULL;\n\n// demo config vars\nint iNumElements = 11444777;\t// Length of float arrays to process (odd # for illustration)\nshrBOOL bNoPrompt = shrFALSE;  \n\nvoid VectorAddHost(const float* pfData1, const float* pfData2, float* pfResult, int iNumElements);\nvoid Cleanup (int argc, char **argv, int iExitCode);\n\nint main(int argc, char **argv)\n{\n    shrQAStart(argc, argv);\n\n    // get command line arg for quick test, if provided\n    bNoPrompt = shrCheckCmdLineFlag(argc, (const char**)argv, \"noprompt\");\n    \n    // start logs \n\tcExecutableName = argv[0];\n    shrSetLogFileName (\"oclVectorAdd.txt\");\n    shrLog(\"%s Starting...\\n\\n# of float elements per Array \\t= %i\\n\", argv[0], iNumElements); \n\n    // set and log Global and Local work size dimensions\n    szLocalWorkSize = 256;\n    szGlobalWorkSize = shrRoundUp((int)szLocalWorkSize, iNumElements);  // rounded up to the nearest multiple of the LocalWorkSize\n    shrLog(\"Global Work Size \\t\\t= %u\\nLocal Work Size \\t\\t= %u\\n# of Work Groups \\t\\t= %u\\n\\n\", \n           szGlobalWorkSize, szLocalWorkSize, (szGlobalWorkSize % szLocalWorkSize + szGlobalWorkSize/szLocalWorkSize)); \n\n    // Allocate and initialize host arrays \n    shrLog( \"Allocate and Init Host Mem...\\n\"); \n    srcA = (void *)malloc(sizeof(cl_float) * szGlobalWorkSize);\n    srcB = (void *)malloc(sizeof(cl_float) * szGlobalWorkSize);\n    dst = (void *)malloc(sizeof(cl_float) * szGlobalWorkSize);\n    Golden = (void *)malloc(sizeof(cl_float) * iNumElements);\n    shrFillArray((float*)srcA, iNumElements);\n    shrFillArray((float*)srcB, iNumElements);\n\n    //Get an OpenCL platform\n    ciErr1 = clGetPlatformIDs(1, &cpPlatform, NULL);\n\n    shrLog(\"clGetPlatformID...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clGetPlatformID, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    //Get the devices\n    ciErr1 = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 1, &cdDevice, NULL);\n    shrLog(\"clGetDeviceIDs...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clGetDeviceIDs, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    //Create the context\n    cxGPUContext = clCreateContext(0, 1, &cdDevice, NULL, NULL, &ciErr1);\n    shrLog(\"clCreateContext...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clCreateContext, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    // Create a command-queue\n    cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevice, 0, &ciErr1);\n    shrLog(\"clCreateCommandQueue...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clCreateCommandQueue, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    // Allocate the OpenCL buffer memory objects for source and result on the device GMEM\n    cmDevSrcA = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, sizeof(cl_float) * szGlobalWorkSize, NULL, &ciErr1);\n    cmDevSrcB = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, sizeof(cl_float) * szGlobalWorkSize, NULL, &ciErr2);\n    ciErr1 |= ciErr2;\n    cmDevDst = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, sizeof(cl_float) * szGlobalWorkSize, NULL, &ciErr2);\n    ciErr1 |= ciErr2;\n    shrLog(\"clCreateBuffer...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clCreateBuffer, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n    \n    // Read the OpenCL kernel in from source file\n    shrLog(\"oclLoadProgSource (%s)...\\n\", cSourceFile); \n    cPathAndName = shrFindFilePath(cSourceFile, argv[0]);\n    cSourceCL = oclLoadProgSource(cPathAndName, \"\", &szKernelLength);\n\n    // Create the program\n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&cSourceCL, &szKernelLength, &ciErr1);\n    shrLog(\"clCreateProgramWithSource...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clCreateProgramWithSource, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    // Build the program with 'mad' Optimization option\n    #ifdef MAC\n        char* flags = \"-cl-fast-relaxed-math -DMAC\";\n    #else\n        char* flags = \"-cl-fast-relaxed-math\";\n    #endif\n    ciErr1 = clBuildProgram(cpProgram, 0, NULL, NULL, NULL, NULL);\n    shrLog(\"clBuildProgram...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clBuildProgram, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    // Create the kernel\n    ckKernel = clCreateKernel(cpProgram, \"VectorAdd\", &ciErr1);\n    shrLog(\"clCreateKernel (VectorAdd)...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clCreateKernel, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    // Set the Argument values\n    ciErr1 = clSetKernelArg(ckKernel, 0, sizeof(cl_mem), (void*)&cmDevSrcA);\n    ciErr1 |= clSetKernelArg(ckKernel, 1, sizeof(cl_mem), (void*)&cmDevSrcB);\n    ciErr1 |= clSetKernelArg(ckKernel, 2, sizeof(cl_mem), (void*)&cmDevDst);\n    ciErr1 |= clSetKernelArg(ckKernel, 3, sizeof(cl_int), (void*)&iNumElements);\n    shrLog(\"clSetKernelArg 0 - 3...\\n\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clSetKernelArg, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    ciErr1 = clEnqueueWriteBuffer(cqCommandQueue, cmDevSrcA, CL_FALSE, 0, sizeof(cl_float) * szGlobalWorkSize, srcA, 0, NULL, NULL);\n    ciErr1 |= clEnqueueWriteBuffer(cqCommandQueue, cmDevSrcB, CL_FALSE, 0, sizeof(cl_float) * szGlobalWorkSize, srcB, 0, NULL, NULL);\n    shrLog(\"clEnqueueWriteBuffer (SrcA and SrcB)...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clEnqueueWriteBuffer, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    // Launch kernel\n    ciErr1 = clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 1, NULL, &szGlobalWorkSize, &szLocalWorkSize, 0, NULL, NULL);\n    shrLog(\"clEnqueueNDRangeKernel (VectorAdd)...\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clEnqueueNDRangeKernel, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    // Synchronous/blocking read of results, and check accumulated errors\n    ciErr1 = clEnqueueReadBuffer(cqCommandQueue, cmDevDst, CL_TRUE, 0, sizeof(cl_float) * szGlobalWorkSize, dst, 0, NULL, NULL);\n    shrLog(\"clEnqueueReadBuffer (Dst)...\\n\\n\"); \n    if (ciErr1 != CL_SUCCESS)\n    {\n        shrLog(\"Error in clEnqueueReadBuffer, Line %u in file %s !!!\\n\\n\", __LINE__, __FILE__);\n        Cleanup(argc, argv, EXIT_FAILURE);\n    }\n\n    shrLog(\"Comparing against Host/C++ computation...\\n\\n\"); \n    VectorAddHost ((const float*)srcA, (const float*)srcB, (float*)Golden, iNumElements);\n    shrBOOL bMatch = shrComparefet((const float*)Golden, (const float*)dst, (unsigned int)iNumElements, 0.0f, 0);\n\n    // Cleanup and leave\n    Cleanup (argc, argv, (bMatch == shrTRUE) ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n\nvoid Cleanup (int argc, char **argv, int iExitCode)\n{\n    // Cleanup allocated objects\n    shrLog(\"Starting Cleanup...\\n\\n\");\n    if(cPathAndName)free(cPathAndName);\n    if(cSourceCL)free(cSourceCL);\n\tif(ckKernel)clReleaseKernel(ckKernel);  \n    if(cpProgram)clReleaseProgram(cpProgram);\n    if(cqCommandQueue)clReleaseCommandQueue(cqCommandQueue);\n    if(cxGPUContext)clReleaseContext(cxGPUContext);\n    if(cmDevSrcA)clReleaseMemObject(cmDevSrcA);\n    if(cmDevSrcB)clReleaseMemObject(cmDevSrcB);\n    if(cmDevDst)clReleaseMemObject(cmDevDst);\n\n    // Free host memory\n    free(srcA); \n    free(srcB);\n    free (dst);\n    free(Golden);\n\n    // finalize logs and leave\n    shrQAFinishExit(argc, (const char **)argv, (iExitCode == EXIT_SUCCESS) ? QA_PASSED : QA_FAILED);\n}\n\nvoid VectorAddHost(const float* pfData1, const float* pfData2, float* pfResult, int iNumElements)\n{\n    int i;\n    for (i = 0; i < iNumElements; i++) \n    {\n        pfResult[i] = pfData1[i] + pfData2[i]; \n    }\n}\n", "VectorAdd.cl": "__kernel void VectorAdd(__global const float* a, __global const float* b, __global float* c, int iNumElements)\n{\n    // get index into global data array\n    int iGID = get_global_id(0);\n\n    if (iGID >= iNumElements)\n    {   \n        return; \n    }\n    \n    // add the vector elements\n    c[iGID] = a[iGID] + b[iGID];\n}\n"}, "code_dirs": {"oclVectorAdd.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclVectorAdd", "VectorAdd.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclVectorAdd"}}
{"kernel_name": "matrixMul", "parallel_api": "cuda", "code": {"matrixMul.cu": "#include <assert.h>\n#include <stdio.h>\n\n#include <cuda_profiler_api.h>\n#include <cuda_runtime.h>\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n\ntemplate <int BLOCK_SIZE> __global__ void MatrixMulCUDA(float *C, float *A, float *B, int wA, int wB)\n{\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n\n    int aBegin = wA * BLOCK_SIZE * by;\n\n    int aEnd = aBegin + wA - 1;\n\n    int aStep = BLOCK_SIZE;\n\n    int bBegin = BLOCK_SIZE * bx;\n\n    int bStep = BLOCK_SIZE * wB;\n\n    float Csub = 0;\n\n    for (int a = aBegin, b = bBegin; a <= aEnd; a += aStep, b += bStep) {\n        __shared__ float As[BLOCK_SIZE][BLOCK_SIZE];\n\n        __shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];\n\n        As[ty][tx] = A[a + wA * ty + tx];\n        Bs[ty][tx] = B[b + wB * ty + tx];\n\n        __syncthreads();\n\n#pragma unroll\n\n        for (int k = 0; k < BLOCK_SIZE; ++k) {\n            Csub += As[ty][k] * Bs[k][tx];\n        }\n\n        __syncthreads();\n    }\n\n    int c               = wB * BLOCK_SIZE * by + BLOCK_SIZE * bx;\n    C[c + wB * ty + tx] = Csub;\n}\n\nvoid ConstantInit(float *data, int size, float val)\n{\n    for (int i = 0; i < size; ++i) {\n        data[i] = val;\n    }\n}\n\nint MatrixMultiply(int argc, char **argv, int block_size, const dim3 &dimsA, const dim3 &dimsB)\n{\n    unsigned int size_A     = dimsA.x * dimsA.y;\n    unsigned int mem_size_A = sizeof(float) * size_A;\n    float       *h_A;\n    checkCudaErrors(cudaMallocHost(&h_A, mem_size_A));\n    unsigned int size_B     = dimsB.x * dimsB.y;\n    unsigned int mem_size_B = sizeof(float) * size_B;\n    float       *h_B;\n    checkCudaErrors(cudaMallocHost(&h_B, mem_size_B));\n    cudaStream_t stream;\n\n    const float valB = 0.01f;\n    ConstantInit(h_A, size_A, 1.0f);\n    ConstantInit(h_B, size_B, valB);\n\n    float *d_A, *d_B, *d_C;\n\n    dim3         dimsC(dimsB.x, dimsA.y, 1);\n    unsigned int mem_size_C = dimsC.x * dimsC.y * sizeof(float);\n    float       *h_C;\n    checkCudaErrors(cudaMallocHost(&h_C, mem_size_C));\n\n    if (h_C == NULL) {\n        fprintf(stderr, \"Failed to allocate host matrix C!\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    checkCudaErrors(cudaMalloc(reinterpret_cast<void **>(&d_A), mem_size_A));\n    checkCudaErrors(cudaMalloc(reinterpret_cast<void **>(&d_B), mem_size_B));\n    checkCudaErrors(cudaMalloc(reinterpret_cast<void **>(&d_C), mem_size_C));\n    cudaEvent_t start, stop;\n    checkCudaErrors(cudaEventCreate(&start));\n    checkCudaErrors(cudaEventCreate(&stop));\n\n    checkCudaErrors(cudaStreamCreateWithFlags(&stream, cudaStreamNonBlocking));\n\n    checkCudaErrors(cudaMemcpyAsync(d_A, h_A, mem_size_A, cudaMemcpyHostToDevice, stream));\n    checkCudaErrors(cudaMemcpyAsync(d_B, h_B, mem_size_B, cudaMemcpyHostToDevice, stream));\n\n    dim3 threads(block_size, block_size);\n    dim3 grid(dimsB.x / threads.x, dimsA.y / threads.y);\n\n    printf(\"Computing result using CUDA Kernel...\\n\");\n\n    if (block_size == 16) {\n        MatrixMulCUDA<16><<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);\n    }\n    else {\n        MatrixMulCUDA<32><<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);\n    }\n\n    printf(\"done\\n\");\n    checkCudaErrors(cudaStreamSynchronize(stream));\n\n    checkCudaErrors(cudaEventRecord(start, stream));\n\n    int nIter = 300;\n\n    for (int j = 0; j < nIter; j++) {\n        if (block_size == 16) {\n            MatrixMulCUDA<16><<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);\n        }\n        else {\n            MatrixMulCUDA<32><<<grid, threads, 0, stream>>>(d_C, d_A, d_B, dimsA.x, dimsB.x);\n        }\n    }\n\n    checkCudaErrors(cudaEventRecord(stop, stream));\n\n    checkCudaErrors(cudaEventSynchronize(stop));\n\n    float msecTotal = 0.0f;\n    checkCudaErrors(cudaEventElapsedTime(&msecTotal, start, stop));\n\n    float  msecPerMatrixMul = msecTotal / nIter;\n    double flopsPerMatrixMul =\n        2.0 * static_cast<double>(dimsA.x) * static_cast<double>(dimsA.y) * static_cast<double>(dimsB.x);\n    double gigaFlops = (flopsPerMatrixMul * 1.0e-9f) / (msecPerMatrixMul / 1000.0f);\n    printf(\"Performance= %.2f GFlop/s, Time= %.3f msec, Size= %.0f Ops,\"\n           \" WorkgroupSize= %u threads/block\\n\",\n           gigaFlops,\n           msecPerMatrixMul,\n           flopsPerMatrixMul,\n           threads.x * threads.y);\n\n    checkCudaErrors(cudaMemcpyAsync(h_C, d_C, mem_size_C, cudaMemcpyDeviceToHost, stream));\n    checkCudaErrors(cudaStreamSynchronize(stream));\n\n    printf(\"Checking computed result for correctness: \");\n    bool correct = true;\n\n    double eps = 1.e-6;\n\n    for (int i = 0; i < static_cast<int>(dimsC.x * dimsC.y); i++) {\n        double abs_err    = fabs(h_C[i] - (dimsA.x * valB));\n        double dot_length = dimsA.x;\n        double abs_val    = fabs(h_C[i]);\n        double rel_err    = abs_err / abs_val / dot_length;\n\n        if (rel_err > eps) {\n            printf(\"Error! Matrix[%05d]=%.8f, ref=%.8f error term is > %E\\n\", i, h_C[i], dimsA.x * valB, eps);\n            correct = false;\n        }\n    }\n\n    printf(\"%s\\n\", correct ? \"Result = PASS\" : \"Result = FAIL\");\n\n    checkCudaErrors(cudaFreeHost(h_A));\n    checkCudaErrors(cudaFreeHost(h_B));\n    checkCudaErrors(cudaFreeHost(h_C));\n    checkCudaErrors(cudaFree(d_A));\n    checkCudaErrors(cudaFree(d_B));\n    checkCudaErrors(cudaFree(d_C));\n    checkCudaErrors(cudaEventDestroy(start));\n    checkCudaErrors(cudaEventDestroy(stop));\n    printf(\"\\nNOTE: The CUDA Samples are not meant for performance \"\n           \"measurements. Results may vary when GPU Boost is enabled.\\n\");\n\n    if (correct) {\n        return EXIT_SUCCESS;\n    }\n    else {\n        return EXIT_FAILURE;\n    }\n}\n\n\nint main(int argc, char **argv)\n{\n    printf(\"[Matrix Multiply Using CUDA] - Starting...\\n\");\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"help\") || checkCmdLineFlag(argc, (const char **)argv, \"?\")) {\n        printf(\"Usage -device=n (n >= 0 for deviceID)\\n\");\n        printf(\"      -wA=WidthA -hA=HeightA (Width x Height of Matrix A)\\n\");\n        printf(\"      -wB=WidthB -hB=HeightB (Width x Height of Matrix B)\\n\");\n        printf(\"  Note: Outer matrix dimensions of A & B matrices\"\n               \" must be equal.\\n\");\n\n        exit(EXIT_SUCCESS);\n    }\n\n    int dev = findCudaDevice(argc, (const char **)argv);\n\n    int block_size = 32;\n\n    dim3 dimsA(5 * 2 * block_size, 5 * 2 * block_size, 1);\n    dim3 dimsB(5 * 4 * block_size, 5 * 2 * block_size, 1);\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"wA\")) {\n        dimsA.x = getCmdLineArgumentInt(argc, (const char **)argv, \"wA\");\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"hA\")) {\n        dimsA.y = getCmdLineArgumentInt(argc, (const char **)argv, \"hA\");\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"wB\")) {\n        dimsB.x = getCmdLineArgumentInt(argc, (const char **)argv, \"wB\");\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"hB\")) {\n        dimsB.y = getCmdLineArgumentInt(argc, (const char **)argv, \"hB\");\n    }\n\n    if (dimsA.x != dimsB.y) {\n        printf(\"Error: outer matrix dimensions must be equal. (%d != %d)\\n\", dimsA.x, dimsB.y);\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"MatrixA(%d,%d), MatrixB(%d,%d)\\n\", dimsA.x, dimsA.y, dimsB.x, dimsB.y);\n\n    checkCudaErrors(cudaProfilerStart());\n    int matrix_result = MatrixMultiply(argc, argv, block_size, dimsA, dimsB);\n    checkCudaErrors(cudaProfilerStop());\n\n    exit(matrix_result);\n}\n"}, "code_dirs": {"matrixMul.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/0_Introduction/matrixMul"}}
{"kernel_name": "matrixMul", "parallel_api": "ocl", "code": {"oclMatrixMul.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n\n// project include\n#include \"matrixMul.h\"\n\n// max GPU's to manage for multi-GPU parallel compute\nconst unsigned int MAX_GPU_COUNT = 8;\n\n// Globals for size of matrices\nunsigned int uiWA, uiHA, uiWB, uiHB, uiWC, uiHC;\nint iSizeMultiple = 1;\n\n// global variables\ncl_context cxGPUContext;\ncl_kernel multiplicationKernel[MAX_GPU_COUNT];\ncl_command_queue commandQueue[MAX_GPU_COUNT];\n\nint runTest(int argc, const char** argv);\nvoid printDiff(float*, float*, int, int, int, float);\nvoid matrixMulGPU(cl_uint ciDeviceCount, cl_mem h_A, float* h_B_data, unsigned int mem_size_B, float* h_C );\n\nextern \"C\"\nvoid computeGold(float*, const float*, const float*, unsigned int, unsigned int, unsigned int);\n\ndouble executionTime(cl_event &event)\n{\n    cl_ulong start, end;\n    \n    clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &end, NULL);\n    clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_START, sizeof(cl_ulong), &start, NULL);\n    \n    return (double)1.0e-9 * (end - start); // convert nanoseconds to seconds on return\n}\n\nint main(int argc, char** argv)\n{\n    shrQAStart(argc, argv);\n\n    // start the logs\n    shrSetLogFileName (\"oclMatrixMul.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    // run the code\n    bool bOK = (runTest(argc, (const char **)argv) == CL_SUCCESS);\n    shrLog(\"%s\\n\\n\", (bOK ? \"PASSED\" : \"FAILED\"));\n\n    // finish\n    shrQAFinishExit(argc, (const char **)argv, (bOK ? QA_PASSED : QA_FAILED));\n}\n\nvoid matrixMulGPU(cl_uint ciDeviceCount, cl_mem h_A, float* h_B_data, unsigned int mem_size_B, float* h_C )\n{\n    cl_mem d_A[MAX_GPU_COUNT];\n    cl_mem d_C[MAX_GPU_COUNT];\n    cl_mem d_B[MAX_GPU_COUNT];\n\n    cl_event GPUDone[MAX_GPU_COUNT];\n    cl_event GPUExecution[MAX_GPU_COUNT];\n\n    int sizePerGPU = uiHA / ciDeviceCount;\n\n    int workOffset[MAX_GPU_COUNT];\n    int workSize[MAX_GPU_COUNT];\n\n    workOffset[0] = 0;\n    for(unsigned int i=0; i < ciDeviceCount; ++i) \n    {\n        workSize[i] = (i != (ciDeviceCount - 1)) ? sizePerGPU : (uiHA - workOffset[i]);        \n\n        d_A[i] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, workSize[i] * sizeof(float) * uiWA, NULL,NULL);\n\n        // Copy only assigned rows from host to device\n        clEnqueueCopyBuffer(commandQueue[i], h_A, d_A[i], workOffset[i] * sizeof(float) * uiWA, \n                            0, workSize[i] * sizeof(float) * uiWA, 0, NULL, NULL);        \n        \n        // create OpenCL buffer on device that will be initiatlize from the host memory on first use\n        // on device\n        d_B[i] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,\n                                mem_size_B, h_B_data, NULL);\n\n        // Output buffer\n        d_C[i] = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY,  workSize[i] * uiWC * sizeof(float), NULL,NULL);\n              \n        // set the args values\n        clSetKernelArg(multiplicationKernel[i], 0, sizeof(cl_mem), (void *) &d_C[i]);\n        clSetKernelArg(multiplicationKernel[i], 1, sizeof(cl_mem), (void *) &d_A[i]);\n        clSetKernelArg(multiplicationKernel[i], 2, sizeof(cl_mem), (void *) &d_B[i]);\n        clSetKernelArg(multiplicationKernel[i], 3, sizeof(float) * BLOCK_SIZE *BLOCK_SIZE, 0 );\n        clSetKernelArg(multiplicationKernel[i], 4, sizeof(float) * BLOCK_SIZE *BLOCK_SIZE, 0 );\n        clSetKernelArg(multiplicationKernel[i], 5, sizeof(cl_int), (void *) &uiWA);\n        clSetKernelArg(multiplicationKernel[i], 6, sizeof(cl_int), (void *) &uiWB);\n        clSetKernelArg(multiplicationKernel[i], 7, sizeof(cl_int), (void *) &workSize[i]);\n\n        if(i+1 < ciDeviceCount)\n            workOffset[i + 1] = workOffset[i] + workSize[i];\n    }\n    \n    size_t localWorkSize[] = {BLOCK_SIZE, BLOCK_SIZE};\n    size_t globalWorkSize[] = {shrRoundUp(BLOCK_SIZE, uiWC), shrRoundUp(BLOCK_SIZE, workSize[0])};\n    \n#ifdef GPU_PROFILING\n\t\n\tint nIter = 30;\n\n    for (int j = -1; j < nIter; j++) \n    {\n        // Sync all queues to host and start timer first time through loop\n        if(j == 0){\n            for(unsigned int i = 0; i < ciDeviceCount; i++) \n            {\n                clFinish(commandQueue[i]);\n            }\n\n            shrDeltaT(0);\n        }\n#endif\n        for(unsigned int i = 0; i < ciDeviceCount; i++) \n        {\n\t\t\t// Multiplication - non-blocking execution:  launch and push to device(s)\n\t\t\tglobalWorkSize[1] = shrRoundUp(BLOCK_SIZE, workSize[i]);\n\t\t\tclEnqueueNDRangeKernel(commandQueue[i], multiplicationKernel[i], 2, 0, globalWorkSize, localWorkSize,\n\t\t\t\t                   0, NULL, &GPUExecution[i]);\n            clFlush(commandQueue[i]);\n\t\t}\n\n#ifdef GPU_PROFILING\n    }\n#endif\n\n    // sync all queues to host\n\tfor(unsigned int i = 0; i < ciDeviceCount; i++) \n    {\n\t\tclFinish(commandQueue[i]);\n\t}\n\n#ifdef GPU_PROFILING\n\n    // stop and log timer \n    double dSeconds = shrDeltaT(0)/(double)nIter;\n    double dNumOps = 2.0 * (double)uiWA * (double)uiHA * (double)uiWB;\n    double gflops = 1.0e-9 * dNumOps/dSeconds;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclMatrixMul, Throughput = %.4f GFlops/s, Time = %.5f s, Size = %.0f, NumDevsUsed = %d, Workgroup = %u\\n\", \n            gflops, dSeconds, dNumOps, ciDeviceCount, localWorkSize[0] * localWorkSize[1]);\n\n    // Print kernel timing per GPU\n    shrLog(\"\\n\");\n    for(unsigned int i = 0; i < ciDeviceCount; i++) \n    {    \n        shrLog(\"  Kernel execution time on GPU %d \\t: %.5f s\\n\", i, executionTime(GPUExecution[i]));\n    }\n    shrLog(\"\\n\");\n#endif\n\n    for(unsigned int i = 0; i < ciDeviceCount; i++) \n    {    \n        // Non-blocking copy of result from device to host\n        clEnqueueReadBuffer(commandQueue[i], d_C[i], CL_FALSE, 0, uiWC * sizeof(float) * workSize[i], \n                            h_C + workOffset[i] * uiWC, 0, NULL, &GPUDone[i]);\n    }\n\n\t// CPU sync with GPU\n    clWaitForEvents(ciDeviceCount, GPUDone);\n\n\n    // Release mem and event objects    \n    for(unsigned int i = 0; i < ciDeviceCount; i++) \n    {\n        clReleaseMemObject(d_A[i]);\n        clReleaseMemObject(d_C[i]);\n        clReleaseMemObject(d_B[i]);\n\t    clReleaseEvent(GPUExecution[i]);\n\t    clReleaseEvent(GPUDone[i]);\n    }\n}\n\nint runTest(int argc, const char** argv)\n{\n    cl_platform_id cpPlatform = NULL;\n    cl_uint ciDeviceCount = 0;\n    cl_device_id *cdDevices = NULL;\n    cl_int ciErrNum = CL_SUCCESS;\n\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        shrLog(\"Error: Failed to create OpenCL context!\\n\");\n        return ciErrNum;\n    }\n\n    //Get the devices\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &ciDeviceCount);\n    cdDevices = (cl_device_id *)malloc(ciDeviceCount * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, ciDeviceCount, cdDevices, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        shrLog(\"Error: Failed to create OpenCL context!\\n\");\n        return ciErrNum;\n    }\n\n    //Create the context\n    cxGPUContext = clCreateContext(0, ciDeviceCount, cdDevices, NULL, NULL, &ciErrNum);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        shrLog(\"Error: Failed to create OpenCL context!\\n\");\n        return ciErrNum;\n    }\n\n    if(shrCheckCmdLineFlag(argc, (const char**)argv, \"device\"))\n    {\n        // User specified GPUs\n        char* deviceList;\n        char* deviceStr;\n        char* next_token;\n        shrGetCmdLineArgumentstr(argc, (const char**)argv, \"device\", &deviceList);\n\n        #ifdef WIN32\n            deviceStr = strtok_s (deviceList,\" ,.-\", &next_token);\n        #else\n            deviceStr = strtok (deviceList,\" ,.-\");\n        #endif   \n        ciDeviceCount = 0;\n        while(deviceStr != NULL) \n        {\n            // get and print the device for this queue\n            cl_device_id device = oclGetDev(cxGPUContext, atoi(deviceStr));\n\t\t\tif( device == (cl_device_id) -1  ) {\n\t\t\t\tshrLog(\" Device %s does not exist!\\n\", deviceStr);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\t\n\t\t\tshrLog(\"Device %s: \", deviceStr);\n            oclPrintDevName(LOGBOTH, device);            \n            shrLog(\"\\n\");\n           \n            // create command queue\n            commandQueue[ciDeviceCount] = clCreateCommandQueue(cxGPUContext, device, CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n            if (ciErrNum != CL_SUCCESS)\n            {\n                shrLog(\" Error %i in clCreateCommandQueue call !!!\\n\\n\", ciErrNum);\n                return ciErrNum;\n            }\n                \n            ++ciDeviceCount;\n\n            #ifdef WIN32\n                deviceStr = strtok_s (NULL,\" ,.-\", &next_token);\n            #else            \n                deviceStr = strtok (NULL,\" ,.-\");\n            #endif\n        }\n\n        free(deviceList);\n    } \n    else \n    {\n\t    size_t nDeviceBytes;\n\t    ciErrNum |= clGetContextInfo(cxGPUContext, CL_CONTEXT_DEVICES, 0, NULL, &nDeviceBytes);\n\t    ciDeviceCount = (cl_uint)nDeviceBytes/sizeof(cl_device_id);\n\n        if (ciErrNum != CL_SUCCESS)\n        {\n            shrLog(\" Error %i in clGetDeviceIDs call !!!\\n\\n\", ciErrNum);\n            return ciErrNum;\n        }\n        else if (ciDeviceCount == 0)\n        {\n            shrLog(\" There are no devices supporting OpenCL (return code %i)\\n\\n\", ciErrNum);\n            return -1;\n        } \n\n        for(unsigned int i = 0; i < ciDeviceCount; ++i) \n        {\n            cl_device_id device = oclGetDev(cxGPUContext, i);\n            shrLog(\"Device %d: \", i);\n            oclPrintDevName(LOGBOTH, device);            \n            shrLog(\"\\n\");\n\n            // create command queue\n            commandQueue[i] = clCreateCommandQueue(cxGPUContext, device, CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n            if (ciErrNum != CL_SUCCESS)\n            {\n                shrLog(\" Error %i in clCreateCommandQueue call !!!\\n\\n\", ciErrNum);\n                return ciErrNum;\n            }\n        }\n    }\n\n    // Optional Command-line multiplier for matrix sizes\n    shrGetCmdLineArgumenti(argc, (const char**)argv, \"sizemult\", &iSizeMultiple); \n    iSizeMultiple = CLAMP(iSizeMultiple, 1, 10);\n    uiWA = WA * iSizeMultiple;\n    uiHA = HA * iSizeMultiple;\n    uiWB = WB * iSizeMultiple;\n    uiHB = HB * iSizeMultiple;\n    uiWC = WC * iSizeMultiple;\n    uiHC = HC * iSizeMultiple;\n    shrLog(\"\\nUsing Matrix Sizes: A(%u x %u), B(%u x %u), C(%u x %u)\\n\", \n            uiWA, uiHA, uiWB, uiHB, uiWC, uiHC);\n\n    // allocate host memory for matrices A and B\n    unsigned int size_A = uiWA * uiHA;\n    unsigned int mem_size_A = sizeof(float) * size_A;\n    float* h_A_data = (float*)malloc(mem_size_A);\n    unsigned int size_B = uiWB * uiHB;\n    unsigned int mem_size_B = sizeof(float) * size_B;\n    float* h_B_data = (float*)malloc(mem_size_B);\n\n    // initialize host memory\n    srand(2006);\n    shrFillArray(h_A_data, size_A);\n    shrFillArray(h_B_data, size_B);\n\n    // allocate host memory for result\n    unsigned int size_C = uiWC * uiHC;\n    unsigned int mem_size_C = sizeof(float) * size_C;\n    float* h_C = (float*) malloc(mem_size_C);\n\n    // create OpenCL buffer pointing to the host memory\n    cl_mem h_A = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_USE_HOST_PTR,\n\t\t\t\t    mem_size_A, h_A_data, &ciErrNum);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        shrLog(\"Error: clCreateBuffer\\n\");\n        return ciErrNum;\n    }\n\n    // Program Setup\n    size_t program_length;\n    const char* header_path = shrFindFilePath(\"matrixMul.h\", argv[0]);\n    oclCheckError(header_path != NULL, shrTRUE);\n    char* header = oclLoadProgSource(header_path, \"\", &program_length);\n    if(!header)\n    {\n        shrLog(\"Error: Failed to load the header %s!\\n\", header_path);\n        return -1000;\n    }\n    const char* source_path = shrFindFilePath(\"matrixMul.cl\", argv[0]);\n    oclCheckError(source_path != NULL, shrTRUE);\n    char *source = oclLoadProgSource(source_path, header, &program_length);\n    if(!source)\n    {\n        shrLog(\"Error: Failed to load compute program %s!\\n\", source_path);\n        return -2000;\n    }\n\n    // create the program\n    cl_program cpProgram = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&source, \n                                                    &program_length, &ciErrNum);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        shrLog(\"Error: Failed to create program\\n\");\n        return ciErrNum;\n    }\n    free(header);\n    free(source);\n    \n    // build the program\n    ciErrNum = clBuildProgram(cpProgram, 0, NULL, \"-cl-fast-relaxed-math\", NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        // write out standard error, Build Log and PTX, then return error\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclMatrixMul.ptx\");\n        return ciErrNum;\n    }\n\n    // write out PTX if requested on the command line\n    if(shrCheckCmdLineFlag(argc, argv, \"dump-ptx\") )\n    {\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclMatrixMul.ptx\");\n    }\n\n    // Create Kernel\n    for(unsigned int i = 0; i < ciDeviceCount; ++i) {\n        multiplicationKernel[i] = clCreateKernel(cpProgram, \"matrixMul\", &ciErrNum);\n        if (ciErrNum != CL_SUCCESS)\n        {\n            shrLog(\"Error: Failed to create kernel\\n\");\n            return ciErrNum;\n        }\n    }\n        \n    // Run multiplication on 1..deviceCount GPUs to compare improvement\n    shrLog(\"\\nRunning Computations on 1 - %d GPU's...\\n\\n\", ciDeviceCount);\n    for(unsigned int k = 1; k <= ciDeviceCount; ++k) \n    {\n        matrixMulGPU(k, h_A, h_B_data, mem_size_B, h_C);\n    }\n\n    // compute reference solution\n    shrLog(\"Comparing results with CPU computation... \\n\\n\");\n    float* reference = (float*) malloc(mem_size_C);\n    computeGold(reference, h_A_data, h_B_data, uiHA, uiWA, uiWB);\n\n    // check result\n    shrBOOL res = shrCompareL2fe(reference, h_C, size_C, 1.0e-6f);\n    if (res != shrTRUE) \n    {\n        printDiff(reference, h_C, uiWC, uiHC, 100, 1.0e-5f);\n    }\n\n    // clean up OCL resources\n    ciErrNum = clReleaseMemObject(h_A);\n    for(unsigned int k = 0; k < ciDeviceCount; ++k) \n    {\n        ciErrNum |= clReleaseKernel( multiplicationKernel[k] );\n        ciErrNum |= clReleaseCommandQueue( commandQueue[k] );\n    }\n    ciErrNum |= clReleaseProgram(cpProgram);\n    ciErrNum |= clReleaseContext(cxGPUContext);\n    if(ciErrNum != CL_SUCCESS)\n    {\n        shrLog(\"Error: Failure releasing OpenCL resources: %d\\n\", ciErrNum);\n        return ciErrNum;\n    }\n\n    // clean up memory\n    free(h_A_data);\n    free(h_B_data);\n    free(h_C);\n    free(reference);\n    \n    return ((shrTRUE == res) ? CL_SUCCESS : -3000);\n}\n\nvoid printDiff(float *data1, float *data2, int width, int height, int iListLength, float fListTol)\n{\n    shrLog(\"Listing first %d Differences > %.6f...\\n\", iListLength, fListTol);\n    int i,j,k;\n    int error_count=0;\n    for (j = 0; j < height; j++) \n    {\n        if (error_count < iListLength)\n        {\n            shrLog(\"\\n  Row %d:\\n\", j);\n        }\n        for (i = 0; i < width; i++) \n        {\n            k = j * width + i;\n            float fDiff = fabs(data1[k] - data2[k]);\n            if (fDiff > fListTol) \n            {                \n                if (error_count < iListLength)\n                {\n                    shrLog(\"    Loc(%d,%d)\\tCPU=%.5f\\tGPU=%.5f\\tDiff=%.6f\\n\", i, j, data1[k], data2[k], fDiff);\n                }\n                error_count++;\n            }\n        }\n    }\n    shrLog(\" \\n  Total Errors = %d\\n\\n\", error_count);\n}\n", "matrixMul.cl": "#define AS(i, j) As[j + i * BLOCK_SIZE]\n#define BS(i, j) Bs[j + i * BLOCK_SIZE]\n\n__kernel void\nmatrixMul( __global float* C, __global float* A, __global float* B, \n\t   __local float* As, __local float* Bs, int uiWA, int uiWB, int trueLocalSize1)\n{\n    // Block index\n    int bx = get_group_id(0);\n    int by = get_group_id(1);\n\n    // Thread index\n    int tx = get_local_id(0);\n    int ty = get_local_id(1);\n\n    // Index of the first sub-matrix of A processed by the block\n    int aBegin = uiWA * BLOCK_SIZE * by;\n\n    // Index of the last sub-matrix of A processed by the block\n    int aEnd   = aBegin + uiWA - 1;\n\n    // Step size used to iterate through the sub-matrices of A\n    int aStep  = BLOCK_SIZE;\n\n    // Index of the first sub-matrix of B processed by the block\n    int bBegin = BLOCK_SIZE * bx;\n\n    // Step size used to iterate through the sub-matrices of B\n    int bStep  = BLOCK_SIZE * uiWB;\n\n    // Csub is used to store the element of the block sub-matrix\n    // that is computed by the thread\n    float Csub = 0.0f;\n\n    // Loop over all the sub-matrices of A and B\n    // required to compute the block sub-matrix\n    for (int a = aBegin, b = bBegin;\n             a <= aEnd;\n             a += aStep, b += bStep) {\n\n        // Load the matrices from device memory\n        // to shared memory; each thread loads\n        // one element of each matrix\n        AS(ty, tx) = A[a + uiWA * ty + tx];\n        BS(ty, tx) = B[b + uiWB * ty + tx];\n\t\n        // Synchronize to make sure the matrices are loaded\n        barrier(CLK_LOCAL_MEM_FENCE);\n   \n        #pragma unroll\n        for (int k = 0; k < BLOCK_SIZE; ++k)\n            Csub += AS(ty, k) * BS(k, tx);\n\n        barrier(CLK_LOCAL_MEM_FENCE);\n    }\n\n    if (get_global_id(1) < trueLocalSize1)\n\n    C[get_global_id(1) * get_global_size(0) + get_global_id(0)] = Csub;\n\n}\n\n"}, "code_dirs": {"oclMatrixMul.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclMatrixMul", "matrixMul.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclMatrixMul"}}
{"kernel_name": "simpleMultiGPU", "parallel_api": "cuda", "code": {"simpleMultiGPU.cu": "#include <assert.h>\n#include <stdio.h>\n\n#include <cuda_runtime.h>\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n\n#ifndef MAX\n#define MAX(a, b) (a > b ? a : b)\n#endif\n\n#include \"simpleMultiGPU.h\"\n\nconst int MAX_GPU_COUNT = 32;\nconst int DATA_N        = 1048576 * 32;\n\n__global__ static void reduceKernel(float *d_Result, float *d_Input, int N)\n{\n    const int tid     = blockIdx.x * blockDim.x + threadIdx.x;\n    const int threadN = gridDim.x * blockDim.x;\n    float     sum     = 0;\n\n    for (int pos = tid; pos < N; pos += threadN)\n        sum += d_Input[pos];\n\n    d_Result[tid] = sum;\n}\n\nint main(int argc, char **argv)\n{\n    TGPUplan plan[MAX_GPU_COUNT];\n\n    float h_SumGPU[MAX_GPU_COUNT];\n\n    float  sumGPU;\n    double sumCPU, diff;\n\n    int i, j, gpuBase, GPU_N;\n\n    const int BLOCK_N  = 32;\n    const int THREAD_N = 256;\n    const int ACCUM_N  = BLOCK_N * THREAD_N;\n\n    printf(\"Starting simpleMultiGPU\\n\");\n    checkCudaErrors(cudaGetDeviceCount(&GPU_N));\n\n    if (GPU_N > MAX_GPU_COUNT) {\n        GPU_N = MAX_GPU_COUNT;\n    }\n\n    printf(\"CUDA-capable device count: %i\\n\", GPU_N);\n\n    printf(\"Generating input data...\\n\\n\");\n\n    for (i = 0; i < GPU_N; i++) {\n        plan[i].dataN = DATA_N / GPU_N;\n    }\n\n    for (i = 0; i < DATA_N % GPU_N; i++) {\n        plan[i].dataN++;\n    }\n\n    gpuBase = 0;\n\n    for (i = 0; i < GPU_N; i++) {\n        plan[i].h_Sum = h_SumGPU + i;\n        gpuBase += plan[i].dataN;\n    }\n\n    for (i = 0; i < GPU_N; i++) {\n        checkCudaErrors(cudaSetDevice(i));\n        checkCudaErrors(cudaStreamCreate(&plan[i].stream));\n        checkCudaErrors(cudaMalloc((void **)&plan[i].d_Data, plan[i].dataN * sizeof(float)));\n        checkCudaErrors(cudaMalloc((void **)&plan[i].d_Sum, ACCUM_N * sizeof(float)));\n        checkCudaErrors(cudaMallocHost((void **)&plan[i].h_Sum_from_device, ACCUM_N * sizeof(float)));\n        checkCudaErrors(cudaMallocHost((void **)&plan[i].h_Data, plan[i].dataN * sizeof(float)));\n\n        for (j = 0; j < plan[i].dataN; j++) {\n            plan[i].h_Data[j] = (float)rand() / (float)RAND_MAX;\n        }\n    }\n\n    printf(\"Computing with %d GPUs...\\n\", GPU_N);\n    StopWatchInterface *timer = NULL;\n    sdkCreateTimer(&timer);\n\n    sdkStartTimer(&timer);\n\n    for (i = 0; i < GPU_N; i++) {\n        checkCudaErrors(cudaSetDevice(i));\n\n        checkCudaErrors(cudaMemcpyAsync(\n            plan[i].d_Data, plan[i].h_Data, plan[i].dataN * sizeof(float), cudaMemcpyHostToDevice, plan[i].stream));\n\n        reduceKernel<<<BLOCK_N, THREAD_N, 0, plan[i].stream>>>(plan[i].d_Sum, plan[i].d_Data, plan[i].dataN);\n        getLastCudaError(\"reduceKernel() execution failed.\\n\");\n\n        checkCudaErrors(cudaMemcpyAsync(\n            plan[i].h_Sum_from_device, plan[i].d_Sum, ACCUM_N * sizeof(float), cudaMemcpyDeviceToHost, plan[i].stream));\n    }\n\n    for (i = 0; i < GPU_N; i++) {\n        float sum;\n\n        checkCudaErrors(cudaSetDevice(i));\n\n        cudaStreamSynchronize(plan[i].stream);\n\n        sum = 0;\n\n        for (j = 0; j < ACCUM_N; j++) {\n            sum += plan[i].h_Sum_from_device[j];\n        }\n\n        *(plan[i].h_Sum) = (float)sum;\n\n        checkCudaErrors(cudaFreeHost(plan[i].h_Sum_from_device));\n        checkCudaErrors(cudaFree(plan[i].d_Sum));\n        checkCudaErrors(cudaFree(plan[i].d_Data));\n        checkCudaErrors(cudaStreamDestroy(plan[i].stream));\n    }\n\n    sumGPU = 0;\n\n    for (i = 0; i < GPU_N; i++) {\n        sumGPU += h_SumGPU[i];\n    }\n\n    sdkStopTimer(&timer);\n    printf(\"  GPU Processing time: %f (ms)\\n\\n\", sdkGetTimerValue(&timer));\n    sdkDeleteTimer(&timer);\n\n    printf(\"Computing with Host CPU...\\n\\n\");\n\n    sumCPU = 0;\n\n    for (i = 0; i < GPU_N; i++) {\n        for (j = 0; j < plan[i].dataN; j++) {\n            sumCPU += plan[i].h_Data[j];\n        }\n    }\n\n    printf(\"Comparing GPU and Host CPU results...\\n\");\n    diff = fabs(sumCPU - sumGPU) / fabs(sumCPU);\n    printf(\"  GPU sum: %f\\n  CPU sum: %f\\n\", sumGPU, sumCPU);\n    printf(\"  Relative difference: %E \\n\\n\", diff);\n\n    for (i = 0; i < GPU_N; i++) {\n        checkCudaErrors(cudaSetDevice(i));\n        checkCudaErrors(cudaFreeHost(plan[i].h_Data));\n    }\n\n    exit((diff < 1e-5) ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n"}, "code_dirs": {"simpleMultiGPU.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/0_Introduction/simpleMultiGPU"}}
{"kernel_name": "simpleMultiGPU", "parallel_api": "ocl", "code": {"oclSimpleMultiGPU.cpp": "\n#include <oclUtils.h>\n#include <shrQATest.h>\n\nconst unsigned int MAX_GPU_COUNT = 8;\nconst unsigned int DATA_N = 1048576*24;\nconst unsigned int BLOCK_N = 128;\nconst unsigned int THREAD_N = 128;\nconst unsigned int ACCUM_N = BLOCK_N * THREAD_N;\n\ndouble executionTime(cl_event &event)\n{\n    cl_ulong start, end;\n    \n    clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &end, NULL);\n    clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_START, sizeof(cl_ulong), &start, NULL);\n   \n    return (double)1.0e-9 * (end - start); // convert nanoseconds to seconds on return\n}\n\nint main(int argc, char **argv)\n{\n    shrQAStart(argc, argv);\n    // start logs \n    shrSetLogFileName (\"oclSimpleMultiGPU.txt\");\n    shrLog(\"%s Starting, Array = %u float values...\\n\\n\", argv[0], DATA_N); \n\n    // OpenCL\n    cl_platform_id cpPlatform;\n    cl_uint ciDeviceCount;\n    cl_device_id* cdDevices;\n    cl_context cxGPUContext;\n    cl_device_id cdDevice;                          // GPU device\n    int deviceNr[MAX_GPU_COUNT];\n    cl_command_queue commandQueue[MAX_GPU_COUNT];\n    cl_mem d_Data[MAX_GPU_COUNT];\n    cl_mem d_Result[MAX_GPU_COUNT];\n    cl_program cpProgram; \n    cl_kernel reduceKernel[MAX_GPU_COUNT];\n    cl_event GPUDone[MAX_GPU_COUNT];\n    cl_event GPUExecution[MAX_GPU_COUNT];\n    size_t programLength;\n    cl_int ciErrNum;\t\t\t               \n    char cDeviceName [256];\n    cl_mem h_DataBuffer;\n\n    // Vars for reduction results\n    float h_SumGPU[MAX_GPU_COUNT * ACCUM_N];   \n    float *h_Data;\n    double sumGPU;\n    double sumCPU, dRelError;\n\n    // allocate and init host buffer with with some random generated input data\n    h_Data = (float *)malloc(DATA_N * sizeof(float));\n    shrFillArray(h_Data, DATA_N);\n\n    // start timer & logs \n    shrLog(\"Setting up OpenCL on the Host...\\n\\n\"); \n    shrDeltaT(1);\n\n    // Annotate profiling state\n    #ifdef GPU_PROFILING\n        shrLog(\"OpenCL Profiling is enabled...\\n\\n\"); \n    #endif\n\n     //Get the NVIDIA platform\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    shrLog(\"clGetPlatformID...\\n\"); \n\n    //Get the devices\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &ciDeviceCount);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    cdDevices = (cl_device_id *)malloc(ciDeviceCount * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, ciDeviceCount, cdDevices, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    shrLog(\"clGetDeviceIDs...\\n\"); \n\n    //Create the context\n    cxGPUContext = clCreateContext(0, ciDeviceCount, cdDevices, NULL, NULL, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    shrLog(\"clCreateContext...\\n\");\n\n    // Set up command queue(s) for GPU's specified on the command line or all GPU's\n    if(shrCheckCmdLineFlag(argc, (const char **)argv, \"device\"))\n    {\n        // User specified GPUs\n        int ciMaxDeviceID = ciDeviceCount-1;\n\n        ciDeviceCount = 0;\n        char* deviceList;\n        char* deviceStr;\n        char* next_token;\n        shrGetCmdLineArgumentstr(argc, (const char **)argv, \"device\", &deviceList);\n\n        #ifdef WIN32\n            deviceStr = strtok_s (deviceList,\" ,.-\", &next_token);\n        #else\n            deviceStr = strtok (deviceList,\" ,.-\");\n        #endif   \n\n        // Create command queues for all Requested GPU's\n        while(deviceStr != NULL) \n        {\n            // get & log device index # and name\n            deviceNr[ciDeviceCount] = atoi(deviceStr);\n            if( deviceNr[ciDeviceCount] > ciMaxDeviceID ) {\n                shrLog(\" Invalid user specified device ID: %d\\n\", deviceNr[ciDeviceCount]);\n                return 1;\n            }\n\n            cdDevice = oclGetDev(cxGPUContext, deviceNr[ciDeviceCount]);\n            ciErrNum = clGetDeviceInfo(cdDevice, CL_DEVICE_NAME, sizeof(cDeviceName), cDeviceName, NULL);\n            oclCheckError(ciErrNum, CL_SUCCESS);\n            shrLog(\" Device %i: %s\\n\\n\", deviceNr[ciDeviceCount], cDeviceName);\n\n            // create a command que\n            commandQueue[ciDeviceCount] = clCreateCommandQueue(cxGPUContext, cdDevice, CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n            oclCheckError(ciErrNum, CL_SUCCESS);\n            shrLog(\"clCreateCommandQueue\\n\"); \n\n            ++ciDeviceCount;\n\n            #ifdef WIN32\n                deviceStr = strtok_s (NULL,\" ,.-\", &next_token);\n            #else            \n                deviceStr = strtok (NULL,\" ,.-\");\n            #endif\n        }\n\n        free(deviceList);\n    } \n    else \n    {\n        // Find out how many GPU's to compute on all available GPUs\n        size_t nDeviceBytes;\n        ciErrNum = clGetContextInfo(cxGPUContext, CL_CONTEXT_DEVICES, 0, NULL, &nDeviceBytes);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ciDeviceCount = (cl_uint)nDeviceBytes/sizeof(cl_device_id);\n\n        for(unsigned int i = 0; i < ciDeviceCount; ++i ) \n        {\n            // get & log device index # and name\n            deviceNr[i] = i;\n            cdDevice = oclGetDev(cxGPUContext, i);\n            ciErrNum = clGetDeviceInfo(cdDevice, CL_DEVICE_NAME, sizeof(cDeviceName), cDeviceName, NULL);\n            oclCheckError(ciErrNum, CL_SUCCESS);\n            shrLog(\" Device %i: %s\\n\", i, cDeviceName);\n\n            // create a command que\n            commandQueue[i] = clCreateCommandQueue(cxGPUContext, cdDevice, CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n            oclCheckError(ciErrNum, CL_SUCCESS);\n            shrLog(\"clCreateCommandQueue\\n\\n\"); \n        }\n    }\n\n    // Load the OpenCL source code from the .cl file \n    const char* source_path = shrFindFilePath(\"simpleMultiGPU.cl\", argv[0]);\n    char *source = oclLoadProgSource(source_path, \"\", &programLength);\n    oclCheckError(source != NULL, shrTRUE);\n    shrLog(\"oclLoadProgSource\\n\"); \n\n    // Create the program for all GPUs in the context\n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&source, &programLength, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    shrLog(\"clCreateProgramWithSource\\n\"); \n    \n    // build the program\n    ciErrNum = clBuildProgram(cpProgram, 0, NULL, \"-cl-fast-relaxed-math\", NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        // write out standard error, Build Log and PTX, then cleanup and exit\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclSimpleMultiGPU.ptx\");\n        oclCheckError(ciErrNum, CL_SUCCESS); \n    }\n    shrLog(\"clBuildProgram\\n\"); \n\n    // Create host buffer with page-locked memory\n    h_DataBuffer = clCreateBuffer(cxGPUContext, CL_MEM_COPY_HOST_PTR | CL_MEM_ALLOC_HOST_PTR,\n                                  DATA_N * sizeof(float), h_Data, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    shrLog(\"clCreateBuffer (Page-locked Host)\\n\\n\"); \n\n    // Create buffers for each GPU, with data divided evenly among GPU's\n    int sizePerGPU = DATA_N / ciDeviceCount;\n    int workOffset[MAX_GPU_COUNT];\n    int workSize[MAX_GPU_COUNT];\n    workOffset[0] = 0;\n    for(unsigned int i = 0; i < ciDeviceCount; ++i ) \n    {\n        workSize[i] = (i != (ciDeviceCount - 1)) ? sizePerGPU : (DATA_N - workOffset[i]);        \n\n        // Input buffer\n        d_Data[i] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, workSize[i] * sizeof(float), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        shrLog(\"clCreateBuffer (Input)\\t\\tDev %i\\n\", i); \n\n        // Copy data from host to device\n        ciErrNum = clEnqueueCopyBuffer(commandQueue[i], h_DataBuffer, d_Data[i], workOffset[i] * sizeof(float), \n                                      0, workSize[i] * sizeof(float), 0, NULL, NULL);        \n        shrLog(\"clEnqueueCopyBuffer (Input)\\tDev %i\\n\", i);\n\n        // Output buffer\n        d_Result[i] = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, ACCUM_N * sizeof(float), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        shrLog(\"clCreateBuffer (Output)\\t\\tDev %i\\n\", i);\n        \n        // Create kernel\n        reduceKernel[i] = clCreateKernel(cpProgram, \"reduce\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        shrLog(\"clCreateKernel\\t\\t\\tDev %i\\n\", i); \n        \n        // Set the args values and check for errors\n        ciErrNum |= clSetKernelArg(reduceKernel[i], 0, sizeof(cl_mem), &d_Result[i]);\n        ciErrNum |= clSetKernelArg(reduceKernel[i], 1, sizeof(cl_mem), &d_Data[i]);\n        ciErrNum |= clSetKernelArg(reduceKernel[i], 2, sizeof(int), &workSize[i]);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        shrLog(\"clSetKernelArg\\t\\t\\tDev %i\\n\\n\", i);\n\n        workOffset[i + 1] = workOffset[i] + workSize[i];\n    }\n\n    // Set # of work items in work group and total in 1 dimensional range\n    size_t localWorkSize[] = {THREAD_N};        \n    size_t globalWorkSize[] = {ACCUM_N};        \n\n    // Start timer and launch reduction kernel on each GPU, with data split between them \n    shrLog(\"Launching Kernels on GPU(s)...\\n\\n\");\n    for(unsigned int i = 0; i < ciDeviceCount; i++) \n    {        \n        ciErrNum = clEnqueueNDRangeKernel(commandQueue[i], reduceKernel[i], 1, 0, globalWorkSize, localWorkSize,\n                                         0, NULL, &GPUExecution[i]);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }\n    \n    // Copy result from device to host for each device\n    for(unsigned int i = 0; i < ciDeviceCount; i++) \n    {\n        ciErrNum = clEnqueueReadBuffer(commandQueue[i], d_Result[i], CL_FALSE, 0, ACCUM_N * sizeof(float), \n                            h_SumGPU + i *  ACCUM_N, 0, NULL, &GPUDone[i]);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }\n\n    // Synchronize with the GPUs and do accumulated error check\n    clWaitForEvents(ciDeviceCount, GPUDone);\n    shrLog(\"clWaitForEvents complete...\\n\\n\"); \n\n    // Aggregate results for multiple GPU's and stop/log processing time\n    sumGPU = 0;\n    for(unsigned int i = 0; i < ciDeviceCount * ACCUM_N; i++)\n    {\n         sumGPU += h_SumGPU[i];\n    }\n\n    // Print Execution Times for each GPU\n    #ifdef GPU_PROFILING\n        shrLog(\"Profiling Information for GPU Processing:\\n\\n\");\n        for(unsigned int i = 0; i < ciDeviceCount; i++) \n        {\n            cdDevice = oclGetDev(cxGPUContext, deviceNr[i]);\n            clGetDeviceInfo(cdDevice, CL_DEVICE_NAME, sizeof(cDeviceName), cDeviceName, NULL);\n            shrLog(\"Device %i : %s\\n\", deviceNr[i], cDeviceName);\n            shrLog(\"  Reduce Kernel     : %.5f s\\n\", executionTime(GPUExecution[i]));\n            shrLog(\"  Copy Device->Host : %.5f s\\n\\n\\n\", executionTime(GPUDone[i]));\n        }\n    #endif\n\n    // Run the computation on the Host CPU and log processing time \n    shrLog(\"Launching Host/CPU C++ Computation...\\n\\n\");\n    sumCPU = 0;\n    for(unsigned int i = 0; i < DATA_N; i++)\n    {\n        sumCPU += h_Data[i];\n    }\n\n    // Check GPU result against CPU result \n    dRelError = 100.0 * fabs(sumCPU - sumGPU) / fabs(sumCPU);\n    shrLog(\"Comparing against Host/C++ computation...\\n\"); \n    shrLog(\" GPU sum: %f\\n CPU sum: %f\\n\", sumGPU, sumCPU);\n    shrLog(\" Relative Error (100.0 * Error / Golden) = %f \\n\\n\", dRelError);\n\n    // cleanup \n    free(source);\n    free(h_Data);\n    for(unsigned int i = 0; i < ciDeviceCount; ++i ) \n    {\n        clReleaseKernel(reduceKernel[i]);\n        clReleaseCommandQueue(commandQueue[i]);\n    }\n    clReleaseProgram(cpProgram);\n    clReleaseContext(cxGPUContext);\n\n    // finish\n    shrQAFinishExit(argc, (const char **)argv, (dRelError < 1e-4) ? QA_PASSED : QA_FAILED);\n  }\n", "simpleMultiGPU.cl": "__kernel void reduce(__global float *d_Result, __global float *d_Input, int N){\n    const int tid = get_global_id(0);\n    const int threadN = get_global_size(0);\n\n    float sum = 0;\n\n    for(int pos = tid; pos < N; pos += threadN)\n        sum += d_Input[pos];\n\n    d_Result[tid] = sum;\n}\n"}, "code_dirs": {"oclSimpleMultiGPU.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclSimpleMultiGPU", "simpleMultiGPU.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclSimpleMultiGPU"}}
{"kernel_name": "simpleTexture3D", "parallel_api": "cuda", "code": {"simpleTexture3D.cpp": "#include <helper_gl.h>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#if defined(__APPLE__) || defined(MACOSX)\n#pragma clang diagnostic ignored \"-Wdeprecated-declarations\"\n#include <GLUT/glut.h>\n#ifndef glutCloseFunc\n#define glutCloseFunc glutWMCloseFunc\n#endif\n#else\n#include <GL/freeglut.h>\n#endif\n\n#include <cuda_gl_interop.h>\n#include <cuda_runtime.h>\n#include <vector_types.h>\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n#include <vector_types.h>\n\ntypedef unsigned int  uint;\ntypedef unsigned char uchar;\n\n#define MAX_EPSILON_ERROR 5.0f\n#define THRESHOLD         0.15f\n\nconst char *sSDKsample = \"simpleTexture3D\";\n\nconst char      *volumeFilename = \"Bucky.raw\";\nconst cudaExtent volumeSize     = make_cudaExtent(32, 32, 32);\n\nconst uint width = 512, height = 512;\nconst dim3 blockSize(16, 16, 1);\nconst dim3 gridSize(width / blockSize.x, height / blockSize.y);\n\nfloat w = 0.5;\n\nGLuint                       pbo;\nstruct cudaGraphicsResource *cuda_pbo_resource;\n\nbool linearFiltering = true;\nbool animate         = true;\n\nStopWatchInterface *timer = NULL;\n\nuint *d_output = NULL;\n\nconst int    frameCheckNumber  = 4;\nint          fpsCount          = 0;\nint          fpsLimit          = 1;\nint          g_Index           = 0;\nunsigned int frameCount        = 0;\nunsigned int g_TotalErrors     = 0;\nvolatile int g_GraphicsMapFlag = 0;\n\nint   *pArgc = NULL;\nchar **pArgv = NULL;\n\n#ifndef MAX\n#define MAX(a, b) ((a > b) ? a : b)\n#endif\n\nextern \"C\" void cleanup();\nextern \"C\" void setTextureFilterMode(bool bLinearFilter);\nextern \"C\" void initCuda(const uchar *h_volume, cudaExtent volumeSize);\nextern \"C\" void render_kernel(dim3 gridSize, dim3 blockSize, uint *d_output, uint imageW, uint imageH, float w);\nextern void     cleanupCuda();\n\nvoid loadVolumeData(char *exec_path);\n\nvoid computeFPS()\n{\n    frameCount++;\n    fpsCount++;\n\n    if (fpsCount == fpsLimit) {\n        char  fps[256];\n        float ifps = 1.f / (sdkGetAverageTimerValue(&timer) / 1000.f);\n        sprintf(fps, \"%s: %3.1f fps\", sSDKsample, ifps);\n\n        glutSetWindowTitle(fps);\n        fpsCount = 0;\n\n        fpsLimit = ftoi(MAX(1.0f, ifps));\n        sdkResetTimer(&timer);\n    }\n}\n\nvoid render()\n{\n    g_GraphicsMapFlag++;\n    checkCudaErrors(cudaGraphicsMapResources(1, &cuda_pbo_resource, 0));\n    size_t num_bytes;\n    checkCudaErrors(cudaGraphicsResourceGetMappedPointer((void **)&d_output, &num_bytes, cuda_pbo_resource));\n\n    render_kernel(gridSize, blockSize, d_output, width, height, w);\n\n    getLastCudaError(\"render_kernel failed\");\n\n    if (g_GraphicsMapFlag) {\n        checkCudaErrors(cudaGraphicsUnmapResources(1, &cuda_pbo_resource, 0));\n        g_GraphicsMapFlag--;\n    }\n}\n\nvoid display()\n{\n    sdkStartTimer(&timer);\n\n    render();\n\n    glClear(GL_COLOR_BUFFER_BIT);\n\n    glDisable(GL_DEPTH_TEST);\n    glRasterPos2i(0, 0);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glDrawPixels(width, height, GL_RGBA, GL_UNSIGNED_BYTE, 0);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n    glutSwapBuffers();\n    glutReportErrors();\n\n    sdkStopTimer(&timer);\n    computeFPS();\n}\n\nvoid idle()\n{\n    if (animate) {\n        w += 0.01f;\n        glutPostRedisplay();\n    }\n}\n\nvoid keyboard(unsigned char key, int x, int y)\n{\n    switch (key) {\n    case 27:\n#if defined(__APPLE__) || defined(MACOSX)\n        exit(EXIT_SUCCESS);\n        glutDestroyWindow(glutGetWindow());\n        return;\n#else\n        glutDestroyWindow(glutGetWindow());\n        return;\n#endif\n\n    case '=':\n    case '+':\n        w += 0.01f;\n        break;\n\n    case '-':\n        w -= 0.01f;\n        break;\n\n    case 'f':\n        linearFiltering = !linearFiltering;\n        setTextureFilterMode(linearFiltering);\n        break;\n\n    case ' ':\n        animate = !animate;\n        break;\n\n    default:\n        break;\n    }\n\n    glutPostRedisplay();\n}\n\nvoid reshape(int x, int y)\n{\n    glViewport(0, 0, x, y);\n\n    glMatrixMode(GL_MODELVIEW);\n    glLoadIdentity();\n\n    glMatrixMode(GL_PROJECTION);\n    glLoadIdentity();\n    glOrtho(0.0, 1.0, 0.0, 1.0, 0.0, 1.0);\n}\n\nvoid cleanup()\n{\n    sdkDeleteTimer(&timer);\n\n    if (g_GraphicsMapFlag) {\n        checkCudaErrors(cudaGraphicsUnmapResources(1, &cuda_pbo_resource, 0));\n        g_GraphicsMapFlag--;\n    }\n\n    checkCudaErrors(cudaGraphicsUnregisterResource(cuda_pbo_resource));\n    glDeleteBuffers(1, &pbo);\n    cleanupCuda();\n}\n\nvoid initGLBuffers()\n{\n    glGenBuffers(1, &pbo);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glBufferData(GL_PIXEL_UNPACK_BUFFER_ARB, width * height * sizeof(GLubyte) * 4, 0, GL_STREAM_DRAW_ARB);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n    checkCudaErrors(cudaGraphicsGLRegisterBuffer(&cuda_pbo_resource, pbo, cudaGraphicsMapFlagsWriteDiscard));\n}\n\nuchar *loadRawFile(const char *filename, size_t size)\n{\n    FILE *fp = fopen(filename, \"rb\");\n\n    if (!fp) {\n        fprintf(stderr, \"Error opening file '%s'\\n\", filename);\n        return 0;\n    }\n\n    uchar *data = (uchar *)malloc(size);\n    size_t read = fread(data, 1, size, fp);\n    fclose(fp);\n\n    printf(\"Read '%s', %zu bytes\\n\", filename, read);\n\n    return data;\n}\n\nvoid initGL(int *argc, char **argv)\n{\n    glutInit(argc, argv);\n    glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE);\n    glutInitWindowSize(width, height);\n    glutCreateWindow(\"CUDA 3D texture\");\n    glutDisplayFunc(display);\n    glutKeyboardFunc(keyboard);\n    glutReshapeFunc(reshape);\n    glutIdleFunc(idle);\n\n    if (!isGLVersionSupported(2, 0) || !areGLExtensionsSupported(\"GL_ARB_pixel_buffer_object\")) {\n        fprintf(stderr, \"Required OpenGL extensions are missing.\");\n        exit(EXIT_FAILURE);\n    }\n}\n\nvoid runAutoTest(const char *ref_file, char *exec_path)\n{\n    checkCudaErrors(cudaMalloc((void **)&d_output, width * height * sizeof(GLubyte) * 4));\n\n    render_kernel(gridSize, blockSize, d_output, width, height, w);\n\n    checkCudaErrors(cudaDeviceSynchronize());\n    getLastCudaError(\"render_kernel failed\");\n\n    void *h_output = malloc(width * height * sizeof(GLubyte) * 4);\n    checkCudaErrors(cudaMemcpy(h_output, d_output, width * height * sizeof(GLubyte) * 4, cudaMemcpyDeviceToHost));\n    sdkDumpBin(h_output, width * height * sizeof(GLubyte) * 4, \"simpleTexture3D.bin\");\n\n    bool bTestResult = sdkCompareBin2BinFloat(\"simpleTexture3D.bin\",\n                                              sdkFindFilePath(ref_file, exec_path),\n                                              width * height,\n                                              MAX_EPSILON_ERROR,\n                                              THRESHOLD,\n                                              exec_path);\n\n    checkCudaErrors(cudaFree(d_output));\n    free(h_output);\n\n    sdkStopTimer(&timer);\n    sdkDeleteTimer(&timer);\n\n    exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n\nvoid loadVolumeData(char *exec_path)\n{\n    const char *path = sdkFindFilePath(volumeFilename, exec_path);\n\n    if (path == NULL) {\n        fprintf(stderr, \"Error unable to find 3D Volume file: '%s'\\n\", volumeFilename);\n        exit(EXIT_FAILURE);\n    }\n\n    size_t size     = volumeSize.width * volumeSize.height * volumeSize.depth;\n    uchar *h_volume = loadRawFile(path, size);\n\n    initCuda(h_volume, volumeSize);\n    sdkCreateTimer(&timer);\n\n    free(h_volume);\n}\n\nint main(int argc, char **argv)\n{\n    pArgc = &argc;\n    pArgv = argv;\n\n    char *ref_file = NULL;\n\n#if defined(__linux__)\n    setenv(\"DISPLAY\", \":0\", 0);\n#endif\n\n    printf(\"%s Starting...\\n\\n\", sSDKsample);\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"file\")) {\n        fpsLimit = frameCheckNumber;\n        getCmdLineArgumentString(argc, (const char **)argv, \"file\", &ref_file);\n    }\n\n    findCudaDevice(argc, (const char **)argv);\n\n    if (ref_file) {\n        loadVolumeData(argv[0]);\n        runAutoTest(ref_file, argv[0]);\n    }\n    else {\n        initGL(&argc, argv);\n\n        initGLBuffers();\n\n        loadVolumeData(argv[0]);\n    }\n\n    printf(\"Press space to toggle animation\\n\"\n           \"Press '+' and '-' to change displayed slice\\n\");\n\n#if defined(__APPLE__) || defined(MACOSX)\n    atexit(cleanup);\n#else\n    glutCloseFunc(cleanup);\n#endif\n\n    glutMainLoop();\n\n    exit(EXIT_SUCCESS);\n}\n", "simpleTexture3D_kernel.cu": "#ifndef _SIMPLETEXTURE3D_KERNEL_CU_\n#define _SIMPLETEXTURE3D_KERNEL_CU_\n\n#include <helper_cuda.h>\n#include <helper_math.h>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\ntypedef unsigned int  uint;\ntypedef unsigned char uchar;\n\ncudaArray          *d_volumeArray = 0;\ncudaTextureObject_t tex;\n\n__global__ void d_render(uint *d_output, uint imageW, uint imageH, float w, cudaTextureObject_t texObj)\n{\n    uint x = __umul24(blockIdx.x, blockDim.x) + threadIdx.x;\n    uint y = __umul24(blockIdx.y, blockDim.y) + threadIdx.y;\n\n    float u = x / (float)imageW;\n    float v = y / (float)imageH;\n    float voxel = tex3D<float>(texObj, u, v, w);\n\n    if ((x < imageW) && (y < imageH)) {\n        uint i      = __umul24(y, imageW) + x;\n        d_output[i] = voxel * 255;\n    }\n}\n\nextern \"C\" void setTextureFilterMode(bool bLinearFilter)\n{\n    if (tex) {\n        checkCudaErrors(cudaDestroyTextureObject(tex));\n    }\n    cudaResourceDesc texRes;\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = d_volumeArray;\n\n    cudaTextureDesc texDescr;\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = true;\n    texDescr.filterMode       = bLinearFilter ? cudaFilterModeLinear : cudaFilterModePoint;\n    ;\n    texDescr.addressMode[0] = cudaAddressModeWrap;\n    texDescr.addressMode[1] = cudaAddressModeWrap;\n    texDescr.addressMode[2] = cudaAddressModeWrap;\n    texDescr.readMode       = cudaReadModeNormalizedFloat;\n\n    checkCudaErrors(cudaCreateTextureObject(&tex, &texRes, &texDescr, NULL));\n}\n\nextern \"C\" void initCuda(const uchar *h_volume, cudaExtent volumeSize)\n{\n    cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc<uchar>();\n    checkCudaErrors(cudaMalloc3DArray(&d_volumeArray, &channelDesc, volumeSize));\n\n    cudaMemcpy3DParms copyParams = {0};\n    copyParams.srcPtr =\n        make_cudaPitchedPtr((void *)h_volume, volumeSize.width * sizeof(uchar), volumeSize.width, volumeSize.height);\n    copyParams.dstArray = d_volumeArray;\n    copyParams.extent   = volumeSize;\n    copyParams.kind     = cudaMemcpyHostToDevice;\n    checkCudaErrors(cudaMemcpy3D(&copyParams));\n\n    cudaResourceDesc texRes;\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = d_volumeArray;\n\n    cudaTextureDesc texDescr;\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = true;\n    texDescr.filterMode = cudaFilterModeLinear;\n    texDescr.addressMode[0] = cudaAddressModeWrap;\n    texDescr.addressMode[1] = cudaAddressModeWrap;\n    texDescr.addressMode[2] = cudaAddressModeWrap;\n    texDescr.readMode       = cudaReadModeNormalizedFloat;\n\n    checkCudaErrors(cudaCreateTextureObject(&tex, &texRes, &texDescr, NULL));\n}\n\nextern \"C\" void render_kernel(dim3 gridSize, dim3 blockSize, uint *d_output, uint imageW, uint imageH, float w)\n{\n    d_render<<<gridSize, blockSize>>>(d_output, imageW, imageH, w, tex);\n}\n\nvoid cleanupCuda()\n{\n    if (tex) {\n        checkCudaErrors(cudaDestroyTextureObject(tex));\n    }\n    if (d_volumeArray) {\n        checkCudaErrors(cudaFreeArray(d_volumeArray));\n    }\n}\n\n#endif // #ifndef _SIMPLETEXTURE3D_KERNEL_CU_\n"}, "code_dirs": {"simpleTexture3D.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/0_Introduction/simpleTexture3D", "simpleTexture3D_kernel.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/0_Introduction/simpleTexture3D"}}
{"kernel_name": "simpleTexture3D", "parallel_api": "ocl", "code": {"oclSimpleTexture3D.cpp": "\n#include <GL/glew.h>\n#if defined (__APPLE__) || defined(MACOSX)\n    #include <GLUT/glut.h>\n#else\n    #include <GL/freeglut.h>\n#endif\n\n#include <oclUtils.h>\n#include <shrQATest.h>\n\n#define REFRESH_DELAY\t  10 //ms\n\n#define MAX_EPSILON_ERROR 5.0f\n#define THRESHOLD         0.15f\n\nconst char *sSDKsample = \"oclSimpleTexture3D\";\n\nint *pArgc = NULL;\nchar **pArgv = NULL;\n\ntypedef unsigned int uint;\ntypedef unsigned char uchar;\n\nconst char *volumeFilename = \"Bucky.raw\";\nconst size_t volumeSize[] = {32, 32, 32};\nconst uint width = 512, height = 512;\nconst size_t localWorkSize[] = {16, 16};\nconst size_t globalWorkSize[] = {width, height};\n\n// OpenCL vars\ncl_platform_id cpPlatform;\ncl_uint uiNumDevices;\ncl_device_id* cdDevices;\ncl_context cxGPUContext;\ncl_device_id cdDevice;\ncl_command_queue cqCommandQueue;\ncl_program cpProgram;\ncl_kernel ckKernel;\ncl_int ciErrNum;\ncl_mem pbo_cl;\ncl_mem d_volume;\ncl_sampler volumeSamplerLinear;\ncl_sampler volumeSamplerNearest;\nchar* cPathAndName = NULL;          // var for full paths to data, src, etc.\nchar* cSourceCL = NULL;             // Buffer to hold source for compilation \nconst char* cExecutableName = NULL;\n\n// Sim app config parameters\nint iFrameCount = 0;                // FPS count for averaging\nint iFrameTrigger = 90;             // FPS trigger for sampling\nint iFramesPerSec = 0;              // frames per second\nint iTestSets = 3;\nfloat w = 0.5;                      // initial texture coordinate in z\nint g_Index = 0;\nshrBOOL bQATest = shrFALSE;\nshrBOOL bNoPrompt = shrFALSE;\nbool linearFiltering = true;\nbool animate = true;\n\nint iGLUTWindowHandle;              // handle to the GLUT window\nGLuint pbo;                         // OpenGL pixel buffer object\n\n// OpenCL functions\ncl_mem initTexture3D(uchar *h_volume, const size_t volumeSize[3]);\nvoid loadVolumeData(const char *exec_path);\nvoid render();\ncl_mem initTexture3D(uchar *h_volume, const size_t volumeSize[3]);\n\n// OpenGL functionality\nvoid InitGL(int* argc, char** argv);\nvoid DisplayGL();\nvoid Reshape(int w, int h);\nvoid Idle(void);\nvoid KeyboardGL(unsigned char key, int x, int y);\nvoid timerEvent(int value);\nvoid initGLBuffers();\n\n// Helpers\nvoid Cleanup(int iExitCode);\nvoid (*pCleanup)(int) = &Cleanup;\nvoid TestNoGL();\n\nint main(int argc, char** argv) \n{\n\tpArgc = &argc;\n\tpArgv = argv;\n\n    shrQAStart(argc, argv);\n\n    // start logs\n\tcExecutableName = argv[0];\n    shrSetLogFileName (\"oclSimpleTexture3D.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n    shrLog(\" Press <spacebar> to toggle animation ON/OFF\\n\");\n    shrLog(\" Press '+' and '-' to change displayed slice\\n\");\n    shrLog(\" Press <f> to toggle filtering ON/OFF\\n\\n\");\n\n    // process command line arguments\n    if (argc > 1) \n    {\n        bQATest   = shrCheckCmdLineFlag(argc, (const char**)argv, \"qatest\");\n        bNoPrompt = shrCheckCmdLineFlag(argc, (const char**)argv, \"noprompt\");\n    }\n\n    // Initialize OpenGL context, so we can properly set the GL for CL.\n    if(!bQATest)\n    {\n        InitGL(&argc, argv); \n    }\n\n    //Get the NVIDIA platform\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    //Get the devices\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiNumDevices);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    cdDevices = (cl_device_id *)malloc(uiNumDevices * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiNumDevices, cdDevices, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    //Create the context\n    cxGPUContext = clCreateContext(0, uiNumDevices, cdDevices, NULL, NULL, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // get and log device info\n    if(shrCheckCmdLineFlag(argc, (const char**)argv, \"device\")) \n    {\n      int device_nr = 0;\n      shrGetCmdLineArgumenti(argc, (const char**)argv, \"device\", &device_nr);\n\t  if( (unsigned int)device_nr < uiNumDevices ) {\n        cdDevice = oclGetDev(cxGPUContext, device_nr);\n\t  } else {\n\t\tshrLog(\"Invalid Device %d Requested.\\n\", device_nr);\n\t\tshrExitEX(argc, (const char **)argv, EXIT_FAILURE);\n\t  }\n    } \n    else \n    {\n      cdDevice = oclGetMaxFlopsDev(cxGPUContext);\n    }\n    oclPrintDevInfo(LOGBOTH, cdDevice);\n\n    // create a command-queue\n    cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevice, 0, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Program Setup\n    size_t program_length;\n    cPathAndName = shrFindFilePath(\"oclSimpleTexture3D_kernel.cl\", argv[0]);\n    oclCheckErrorEX(cPathAndName != NULL, shrTRUE, pCleanup);\n    cSourceCL = oclLoadProgSource(cPathAndName, \"\", &program_length);\n    oclCheckErrorEX(cSourceCL != NULL, shrTRUE, pCleanup);\n\n    // create the program\n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1,\n\t\t\t\t\t  (const char **) &cSourceCL , &program_length, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    \n    // build the program\n    ciErrNum = clBuildProgram(cpProgram, 0, NULL, \"-cl-fast-relaxed-math\", NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        // write out standard error, Build Log and PTX, then cleanup and exit\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclSimpleTexture3D.ptx\");\n        Cleanup(EXIT_FAILURE); \n    }\n\n    // create the kernel\n    ckKernel = clCreateKernel(cpProgram, \"render\", &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Load the data\n    loadVolumeData(argv[0]);\n\n    // Create buffers and textures, \n    // and then start main GLUT rendering loop for processing and rendering, \n\t// or otherwise run No-GL Q/A test sequence\n    if (!bQATest)\n    {\n        // OpenGL buffers\n        initGLBuffers();\n\n        // init timer 1 for fps measurement \n        shrDeltaT(1);    \n\n        // start rendering mainloop\n        glutMainLoop();\n    } \n    else \n    {\n\t    TestNoGL();\n    }\n    \n    Cleanup(EXIT_SUCCESS);\n}\n\nvoid InitGL(int* argc, char **argv )\n{\n    // init GLUT \n    glutInit(argc, (char**)argv);\n    glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE);\n    glutInitWindowPosition (glutGet(GLUT_SCREEN_WIDTH)/2 - width/2, \n                            glutGet(GLUT_SCREEN_HEIGHT)/2 - height/2);\n    glutInitWindowSize(width, height);\n    iGLUTWindowHandle = glutCreateWindow(\"OpenCL 3D texture\");\n#if !(defined (__APPLE__) || defined(MACOSX))\n    glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_GLUTMAINLOOP_RETURNS);\n#endif\n\n    // register GLUT callback functions\n    glutDisplayFunc(DisplayGL);\n    glutKeyboardFunc(KeyboardGL);\n    glutReshapeFunc(Reshape);\n    glutTimerFunc(REFRESH_DELAY, timerEvent, 0);\n    glutIdleFunc(Idle);\n\n    // init GLEW\n    glewInit();\n    GLboolean bGLEW = glewIsSupported(\"GL_VERSION_2_0 GL_ARB_pixel_buffer_object\"); \n    shrCheckErrorEX(bGLEW, shrTRUE, pCleanup);\n}\n\nvoid render()\n{\n    ciErrNum = CL_SUCCESS;\n\n    // Transfer ownership of buffer from GL to CL\n#ifdef GL_INTEROP\n    // Acquire PBO for OpenCL writing\n    ciErrNum |= clEnqueueAcquireGLObjects(cqCommandQueue, 1, &pbo_cl, 0,0,0);\n#endif    \n\n    // set kernel argumanets \n    ciErrNum |= clSetKernelArg(ckKernel, 5, sizeof(float), &w);\n\n    // execute OpenCL kernel, writing results to PBO\n    ciErrNum |= clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 2, NULL, globalWorkSize, localWorkSize, 0, 0, 0);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n#ifdef GL_INTEROP\n    // Transfer ownership of buffer back from CL to GL    \n    ciErrNum |= clEnqueueReleaseGLObjects(cqCommandQueue, 1, &pbo_cl, 0, 0, 0);\n#else\n\n    // Explicit Copy \n    // map the PBO to copy data from the CL buffer via host\n    glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);    \n\n    // map the buffer object into client's memory\n    GLubyte* ptr = (GLubyte*)glMapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB,\n                                        GL_WRITE_ONLY_ARB);\n    ciErrNum |= clEnqueueReadBuffer(cqCommandQueue, pbo_cl, CL_TRUE, 0, sizeof(unsigned int) * height * width, ptr, 0, NULL, NULL);        \n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    glUnmapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB); \n#endif\n}\n\nvoid DisplayGL()\n{\n    // start timer 0 if it's update time\n    double dProcessingTime = 0.0;\n    if (iFrameCount >= iFrameTrigger)\n    {\n        shrDeltaT(0); \n    }\n\n    // run OpenCL kernel \n    render();\n\n    // get processing time from timer 0, if it's update time\n    if (iFrameCount >= iFrameTrigger)\n    {\n        dProcessingTime = shrDeltaT(0); \n    }\n\n    // display results\n    glClear(GL_COLOR_BUFFER_BIT);\n    glDisable(GL_DEPTH_TEST);\n    glRasterPos2i(0, 0);\n    glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glDrawPixels(width, height, GL_RGBA, GL_UNSIGNED_BYTE, 0);\n    glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n    // flip backbuffer to screen\n    glutSwapBuffers();\n    glutReportErrors();\n\n    // Increment the frame counter, and do fps and Q/A stuff if it's time\n    if (iFrameCount++ > iFrameTrigger) \n    {\n        // set GLUT Window Title\n        char cTitle[256];\n        iFramesPerSec = (int)((double)iFrameCount/shrDeltaT(1));\n#ifdef GPU_PROFILING\n        #ifdef _WIN32\n            sprintf_s(cTitle, 256, \"%s | %i fps | Proc. t = %.4f s\", sSDKsample, iFramesPerSec, dProcessingTime);\n        #else \n            sprintf(cTitle, \"%s | %i fps | Proc. t = %.4f s\", sSDKsample, iFramesPerSec, dProcessingTime);\n        #endif\n#else \n        #ifdef _WIN32\n            sprintf_s(cTitle, 256, \"%s\", sSDKsample);\n        #else \n            sprintf(cTitle, \"%s\", sSDKsample);\n        #endif\n#endif\n       glutSetWindowTitle(cTitle); \n\n        // Log fps and processing info to console and file \n       shrLog(\" %s\\n\", cTitle);  \n       \n        // Cleanup and leave if --noprompt mode and counter is up\n        iTestSets--;\n        if (bNoPrompt && (!iTestSets)) \n        {\n            Cleanup(EXIT_SUCCESS);\n        }\n\n        // reset the frame counter and adjust trigger\n        iFrameCount = 0; \n        iFrameTrigger = (iFramesPerSec > 1) ? iFramesPerSec * 2 : 1;\n    }\n}\n\nvoid Idle()\n{\n    if (animate) {\n        w += 0.01f;\n\t\tif( w > 1.0f )\n\t\t\tw = 0.0f;\n    }\n}\n\nvoid Reshape(int x, int y)\n{\n    glViewport(0, 0, x, y);\n\n    glMatrixMode(GL_MODELVIEW);\n    glLoadIdentity();\n\n    glMatrixMode(GL_PROJECTION);\n    glLoadIdentity();\n    glOrtho(0.0, 1.0, 0.0, 1.0, 0.0, 1.0); \n}\n\nvoid timerEvent(int value)\n{\n    glutPostRedisplay();\n\tglutTimerFunc(REFRESH_DELAY, timerEvent,0);\n}\n\nvoid KeyboardGL(unsigned char key, int /*x*/, int /*y*/)\n{\n    switch(key) {\n        case '=':\n        case '+':\n            w += 0.01f;\n            break;\n        case '-':\n        case '_':\n            w -= 0.01f;\n            break;\n        case 'F':\n        case 'f':\n            linearFiltering = !linearFiltering;\n            ciErrNum = clSetKernelArg(ckKernel, 1, sizeof(cl_sampler), linearFiltering ? &volumeSamplerLinear : &volumeSamplerNearest);\n            shrLog(\"\\nLinear Filtering Toggled %s...\\n\", linearFiltering ? \"ON\" : \"OFF\");\n            oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n            break;\n        case ' ':\n            animate = !animate;\n            break;\n        case '\\033': // escape quits\n        case '\\015':// Enter quits    \n        case 'Q':    // Q quits\n        case 'q':    // q (or escape) quits\n            // Cleanup up and quit\n            bNoPrompt = shrTRUE;\n            Cleanup(EXIT_SUCCESS);\n            break;\n    }\n}\n\nvoid initGLBuffers()\n{\n    // create pixel buffer object\n    glGenBuffersARB(1, &pbo);\n    glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glBufferDataARB(GL_PIXEL_UNPACK_BUFFER_ARB, width*height*sizeof(GLubyte)*4, 0, GL_STREAM_DRAW_ARB);\n    glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n#ifdef GL_INTEROP\n    // create OpenCL buffer from GL PBO\n    pbo_cl = clCreateFromGLBuffer(cxGPUContext,CL_MEM_WRITE_ONLY, pbo, &ciErrNum);\n#else            \n    pbo_cl = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY,  width*height*sizeof(GLubyte)*4, NULL, &ciErrNum);\n#endif\n\n    ciErrNum |= clSetKernelArg(ckKernel, 2, sizeof(cl_mem), (void *) &pbo_cl);\n    ciErrNum |= clSetKernelArg(ckKernel, 3, sizeof(unsigned int), &width);\n    ciErrNum |= clSetKernelArg(ckKernel, 4, sizeof(unsigned int), &height);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n}\n\ncl_mem initTexture3D(uchar *h_volume, const size_t volumeSize[3])\n{\n    cl_int ciErrNum;\n\n    // create 3D array and copy data to device\n\tcl_image_format volume_format;\n    volume_format.image_channel_order = CL_RGBA;\n    volume_format.image_channel_data_type = CL_UNORM_INT8;\n    uchar* h_tempVolume =(uchar*)malloc(volumeSize[0] * volumeSize[1] * volumeSize[2] * 4);\n    for(unsigned int i = 0; i<(volumeSize[0] * volumeSize[1] * volumeSize[2]); i++)\n    {\n        h_tempVolume[4 * i] = h_volume[i];\n    }\n    cl_mem d_volume = clCreateImage3D(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, &volume_format, \n                                        volumeSize[0], volumeSize[1], volumeSize[2],\n                                        (volumeSize[0] * 4), (volumeSize[0] * volumeSize[1] * 4),\n                                        h_tempVolume, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    free (h_tempVolume);\n    return d_volume;\n}\n\nvoid loadVolumeData(const char *exec_path)\n{\n    // load volume data\n    if(cPathAndName)free(cPathAndName);\n    cPathAndName = shrFindFilePath(volumeFilename, exec_path);\n    oclCheckErrorEX(cPathAndName != NULL, shrTRUE, pCleanup);\n    size_t size = volumeSize[0]*volumeSize[1]*volumeSize[2];\n    uchar* h_volume = shrLoadRawFile(cPathAndName, size);\n    oclCheckErrorEX(h_volume != NULL, true, pCleanup);\n    shrLog(\" Raw file data loaded...\\n\\n\");\n\n    // setup 3D image\n    d_volume = initTexture3D(h_volume, volumeSize);\n    ciErrNum = clSetKernelArg(ckKernel, 0, sizeof(cl_mem), &d_volume);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Create samplers for linear and nearest interpolation\n    volumeSamplerLinear = clCreateSampler(cxGPUContext, true, CL_ADDRESS_REPEAT, CL_FILTER_LINEAR, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    volumeSamplerNearest = clCreateSampler(cxGPUContext, true, CL_ADDRESS_REPEAT, CL_FILTER_NEAREST, &ciErrNum);\n    ciErrNum |= clSetKernelArg(ckKernel, 1, sizeof(cl_sampler), &volumeSamplerLinear);        \n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    free(h_volume);\n}\n\nvoid TestNoGL()\n{\n    // execute OpenCL kernel without GL interaction\n\n    pbo_cl = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, width * height * sizeof(GLubyte) * 4, NULL, &ciErrNum);\n    ciErrNum |= clSetKernelArg(ckKernel, 2, sizeof(cl_mem), (void *)&pbo_cl);\n    ciErrNum |= clSetKernelArg(ckKernel, 3, sizeof(unsigned int), &width);\n    ciErrNum |= clSetKernelArg(ckKernel, 4, sizeof(unsigned int), &height);   \n    ciErrNum |= clSetKernelArg(ckKernel, 5, sizeof(float), &w);\n\n    // warm up\n    int iCycles = 20;\n    for (int i = 0; i < iCycles; i++)\n    {\n        ciErrNum |= clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 2, NULL, globalWorkSize, localWorkSize, 0,0,0 );\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\t\n    }\n    clFinish(cqCommandQueue);\n    \n\t// Start timer 0 and process n loops on the GPU \n\tshrDeltaT(0); \n    for (int i = 0; i < iCycles; i++)\n    {\n        ciErrNum |= clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 2, NULL, globalWorkSize, localWorkSize, 0,0,0 );\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\t\n    }\n    clFinish(cqCommandQueue);\n    \n    // Get elapsed time and throughput, then log to sample and master logs\n    double dAvgTime = shrDeltaT(0)/(double)iCycles;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclSimpleTexture3D, Throughput = %.4f, Time = %.5f, Size = %u, NumDevsUsed = %u, Workgroup = %u\\n\", \n           (1.0e-6 * width * height)/dAvgTime, dAvgTime, (width * height), 1, (localWorkSize[0] * localWorkSize[1])); \n\n    // Cleanup and exit\n    Cleanup(EXIT_SUCCESS);\n}\n\nvoid Cleanup(int iExitCode)\n{\n    // Cleanup allocated objects\n    shrLog( \"\\nStarting Cleanup...\\n\\n\");\n    if(cPathAndName)free(cPathAndName);\n    if(cSourceCL)free(cSourceCL);\n\tif(ckKernel)clReleaseKernel(ckKernel); \n    if(cpProgram)clReleaseProgram(cpProgram);\n    if(cqCommandQueue)clReleaseCommandQueue(cqCommandQueue);\n    if(cxGPUContext)clReleaseContext(cxGPUContext);\n    if(volumeSamplerLinear)clReleaseSampler(volumeSamplerLinear);\n    if(volumeSamplerNearest)clReleaseSampler(volumeSamplerNearest);\n    if(pbo_cl)clReleaseMemObject(pbo_cl);\n    if(!bQATest)glDeleteBuffersARB(1, &pbo);\n    shrQAFinish2(bQATest, *pArgc, (const char **)pArgv, (iExitCode == 0) ? QA_PASSED : QA_FAILED); \n\n    // finalize logs and leave\n    if (bQATest || bNoPrompt)\n    {\n        shrLogEx(LOGBOTH | CLOSELOG, 0, \"%s Exiting...\\n\", cExecutableName);\n    }\n    else \n    {\n        shrLogEx(LOGBOTH | CLOSELOG, 0, \"%s Exiting...\\nPress <Enter> to Quit\\n\", cExecutableName);\n        #ifdef WIN32\n            getchar();\n        #endif\n    }\n    exit(iExitCode);\n}\n", "oclSimpleTexture3D_kernel.cl": "__kernel void render(__read_only image3d_t volume, sampler_t volumeSampler,  __global uint *d_output, uint imageW, uint imageH, float w)\n{\n\tuint x = get_global_id(0);\n    uint y = get_global_id(1);\n\n    // compute normalized texture coordinates\n    float u = x / (float) imageW;\n    float v = y / (float) imageH;\n\n    // read from 3D texture\n    float4 voxel = read_imagef(volume, volumeSampler, (float4)(u,v,w,1.0f));\n\n    if ((x < imageW) && (y < imageH)) {\n        // write output color\n        uint i = (y * imageW) + x;\n        d_output[i] = voxel.x*255;\n    }\n}\n"}, "code_dirs": {"oclSimpleTexture3D.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclSimpleTexture3D", "oclSimpleTexture3D_kernel.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclSimpleTexture3D"}}
{"kernel_name": "sortingNetworks_bitonic", "parallel_api": "cuda", "code": {"bitonicSort.cu": "#include <assert.h>\n#include <cooperative_groups.h>\n\nnamespace cg = cooperative_groups;\n#include <helper_cuda.h>\n\n#include \"sortingNetworks_common.cuh\"\n#include \"sortingNetworks_common.h\"\n\n__global__ void\nbitonicSortShared(uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey, uint *d_SrcVal, uint arrayLength, uint dir)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ uint s_key[SHARED_SIZE_LIMIT];\n    __shared__ uint s_val[SHARED_SIZE_LIMIT];\n\n    d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    s_key[threadIdx.x + 0]                       = d_SrcKey[0];\n    s_val[threadIdx.x + 0]                       = d_SrcVal[0];\n    s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] = d_SrcKey[(SHARED_SIZE_LIMIT / 2)];\n    s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] = d_SrcVal[(SHARED_SIZE_LIMIT / 2)];\n\n    for (uint size = 2; size < arrayLength; size <<= 1) {\n        uint ddd = dir ^ ((threadIdx.x & (size / 2)) != 0);\n\n        for (uint stride = size / 2; stride > 0; stride >>= 1) {\n            cg::sync(cta);\n            uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));\n            Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride], s_val[pos + stride], ddd);\n        }\n    }\n\n    {\n        for (uint stride = arrayLength / 2; stride > 0; stride >>= 1) {\n            cg::sync(cta);\n            uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));\n            Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride], s_val[pos + stride], dir);\n        }\n    }\n\n    cg::sync(cta);\n    d_DstKey[0]                       = s_key[threadIdx.x + 0];\n    d_DstVal[0]                       = s_val[threadIdx.x + 0];\n    d_DstKey[(SHARED_SIZE_LIMIT / 2)] = s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];\n    d_DstVal[(SHARED_SIZE_LIMIT / 2)] = s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];\n}\n\n__global__ void bitonicSortShared1(uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey, uint *d_SrcVal)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ uint s_key[SHARED_SIZE_LIMIT];\n    __shared__ uint s_val[SHARED_SIZE_LIMIT];\n\n    d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    s_key[threadIdx.x + 0]                       = d_SrcKey[0];\n    s_val[threadIdx.x + 0]                       = d_SrcVal[0];\n    s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] = d_SrcKey[(SHARED_SIZE_LIMIT / 2)];\n    s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] = d_SrcVal[(SHARED_SIZE_LIMIT / 2)];\n\n    for (uint size = 2; size < SHARED_SIZE_LIMIT; size <<= 1) {\n        uint ddd = (threadIdx.x & (size / 2)) != 0;\n\n        for (uint stride = size / 2; stride > 0; stride >>= 1) {\n            cg::sync(cta);\n            uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));\n            Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride], s_val[pos + stride], ddd);\n        }\n    }\n\n    uint ddd = blockIdx.x & 1;\n    {\n        for (uint stride = SHARED_SIZE_LIMIT / 2; stride > 0; stride >>= 1) {\n            cg::sync(cta);\n            uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));\n            Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride], s_val[pos + stride], ddd);\n        }\n    }\n\n    cg::sync(cta);\n    d_DstKey[0]                       = s_key[threadIdx.x + 0];\n    d_DstVal[0]                       = s_val[threadIdx.x + 0];\n    d_DstKey[(SHARED_SIZE_LIMIT / 2)] = s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];\n    d_DstVal[(SHARED_SIZE_LIMIT / 2)] = s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];\n}\n\n__global__ void bitonicMergeGlobal(uint *d_DstKey,\n                                   uint *d_DstVal,\n                                   uint *d_SrcKey,\n                                   uint *d_SrcVal,\n                                   uint  arrayLength,\n                                   uint  size,\n                                   uint  stride,\n                                   uint  dir)\n{\n    uint global_comparatorI = blockIdx.x * blockDim.x + threadIdx.x;\n    uint comparatorI        = global_comparatorI & (arrayLength / 2 - 1);\n\n    uint ddd = dir ^ ((comparatorI & (size / 2)) != 0);\n    uint pos = 2 * global_comparatorI - (global_comparatorI & (stride - 1));\n\n    uint keyA = d_SrcKey[pos + 0];\n    uint valA = d_SrcVal[pos + 0];\n    uint keyB = d_SrcKey[pos + stride];\n    uint valB = d_SrcVal[pos + stride];\n\n    Comparator(keyA, valA, keyB, valB, ddd);\n\n    d_DstKey[pos + 0]      = keyA;\n    d_DstVal[pos + 0]      = valA;\n    d_DstKey[pos + stride] = keyB;\n    d_DstVal[pos + stride] = valB;\n}\n\n__global__ void bitonicMergeShared(uint *d_DstKey,\n                                   uint *d_DstVal,\n                                   uint *d_SrcKey,\n                                   uint *d_SrcVal,\n                                   uint  arrayLength,\n                                   uint  size,\n                                   uint  dir)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ uint s_key[SHARED_SIZE_LIMIT];\n    __shared__ uint s_val[SHARED_SIZE_LIMIT];\n\n    d_SrcKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    d_SrcVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    d_DstKey += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    d_DstVal += blockIdx.x * SHARED_SIZE_LIMIT + threadIdx.x;\n    s_key[threadIdx.x + 0]                       = d_SrcKey[0];\n    s_val[threadIdx.x + 0]                       = d_SrcVal[0];\n    s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] = d_SrcKey[(SHARED_SIZE_LIMIT / 2)];\n    s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)] = d_SrcVal[(SHARED_SIZE_LIMIT / 2)];\n\n    uint comparatorI = UMAD(blockIdx.x, blockDim.x, threadIdx.x) & ((arrayLength / 2) - 1);\n    uint ddd         = dir ^ ((comparatorI & (size / 2)) != 0);\n\n    for (uint stride = SHARED_SIZE_LIMIT / 2; stride > 0; stride >>= 1) {\n        cg::sync(cta);\n        uint pos = 2 * threadIdx.x - (threadIdx.x & (stride - 1));\n        Comparator(s_key[pos + 0], s_val[pos + 0], s_key[pos + stride], s_val[pos + stride], ddd);\n    }\n\n    cg::sync(cta);\n    d_DstKey[0]                       = s_key[threadIdx.x + 0];\n    d_DstVal[0]                       = s_val[threadIdx.x + 0];\n    d_DstKey[(SHARED_SIZE_LIMIT / 2)] = s_key[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];\n    d_DstVal[(SHARED_SIZE_LIMIT / 2)] = s_val[threadIdx.x + (SHARED_SIZE_LIMIT / 2)];\n}\n\nextern \"C\" uint factorRadix2(uint *log2L, uint L)\n{\n    if (!L) {\n        *log2L = 0;\n        return 0;\n    }\n    else {\n        for (*log2L = 0; (L & 1) == 0; L >>= 1, *log2L++)\n            ;\n\n        return L;\n    }\n}\n\nextern \"C\" uint\nbitonicSort(uint *d_DstKey, uint *d_DstVal, uint *d_SrcKey, uint *d_SrcVal, uint batchSize, uint arrayLength, uint dir)\n{\n    if (arrayLength < 2)\n        return 0;\n\n    uint log2L;\n    uint factorizationRemainder = factorRadix2(&log2L, arrayLength);\n    assert(factorizationRemainder == 1);\n\n    dir = (dir != 0);\n\n    uint blockCount  = batchSize * arrayLength / SHARED_SIZE_LIMIT;\n    uint threadCount = SHARED_SIZE_LIMIT / 2;\n\n    if (arrayLength <= SHARED_SIZE_LIMIT) {\n        assert((batchSize * arrayLength) % SHARED_SIZE_LIMIT == 0);\n        bitonicSortShared<<<blockCount, threadCount>>>(d_DstKey, d_DstVal, d_SrcKey, d_SrcVal, arrayLength, dir);\n    }\n    else {\n        bitonicSortShared1<<<blockCount, threadCount>>>(d_DstKey, d_DstVal, d_SrcKey, d_SrcVal);\n\n        for (uint size = 2 * SHARED_SIZE_LIMIT; size <= arrayLength; size <<= 1)\n            for (unsigned stride = size / 2; stride > 0; stride >>= 1)\n                if (stride >= SHARED_SIZE_LIMIT) {\n                    bitonicMergeGlobal<<<(batchSize * arrayLength) / 512, 256>>>(\n                        d_DstKey, d_DstVal, d_DstKey, d_DstVal, arrayLength, size, stride, dir);\n                }\n                else {\n                    bitonicMergeShared<<<blockCount, threadCount>>>(\n                        d_DstKey, d_DstVal, d_DstKey, d_DstVal, arrayLength, size, dir);\n                    break;\n                }\n    }\n\n    return threadCount;\n}\n", "main.cpp": "#include <cuda_runtime.h>\n\n#include <helper_cuda.h>\n#include <helper_timer.h>\n\n#include \"sortingNetworks_common.h\"\n\nint main(int argc, char **argv)\n{\n    cudaError_t error;\n    printf(\"%s Starting...\\n\\n\", argv[0]);\n\n    printf(\"Starting up CUDA context...\\n\");\n    int dev = findCudaDevice(argc, (const char **)argv);\n\n    uint               *h_InputKey, *h_InputVal, *h_OutputKeyGPU, *h_OutputValGPU;\n    uint               *d_InputKey, *d_InputVal, *d_OutputKey, *d_OutputVal;\n    StopWatchInterface *hTimer = NULL;\n\n    const uint N             = 1048576;\n    const uint DIR           = 0;\n    const uint numValues     = 65536;\n    const uint numIterations = 1;\n\n    printf(\"Allocating and initializing host arrays...\\n\\n\");\n    sdkCreateTimer(&hTimer);\n    h_InputKey     = (uint *)malloc(N * sizeof(uint));\n    h_InputVal     = (uint *)malloc(N * sizeof(uint));\n    h_OutputKeyGPU = (uint *)malloc(N * sizeof(uint));\n    h_OutputValGPU = (uint *)malloc(N * sizeof(uint));\n    srand(2001);\n\n    for (uint i = 0; i < N; i++) {\n        h_InputKey[i] = rand() % numValues;\n        h_InputVal[i] = i;\n    }\n\n    printf(\"Allocating and initializing CUDA arrays...\\n\\n\");\n    error = cudaMalloc((void **)&d_InputKey, N * sizeof(uint));\n    checkCudaErrors(error);\n    error = cudaMalloc((void **)&d_InputVal, N * sizeof(uint));\n    checkCudaErrors(error);\n    error = cudaMalloc((void **)&d_OutputKey, N * sizeof(uint));\n    checkCudaErrors(error);\n    error = cudaMalloc((void **)&d_OutputVal, N * sizeof(uint));\n    checkCudaErrors(error);\n    error = cudaMemcpy(d_InputKey, h_InputKey, N * sizeof(uint), cudaMemcpyHostToDevice);\n    checkCudaErrors(error);\n    error = cudaMemcpy(d_InputVal, h_InputVal, N * sizeof(uint), cudaMemcpyHostToDevice);\n    checkCudaErrors(error);\n\n    int flag = 1;\n    printf(\"Running GPU bitonic sort (%u identical iterations)...\\n\\n\", numIterations);\n\n    for (uint arrayLength = 64; arrayLength <= N; arrayLength *= 2) {\n        printf(\"Testing array length %u (%u arrays per batch)...\\n\", arrayLength, N / arrayLength);\n        error = cudaDeviceSynchronize();\n        checkCudaErrors(error);\n\n        sdkResetTimer(&hTimer);\n        sdkStartTimer(&hTimer);\n        uint threadCount = 0;\n\n        for (uint i = 0; i < numIterations; i++)\n            threadCount =\n                bitonicSort(d_OutputKey, d_OutputVal, d_InputKey, d_InputVal, N / arrayLength, arrayLength, DIR);\n\n        error = cudaDeviceSynchronize();\n        checkCudaErrors(error);\n\n        sdkStopTimer(&hTimer);\n        printf(\"Average time: %f ms\\n\\n\", sdkGetTimerValue(&hTimer) / numIterations);\n\n        if (arrayLength == N) {\n            double dTimeSecs = 1.0e-3 * sdkGetTimerValue(&hTimer) / numIterations;\n            printf(\"sortingNetworks-bitonic, Throughput = %.4f MElements/s, Time = %.5f \"\n                   \"s, Size = %u elements, NumDevsUsed = %u, Workgroup = %u\\n\",\n                   (1.0e-6 * (double)arrayLength / dTimeSecs),\n                   dTimeSecs,\n                   arrayLength,\n                   1,\n                   threadCount);\n        }\n\n        printf(\"\\nValidating the results...\\n\");\n        printf(\"...reading back GPU results\\n\");\n        error = cudaMemcpy(h_OutputKeyGPU, d_OutputKey, N * sizeof(uint), cudaMemcpyDeviceToHost);\n        checkCudaErrors(error);\n        error = cudaMemcpy(h_OutputValGPU, d_OutputVal, N * sizeof(uint), cudaMemcpyDeviceToHost);\n        checkCudaErrors(error);\n\n        int keysFlag   = validateSortedKeys(h_OutputKeyGPU, h_InputKey, N / arrayLength, arrayLength, numValues, DIR);\n        int valuesFlag = validateValues(h_OutputKeyGPU, h_OutputValGPU, h_InputKey, N / arrayLength, arrayLength);\n        flag           = flag && keysFlag && valuesFlag;\n\n        printf(\"\\n\");\n    }\n\n    printf(\"Shutting down...\\n\");\n    sdkDeleteTimer(&hTimer);\n    cudaFree(d_OutputVal);\n    cudaFree(d_OutputKey);\n    cudaFree(d_InputVal);\n    cudaFree(d_InputKey);\n    free(h_OutputValGPU);\n    free(h_OutputKeyGPU);\n    free(h_InputVal);\n    free(h_InputKey);\n\n    exit(flag ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n"}, "code_dirs": {"bitonicSort.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/sortingNetworks_bitonic", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/sortingNetworks_bitonic"}}
{"kernel_name": "sortingNetworks_bitonic", "parallel_api": "ocl", "code": {"BitonicSort.cl": "inline void ComparatorPrivate(\n    uint *keyA,\n    uint *valA,\n    uint *keyB,\n    uint *valB,\n    uint arrowDir\n){\n    if( (*keyA > *keyB) == arrowDir ){\n        uint t;\n        t = *keyA; *keyA = *keyB; *keyB = t;\n        t = *valA; *valA = *valB; *valB = t;\n    }\n}\n\ninline void ComparatorLocal(\n    __local uint *keyA,\n    __local uint *valA,\n    __local uint *keyB,\n    __local uint *valB,\n    uint arrowDir\n){\n    if( (*keyA > *keyB) == arrowDir ){\n        uint t;\n        t = *keyA; *keyA = *keyB; *keyB = t;\n        t = *valA; *valA = *valB; *valB = t;\n    }\n}\n\n__kernel __attribute__((reqd_work_group_size(LOCAL_SIZE_LIMIT / 2, 1, 1)))\nvoid bitonicSortLocal(\n    __global uint *d_DstKey,\n    __global uint *d_DstVal,\n    __global uint *d_SrcKey,\n    __global uint *d_SrcVal,\n    uint arrayLength,\n    uint sortDir\n){\n    __local  uint l_key[LOCAL_SIZE_LIMIT];\n    __local  uint l_val[LOCAL_SIZE_LIMIT];\n\n    //Offset to the beginning of subbatch and load data\n    d_SrcKey += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    d_SrcVal += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    d_DstKey += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    d_DstVal += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    l_key[get_local_id(0) +                      0] = d_SrcKey[                     0];\n    l_val[get_local_id(0) +                      0] = d_SrcVal[                     0];\n    l_key[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)] = d_SrcKey[(LOCAL_SIZE_LIMIT / 2)];\n    l_val[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)] = d_SrcVal[(LOCAL_SIZE_LIMIT / 2)];\n\n    for(uint size = 2; size < arrayLength; size <<= 1){\n        //Bitonic merge\n        uint dir = ( (get_local_id(0) & (size / 2)) != 0 );\n        for(uint stride = size / 2; stride > 0; stride >>= 1){\n            barrier(CLK_LOCAL_MEM_FENCE);\n            uint pos = 2 * get_local_id(0) - (get_local_id(0) & (stride - 1));\n            ComparatorLocal(\n                &l_key[pos +      0], &l_val[pos +      0],\n                &l_key[pos + stride], &l_val[pos + stride],\n                dir\n            );\n        }\n    }\n\n    //dir == sortDir for the last bitonic merge step\n    {\n        for(uint stride = arrayLength / 2; stride > 0; stride >>= 1){\n            barrier(CLK_LOCAL_MEM_FENCE);\n            uint pos = 2 * get_local_id(0) - (get_local_id(0) & (stride - 1));\n            ComparatorLocal(\n                &l_key[pos +      0], &l_val[pos +      0],\n                &l_key[pos + stride], &l_val[pos + stride],\n                sortDir\n            );\n        }\n    }\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n    d_DstKey[                     0] = l_key[get_local_id(0) +                      0];\n    d_DstVal[                     0] = l_val[get_local_id(0) +                      0];\n    d_DstKey[(LOCAL_SIZE_LIMIT / 2)] = l_key[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)];\n    d_DstVal[(LOCAL_SIZE_LIMIT / 2)] = l_val[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)];\n}\n\n//Bottom-level bitonic sort\n//Almost the same as bitonicSortLocal with the only exception\n//of even / odd subarrays (of LOCAL_SIZE_LIMIT points) being\n//sorted in opposite directions\n__kernel __attribute__((reqd_work_group_size(LOCAL_SIZE_LIMIT / 2, 1, 1)))\nvoid bitonicSortLocal1(\n    __global uint *d_DstKey,\n    __global uint *d_DstVal,\n    __global uint *d_SrcKey,\n    __global uint *d_SrcVal\n){\n    __local uint l_key[LOCAL_SIZE_LIMIT];\n    __local uint l_val[LOCAL_SIZE_LIMIT];\n\n    //Offset to the beginning of subarray and load data\n    d_SrcKey += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    d_SrcVal += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    d_DstKey += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    d_DstVal += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    l_key[get_local_id(0) +                      0] = d_SrcKey[                     0];\n    l_val[get_local_id(0) +                      0] = d_SrcVal[                     0];\n    l_key[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)] = d_SrcKey[(LOCAL_SIZE_LIMIT / 2)];\n    l_val[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)] = d_SrcVal[(LOCAL_SIZE_LIMIT / 2)];\n\n    uint comparatorI = get_global_id(0) & ((LOCAL_SIZE_LIMIT / 2) - 1);\n\n    for(uint size = 2; size < LOCAL_SIZE_LIMIT; size <<= 1){\n        //Bitonic merge\n        uint dir = (comparatorI & (size / 2)) != 0;\n        for(uint stride = size / 2; stride > 0; stride >>= 1){\n            barrier(CLK_LOCAL_MEM_FENCE);\n            uint pos = 2 * get_local_id(0) - (get_local_id(0) & (stride - 1));\n            ComparatorLocal(\n                &l_key[pos +      0], &l_val[pos +      0],\n                &l_key[pos + stride], &l_val[pos + stride],\n                dir\n            );\n        }\n    }\n\n    //Odd / even arrays of LOCAL_SIZE_LIMIT elements\n    //sorted in opposite directions\n    {\n        uint dir = (get_group_id(0) & 1);\n        for(uint stride = LOCAL_SIZE_LIMIT / 2; stride > 0; stride >>= 1){\n            barrier(CLK_LOCAL_MEM_FENCE);\n            uint pos = 2 * get_local_id(0) - (get_local_id(0) & (stride - 1));\n            ComparatorLocal(\n                &l_key[pos +      0], &l_val[pos +      0],\n                &l_key[pos + stride], &l_val[pos + stride],\n               dir\n            );\n        }\n    }\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n    d_DstKey[                     0] = l_key[get_local_id(0) +                      0];\n    d_DstVal[                     0] = l_val[get_local_id(0) +                      0];\n    d_DstKey[(LOCAL_SIZE_LIMIT / 2)] = l_key[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)];\n    d_DstVal[(LOCAL_SIZE_LIMIT / 2)] = l_val[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)];\n}\n\n//Bitonic merge iteration for 'stride' >= LOCAL_SIZE_LIMIT\n__kernel void bitonicMergeGlobal(\n    __global uint *d_DstKey,\n    __global uint *d_DstVal,\n    __global uint *d_SrcKey,\n    __global uint *d_SrcVal,\n    uint arrayLength,\n    uint size,\n    uint stride,\n    uint sortDir\n){\n    uint global_comparatorI = get_global_id(0);\n    uint        comparatorI = global_comparatorI & (arrayLength / 2 - 1);\n\n    //Bitonic merge\n    uint dir = sortDir ^ ( (comparatorI & (size / 2)) != 0 );\n    uint pos = 2 * global_comparatorI - (global_comparatorI & (stride - 1));\n\n    uint keyA = d_SrcKey[pos +      0];\n    uint valA = d_SrcVal[pos +      0];\n    uint keyB = d_SrcKey[pos + stride];\n    uint valB = d_SrcVal[pos + stride];\n\n    ComparatorPrivate(\n        &keyA, &valA,\n        &keyB, &valB,\n        dir\n    );\n\n    d_DstKey[pos +      0] = keyA;\n    d_DstVal[pos +      0] = valA;\n    d_DstKey[pos + stride] = keyB;\n    d_DstVal[pos + stride] = valB;\n}\n\n//Combined bitonic merge steps for\n//'size' > LOCAL_SIZE_LIMIT and 'stride' = [1 .. LOCAL_SIZE_LIMIT / 2]\n__kernel __attribute__((reqd_work_group_size(LOCAL_SIZE_LIMIT / 2, 1, 1)))\nvoid bitonicMergeLocal(\n    __global uint *d_DstKey,\n    __global uint *d_DstVal,\n    __global uint *d_SrcKey,\n    __global uint *d_SrcVal,\n    uint arrayLength,\n    uint stride,\n    uint size,\n    uint sortDir\n){\n    __local uint l_key[LOCAL_SIZE_LIMIT];\n    __local uint l_val[LOCAL_SIZE_LIMIT];\n\n    d_SrcKey += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    d_SrcVal += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    d_DstKey += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    d_DstVal += get_group_id(0) * LOCAL_SIZE_LIMIT + get_local_id(0);\n    l_key[get_local_id(0) +                      0] = d_SrcKey[                     0];\n    l_val[get_local_id(0) +                      0] = d_SrcVal[                     0];\n    l_key[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)] = d_SrcKey[(LOCAL_SIZE_LIMIT / 2)];\n    l_val[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)] = d_SrcVal[(LOCAL_SIZE_LIMIT / 2)];\n\n    //Bitonic merge\n    uint comparatorI = get_global_id(0) & ((arrayLength / 2) - 1);\n    uint         dir = sortDir ^ ( (comparatorI & (size / 2)) != 0 );\n    for(; stride > 0; stride >>= 1){\n        barrier(CLK_LOCAL_MEM_FENCE);\n        uint pos = 2 * get_local_id(0) - (get_local_id(0) & (stride - 1));\n        ComparatorLocal(\n            &l_key[pos +      0], &l_val[pos +      0],\n            &l_key[pos + stride], &l_val[pos + stride],\n            dir\n        );\n    }\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n    d_DstKey[                     0] = l_key[get_local_id(0) +                      0];\n    d_DstVal[                     0] = l_val[get_local_id(0) +                      0];\n    d_DstKey[(LOCAL_SIZE_LIMIT / 2)] = l_key[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)];\n    d_DstVal[(LOCAL_SIZE_LIMIT / 2)] = l_val[get_local_id(0) + (LOCAL_SIZE_LIMIT / 2)];\n}\n", "oclBitonicSort_launcher.cpp": "#include <oclUtils.h>\n#include \"oclSortingNetworks_common.h\"\n\nstatic cl_program cpBitonicSort;\n\nstatic cl_kernel\n    ckBitonicSortLocal,\n    ckBitonicSortLocal1,\n    ckBitonicMergeGlobal,\n    ckBitonicMergeLocal;\n\nstatic cl_command_queue cqDefaultCommandQue;\n\nstatic const uint LOCAL_SIZE_LIMIT = 512U;\nstatic const char  *compileOptions = \"-D LOCAL_SIZE_LIMIT=512\";\n\nextern \"C\" void initBitonicSort(cl_context cxGPUContext, cl_command_queue cqParamCommandQue, const char **argv){\n    cl_int ciErrNum;\n    size_t kernelLength;\n\n    shrLog(\"...loading BitonicSort.cl\\n\");\n        char *cBitonicSort = oclLoadProgSource(shrFindFilePath(\"BitonicSort.cl\", argv[0]), \"// My comment\\n\", &kernelLength);\n        oclCheckError(cBitonicSort != NULL, shrTRUE);\n\n    shrLog(\"...creating bitonic sort program\\n\");\n        cpBitonicSort = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&cBitonicSort, &kernelLength, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"...building bitonic sort program\\n\");\n        ciErrNum = clBuildProgram(cpBitonicSort, 0, NULL, compileOptions, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog( \"...creating bitonic sort kernels\\n\");\n        ckBitonicSortLocal = clCreateKernel(cpBitonicSort, \"bitonicSortLocal\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ckBitonicSortLocal1 = clCreateKernel(cpBitonicSort, \"bitonicSortLocal1\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ckBitonicMergeGlobal = clCreateKernel(cpBitonicSort, \"bitonicMergeGlobal\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ckBitonicMergeLocal = clCreateKernel(cpBitonicSort, \"bitonicMergeLocal\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog( \"...checking minimum supported workgroup size\\n\");\n        //Check for work group size\n        cl_device_id device;\n        size_t szBitonicSortLocal, szBitonicSortLocal1, szBitonicMergeLocal;\n\n        ciErrNum  = clGetCommandQueueInfo(cqParamCommandQue, CL_QUEUE_DEVICE, sizeof(cl_device_id), &device, NULL);\n        ciErrNum |= clGetKernelWorkGroupInfo(ckBitonicSortLocal,  device, CL_KERNEL_WORK_GROUP_SIZE, sizeof(size_t), &szBitonicSortLocal, NULL);\n        ciErrNum |= clGetKernelWorkGroupInfo(ckBitonicSortLocal1, device, CL_KERNEL_WORK_GROUP_SIZE, sizeof(size_t), &szBitonicSortLocal1, NULL);\n        ciErrNum |= clGetKernelWorkGroupInfo(ckBitonicMergeLocal, device, CL_KERNEL_WORK_GROUP_SIZE, sizeof(size_t), &szBitonicMergeLocal, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        if( (szBitonicSortLocal < (LOCAL_SIZE_LIMIT / 2)) || (szBitonicSortLocal1 < (LOCAL_SIZE_LIMIT / 2)) || (szBitonicMergeLocal < (LOCAL_SIZE_LIMIT / 2)) ){\n            shrLog(\"\\nERROR !!! Minimum work-group size %u required by this application is not supported on this device.\\n\\n\", LOCAL_SIZE_LIMIT / 2);\n            closeBitonicSort();\n            free(cBitonicSort);\n            shrLogEx(LOGBOTH | CLOSELOG, 0, \"Exiting...\\n\");\n            exit(EXIT_FAILURE);\n        }\n\n    //Save default command queue\n    cqDefaultCommandQue = cqParamCommandQue;\n\n    //Discard temp storage\n    free(cBitonicSort);\n}\n\nextern \"C\" void closeBitonicSort(void)\n{\n    cl_int ciErrNum;\n    ciErrNum  = clReleaseKernel(ckBitonicMergeLocal);\n    ciErrNum |= clReleaseKernel(ckBitonicMergeGlobal);\n    ciErrNum |= clReleaseKernel(ckBitonicSortLocal1);\n    ciErrNum |= clReleaseKernel(ckBitonicSortLocal);\n    ciErrNum |= clReleaseProgram(cpBitonicSort);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n}\n\nstatic cl_uint factorRadix2(cl_uint& log2L, cl_uint L){\n    if(!L){\n        log2L = 0;\n        return 0;\n    }else{\n        for(log2L = 0; (L & 1) == 0; L >>= 1, log2L++);\n        return L;\n    }\n}\n\nextern \"C\" size_t bitonicSort(\n    cl_command_queue cqCommandQueue,\n    cl_mem d_DstKey,\n    cl_mem d_DstVal,\n    cl_mem d_SrcKey,\n    cl_mem d_SrcVal,\n    uint batch,\n    uint arrayLength,\n    uint dir\n){\n    if(arrayLength < 2)\n        return 0;\n\n    //Only power-of-two array lengths are supported so far\n    cl_uint log2L;\n    cl_uint factorizationRemainder = factorRadix2(log2L, arrayLength);\n    oclCheckError( factorizationRemainder == 1, shrTRUE );\n\n    if(!cqCommandQueue)\n        cqCommandQueue = cqDefaultCommandQue;\n\n    dir = (dir != 0);\n\n    cl_int ciErrNum;\n    size_t localWorkSize; \n    size_t globalWorkSize;\n\n    if(arrayLength <= LOCAL_SIZE_LIMIT)\n    {\n        oclCheckError( (batch * arrayLength) % LOCAL_SIZE_LIMIT == 0, shrTRUE );\n        //Launch bitonicSortLocal\n        ciErrNum  = clSetKernelArg(ckBitonicSortLocal, 0,   sizeof(cl_mem), (void *)&d_DstKey);\n        ciErrNum |= clSetKernelArg(ckBitonicSortLocal, 1,   sizeof(cl_mem), (void *)&d_DstVal);\n        ciErrNum |= clSetKernelArg(ckBitonicSortLocal, 2,   sizeof(cl_mem), (void *)&d_SrcKey);\n        ciErrNum |= clSetKernelArg(ckBitonicSortLocal, 3,   sizeof(cl_mem), (void *)&d_SrcVal);\n        ciErrNum |= clSetKernelArg(ckBitonicSortLocal, 4,  sizeof(cl_uint), (void *)&arrayLength);\n        ciErrNum |= clSetKernelArg(ckBitonicSortLocal, 5,  sizeof(cl_uint), (void *)&dir);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        localWorkSize  = LOCAL_SIZE_LIMIT / 2;\n        globalWorkSize = batch * arrayLength / 2;\n        ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckBitonicSortLocal, 1, NULL, &globalWorkSize, &localWorkSize, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }\n    else\n    {\n        //Launch bitonicSortLocal1\n        ciErrNum  = clSetKernelArg(ckBitonicSortLocal1, 0,  sizeof(cl_mem), (void *)&d_DstKey);\n        ciErrNum |= clSetKernelArg(ckBitonicSortLocal1, 1,  sizeof(cl_mem), (void *)&d_DstVal);\n        ciErrNum |= clSetKernelArg(ckBitonicSortLocal1, 2,  sizeof(cl_mem), (void *)&d_SrcKey);\n        ciErrNum |= clSetKernelArg(ckBitonicSortLocal1, 3,  sizeof(cl_mem), (void *)&d_SrcVal);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        localWorkSize = LOCAL_SIZE_LIMIT / 2;\n        globalWorkSize = batch * arrayLength / 2;\n        ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckBitonicSortLocal1, 1, NULL, &globalWorkSize, &localWorkSize, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        for(uint size = 2 * LOCAL_SIZE_LIMIT; size <= arrayLength; size <<= 1)\n        {\n            for(unsigned stride = size / 2; stride > 0; stride >>= 1)\n            {\n                if(stride >= LOCAL_SIZE_LIMIT)\n                {\n                    //Launch bitonicMergeGlobal\n                    ciErrNum  = clSetKernelArg(ckBitonicMergeGlobal, 0,  sizeof(cl_mem), (void *)&d_DstKey);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeGlobal, 1,  sizeof(cl_mem), (void *)&d_DstVal);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeGlobal, 2,  sizeof(cl_mem), (void *)&d_DstKey);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeGlobal, 3,  sizeof(cl_mem), (void *)&d_DstVal);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeGlobal, 4, sizeof(cl_uint), (void *)&arrayLength);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeGlobal, 5, sizeof(cl_uint), (void *)&size);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeGlobal, 6, sizeof(cl_uint), (void *)&stride);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeGlobal, 7, sizeof(cl_uint), (void *)&dir);\n                    oclCheckError(ciErrNum, CL_SUCCESS);\n\n                    globalWorkSize = batch * arrayLength / 2;\n                    ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckBitonicMergeGlobal, 1, NULL, &globalWorkSize, NULL, 0, NULL, NULL);\n                    oclCheckError(ciErrNum, CL_SUCCESS);\n                }\n                else\n                {\n                    //Launch bitonicMergeLocal\n                    ciErrNum  = clSetKernelArg(ckBitonicMergeLocal, 0,  sizeof(cl_mem), (void *)&d_DstKey);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeLocal, 1,  sizeof(cl_mem), (void *)&d_DstVal);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeLocal, 2,  sizeof(cl_mem), (void *)&d_DstKey);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeLocal, 3,  sizeof(cl_mem), (void *)&d_DstVal);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeLocal, 4, sizeof(cl_uint), (void *)&arrayLength);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeLocal, 5, sizeof(cl_uint), (void *)&stride);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeLocal, 6, sizeof(cl_uint), (void *)&size);\n                    ciErrNum |= clSetKernelArg(ckBitonicMergeLocal, 7, sizeof(cl_uint), (void *)&dir);\n                    oclCheckError(ciErrNum, CL_SUCCESS);\n\n                    localWorkSize  = LOCAL_SIZE_LIMIT / 2;\n                    globalWorkSize = batch * arrayLength / 2;\n\n                    ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckBitonicMergeLocal, 1, NULL, &globalWorkSize, &localWorkSize, 0, NULL, NULL);\n                    oclCheckError(ciErrNum, CL_SUCCESS);\n                    break;\n                }\n            }\n        }\n    }\n    return localWorkSize;\n}\n", "main.cpp": "//Standard utilities and systems includes\n#include <oclUtils.h>\n#include <shrQATest.h>\n\n#include \"oclSortingNetworks_common.h\"\n\n//Test driver\nint main(int argc, const char **argv){\n    cl_platform_id cpPlatform;\n    cl_device_id cdDevice;\n    cl_context cxGPUContext;\n    cl_command_queue cqCommandQueue;\n    cl_mem d_InputKey, d_InputVal, d_OutputKey, d_OutputVal;\n\n    cl_int ciErrNum;\n    uint *h_InputKey, *h_InputVal, *h_OutputKeyGPU, *h_OutputValGPU;\n\n    const uint dir = 1;\n    const uint N = 1048576;\n    const uint numValues = 65536;\n\n    shrQAStart(argc, (char **)argv);\n\n    // set logfile name and start logs\n    shrSetLogFileName (\"oclSortingNetworks.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    shrLog(\"Initializing data...\\n\");\n        h_InputKey      = (uint *)malloc(N * sizeof(uint));\n        h_InputVal      = (uint *)malloc(N * sizeof(uint));\n        h_OutputKeyGPU  = (uint *)malloc(N * sizeof(uint));\n        h_OutputValGPU  = (uint *)malloc(N * sizeof(uint));\n        srand(2009);\n        for(uint i = 0; i < N; i++)\n            h_InputKey[i] = rand() % numValues;\n        fillValues(h_InputVal, N);\n\n    shrLog(\"Initializing OpenCL...\\n\");\n        //Get the NVIDIA platform\n        ciErrNum = oclGetPlatformID(&cpPlatform);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Get the devices\n        ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 1, &cdDevice, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Create the context\n        cxGPUContext = clCreateContext(0, 1, &cdDevice, NULL, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Create a command-queue\n        cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevice, CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Initializing OpenCL bitonic sorter...\\n\");\n        initBitonicSort(cxGPUContext, cqCommandQueue, argv);\n\n    shrLog(\"Creating OpenCL memory objects...\\n\\n\");\n        d_InputKey = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, N * sizeof(cl_uint), h_InputKey, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_InputVal = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, N * sizeof(cl_uint), h_InputVal, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_OutputKey = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, N * sizeof(cl_uint), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_OutputVal = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, N * sizeof(cl_uint), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    //Temp storage for key array validation routine\n    uint *srcHist = (uint *)malloc(numValues * sizeof(uint));\n    uint *resHist = (uint *)malloc(numValues * sizeof(uint));\n\n#ifdef GPU_PROFILING\n    cl_event startTime, endTime;\n#endif\n\n    int globalFlag = 1;// init pass/fail flag to pass\n    for(uint arrayLength = 64; arrayLength <= N; arrayLength *= 2){\n        shrLog(\"Test array length %u (%u arrays in the batch)...\\n\", arrayLength, N / arrayLength);\n\n#ifdef GPU_PROFILING\n            clFinish(cqCommandQueue);\n            ciErrNum = clEnqueueMarker(cqCommandQueue, &startTime);\n            oclCheckError(ciErrNum, CL_SUCCESS);\n            shrDeltaT(0);\n#endif\n\n            size_t szWorkgroup = bitonicSort(\n                NULL,\n                d_OutputKey,\n                d_OutputVal,\n                d_InputKey,\n                d_InputVal,\n                N / arrayLength,\n                arrayLength,\n                dir\n            );\n            oclCheckError(szWorkgroup > 0, true); \n\n#ifdef GPU_PROFILING\n            if (arrayLength == N)\n            {\n                ciErrNum = clEnqueueMarker(cqCommandQueue, &endTime);\n                oclCheckError(ciErrNum, CL_SUCCESS);\n                clFinish(cqCommandQueue);\n                double timerValue = shrDeltaT(0);\n                shrLogEx(LOGBOTH | MASTER, 0, \"oclSortingNetworks-bitonic, Throughput = %.4f MElements/s, Time = %.5f s, Size = %u elements, NumDevsUsed = %u, Workgroup = %u\\n\", \n                       (1.0e-6 * (double)arrayLength/timerValue), timerValue, arrayLength, 1, szWorkgroup);\n\n                cl_ulong startTimeVal = 0, endTimeVal = 0;\n                ciErrNum = clGetEventProfilingInfo(\n                    startTime, \n                    CL_PROFILING_COMMAND_END, \n                    sizeof(cl_ulong),\n                    &startTimeVal,\n                    NULL\n                );\n\n                ciErrNum = clGetEventProfilingInfo(\n                    endTime, \n                    CL_PROFILING_COMMAND_END, \n                    sizeof(cl_ulong),\n                    &endTimeVal,\n                    NULL\n                );\n\n                shrLog(\"OpenCL time: %.5f s\\n\", 1.0e-9 * (double)(endTimeVal - startTimeVal));\n            }\n#endif\n\n        //Reading back results from device to host\n        ciErrNum = clEnqueueReadBuffer(cqCommandQueue, d_OutputKey, CL_TRUE, 0, N * sizeof(cl_uint), h_OutputKeyGPU, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ciErrNum = clEnqueueReadBuffer(cqCommandQueue, d_OutputVal, CL_TRUE, 0, N * sizeof(cl_uint), h_OutputValGPU, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Check if keys array is not corrupted and properly ordered\n        int keysFlag = validateSortedKeys(h_OutputKeyGPU, h_InputKey, N / arrayLength, arrayLength, numValues, dir, srcHist, resHist);\n\n        //Check if values array is not corrupted\n        int valuesFlag = validateSortedValues(h_OutputKeyGPU, h_OutputValGPU, h_InputKey, N / arrayLength, arrayLength);\n\n        // accumulate any error or failure\n        globalFlag = globalFlag && keysFlag && valuesFlag;\n    }\n\n    // Start Cleanup\n    shrLog(\"Shutting down...\\n\");\n        free(srcHist);\n        free(resHist);\n\n        closeBitonicSort();\n\n        ciErrNum  = clReleaseMemObject(d_OutputVal);\n        ciErrNum |= clReleaseMemObject(d_OutputKey);\n        ciErrNum |= clReleaseMemObject(d_InputVal);\n        ciErrNum |= clReleaseMemObject(d_InputKey);\n        ciErrNum |= clReleaseCommandQueue(cqCommandQueue);\n        ciErrNum |= clReleaseContext(cxGPUContext);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Release host buffers\n        free(h_OutputValGPU);\n        free(h_OutputKeyGPU);\n        free(h_InputVal);\n        free(h_InputKey);\n\n    shrQAFinishExit(argc, (const char **)argv, globalFlag ? QA_PASSED : QA_FAILED);\n    shrEXIT(argc, argv);\n}\n"}, "code_dirs": {"BitonicSort.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclSortingNetworks", "oclBitonicSort_launcher.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclSortingNetworks/src", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclSortingNetworks/src"}}
{"kernel_name": "histogram", "parallel_api": "cuda", "code": {"histogram256.cu": "#include <assert.h>\n#include <cooperative_groups.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\nnamespace cg = cooperative_groups;\n#include <helper_cuda.h>\n\n#include \"histogram_common.h\"\n\n#define TAG_MASK 0xFFFFFFFFU\ninline __device__ void addByte(uint *s_WarpHist, uint data, uint threadTag) { atomicAdd(s_WarpHist + data, 1); }\n\ninline __device__ void addWord(uint *s_WarpHist, uint data, uint tag)\n{\n    addByte(s_WarpHist, (data >> 0) & 0xFFU, tag);\n    addByte(s_WarpHist, (data >> 8) & 0xFFU, tag);\n    addByte(s_WarpHist, (data >> 16) & 0xFFU, tag);\n    addByte(s_WarpHist, (data >> 24) & 0xFFU, tag);\n}\n\n__global__ void histogram256Kernel(uint *d_PartialHistograms, uint *d_Data, uint dataCount)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ uint s_Hist[HISTOGRAM256_THREADBLOCK_MEMORY];\n    uint           *s_WarpHist = s_Hist + (threadIdx.x >> LOG2_WARP_SIZE) * HISTOGRAM256_BIN_COUNT;\n\n#pragma unroll\n\n    for (uint i = 0; i < (HISTOGRAM256_THREADBLOCK_MEMORY / HISTOGRAM256_THREADBLOCK_SIZE); i++) {\n        s_Hist[threadIdx.x + i * HISTOGRAM256_THREADBLOCK_SIZE] = 0;\n    }\n\n    const uint tag = threadIdx.x << (UINT_BITS - LOG2_WARP_SIZE);\n\n    cg::sync(cta);\n\n    for (uint pos = UMAD(blockIdx.x, blockDim.x, threadIdx.x); pos < dataCount; pos += UMUL(blockDim.x, gridDim.x)) {\n        uint data = d_Data[pos];\n        addWord(s_WarpHist, data, tag);\n    }\n\n    cg::sync(cta);\n\n    for (uint bin = threadIdx.x; bin < HISTOGRAM256_BIN_COUNT; bin += HISTOGRAM256_THREADBLOCK_SIZE) {\n        uint sum = 0;\n\n        for (uint i = 0; i < WARP_COUNT; i++) {\n            sum += s_Hist[bin + i * HISTOGRAM256_BIN_COUNT] & TAG_MASK;\n        }\n\n        d_PartialHistograms[blockIdx.x * HISTOGRAM256_BIN_COUNT + bin] = sum;\n    }\n}\n\n#define MERGE_THREADBLOCK_SIZE 256\n\n__global__ void mergeHistogram256Kernel(uint *d_Histogram, uint *d_PartialHistograms, uint histogramCount)\n{\n    cg::thread_block cta = cg::this_thread_block();\n\n    uint sum = 0;\n\n    for (uint i = threadIdx.x; i < histogramCount; i += MERGE_THREADBLOCK_SIZE) {\n        sum += d_PartialHistograms[blockIdx.x + i * HISTOGRAM256_BIN_COUNT];\n    }\n\n    __shared__ uint data[MERGE_THREADBLOCK_SIZE];\n    data[threadIdx.x] = sum;\n\n    for (uint stride = MERGE_THREADBLOCK_SIZE / 2; stride > 0; stride >>= 1) {\n        cg::sync(cta);\n\n        if (threadIdx.x < stride) {\n            data[threadIdx.x] += data[threadIdx.x + stride];\n        }\n    }\n\n    if (threadIdx.x == 0) {\n        d_Histogram[blockIdx.x] = data[0];\n    }\n}\n\nstatic const uint PARTIAL_HISTOGRAM256_COUNT = 240;\nstatic uint      *d_PartialHistograms;\n\nextern \"C\" void initHistogram256(void)\n{\n    checkCudaErrors(\n        cudaMalloc((void **)&d_PartialHistograms, PARTIAL_HISTOGRAM256_COUNT * HISTOGRAM256_BIN_COUNT * sizeof(uint)));\n}\n\nextern \"C\" void closeHistogram256(void) { checkCudaErrors(cudaFree(d_PartialHistograms)); }\n\nextern \"C\" void histogram256(uint *d_Histogram, void *d_Data, uint byteCount)\n{\n    assert(byteCount % sizeof(uint) == 0);\n    histogram256Kernel<<<PARTIAL_HISTOGRAM256_COUNT, HISTOGRAM256_THREADBLOCK_SIZE>>>(\n        d_PartialHistograms, (uint *)d_Data, byteCount / sizeof(uint));\n    getLastCudaError(\"histogram256Kernel() execution failed\\n\");\n\n    mergeHistogram256Kernel<<<HISTOGRAM256_BIN_COUNT, MERGE_THREADBLOCK_SIZE>>>(\n        d_Histogram, d_PartialHistograms, PARTIAL_HISTOGRAM256_COUNT);\n    getLastCudaError(\"mergeHistogram256Kernel() execution failed\\n\");\n}\n", "histogram64.cu": "#include <assert.h>\n#include <cooperative_groups.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\nnamespace cg = cooperative_groups;\n#include <helper_cuda.h>\n\n#include \"histogram_common.h\"\n\ntypedef uint4 data_t;\n\n#define SHARED_MEMORY_BANKS 16\n\ninline __device__ void addByte(uchar *s_ThreadBase, uint data)\n{\n    s_ThreadBase[UMUL(data, HISTOGRAM64_THREADBLOCK_SIZE)]++;\n}\n\ninline __device__ void addWord(uchar *s_ThreadBase, uint data)\n{\n    addByte(s_ThreadBase, (data >> 2) & 0x3FU);\n    addByte(s_ThreadBase, (data >> 10) & 0x3FU);\n    addByte(s_ThreadBase, (data >> 18) & 0x3FU);\n    addByte(s_ThreadBase, (data >> 26) & 0x3FU);\n}\n\n__global__ void histogram64Kernel(uint *d_PartialHistograms, data_t *d_Data, uint dataCount)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    const uint threadPos = ((threadIdx.x & ~(SHARED_MEMORY_BANKS * 4 - 1)) << 0)\n                         | ((threadIdx.x & (SHARED_MEMORY_BANKS - 1)) << 2)\n                         | ((threadIdx.x & (SHARED_MEMORY_BANKS * 3)) >> 4);\n\n    __shared__ uchar s_Hist[HISTOGRAM64_THREADBLOCK_SIZE * HISTOGRAM64_BIN_COUNT];\n    uchar           *s_ThreadBase = s_Hist + threadPos;\n\n#pragma unroll\n\n    for (uint i = 0; i < (HISTOGRAM64_BIN_COUNT / 4); i++) {\n        ((uint *)s_Hist)[threadIdx.x + i * HISTOGRAM64_THREADBLOCK_SIZE] = 0;\n    }\n\n    cg::sync(cta);\n\n    for (uint pos = UMAD(blockIdx.x, blockDim.x, threadIdx.x); pos < dataCount; pos += UMUL(blockDim.x, gridDim.x)) {\n        data_t data = d_Data[pos];\n        addWord(s_ThreadBase, data.x);\n        addWord(s_ThreadBase, data.y);\n        addWord(s_ThreadBase, data.z);\n        addWord(s_ThreadBase, data.w);\n    }\n\n    cg::sync(cta);\n\n    if (threadIdx.x < HISTOGRAM64_BIN_COUNT) {\n        uchar *s_HistBase = s_Hist + UMUL(threadIdx.x, HISTOGRAM64_THREADBLOCK_SIZE);\n\n        uint sum = 0;\n        uint pos = 4 * (threadIdx.x & (SHARED_MEMORY_BANKS - 1));\n\n#pragma unroll\n\n        for (uint i = 0; i < (HISTOGRAM64_THREADBLOCK_SIZE / 4); i++) {\n            sum += s_HistBase[pos + 0] + s_HistBase[pos + 1] + s_HistBase[pos + 2] + s_HistBase[pos + 3];\n            pos = (pos + 4) & (HISTOGRAM64_THREADBLOCK_SIZE - 1);\n        }\n\n        d_PartialHistograms[blockIdx.x * HISTOGRAM64_BIN_COUNT + threadIdx.x] = sum;\n    }\n}\n\n#define MERGE_THREADBLOCK_SIZE 256\n\n__global__ void mergeHistogram64Kernel(uint *d_Histogram, uint *d_PartialHistograms, uint histogramCount)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ uint  data[MERGE_THREADBLOCK_SIZE];\n\n    uint sum = 0;\n\n    for (uint i = threadIdx.x; i < histogramCount; i += MERGE_THREADBLOCK_SIZE) {\n        sum += d_PartialHistograms[blockIdx.x + i * HISTOGRAM64_BIN_COUNT];\n    }\n\n    data[threadIdx.x] = sum;\n\n    for (uint stride = MERGE_THREADBLOCK_SIZE / 2; stride > 0; stride >>= 1) {\n        cg::sync(cta);\n\n        if (threadIdx.x < stride) {\n            data[threadIdx.x] += data[threadIdx.x + stride];\n        }\n    }\n\n    if (threadIdx.x == 0) {\n        d_Histogram[blockIdx.x] = data[0];\n    }\n}\n\nstatic const uint MAX_PARTIAL_HISTOGRAM64_COUNT = 32768;\nstatic uint      *d_PartialHistograms;\n\nextern \"C\" void initHistogram64(void)\n{\n    assert(HISTOGRAM64_THREADBLOCK_SIZE % (4 * SHARED_MEMORY_BANKS) == 0);\n    checkCudaErrors(cudaMalloc((void **)&d_PartialHistograms,\n                               MAX_PARTIAL_HISTOGRAM64_COUNT * HISTOGRAM64_BIN_COUNT * sizeof(uint)));\n}\n\nextern \"C\" void closeHistogram64(void) { checkCudaErrors(cudaFree(d_PartialHistograms)); }\n\ninline uint iDivUp(uint a, uint b) { return (a % b != 0) ? (a / b + 1) : (a / b); }\n\ninline uint iSnapDown(uint a, uint b) { return a - a % b; }\n\nextern \"C\" void histogram64(uint *d_Histogram, void *d_Data, uint byteCount)\n{\n    const uint histogramCount = iDivUp(byteCount, HISTOGRAM64_THREADBLOCK_SIZE * iSnapDown(255, sizeof(data_t)));\n\n    assert(byteCount % sizeof(data_t) == 0);\n    assert(histogramCount <= MAX_PARTIAL_HISTOGRAM64_COUNT);\n\n    histogram64Kernel<<<histogramCount, HISTOGRAM64_THREADBLOCK_SIZE>>>(\n        d_PartialHistograms, (data_t *)d_Data, byteCount / sizeof(data_t));\n    getLastCudaError(\"histogram64Kernel() execution failed\\n\");\n\n    mergeHistogram64Kernel<<<HISTOGRAM64_BIN_COUNT, MERGE_THREADBLOCK_SIZE>>>(\n        d_Histogram, d_PartialHistograms, histogramCount);\n    getLastCudaError(\"mergeHistogram64() execution failed\\n\");\n}\n", "main.cpp": "#include <cuda_runtime.h>\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n\n#include \"histogram_common.h\"\n\nconst int          numRuns    = 16;\nconst static char *sSDKsample = \"[histogram]\\0\";\n\nint main(int argc, char **argv)\n{\n    uchar              *h_Data;\n    uint               *h_HistogramCPU, *h_HistogramGPU;\n    uchar              *d_Data;\n    uint               *d_Histogram;\n    StopWatchInterface *hTimer       = NULL;\n    int                 PassFailFlag = 1;\n    uint                byteCount    = 64 * 1048576;\n    uint                uiSizeMult   = 1;\n\n    cudaDeviceProp deviceProp;\n    deviceProp.major = 0;\n    deviceProp.minor = 0;\n\n    printf(\"[%s] - Starting...\\n\", sSDKsample);\n\n    int dev = findCudaDevice(argc, (const char **)argv);\n\n    checkCudaErrors(cudaGetDeviceProperties(&deviceProp, dev));\n\n    printf(\"CUDA device [%s] has %d Multi-Processors, Compute %d.%d\\n\",\n           deviceProp.name,\n           deviceProp.multiProcessorCount,\n           deviceProp.major,\n           deviceProp.minor);\n\n    sdkCreateTimer(&hTimer);\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"sizemult\")) {\n        uiSizeMult = getCmdLineArgumentInt(argc, (const char **)argv, \"sizemult\");\n        uiSizeMult = MAX(1, MIN(uiSizeMult, 10));\n        byteCount *= uiSizeMult;\n    }\n\n    printf(\"Initializing data...\\n\");\n    printf(\"...allocating CPU memory.\\n\");\n    h_Data         = (uchar *)malloc(byteCount);\n    h_HistogramCPU = (uint *)malloc(HISTOGRAM256_BIN_COUNT * sizeof(uint));\n    h_HistogramGPU = (uint *)malloc(HISTOGRAM256_BIN_COUNT * sizeof(uint));\n\n    printf(\"...generating input data\\n\");\n    srand(2009);\n\n    for (uint i = 0; i < byteCount; i++) {\n        h_Data[i] = rand() % 256;\n    }\n\n    printf(\"...allocating GPU memory and copying input data\\n\\n\");\n    checkCudaErrors(cudaMalloc((void **)&d_Data, byteCount));\n    checkCudaErrors(cudaMalloc((void **)&d_Histogram, HISTOGRAM256_BIN_COUNT * sizeof(uint)));\n    checkCudaErrors(cudaMemcpy(d_Data, h_Data, byteCount, cudaMemcpyHostToDevice));\n\n    {\n        printf(\"Starting up 64-bin histogram...\\n\\n\");\n        initHistogram64();\n\n        printf(\"Running 64-bin GPU histogram for %u bytes (%u runs)...\\n\\n\", byteCount, numRuns);\n\n        for (int iter = -1; iter < numRuns; iter++) {\n            if (iter == 0) {\n                cudaDeviceSynchronize();\n                sdkResetTimer(&hTimer);\n                sdkStartTimer(&hTimer);\n            }\n\n            histogram64(d_Histogram, d_Data, byteCount);\n        }\n\n        cudaDeviceSynchronize();\n        sdkStopTimer(&hTimer);\n        double dAvgSecs = 1.0e-3 * (double)sdkGetTimerValue(&hTimer) / (double)numRuns;\n        printf(\"histogram64() time (average) : %.5f sec, %.4f MB/sec\\n\\n\",\n               dAvgSecs,\n               ((double)byteCount * 1.0e-6) / dAvgSecs);\n        printf(\"histogram64, Throughput = %.4f MB/s, Time = %.5f s, Size = %u Bytes, \"\n               \"NumDevsUsed = %u, Workgroup = %u\\n\",\n               (1.0e-6 * (double)byteCount / dAvgSecs),\n               dAvgSecs,\n               byteCount,\n               1,\n               HISTOGRAM64_THREADBLOCK_SIZE);\n\n        printf(\"\\nValidating GPU results...\\n\");\n        printf(\" ...reading back GPU results\\n\");\n        checkCudaErrors(\n            cudaMemcpy(h_HistogramGPU, d_Histogram, HISTOGRAM64_BIN_COUNT * sizeof(uint), cudaMemcpyDeviceToHost));\n\n        printf(\" ...histogram64CPU()\\n\");\n        histogram64CPU(h_HistogramCPU, h_Data, byteCount);\n\n        printf(\" ...comparing the results...\\n\");\n\n        for (uint i = 0; i < HISTOGRAM64_BIN_COUNT; i++)\n            if (h_HistogramGPU[i] != h_HistogramCPU[i]) {\n                PassFailFlag = 0;\n            }\n\n        printf(PassFailFlag ? \" ...64-bin histograms match\\n\\n\" : \" ***64-bin histograms do not match!!!***\\n\\n\");\n\n        printf(\"Shutting down 64-bin histogram...\\n\\n\\n\");\n        closeHistogram64();\n    }\n\n    {\n        printf(\"Initializing 256-bin histogram...\\n\");\n        initHistogram256();\n\n        printf(\"Running 256-bin GPU histogram for %u bytes (%u runs)...\\n\\n\", byteCount, numRuns);\n\n        for (int iter = -1; iter < numRuns; iter++) {\n            if (iter == 0) {\n                checkCudaErrors(cudaDeviceSynchronize());\n                sdkResetTimer(&hTimer);\n                sdkStartTimer(&hTimer);\n            }\n\n            histogram256(d_Histogram, d_Data, byteCount);\n        }\n\n        cudaDeviceSynchronize();\n        sdkStopTimer(&hTimer);\n        double dAvgSecs = 1.0e-3 * (double)sdkGetTimerValue(&hTimer) / (double)numRuns;\n        printf(\"histogram256() time (average) : %.5f sec, %.4f MB/sec\\n\\n\",\n               dAvgSecs,\n               ((double)byteCount * 1.0e-6) / dAvgSecs);\n        printf(\"histogram256, Throughput = %.4f MB/s, Time = %.5f s, Size = %u Bytes, \"\n               \"NumDevsUsed = %u, Workgroup = %u\\n\",\n               (1.0e-6 * (double)byteCount / dAvgSecs),\n               dAvgSecs,\n               byteCount,\n               1,\n               HISTOGRAM256_THREADBLOCK_SIZE);\n\n        printf(\"\\nValidating GPU results...\\n\");\n        printf(\" ...reading back GPU results\\n\");\n        checkCudaErrors(\n            cudaMemcpy(h_HistogramGPU, d_Histogram, HISTOGRAM256_BIN_COUNT * sizeof(uint), cudaMemcpyDeviceToHost));\n\n        printf(\" ...histogram256CPU()\\n\");\n        histogram256CPU(h_HistogramCPU, h_Data, byteCount);\n\n        printf(\" ...comparing the results\\n\");\n\n        for (uint i = 0; i < HISTOGRAM256_BIN_COUNT; i++)\n            if (h_HistogramGPU[i] != h_HistogramCPU[i]) {\n                PassFailFlag = 0;\n            }\n\n        printf(PassFailFlag ? \" ...256-bin histograms match\\n\\n\" : \" ***256-bin histograms do not match!!!***\\n\\n\");\n\n        printf(\"Shutting down 256-bin histogram...\\n\\n\\n\");\n        closeHistogram256();\n    }\n\n    printf(\"Shutting down...\\n\");\n    sdkDeleteTimer(&hTimer);\n    checkCudaErrors(cudaFree(d_Histogram));\n    checkCudaErrors(cudaFree(d_Data));\n    free(h_HistogramGPU);\n    free(h_HistogramCPU);\n    free(h_Data);\n\n    printf(\"\\nNOTE: The CUDA Samples are not meant for performance measurements. \"\n           \"Results may vary when GPU Boost is enabled.\\n\\n\");\n\n    printf(\"%s - Test Summary\\n\", sSDKsample);\n\n    if (!PassFailFlag) {\n        printf(\"Test failed!\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"Test passed\\n\");\n    exit(EXIT_SUCCESS);\n}\n"}, "code_dirs": {"histogram256.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/histogram", "histogram64.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/histogram", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/histogram"}}
{"kernel_name": "histogram", "parallel_api": "ocl", "code": {"Histogram256.cl": "#define HISTOGRAM256_BIN_COUNT 256\n\n#define      UINT_BITS 32U\n#define      WARP_SIZE (1U << LOG2_WARP_SIZE)\n\n#define HISTOGRAM256_WORKGROUP_SIZE (WARP_COUNT * WARP_SIZE)\n\n#define HISTOGRAM256_WORKGROUP_MEMORY (WARP_COUNT * HISTOGRAM256_BIN_COUNT)\n\n#define TAG_MASK ( (1U << (UINT_BITS - LOG2_WARP_SIZE)) - 1U )\n\ninline void addByte(volatile __local uint *l_WarpHist, uint data, uint tag){\n    uint count;\n    do{\n        count = l_WarpHist[data] & TAG_MASK;\n        count = tag | (count + 1);\n        l_WarpHist[data] = count;\n    }while(l_WarpHist[data] != count);\n}\n\ninline void addWord(volatile __local uint *l_WarpHist, uint data, uint tag){\n    addByte(l_WarpHist, (data >>  0) & 0xFFU, tag);\n    addByte(l_WarpHist, (data >>  8) & 0xFFU, tag);\n    addByte(l_WarpHist, (data >> 16) & 0xFFU, tag);\n    addByte(l_WarpHist, (data >> 24) & 0xFFU, tag);\n}\n\n__kernel __attribute__((reqd_work_group_size(HISTOGRAM256_WORKGROUP_SIZE, 1, 1)))\nvoid histogram256(\n    __global uint *d_PartialHistograms,\n    __global uint *d_Data,\n    uint dataCount\n){\n    //Per-warp substorage storage\n    __local uint l_Hist[WARP_COUNT * HISTOGRAM256_BIN_COUNT];\n    __local uint *l_WarpHist = l_Hist + (get_local_id(0) >> LOG2_WARP_SIZE) * HISTOGRAM256_BIN_COUNT;\n\n    //Clear shared memory storage for current threadblock before processing\n    for(uint i = 0; i < (HISTOGRAM256_BIN_COUNT / WARP_SIZE); i++)\n        l_Hist[get_local_id(0) + i  * (WARP_COUNT * WARP_SIZE)] = 0;\n\n    const uint tag =  get_local_id(0) << (32 - LOG2_WARP_SIZE);\n\n    //Read through the entire input buffer, build per-warp histograms\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for(uint pos = get_global_id(0); pos < dataCount; pos += get_global_size(0)){\n        uint data = d_Data[pos];\n        addWord(l_WarpHist, data, tag);\n    }\n\n    //Per-block histogram reduction\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for(uint pos = get_local_id(0); pos < HISTOGRAM256_BIN_COUNT; pos += HISTOGRAM256_WORKGROUP_SIZE){\n        uint sum = 0;\n\n        for(uint i = 0; i < WARP_COUNT; i++)\n            sum += l_Hist[pos + i * HISTOGRAM256_BIN_COUNT] & TAG_MASK;\n\n        d_PartialHistograms[get_group_id(0) * HISTOGRAM256_BIN_COUNT + pos] = sum;\n    }\n}\n\n__kernel __attribute__((reqd_work_group_size(MERGE_WORKGROUP_SIZE, 1, 1)))\nvoid mergeHistogram256(\n    __global uint *d_Histogram,\n    __global uint *d_PartialHistograms,\n    uint histogramCount\n){\n    __local uint l_Data[MERGE_WORKGROUP_SIZE];\n\n    uint sum = 0;\n    for(uint i = get_local_id(0); i < histogramCount; i += MERGE_WORKGROUP_SIZE)\n        sum += d_PartialHistograms[get_group_id(0) + i * HISTOGRAM256_BIN_COUNT];\n    l_Data[get_local_id(0)] = sum;\n\n    for(uint stride = MERGE_WORKGROUP_SIZE / 2; stride > 0; stride >>= 1){\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if(get_local_id(0) < stride)\n            l_Data[get_local_id(0)] += l_Data[get_local_id(0) + stride];\n    }\n\n    if(get_local_id(0) == 0)\n        d_Histogram[get_group_id(0)] = l_Data[0];\n}\n", "Histogram64.cl": "#pragma OPENCL EXTENSION cl_khr_byte_addressable_store : enable\n\n#define HISTOGRAM64_BIN_COUNT 64\n\ntypedef uint4 data_t;\n\n#define UMUL(a, b)    ( (a) * (b) )\n#define UMAD(a, b, c) ( UMUL((a), (b)) + (c) )\n\ninline void addByte(__local uchar *l_WorkitemBase, uint data){\n    l_WorkitemBase[UMUL(data, HISTOGRAM64_WORKGROUP_SIZE)]++;\n}\n\ninline void addWord(__local uchar *l_WorkitemBase, uint data){\n    addByte(l_WorkitemBase, (data >>  2) & 0x3FU);\n    addByte(l_WorkitemBase, (data >> 10) & 0x3FU);\n    addByte(l_WorkitemBase, (data >> 18) & 0x3FU);\n    addByte(l_WorkitemBase, (data >> 26) & 0x3FU);\n}\n\n__kernel __attribute__((reqd_work_group_size(HISTOGRAM64_WORKGROUP_SIZE, 1, 1)))\nvoid histogram64(\n    __global uint *d_PartialHistograms,\n    __global data_t *d_Data,\n    uint dataCount\n){\n\n    const uint lPos = \n        ( (get_local_id(0) & ~(LOCAL_MEMORY_BANKS * 4 - 1)) << 0 ) |\n        ( (get_local_id(0) &  (LOCAL_MEMORY_BANKS     - 1)) << 2 ) |\n        ( (get_local_id(0) &  (LOCAL_MEMORY_BANKS * 3    )) >> 4 );\n\n    __local uchar l_Hist[HISTOGRAM64_WORKGROUP_SIZE * HISTOGRAM64_BIN_COUNT];\n    __local uchar *l_WorkitemBase = l_Hist + lPos;\n\n    for(uint i = 0; i < (HISTOGRAM64_BIN_COUNT / 4); i++)\n        ((__local uint *)l_Hist)[lPos + i * HISTOGRAM64_WORKGROUP_SIZE] = 0;\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for(uint pos = get_global_id(0); pos < dataCount; pos += get_global_size(0)){\n        data_t data = d_Data[pos];\n        addWord(l_WorkitemBase, data.x);\n        addWord(l_WorkitemBase, data.y);\n        addWord(l_WorkitemBase, data.z);\n        addWord(l_WorkitemBase, data.w);\n    }\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n    if(get_local_id(0) < HISTOGRAM64_BIN_COUNT){\n        __local uchar *l_HistBase = l_Hist + UMUL(get_local_id(0), HISTOGRAM64_WORKGROUP_SIZE);\n\n        uint sum = 0;\n        uint pos = 4 * (get_local_id(0) & (LOCAL_MEMORY_BANKS - 1));\n        for(uint i = 0; i < (HISTOGRAM64_WORKGROUP_SIZE / 4); i++){\n            sum += \n                l_HistBase[pos + 0] + \n                l_HistBase[pos + 1] + \n                l_HistBase[pos + 2] + \n                l_HistBase[pos + 3];\n            pos = (pos + 4) & (HISTOGRAM64_WORKGROUP_SIZE - 1);\n        }\n\n        d_PartialHistograms[get_group_id(0) * HISTOGRAM64_BIN_COUNT + get_local_id(0)] = sum;\n    }\n}\n\n__kernel __attribute__((reqd_work_group_size(MERGE_WORKGROUP_SIZE, 1, 1)))\nvoid mergeHistogram64(\n    __global uint *d_Histogram,\n    __global uint *d_PartialHistograms,\n    uint histogramCount\n){\n    __local uint l_Data[MERGE_WORKGROUP_SIZE];\n\n    uint sum = 0;\n    for(uint i = get_local_id(0); i < histogramCount; i += MERGE_WORKGROUP_SIZE)\n        sum += d_PartialHistograms[get_group_id(0) + i * HISTOGRAM64_BIN_COUNT];\n    l_Data[get_local_id(0)] = sum;\n\n    for(uint stride = MERGE_WORKGROUP_SIZE / 2; stride > 0; stride >>= 1){\n        barrier(CLK_LOCAL_MEM_FENCE);\n        if(get_local_id(0) < stride)\n            l_Data[get_local_id(0)] += l_Data[get_local_id(0) + stride];\n    }\n\n    if(get_local_id(0) == 0)\n        d_Histogram[get_group_id(0)] = l_Data[0];\n}\n", "main.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n#include \"oclHistogram_common.h\"\n\nint main(int argc, char **argv)\n{\n    cl_platform_id   cpPlatform;\n    cl_device_id*    cdDevices;\n    cl_context       cxGPUContext;\n    cl_command_queue cqCommandQueue;\n    cl_mem    d_Data, d_Histogram;\n    cl_int ciErrNum;\n    int PassFailFlag = 1;\n    uchar *h_Data;\n    uint *h_HistogramCPU, *h_HistogramGPU;\n    uint byteCount = 64 * 1048576;\n    uint uiSizeMult = 1;\n\n    shrQAStart(argc, argv);\n\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    shrLog(\"clGetPlatformID...\\n\"); \n\n    cl_uint uiNumDevices = 0;\n    cl_uint uiTargetDevice = 0;\n    cl_uint uiNumComputeUnits;\n    shrLog(\"Get the Device info and select Device...\\n\");\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiNumDevices);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    cdDevices = (cl_device_id *)malloc(uiNumDevices * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiNumDevices, cdDevices, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n\n    shrLog(\"  # of Devices Available = %u\\n\", uiNumDevices); \n    if(shrGetCmdLineArgumentu(argc, (const char**)argv, \"device\", &uiTargetDevice)== shrTRUE) \n    {\n        uiTargetDevice = CLAMP(uiTargetDevice, 0, (uiNumDevices - 1));\n    }\n    shrLog(\"  Using Device %u: \", uiTargetDevice); \n    oclPrintDevName(LOGBOTH, cdDevices[uiTargetDevice]);\n    ciErrNum = clGetDeviceInfo(cdDevices[uiTargetDevice], CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(uiNumComputeUnits), &uiNumComputeUnits, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    shrLog(\"\\n  # of Compute Units = %u\\n\", uiNumComputeUnits); \n\n    shrSetLogFileName (\"oclHistogram.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    if (shrGetCmdLineArgumentu(argc, (const char**)argv, \"sizemult\", &uiSizeMult))\n    {\n        uiSizeMult = CLAMP(uiSizeMult, 1, 10);\n        byteCount *= uiSizeMult;\n    }\n\n    shrLog(\"Initializing data...\\n\");\n        h_Data         = (uchar *)malloc(byteCount              * sizeof(uchar));\n        h_HistogramCPU = (uint  *)malloc(HISTOGRAM256_BIN_COUNT * sizeof(uint));\n        h_HistogramGPU = (uint  *)malloc(HISTOGRAM256_BIN_COUNT * sizeof(uint));\n        srand(2009);\n        for(uint i = 0; i < byteCount; i++)\n            h_Data[i] = rand() & 0xFFU;\n\n    shrLog(\"Initializing OpenCL...\\n\");\n        ciErrNum = oclGetPlatformID(&cpPlatform);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 1, &cdDevices[uiTargetDevice], NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        cxGPUContext = clCreateContext(0, 1, &cdDevices[uiTargetDevice], NULL, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevices[uiTargetDevice], CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Allocating OpenCL memory...\\n\\n\\n\");\n        d_Data = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, byteCount * sizeof(cl_char), h_Data, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_Histogram = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, HISTOGRAM256_BIN_COUNT * sizeof(uint), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n\n    {\n        size_t szWorkgroup;\n        shrLog(\"Initializing 64-bin OpenCL histogram...\\n\");\n            initHistogram64(cxGPUContext, cqCommandQueue, (const char **)argv);\n\n        shrLog(\"Running 64-bin OpenCL histogram for %u bytes...\\n\\n\", byteCount);\n            szWorkgroup = histogram64(NULL, d_Histogram, d_Data, byteCount);\n\n#ifdef GPU_PROFILING\n        const uint numIterations = 16;\n        cl_event startMark, endMark;\n        ciErrNum = clEnqueueMarker(cqCommandQueue, &startMark);\n        ciErrNum |= clFinish(cqCommandQueue);\n        shrCheckError(ciErrNum, CL_SUCCESS);\n        shrDeltaT(0);\n\n        for(uint iter = 0; iter < numIterations; iter++)\n            szWorkgroup = histogram64(NULL, d_Histogram, d_Data, byteCount);\n\n        ciErrNum  = clEnqueueMarker(cqCommandQueue, &endMark);\n        ciErrNum |= clFinish(cqCommandQueue);\n        shrCheckError(ciErrNum, CL_SUCCESS);\n\n        double gpuTime = shrDeltaT(0) / (double)numIterations;\n        shrLogEx(LOGBOTH | MASTER, 0, \"oclHistogram64, Throughput = %.4f MB/s, Time = %.5f s, Size = %u Bytes, NumDevsUsed = %u, Workgroup = %u\\n\", \n                (1.0e-6 * (double)byteCount / gpuTime), gpuTime, byteCount, 1, szWorkgroup); \n\n        cl_ulong startTime = 0, endTime = 0;\n        ciErrNum  = clGetEventProfilingInfo(startMark, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &startTime, NULL);\n        ciErrNum |= clGetEventProfilingInfo(endMark, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &endTime, NULL);\n        shrCheckError(ciErrNum, CL_SUCCESS);\n        shrLog(\"\\nOpenCL time: %.5f s\\n\\n\", 1.0e-9 * ((double)endTime - (double)startTime)/(double)numIterations);\n#endif\n\n        shrLog(\"Validating 64-bin histogram OpenCL results...\\n\");\n            shrLog(\" ...reading back OpenCL results\\n\");\n                ciErrNum = clEnqueueReadBuffer(cqCommandQueue, d_Histogram, CL_TRUE, 0, HISTOGRAM64_BIN_COUNT * sizeof(uint), h_HistogramGPU, 0, NULL, NULL);\n                shrCheckError(ciErrNum, CL_SUCCESS);\n\n            shrLog(\" ...histogram64CPU()\\n\");\n                histogram64CPU(h_HistogramCPU, h_Data, byteCount);\n\n            shrLog(\" ...comparing the results\\n\");\n                for(uint i = 0; i < HISTOGRAM64_BIN_COUNT; i++)\n                    if(h_HistogramGPU[i] != h_HistogramCPU[i]) PassFailFlag = 0;\n            shrLog(PassFailFlag ? \" ...64-bin histograms match\\n\\n\" : \" ***64-bin histograms do not match!!!***\\n\\n\" );\n\n        shrLog(\"Shutting down 64-bin OpenCL histogram\\n\\n\\n\"); \n            closeHistogram64();\n    }\n\n    {\n        size_t szWorkgroup;\n        shrLog(\"Initializing 256-bin OpenCL histogram...\\n\");\n            initHistogram256(cxGPUContext, cqCommandQueue, (const char **)argv);\n\n        shrLog(\"Running 256-bin OpenCL histogram for %u bytes...\\n\\n\", byteCount);\n            szWorkgroup = histogram256(NULL, d_Histogram, d_Data, byteCount);\n\n#ifdef GPU_PROFILING\n        const uint numIterations = 16;\n        cl_event startMark, endMark;\n        ciErrNum = clEnqueueMarker(cqCommandQueue, &startMark);\n        ciErrNum |= clFinish(cqCommandQueue);\n        shrCheckError(ciErrNum, CL_SUCCESS);\n        shrDeltaT(0);\n\n        for(uint iter = 0; iter < numIterations; iter++)\n            szWorkgroup = histogram256(NULL, d_Histogram, d_Data, byteCount);\n\n        ciErrNum  = clEnqueueMarker(cqCommandQueue, &endMark);\n        ciErrNum |= clFinish(cqCommandQueue);\n        shrCheckError(ciErrNum, CL_SUCCESS);\n\n        double gpuTime = shrDeltaT(0) / (double)numIterations;\n        shrLogEx(LOGBOTH | MASTER, 0, \"oclHistogram256, Throughput = %.4f MB/s, Time = %.5f s, Size = %u Bytes, NumDevsUsed = %u, Workgroup = %u\\n\", \n                (1.0e-6 * (double)byteCount / gpuTime), gpuTime, byteCount, 1, szWorkgroup); \n\n        cl_ulong startTime = 0, endTime = 0;\n        ciErrNum  = clGetEventProfilingInfo(startMark, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &startTime, NULL);\n        ciErrNum |= clGetEventProfilingInfo(endMark, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &endTime, NULL);\n        shrCheckError(ciErrNum, CL_SUCCESS);\n        shrLog(\"\\nOpenCL time: %.5f s\\n\\n\", 1.0e-9 * (double)(endTime - startTime)/(double)numIterations);\n#endif\n\n        shrLog(\"Validating 256-bin histogram OpenCL results...\\n\");\n            shrLog(\" ...reading back OpenCL results\\n\");\n                ciErrNum = clEnqueueReadBuffer(cqCommandQueue, d_Histogram, CL_TRUE, 0, HISTOGRAM256_BIN_COUNT * sizeof(uint), h_HistogramGPU, 0, NULL, NULL);\n                shrCheckError(ciErrNum, CL_SUCCESS);\n\n            shrLog(\" ...histogram256CPU()\\n\");\n                histogram256CPU(h_HistogramCPU, h_Data, byteCount);\n\n            shrLog(\" ...comparing the results\\n\");\n                for(uint i = 0; i < HISTOGRAM256_BIN_COUNT; i++)\n                    if(h_HistogramGPU[i] != h_HistogramCPU[i]) PassFailFlag = 0;\n            shrLog(PassFailFlag ? \" ...256-bin histograms match\\n\\n\" : \" ***256-bin histograms do not match!!!***\\n\\n\" );\n\n        shrLog(\"Shutting down 256-bin OpenCL histogram\\n\\n\\n\"); \n            closeHistogram256();\n    }\n\n    shrLog(\"Shutting down...\\n\");\n        ciErrNum  = clReleaseMemObject(d_Histogram);\n        ciErrNum |= clReleaseMemObject(d_Data);\n        ciErrNum |= clReleaseCommandQueue(cqCommandQueue);\n        ciErrNum |= clReleaseContext(cxGPUContext);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        free(h_HistogramGPU);\n        free(h_HistogramCPU);\n        free(h_Data);\n\n        if (cdDevices) free(cdDevices);\n\n    shrQAFinishExit(argc, (const char **)argv, PassFailFlag ? QA_PASSED : QA_FAILED);\n}\n"}, "code_dirs": {"Histogram256.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclHistogram", "Histogram64.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclHistogram", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclHistogram/src"}}
{"kernel_name": "convolutionSeparable", "parallel_api": "cuda", "code": {"convolutionSeparable.cu": "#include <assert.h>\n#include <cooperative_groups.h>\n#include <helper_cuda.h>\n\nnamespace cg = cooperative_groups;\n#include \"convolutionSeparable_common.h\"\n\n__constant__ float c_Kernel[KERNEL_LENGTH];\n\nextern \"C\" void setConvolutionKernel(float *h_Kernel)\n{\n    cudaMemcpyToSymbol(c_Kernel, h_Kernel, KERNEL_LENGTH * sizeof(float));\n}\n\n#define ROWS_BLOCKDIM_X   16\n#define ROWS_BLOCKDIM_Y   4\n#define ROWS_RESULT_STEPS 8\n#define ROWS_HALO_STEPS   1\n\n__global__ void convolutionRowsKernel(float *d_Dst, float *d_Src, int imageW, int imageH, int pitch)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ float s_Data[ROWS_BLOCKDIM_Y][(ROWS_RESULT_STEPS + 2 * ROWS_HALO_STEPS) * ROWS_BLOCKDIM_X];\n\n    const int baseX = (blockIdx.x * ROWS_RESULT_STEPS - ROWS_HALO_STEPS) * ROWS_BLOCKDIM_X + threadIdx.x;\n    const int baseY = blockIdx.y * ROWS_BLOCKDIM_Y + threadIdx.y;\n\n    d_Src += baseY * pitch + baseX;\n    d_Dst += baseY * pitch + baseX;\n\n#pragma unroll\n\n    for (int i = ROWS_HALO_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i++) {\n        s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X] = d_Src[i * ROWS_BLOCKDIM_X];\n    }\n\n#pragma unroll\n\n    for (int i = 0; i < ROWS_HALO_STEPS; i++) {\n        s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X] =\n            (baseX >= -i * ROWS_BLOCKDIM_X) ? d_Src[i * ROWS_BLOCKDIM_X] : 0;\n    }\n\n#pragma unroll\n\n    for (int i = ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS + ROWS_HALO_STEPS; i++) {\n        s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X] =\n            (imageW - baseX > i * ROWS_BLOCKDIM_X) ? d_Src[i * ROWS_BLOCKDIM_X] : 0;\n    }\n\n    cg::sync(cta);\n#pragma unroll\n\n    for (int i = ROWS_HALO_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i++) {\n        float sum = 0;\n\n#pragma unroll\n\n        for (int j = -KERNEL_RADIUS; j <= KERNEL_RADIUS; j++) {\n            sum += c_Kernel[KERNEL_RADIUS - j] * s_Data[threadIdx.y][threadIdx.x + i * ROWS_BLOCKDIM_X + j];\n        }\n\n        d_Dst[i * ROWS_BLOCKDIM_X] = sum;\n    }\n}\n\nextern \"C\" void convolutionRowsGPU(float *d_Dst, float *d_Src, int imageW, int imageH)\n{\n    assert(ROWS_BLOCKDIM_X * ROWS_HALO_STEPS >= KERNEL_RADIUS);\n    assert(imageW % (ROWS_RESULT_STEPS * ROWS_BLOCKDIM_X) == 0);\n    assert(imageH % ROWS_BLOCKDIM_Y == 0);\n\n    dim3 blocks(imageW / (ROWS_RESULT_STEPS * ROWS_BLOCKDIM_X), imageH / ROWS_BLOCKDIM_Y);\n    dim3 threads(ROWS_BLOCKDIM_X, ROWS_BLOCKDIM_Y);\n\n    convolutionRowsKernel<<<blocks, threads>>>(d_Dst, d_Src, imageW, imageH, imageW);\n    getLastCudaError(\"convolutionRowsKernel() execution failed\\n\");\n}\n\n#define COLUMNS_BLOCKDIM_X   16\n#define COLUMNS_BLOCKDIM_Y   8\n#define COLUMNS_RESULT_STEPS 8\n#define COLUMNS_HALO_STEPS   1\n\n__global__ void convolutionColumnsKernel(float *d_Dst, float *d_Src, int imageW, int imageH, int pitch)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ float s_Data[COLUMNS_BLOCKDIM_X]\n                           [(COLUMNS_RESULT_STEPS + 2 * COLUMNS_HALO_STEPS) * COLUMNS_BLOCKDIM_Y + 1];\n\n    const int baseX = blockIdx.x * COLUMNS_BLOCKDIM_X + threadIdx.x;\n    const int baseY = (blockIdx.y * COLUMNS_RESULT_STEPS - COLUMNS_HALO_STEPS) * COLUMNS_BLOCKDIM_Y + threadIdx.y;\n    d_Src += baseY * pitch + baseX;\n    d_Dst += baseY * pitch + baseX;\n\n#pragma unroll\n\n    for (int i = COLUMNS_HALO_STEPS; i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS; i++) {\n        s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y] = d_Src[i * COLUMNS_BLOCKDIM_Y * pitch];\n    }\n\n#pragma unroll\n\n    for (int i = 0; i < COLUMNS_HALO_STEPS; i++) {\n        s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y] =\n            (baseY >= -i * COLUMNS_BLOCKDIM_Y) ? d_Src[i * COLUMNS_BLOCKDIM_Y * pitch] : 0;\n    }\n\n#pragma unroll\n\n    for (int i = COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS;\n         i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS + COLUMNS_HALO_STEPS;\n         i++) {\n        s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y] =\n            (imageH - baseY > i * COLUMNS_BLOCKDIM_Y) ? d_Src[i * COLUMNS_BLOCKDIM_Y * pitch] : 0;\n    }\n\n    cg::sync(cta);\n#pragma unroll\n\n    for (int i = COLUMNS_HALO_STEPS; i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS; i++) {\n        float sum = 0;\n#pragma unroll\n\n        for (int j = -KERNEL_RADIUS; j <= KERNEL_RADIUS; j++) {\n            sum += c_Kernel[KERNEL_RADIUS - j] * s_Data[threadIdx.x][threadIdx.y + i * COLUMNS_BLOCKDIM_Y + j];\n        }\n\n        d_Dst[i * COLUMNS_BLOCKDIM_Y * pitch] = sum;\n    }\n}\n\nextern \"C\" void convolutionColumnsGPU(float *d_Dst, float *d_Src, int imageW, int imageH)\n{\n    assert(COLUMNS_BLOCKDIM_Y * COLUMNS_HALO_STEPS >= KERNEL_RADIUS);\n    assert(imageW % COLUMNS_BLOCKDIM_X == 0);\n    assert(imageH % (COLUMNS_RESULT_STEPS * COLUMNS_BLOCKDIM_Y) == 0);\n\n    dim3 blocks(imageW / COLUMNS_BLOCKDIM_X, imageH / (COLUMNS_RESULT_STEPS * COLUMNS_BLOCKDIM_Y));\n    dim3 threads(COLUMNS_BLOCKDIM_X, COLUMNS_BLOCKDIM_Y);\n\n    convolutionColumnsKernel<<<blocks, threads>>>(d_Dst, d_Src, imageW, imageH, imageW);\n    getLastCudaError(\"convolutionColumnsKernel() execution failed\\n\");\n}\n", "main.cpp": "#include <cuda_runtime.h>\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n\n#include \"convolutionSeparable_common.h\"\n\nextern \"C\" void convolutionRowCPU(float *h_Result, float *h_Data, float *h_Kernel, int imageW, int imageH, int kernelR);\n\nextern \"C\" void\nconvolutionColumnCPU(float *h_Result, float *h_Data, float *h_Kernel, int imageW, int imageH, int kernelR);\n\nint main(int argc, char **argv)\n{\n    printf(\"[%s] - Starting...\\n\", argv[0]);\n\n    float *h_Kernel, *h_Input, *h_Buffer, *h_OutputCPU, *h_OutputGPU;\n\n    float *d_Input, *d_Output, *d_Buffer;\n\n    const int imageW     = 3072;\n    const int imageH     = 3072;\n    const int iterations = 16;\n\n    StopWatchInterface *hTimer = NULL;\n\n    findCudaDevice(argc, (const char **)argv);\n\n    sdkCreateTimer(&hTimer);\n\n    printf(\"Image Width x Height = %i x %i\\n\\n\", imageW, imageH);\n    printf(\"Allocating and initializing host arrays...\\n\");\n    h_Kernel    = (float *)malloc(KERNEL_LENGTH * sizeof(float));\n    h_Input     = (float *)malloc(imageW * imageH * sizeof(float));\n    h_Buffer    = (float *)malloc(imageW * imageH * sizeof(float));\n    h_OutputCPU = (float *)malloc(imageW * imageH * sizeof(float));\n    h_OutputGPU = (float *)malloc(imageW * imageH * sizeof(float));\n    srand(200);\n\n    for (unsigned int i = 0; i < KERNEL_LENGTH; i++) {\n        h_Kernel[i] = (float)(rand() % 16);\n    }\n\n    for (unsigned i = 0; i < imageW * imageH; i++) {\n        h_Input[i] = (float)(rand() % 16);\n    }\n\n    printf(\"Allocating and initializing CUDA arrays...\\n\");\n    checkCudaErrors(cudaMalloc((void **)&d_Input, imageW * imageH * sizeof(float)));\n    checkCudaErrors(cudaMalloc((void **)&d_Output, imageW * imageH * sizeof(float)));\n    checkCudaErrors(cudaMalloc((void **)&d_Buffer, imageW * imageH * sizeof(float)));\n\n    setConvolutionKernel(h_Kernel);\n    checkCudaErrors(cudaMemcpy(d_Input, h_Input, imageW * imageH * sizeof(float), cudaMemcpyHostToDevice));\n\n    printf(\"Running GPU convolution (%u identical iterations)...\\n\\n\", iterations);\n\n    for (int i = -1; i < iterations; i++) {\n        if (i == 0) {\n            checkCudaErrors(cudaDeviceSynchronize());\n            sdkResetTimer(&hTimer);\n            sdkStartTimer(&hTimer);\n        }\n\n        convolutionRowsGPU(d_Buffer, d_Input, imageW, imageH);\n\n        convolutionColumnsGPU(d_Output, d_Buffer, imageW, imageH);\n    }\n\n    checkCudaErrors(cudaDeviceSynchronize());\n    sdkStopTimer(&hTimer);\n    double gpuTime = 0.001 * sdkGetTimerValue(&hTimer) / (double)iterations;\n    printf(\"convolutionSeparable, Throughput = %.4f MPixels/sec, Time = %.5f s, \"\n           \"Size = %u Pixels, NumDevsUsed = %i, Workgroup = %u\\n\",\n           (1.0e-6 * (double)(imageW * imageH) / gpuTime),\n           gpuTime,\n           (imageW * imageH),\n           1,\n           0);\n\n    printf(\"\\nReading back GPU results...\\n\\n\");\n    checkCudaErrors(cudaMemcpy(h_OutputGPU, d_Output, imageW * imageH * sizeof(float), cudaMemcpyDeviceToHost));\n\n    printf(\"Checking the results...\\n\");\n    printf(\" ...running convolutionRowCPU()\\n\");\n    convolutionRowCPU(h_Buffer, h_Input, h_Kernel, imageW, imageH, KERNEL_RADIUS);\n\n    printf(\" ...running convolutionColumnCPU()\\n\");\n    convolutionColumnCPU(h_OutputCPU, h_Buffer, h_Kernel, imageW, imageH, KERNEL_RADIUS);\n\n    printf(\" ...comparing the results\\n\");\n    double sum = 0, delta = 0;\n\n    for (unsigned i = 0; i < imageW * imageH; i++) {\n        delta += (h_OutputGPU[i] - h_OutputCPU[i]) * (h_OutputGPU[i] - h_OutputCPU[i]);\n        sum += h_OutputCPU[i] * h_OutputCPU[i];\n    }\n\n    double L2norm = sqrt(delta / sum);\n    printf(\" ...Relative L2 norm: %E\\n\\n\", L2norm);\n    printf(\"Shutting down...\\n\");\n\n    checkCudaErrors(cudaFree(d_Buffer));\n    checkCudaErrors(cudaFree(d_Output));\n    checkCudaErrors(cudaFree(d_Input));\n    free(h_OutputGPU);\n    free(h_OutputCPU);\n    free(h_Buffer);\n    free(h_Input);\n    free(h_Kernel);\n\n    sdkDeleteTimer(&hTimer);\n\n    if (L2norm > 1e-6) {\n        printf(\"Test failed!\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"Test passed\\n\");\n    exit(EXIT_SUCCESS);\n}\n"}, "code_dirs": {"convolutionSeparable.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/convolutionSeparable", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/convolutionSeparable"}}
{"kernel_name": "convolutionSeparable", "parallel_api": "ocl", "code": {"ConvolutionSeparable.cl": "#define KERNEL_LENGTH (2 * KERNEL_RADIUS + 1)\n\n__kernel __attribute__((reqd_work_group_size(ROWS_BLOCKDIM_X, ROWS_BLOCKDIM_Y, 1)))\nvoid convolutionRows(\n    __global float *d_Dst,\n    __global float *d_Src,\n    __constant float *c_Kernel,\n    int imageW,\n    int imageH,\n    int pitch\n){\n    __local float l_Data[ROWS_BLOCKDIM_Y][(ROWS_RESULT_STEPS + 2 * ROWS_HALO_STEPS) * ROWS_BLOCKDIM_X];\n\n    const int baseX = (get_group_id(0) * ROWS_RESULT_STEPS - ROWS_HALO_STEPS) * ROWS_BLOCKDIM_X + get_local_id(0);\n    const int baseY = get_group_id(1) * ROWS_BLOCKDIM_Y + get_local_id(1);\n\n    d_Src += baseY * pitch + baseX;\n    d_Dst += baseY * pitch + baseX;\n\n    for(int i = ROWS_HALO_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i++)\n        l_Data[get_local_id(1)][get_local_id(0) + i * ROWS_BLOCKDIM_X] = d_Src[i * ROWS_BLOCKDIM_X];\n\n    for(int i = 0; i < ROWS_HALO_STEPS; i++)\n        l_Data[get_local_id(1)][get_local_id(0) + i * ROWS_BLOCKDIM_X]  = (baseX + i * ROWS_BLOCKDIM_X >= 0) ? d_Src[i * ROWS_BLOCKDIM_X] : 0;\n\n    for(int i = ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS + ROWS_HALO_STEPS; i++)\n        l_Data[get_local_id(1)][get_local_id(0) + i * ROWS_BLOCKDIM_X]  = (baseX + i * ROWS_BLOCKDIM_X < imageW) ? d_Src[i * ROWS_BLOCKDIM_X] : 0;\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for(int i = ROWS_HALO_STEPS; i < ROWS_HALO_STEPS + ROWS_RESULT_STEPS; i++){\n        float sum = 0;\n\n        for(int j = -KERNEL_RADIUS; j <= KERNEL_RADIUS; j++)\n            sum += c_Kernel[KERNEL_RADIUS - j] * l_Data[get_local_id(1)][get_local_id(0) + i * ROWS_BLOCKDIM_X + j];\n\n        d_Dst[i * ROWS_BLOCKDIM_X] = sum;\n    }\n}\n\n__kernel __attribute__((reqd_work_group_size(COLUMNS_BLOCKDIM_X, COLUMNS_BLOCKDIM_Y, 1)))\nvoid convolutionColumns(\n    __global float *d_Dst,\n    __global float *d_Src,\n    __constant float *c_Kernel,\n    int imageW,\n    int imageH,\n    int pitch\n){\n    __local float l_Data[COLUMNS_BLOCKDIM_X][(COLUMNS_RESULT_STEPS + 2 * COLUMNS_HALO_STEPS) * COLUMNS_BLOCKDIM_Y + 1];\n\n    const int baseX = get_group_id(0) * COLUMNS_BLOCKDIM_X + get_local_id(0);\n    const int baseY = (get_group_id(1) * COLUMNS_RESULT_STEPS - COLUMNS_HALO_STEPS) * COLUMNS_BLOCKDIM_Y + get_local_id(1);\n    d_Src += baseY * pitch + baseX;\n    d_Dst += baseY * pitch + baseX;\n\n    for(int i = COLUMNS_HALO_STEPS; i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS; i++)\n        l_Data[get_local_id(0)][get_local_id(1) + i * COLUMNS_BLOCKDIM_Y] = d_Src[i * COLUMNS_BLOCKDIM_Y * pitch];\n\n    for(int i = 0; i < COLUMNS_HALO_STEPS; i++)\n        l_Data[get_local_id(0)][get_local_id(1) + i * COLUMNS_BLOCKDIM_Y] = (baseY + i * COLUMNS_BLOCKDIM_Y >= 0) ? d_Src[i * COLUMNS_BLOCKDIM_Y * pitch] : 0;\n\n    for(int i = COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS; i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS + COLUMNS_HALO_STEPS; i++)\n        l_Data[get_local_id(0)][get_local_id(1) + i * COLUMNS_BLOCKDIM_Y]  = (baseY + i * COLUMNS_BLOCKDIM_Y < imageH) ? d_Src[i * COLUMNS_BLOCKDIM_Y * pitch] : 0;\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n    for(int i = COLUMNS_HALO_STEPS; i < COLUMNS_HALO_STEPS + COLUMNS_RESULT_STEPS; i++){\n        float sum = 0;\n\n        for(int j = -KERNEL_RADIUS; j <= KERNEL_RADIUS; j++)\n            sum += c_Kernel[KERNEL_RADIUS - j] * l_Data[get_local_id(0)][get_local_id(1) + i * COLUMNS_BLOCKDIM_Y + j];\n\n        d_Dst[i * COLUMNS_BLOCKDIM_Y * pitch] = sum;\n    }\n}\n\n\n", "oclConvolutionSeparable_launcher.cpp": "#include <oclUtils.h>\n#include \"oclConvolutionSeparable_common.h\"\n\nstatic cl_program\n    cpConvolutionSeparable;\n\nstatic cl_kernel\n    ckConvolutionRows, ckConvolutionColumns;\n\nstatic cl_command_queue\n    cqDefaultCommandQueue;\n\nstatic const cl_uint\n    ROWS_BLOCKDIM_X   = 16, COLUMNS_BLOCKDIM_X = 16,\n    ROWS_BLOCKDIM_Y   = 4,  COLUMNS_BLOCKDIM_Y = 8,\n    ROWS_RESULT_STEPS = 8,  COLUMNS_RESULT_STEPS = 8,\n    ROWS_HALO_STEPS   = 1,  COLUMNS_HALO_STEPS = 1;\n\nextern \"C\" void initConvolutionSeparable(cl_context cxGPUContext, cl_command_queue cqParamCommandQueue, const char **argv){\n    cl_int ciErrNum;\n    size_t kernelLength;\n\n    shrLog(\"Loading ConvolutionSeparable.cl...\\n\");\n        char *cPathAndName = shrFindFilePath(\"ConvolutionSeparable.cl\", argv[0]);\n        oclCheckError(cPathAndName != NULL, shrTRUE);\n        char *cConvolutionSeparable = oclLoadProgSource(cPathAndName, \"// My comment\\n\", &kernelLength);\n        oclCheckError(cConvolutionSeparable != NULL, shrTRUE);\n\n    shrLog(\"Creating convolutionSeparable program...\\n\");\n        cpConvolutionSeparable = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&cConvolutionSeparable, &kernelLength, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Building convolutionSeparable program...\\n\");\n        char compileOptions[2048];\n        #ifdef _WIN32\n            sprintf_s(compileOptions, 2048, \"\\\n                -cl-fast-relaxed-math                                  \\\n                -D KERNEL_RADIUS=%u\\\n                -D ROWS_BLOCKDIM_X=%u -D COLUMNS_BLOCKDIM_X=%u\\\n                -D ROWS_BLOCKDIM_Y=%u -D COLUMNS_BLOCKDIM_Y=%u\\\n                -D ROWS_RESULT_STEPS=%u -D COLUMNS_RESULT_STEPS=%u\\\n                -D ROWS_HALO_STEPS=%u -D COLUMNS_HALO_STEPS=%u\\\n                \",\n                KERNEL_RADIUS,\n                ROWS_BLOCKDIM_X,   COLUMNS_BLOCKDIM_X,\n                ROWS_BLOCKDIM_Y,   COLUMNS_BLOCKDIM_Y,\n                ROWS_RESULT_STEPS, COLUMNS_RESULT_STEPS,\n                ROWS_HALO_STEPS,   COLUMNS_HALO_STEPS\n            );\n        #else\n            sprintf(compileOptions, \"\\\n                -cl-fast-relaxed-math                                  \\\n                -D KERNEL_RADIUS=%u\\\n                -D ROWS_BLOCKDIM_X=%u -D COLUMNS_BLOCKDIM_X=%u\\\n                -D ROWS_BLOCKDIM_Y=%u -D COLUMNS_BLOCKDIM_Y=%u\\\n                -D ROWS_RESULT_STEPS=%u -D COLUMNS_RESULT_STEPS=%u\\\n                -D ROWS_HALO_STEPS=%u -D COLUMNS_HALO_STEPS=%u\\\n                \",\n                KERNEL_RADIUS,\n                ROWS_BLOCKDIM_X,   COLUMNS_BLOCKDIM_X,\n                ROWS_BLOCKDIM_Y,   COLUMNS_BLOCKDIM_Y,\n                ROWS_RESULT_STEPS, COLUMNS_RESULT_STEPS,\n                ROWS_HALO_STEPS,   COLUMNS_HALO_STEPS\n            );\n        #endif\n        ciErrNum = clBuildProgram(cpConvolutionSeparable, 0, NULL, compileOptions, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ckConvolutionRows = clCreateKernel(cpConvolutionSeparable, \"convolutionRows\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ckConvolutionColumns = clCreateKernel(cpConvolutionSeparable, \"convolutionColumns\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    cqDefaultCommandQueue = cqParamCommandQueue;\n    free(cConvolutionSeparable);\n}\n\nextern \"C\" void closeConvolutionSeparable(void){\n    cl_int ciErrNum;\n\n    ciErrNum  = clReleaseKernel(ckConvolutionColumns);\n    ciErrNum |= clReleaseKernel(ckConvolutionRows);\n    ciErrNum |= clReleaseProgram(cpConvolutionSeparable);\n}\n\nextern \"C\" void convolutionRows(\n    cl_command_queue cqCommandQueue,\n    cl_mem d_Dst,\n    cl_mem d_Src,\n    cl_mem c_Kernel,\n    cl_uint imageW,\n    cl_uint imageH\n){\n    cl_int ciErrNum;\n    size_t localWorkSize[2], globalWorkSize[2];\n\n    oclCheckError( ROWS_BLOCKDIM_X * ROWS_HALO_STEPS >= KERNEL_RADIUS, shrTRUE );\n    oclCheckError( imageW % (ROWS_RESULT_STEPS * ROWS_BLOCKDIM_X) == 0, shrTRUE );\n    oclCheckError( imageH % ROWS_BLOCKDIM_Y == 0, shrTRUE );\n\n    if(!cqCommandQueue)\n        cqCommandQueue = cqDefaultCommandQueue;\n\n    ciErrNum  = clSetKernelArg(ckConvolutionRows, 0, sizeof(cl_mem),       (void*)&d_Dst);\n    ciErrNum |= clSetKernelArg(ckConvolutionRows, 1, sizeof(cl_mem),       (void*)&d_Src);\n    ciErrNum |= clSetKernelArg(ckConvolutionRows, 2, sizeof(cl_mem),       (void*)&c_Kernel);\n    ciErrNum |= clSetKernelArg(ckConvolutionRows, 3, sizeof(unsigned int), (void*)&imageW);\n    ciErrNum |= clSetKernelArg(ckConvolutionRows, 4, sizeof(unsigned int), (void*)&imageH);\n    ciErrNum |= clSetKernelArg(ckConvolutionRows, 5, sizeof(unsigned int), (void*)&imageW);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    localWorkSize[0] = ROWS_BLOCKDIM_X;\n    localWorkSize[1] = ROWS_BLOCKDIM_Y;\n    globalWorkSize[0] = imageW / ROWS_RESULT_STEPS;\n    globalWorkSize[1] = imageH;\n\n    ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckConvolutionRows, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n}\n\nextern \"C\" void convolutionColumns(\n    cl_command_queue cqCommandQueue,\n    cl_mem d_Dst,\n    cl_mem d_Src,\n    cl_mem c_Kernel,\n    cl_uint imageW,\n    cl_uint imageH\n){\n    cl_int ciErrNum;\n    size_t localWorkSize[2], globalWorkSize[2];\n\n    oclCheckError( COLUMNS_BLOCKDIM_Y * COLUMNS_HALO_STEPS >= KERNEL_RADIUS, shrTRUE );\n    oclCheckError( imageW % COLUMNS_BLOCKDIM_X == 0, shrTRUE );\n    oclCheckError( imageH % (COLUMNS_RESULT_STEPS * COLUMNS_BLOCKDIM_Y) == 0, shrTRUE );\n\n    if(!cqCommandQueue)\n        cqCommandQueue = cqDefaultCommandQueue;\n\n    ciErrNum  = clSetKernelArg(ckConvolutionColumns, 0, sizeof(cl_mem),       (void*)&d_Dst);\n    ciErrNum |= clSetKernelArg(ckConvolutionColumns, 1, sizeof(cl_mem),       (void*)&d_Src);\n    ciErrNum |= clSetKernelArg(ckConvolutionColumns, 2, sizeof(cl_mem),       (void*)&c_Kernel);\n    ciErrNum |= clSetKernelArg(ckConvolutionColumns, 3, sizeof(unsigned int), (void*)&imageW);\n    ciErrNum |= clSetKernelArg(ckConvolutionColumns, 4, sizeof(unsigned int), (void*)&imageH);\n    ciErrNum |= clSetKernelArg(ckConvolutionColumns, 5, sizeof(unsigned int), (void*)&imageW);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    localWorkSize[0] = COLUMNS_BLOCKDIM_X;\n    localWorkSize[1] = COLUMNS_BLOCKDIM_Y;\n    globalWorkSize[0] = imageW;\n    globalWorkSize[1] = imageH / COLUMNS_RESULT_STEPS;\n\n    ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckConvolutionColumns, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n}\n", "main.cpp": "\n#include \"oclConvolutionSeparable_common.h\"\n\n#include <shrQATest.h>\n\nint main(int argc, char **argv)\n{\n    cl_platform_id   cpPlatform;\n    cl_device_id*    cdDevices = NULL;\n    cl_context       cxGPUContext;                        //OpenCL context\n    cl_command_queue cqCommandQueue;                //OpenCL command queue\n    cl_mem c_Kernel, d_Input, d_Buffer, d_Output;   //OpenCL memory buffer objects\n    cl_float *h_Kernel, *h_Input, *h_Buffer, *h_OutputCPU, *h_OutputGPU;\n\n    cl_int ciErrNum;\n\n    const unsigned int imageW = 3072;\n    const unsigned int imageH = 3072;\n\n    shrQAStart(argc, argv);\n\n    // Get the NVIDIA platform\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    shrLog(\"clGetPlatformID...\\n\"); \n\n    //Get all the devices\n    cl_uint uiNumDevices = 0;           // Number of devices available\n    cl_uint uiTargetDevice = 0;\t        // Default Device to compute on\n    cl_uint uiNumComputeUnits;          // Number of compute units (SM's on NV GPU)\n    shrLog(\"Get the Device info and select Device...\\n\");\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiNumDevices);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    cdDevices = (cl_device_id *)malloc(uiNumDevices * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiNumDevices, cdDevices, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n\n    // Get command line device options and config accordingly\n    shrLog(\"  # of Devices Available = %u\\n\", uiNumDevices); \n    if(shrGetCmdLineArgumentu(argc, (const char**)argv, \"device\", &uiTargetDevice)== shrTRUE) \n    {\n        uiTargetDevice = CLAMP(uiTargetDevice, 0, (uiNumDevices - 1));\n    }\n    shrLog(\"  Using Device %u: \", uiTargetDevice); \n    oclPrintDevName(LOGBOTH, cdDevices[uiTargetDevice]);\n    ciErrNum = clGetDeviceInfo(cdDevices[uiTargetDevice], CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(uiNumComputeUnits), &uiNumComputeUnits, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    shrLog(\"\\n  # of Compute Units = %u\\n\", uiNumComputeUnits); \n\n    // set logfile name and start logs\n    shrSetLogFileName (\"oclConvolutionSeparable.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    shrLog(\"Allocating and initializing host memory...\\n\");\n        h_Kernel    = (cl_float *)malloc(KERNEL_LENGTH * sizeof(cl_float));\n        h_Input     = (cl_float *)malloc(imageW * imageH * sizeof(cl_float));\n        h_Buffer    = (cl_float *)malloc(imageW * imageH * sizeof(cl_float));\n        h_OutputCPU = (cl_float *)malloc(imageW * imageH * sizeof(cl_float));\n        h_OutputGPU = (cl_float *)malloc(imageW * imageH * sizeof(cl_float));\n\n        srand(2009);\n        for(unsigned int i = 0; i < KERNEL_LENGTH; i++)\n            h_Kernel[i] = (cl_float)(rand() % 16);\n\n        for(unsigned int i = 0; i < imageW * imageH; i++)\n            h_Input[i] = (cl_float)(rand() % 16);\n\n    shrLog(\"Initializing OpenCL...\\n\");\n        //Get the NVIDIA platform\n        ciErrNum = oclGetPlatformID(&cpPlatform);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Get the devices\n        ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 1, &cdDevices[uiTargetDevice], NULL);\n\n        //Create the context\n        cxGPUContext = clCreateContext(0, 1, &cdDevices[uiTargetDevice], NULL, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Create a command-queue\n        cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevices[uiTargetDevice], CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Initializing OpenCL separable convolution...\\n\");\n        initConvolutionSeparable(cxGPUContext, cqCommandQueue, (const char **)argv);\n\n    shrLog(\"Creating OpenCL memory objects...\\n\");\n        c_Kernel = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, KERNEL_LENGTH * sizeof(cl_float), h_Kernel, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_Input = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, imageW * imageH * sizeof(cl_float), h_Input, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_Buffer = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, imageW * imageH * sizeof(cl_float), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_Output = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, imageW * imageH * sizeof(cl_float), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Applying separable convolution to %u x %u image...\\n\\n\", imageW, imageH);\n        //Just a single run or a warmup iteration\n        convolutionRows(\n            NULL,\n            d_Buffer,\n            d_Input,\n            c_Kernel,\n            imageW,\n            imageH\n        );\n\n        convolutionColumns(\n            NULL,\n            d_Output,\n            d_Buffer,\n            c_Kernel,\n            imageW,\n            imageH\n        );\n\n#ifdef GPU_PROFILING\n    const int numIterations = 16;\n    cl_event startMark, endMark;\n    ciErrNum = clEnqueueMarker(cqCommandQueue, &startMark);\n    ciErrNum |= clFinish(cqCommandQueue);\n    shrCheckError(ciErrNum, CL_SUCCESS);\n    shrDeltaT(0);\n\n    for(int iter = 0; iter < numIterations; iter++){\n        convolutionRows(\n            cqCommandQueue,\n            d_Buffer,\n            d_Input,\n            c_Kernel,\n            imageW,\n            imageH\n        );\n\n        convolutionColumns(\n            cqCommandQueue,\n            d_Output,\n            d_Buffer,\n            c_Kernel,\n            imageW,\n            imageH\n        );\n    }\n    ciErrNum  = clEnqueueMarker(cqCommandQueue, &endMark);\n    ciErrNum |= clFinish(cqCommandQueue);\n    shrCheckError(ciErrNum, CL_SUCCESS);\n\n    //Calculate performance metrics by wallclock time\n    double gpuTime = shrDeltaT(0) / (double)numIterations;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclConvolutionSeparable, Throughput = %.4f MPixels/s, Time = %.5f s, Size = %u Pixels, NumDevsUsed = %i, Workgroup = %u\\n\",\n            (1.0e-6 * (double)(imageW * imageH)/ gpuTime), gpuTime, (imageW * imageH), 1, 0);\n\n    //Get OpenCL profiler  info\n    cl_ulong startTime = 0, endTime = 0;\n    ciErrNum  = clGetEventProfilingInfo(startMark, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &startTime, NULL);\n    ciErrNum |= clGetEventProfilingInfo(endMark, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &endTime, NULL);\n    shrCheckError(ciErrNum, CL_SUCCESS);\n    shrLog(\"\\nOpenCL time: %.5f s\\n\\n\", 1.0e-9 * ((double)endTime - (double)startTime)/ (double)numIterations);\n#endif\n\n    shrLog(\"Reading back OpenCL results...\\n\\n\");\n        ciErrNum = clEnqueueReadBuffer(cqCommandQueue, d_Output, CL_TRUE, 0, imageW * imageH * sizeof(cl_float), h_OutputGPU, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Comparing against Host/C++ computation...\\n\"); \n        convolutionRowHost(h_Buffer, h_Input, h_Kernel, imageW, imageH, KERNEL_RADIUS);\n        convolutionColumnHost(h_OutputCPU, h_Buffer, h_Kernel, imageW, imageH, KERNEL_RADIUS);\n        double sum = 0, delta = 0;\n        double L2norm;\n        for(unsigned int i = 0; i < imageW * imageH; i++){\n            delta += (h_OutputCPU[i] - h_OutputGPU[i]) * (h_OutputCPU[i] - h_OutputGPU[i]);\n            sum += h_OutputCPU[i] * h_OutputCPU[i];\n        }\n        L2norm = sqrt(delta / sum);\n        shrLog(\"Relative L2 norm: %.3e\\n\\n\", L2norm);\n\n    // cleanup\n    closeConvolutionSeparable();\n    ciErrNum  = clReleaseMemObject(d_Output);\n    ciErrNum |= clReleaseMemObject(d_Buffer);\n    ciErrNum |= clReleaseMemObject(d_Input);\n    ciErrNum |= clReleaseMemObject(c_Kernel);\n    ciErrNum |= clReleaseCommandQueue(cqCommandQueue);\n    ciErrNum |= clReleaseContext(cxGPUContext);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    free(h_OutputGPU);\n    free(h_OutputCPU);\n    free(h_Buffer);\n    free(h_Input);\n    free(h_Kernel);\n\n   if(cdDevices)free(cdDevices);\n\n    // finish\n    shrQAFinishExit(argc, (const char **)argv, (L2norm < 1e-6) ? QA_PASSED : QA_FAILED);\n}\n"}, "code_dirs": {"ConvolutionSeparable.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclConvolutionSeparable", "oclConvolutionSeparable_launcher.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclConvolutionSeparable/src", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclConvolutionSeparable/src"}}
{"kernel_name": "scan", "parallel_api": "cuda", "code": {"scan.cu": "#include <assert.h>\n#include <cooperative_groups.h>\n\nnamespace cg = cooperative_groups;\n#include <helper_cuda.h>\n\n#include \"scan_common.h\"\n\n#define THREADBLOCK_SIZE 256\n\ninline __device__ uint scan1Inclusive(uint idata, volatile uint *s_Data, uint size, cg::thread_block cta)\n{\n    uint pos    = 2 * threadIdx.x - (threadIdx.x & (size - 1));\n    s_Data[pos] = 0;\n    pos += size;\n    s_Data[pos] = idata;\n\n    for (uint offset = 1; offset < size; offset <<= 1) {\n        cg::sync(cta);\n        uint t = s_Data[pos] + s_Data[pos - offset];\n        cg::sync(cta);\n        s_Data[pos] = t;\n    }\n\n    return s_Data[pos];\n}\n\ninline __device__ uint scan1Exclusive(uint idata, volatile uint *s_Data, uint size, cg::thread_block cta)\n{\n    return scan1Inclusive(idata, s_Data, size, cta) - idata;\n}\n\ninline __device__ uint4 scan4Inclusive(uint4 idata4, volatile uint *s_Data, uint size, cg::thread_block cta)\n{\n    idata4.y += idata4.x;\n    idata4.z += idata4.y;\n    idata4.w += idata4.z;\n\n    uint oval = scan1Exclusive(idata4.w, s_Data, size / 4, cta);\n\n    idata4.x += oval;\n    idata4.y += oval;\n    idata4.z += oval;\n    idata4.w += oval;\n\n    return idata4;\n}\n\ninline __device__ uint4 scan4Exclusive(uint4 idata4, volatile uint *s_Data, uint size, cg::thread_block cta)\n{\n    uint4 odata4 = scan4Inclusive(idata4, s_Data, size, cta);\n    odata4.x -= idata4.x;\n    odata4.y -= idata4.y;\n    odata4.z -= idata4.z;\n    odata4.w -= idata4.w;\n    return odata4;\n}\n\n__global__ void scanExclusiveShared(uint4 *d_Dst, uint4 *d_Src, uint size)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ uint  s_Data[2 * THREADBLOCK_SIZE];\n\n    uint pos = blockIdx.x * blockDim.x + threadIdx.x;\n\n    uint4 idata4 = d_Src[pos];\n\n    uint4 odata4 = scan4Exclusive(idata4, s_Data, size, cta);\n\n    d_Dst[pos] = odata4;\n}\n\n__global__ void scanExclusiveShared2(uint *d_Buf, uint *d_Dst, uint *d_Src, uint N, uint arrayLength)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ uint  s_Data[2 * THREADBLOCK_SIZE];\n\n    uint pos = blockIdx.x * blockDim.x + threadIdx.x;\n\n    uint idata = 0;\n\n    if (pos < N)\n        idata = d_Dst[(4 * THREADBLOCK_SIZE) - 1 + (4 * THREADBLOCK_SIZE) * pos]\n              + d_Src[(4 * THREADBLOCK_SIZE) - 1 + (4 * THREADBLOCK_SIZE) * pos];\n\n    uint odata = scan1Exclusive(idata, s_Data, arrayLength, cta);\n\n    if (pos < N) {\n        d_Buf[pos] = odata;\n    }\n}\n\n__global__ void uniformUpdate(uint4 *d_Data, uint *d_Buffer)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ uint  buf;\n    uint             pos = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (threadIdx.x == 0) {\n        buf = d_Buffer[blockIdx.x];\n    }\n\n    cg::sync(cta);\n\n    uint4 data4 = d_Data[pos];\n    data4.x += buf;\n    data4.y += buf;\n    data4.z += buf;\n    data4.w += buf;\n    d_Data[pos] = data4;\n}\n\nextern \"C\" const uint MAX_BATCH_ELEMENTS   = 64 * 1048576;\nextern \"C\" const uint MIN_SHORT_ARRAY_SIZE = 4;\nextern \"C\" const uint MAX_SHORT_ARRAY_SIZE = 4 * THREADBLOCK_SIZE;\nextern \"C\" const uint MIN_LARGE_ARRAY_SIZE = 8 * THREADBLOCK_SIZE;\nextern \"C\" const uint MAX_LARGE_ARRAY_SIZE = 4 * THREADBLOCK_SIZE * THREADBLOCK_SIZE;\n\nstatic uint *d_Buf;\n\nextern \"C\" void initScan(void)\n{\n    checkCudaErrors(cudaMalloc((void **)&d_Buf, (MAX_BATCH_ELEMENTS / (4 * THREADBLOCK_SIZE)) * sizeof(uint)));\n}\n\nextern \"C\" void closeScan(void) { checkCudaErrors(cudaFree(d_Buf)); }\n\nstatic uint factorRadix2(uint &log2L, uint L)\n{\n    if (!L) {\n        log2L = 0;\n        return 0;\n    }\n    else {\n        for (log2L = 0; (L & 1) == 0; L >>= 1, log2L++)\n            ;\n\n        return L;\n    }\n}\n\nstatic uint iDivUp(uint dividend, uint divisor)\n{\n    return ((dividend % divisor) == 0) ? (dividend / divisor) : (dividend / divisor + 1);\n}\n\nextern \"C\" size_t scanExclusiveShort(uint *d_Dst, uint *d_Src, uint batchSize, uint arrayLength)\n{\n    uint log2L;\n    uint factorizationRemainder = factorRadix2(log2L, arrayLength);\n    assert(factorizationRemainder == 1);\n\n    assert((arrayLength >= MIN_SHORT_ARRAY_SIZE) && (arrayLength <= MAX_SHORT_ARRAY_SIZE));\n\n    assert((batchSize * arrayLength) <= MAX_BATCH_ELEMENTS);\n\n    assert((batchSize * arrayLength) % (4 * THREADBLOCK_SIZE) == 0);\n\n    scanExclusiveShared<<<(batchSize * arrayLength) / (4 * THREADBLOCK_SIZE), THREADBLOCK_SIZE>>>(\n        (uint4 *)d_Dst, (uint4 *)d_Src, arrayLength);\n    getLastCudaError(\"scanExclusiveShared() execution FAILED\\n\");\n\n    return THREADBLOCK_SIZE;\n}\n\nextern \"C\" size_t scanExclusiveLarge(uint *d_Dst, uint *d_Src, uint batchSize, uint arrayLength)\n{\n    uint log2L;\n    uint factorizationRemainder = factorRadix2(log2L, arrayLength);\n    assert(factorizationRemainder == 1);\n\n    assert((arrayLength >= MIN_LARGE_ARRAY_SIZE) && (arrayLength <= MAX_LARGE_ARRAY_SIZE));\n\n    assert((batchSize * arrayLength) <= MAX_BATCH_ELEMENTS);\n\n    scanExclusiveShared<<<(batchSize * arrayLength) / (4 * THREADBLOCK_SIZE), THREADBLOCK_SIZE>>>(\n        (uint4 *)d_Dst, (uint4 *)d_Src, 4 * THREADBLOCK_SIZE);\n    getLastCudaError(\"scanExclusiveShared() execution FAILED\\n\");\n\n    const uint blockCount2 = iDivUp((batchSize * arrayLength) / (4 * THREADBLOCK_SIZE), THREADBLOCK_SIZE);\n    scanExclusiveShared2<<<blockCount2, THREADBLOCK_SIZE>>>((uint *)d_Buf,\n                                                            (uint *)d_Dst,\n                                                            (uint *)d_Src,\n                                                            (batchSize * arrayLength) / (4 * THREADBLOCK_SIZE),\n                                                            arrayLength / (4 * THREADBLOCK_SIZE));\n    getLastCudaError(\"scanExclusiveShared2() execution FAILED\\n\");\n\n    uniformUpdate<<<(batchSize * arrayLength) / (4 * THREADBLOCK_SIZE), THREADBLOCK_SIZE>>>((uint4 *)d_Dst,\n                                                                                            (uint *)d_Buf);\n    getLastCudaError(\"uniformUpdate() execution FAILED\\n\");\n\n    return THREADBLOCK_SIZE;\n}\n", "main.cpp": "#include <cuda_runtime.h>\n#include <helper_cuda.h>\n#include <helper_functions.h>\n\n#include \"scan_common.h\"\n\nint main(int argc, char **argv)\n{\n    printf(\"%s Starting...\\n\\n\", argv[0]);\n\n    findCudaDevice(argc, (const char **)argv);\n\n    uint               *d_Input, *d_Output;\n    uint               *h_Input, *h_OutputCPU, *h_OutputGPU;\n    StopWatchInterface *hTimer = NULL;\n    const uint          N      = 13 * 1048576 / 2;\n\n    printf(\"Allocating and initializing host arrays...\\n\");\n    sdkCreateTimer(&hTimer);\n    h_Input     = (uint *)malloc(N * sizeof(uint));\n    h_OutputCPU = (uint *)malloc(N * sizeof(uint));\n    h_OutputGPU = (uint *)malloc(N * sizeof(uint));\n    srand(2009);\n\n    for (uint i = 0; i < N; i++) {\n        h_Input[i] = rand();\n    }\n\n    printf(\"Allocating and initializing CUDA arrays...\\n\");\n    checkCudaErrors(cudaMalloc((void **)&d_Input, N * sizeof(uint)));\n    checkCudaErrors(cudaMalloc((void **)&d_Output, N * sizeof(uint)));\n    checkCudaErrors(cudaMemcpy(d_Input, h_Input, N * sizeof(uint), cudaMemcpyHostToDevice));\n\n    printf(\"Initializing CUDA-C scan...\\n\\n\");\n    initScan();\n\n    int       globalFlag = 1;\n    size_t    szWorkgroup;\n    const int iCycles = 100;\n    printf(\"*** Running GPU scan for short arrays (%d identical iterations)...\\n\\n\", iCycles);\n\n    for (uint arrayLength = MIN_SHORT_ARRAY_SIZE; arrayLength <= MAX_SHORT_ARRAY_SIZE; arrayLength <<= 1) {\n        printf(\"Running scan for %u elements (%u arrays)...\\n\", arrayLength, N / arrayLength);\n        checkCudaErrors(cudaDeviceSynchronize());\n        sdkResetTimer(&hTimer);\n        sdkStartTimer(&hTimer);\n\n        for (int i = 0; i < iCycles; i++) {\n            szWorkgroup = scanExclusiveShort(d_Output, d_Input, N / arrayLength, arrayLength);\n        }\n\n        checkCudaErrors(cudaDeviceSynchronize());\n        sdkStopTimer(&hTimer);\n        double timerValue = 1.0e-3 * sdkGetTimerValue(&hTimer) / iCycles;\n\n        printf(\"Validating the results...\\n\");\n        printf(\"...reading back GPU results\\n\");\n        checkCudaErrors(cudaMemcpy(h_OutputGPU, d_Output, N * sizeof(uint), cudaMemcpyDeviceToHost));\n\n        printf(\" ...scanExclusiveHost()\\n\");\n        scanExclusiveHost(h_OutputCPU, h_Input, N / arrayLength, arrayLength);\n\n        printf(\" ...comparing the results\\n\");\n        int localFlag = 1;\n\n        for (uint i = 0; i < N; i++) {\n            if (h_OutputCPU[i] != h_OutputGPU[i]) {\n                localFlag = 0;\n                break;\n            }\n        }\n\n        printf(\" ...Results %s\\n\\n\", (localFlag == 1) ? \"Match\" : \"DON'T Match !!!\");\n        globalFlag = globalFlag && localFlag;\n\n        if (arrayLength == MAX_SHORT_ARRAY_SIZE) {\n            printf(\"\\n\");\n            printf(\"scan, Throughput = %.4f MElements/s, Time = %.5f s, Size = %u \"\n                   \"Elements, NumDevsUsed = %u, Workgroup = %u\\n\",\n                   (1.0e-6 * (double)arrayLength / timerValue),\n                   timerValue,\n                   (unsigned int)arrayLength,\n                   1,\n                   (unsigned int)szWorkgroup);\n            printf(\"\\n\");\n        }\n    }\n\n    printf(\"***Running GPU scan for large arrays (%u identical iterations)...\\n\\n\", iCycles);\n\n    for (uint arrayLength = MIN_LARGE_ARRAY_SIZE; arrayLength <= MAX_LARGE_ARRAY_SIZE; arrayLength <<= 1) {\n        printf(\"Running scan for %u elements (%u arrays)...\\n\", arrayLength, N / arrayLength);\n        checkCudaErrors(cudaDeviceSynchronize());\n        sdkResetTimer(&hTimer);\n        sdkStartTimer(&hTimer);\n\n        for (int i = 0; i < iCycles; i++) {\n            szWorkgroup = scanExclusiveLarge(d_Output, d_Input, N / arrayLength, arrayLength);\n        }\n\n        checkCudaErrors(cudaDeviceSynchronize());\n        sdkStopTimer(&hTimer);\n        double timerValue = 1.0e-3 * sdkGetTimerValue(&hTimer) / iCycles;\n\n        printf(\"Validating the results...\\n\");\n        printf(\"...reading back GPU results\\n\");\n        checkCudaErrors(cudaMemcpy(h_OutputGPU, d_Output, N * sizeof(uint), cudaMemcpyDeviceToHost));\n\n        printf(\"...scanExclusiveHost()\\n\");\n        scanExclusiveHost(h_OutputCPU, h_Input, N / arrayLength, arrayLength);\n\n        printf(\" ...comparing the results\\n\");\n        int localFlag = 1;\n\n        for (uint i = 0; i < N; i++) {\n            if (h_OutputCPU[i] != h_OutputGPU[i]) {\n                localFlag = 0;\n                break;\n            }\n        }\n\n        printf(\" ...Results %s\\n\\n\", (localFlag == 1) ? \"Match\" : \"DON'T Match !!!\");\n        globalFlag = globalFlag && localFlag;\n\n        if (arrayLength == MAX_LARGE_ARRAY_SIZE) {\n            printf(\"\\n\");\n            printf(\"scan, Throughput = %.4f MElements/s, Time = %.5f s, Size = %u \"\n                   \"Elements, NumDevsUsed = %u, Workgroup = %u\\n\",\n                   (1.0e-6 * (double)arrayLength / timerValue),\n                   timerValue,\n                   (unsigned int)arrayLength,\n                   1,\n                   (unsigned int)szWorkgroup);\n            printf(\"\\n\");\n        }\n    }\n\n    printf(\"Shutting down...\\n\");\n    closeScan();\n    checkCudaErrors(cudaFree(d_Output));\n    checkCudaErrors(cudaFree(d_Input));\n\n    sdkDeleteTimer(&hTimer);\n\n    exit(globalFlag ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n"}, "code_dirs": {"scan.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/scan", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/scan"}}
{"kernel_name": "scan", "parallel_api": "ocl", "code": {"Scan.cl": "//#define WORKGROUP_SIZE 256\n\n#if(1)\n    inline uint scan1Inclusive(uint idata, __local uint *l_Data, uint size){\n        uint pos = 2 * get_local_id(0) - (get_local_id(0) & (size - 1));\n        l_Data[pos] = 0;\n        pos += size;\n        l_Data[pos] = idata;\n\n        for(uint offset = 1; offset < size; offset <<= 1){\n            barrier(CLK_LOCAL_MEM_FENCE);\n            uint t = l_Data[pos] + l_Data[pos - offset];\n            barrier(CLK_LOCAL_MEM_FENCE);\n            l_Data[pos] = t;\n        }\n\n        return l_Data[pos];\n    }\n\n    inline uint scan1Exclusive(uint idata, __local uint *l_Data, uint size){\n        return scan1Inclusive(idata, l_Data, size) - idata;\n    }\n\n#else\n    #define LOG2_WARP_SIZE 5U\n    #define      WARP_SIZE (1U << LOG2_WARP_SIZE)\n\n    //Almost the same as naive scan1Inclusive but doesn't need barriers\n    //and works only for size <= WARP_SIZE\n    inline uint warpScanInclusive(uint idata, volatile __local uint *l_Data, uint size){\n        uint pos = 2 * get_local_id(0) - (get_local_id(0) & (size - 1));\n        l_Data[pos] = 0;\n        pos += size;\n        l_Data[pos] = idata;\n\n        if(size >=  2) l_Data[pos] += l_Data[pos -  1];\n        if(size >=  4) l_Data[pos] += l_Data[pos -  2];\n        if(size >=  8) l_Data[pos] += l_Data[pos -  4];\n        if(size >= 16) l_Data[pos] += l_Data[pos -  8];\n        if(size >= 32) l_Data[pos] += l_Data[pos - 16];\n\n        return l_Data[pos];\n    }\n\n    inline uint warpScanExclusive(uint idata, __local uint *l_Data, uint size){\n        return warpScanInclusive(idata, l_Data, size) - idata;\n    }\n\n    inline uint scan1Inclusive(uint idata, __local uint *l_Data, uint size){\n        if(size > WARP_SIZE){\n            uint warpResult = warpScanInclusive(idata, l_Data, WARP_SIZE);\n\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if( (get_local_id(0) & (WARP_SIZE - 1)) == (WARP_SIZE - 1) )\n                l_Data[get_local_id(0) >> LOG2_WARP_SIZE] = warpResult;\n\n            barrier(CLK_LOCAL_MEM_FENCE);\n            if( get_local_id(0) < (WORKGROUP_SIZE / WARP_SIZE) ){\n                //grab top warp elements\n                uint val = l_Data[get_local_id(0)];\n                //calculate exclsive scan and write back to shared memory\n                l_Data[get_local_id(0)] = warpScanExclusive(val, l_Data, size >> LOG2_WARP_SIZE);\n            }\n\n            barrier(CLK_LOCAL_MEM_FENCE);\n            return warpResult + l_Data[get_local_id(0) >> LOG2_WARP_SIZE];\n        }else{\n            return warpScanInclusive(idata, l_Data, size);\n        }\n    }\n\n    inline uint scan1Exclusive(uint idata, __local uint *l_Data, uint size){\n        return scan1Inclusive(idata, l_Data, size) - idata;\n    }\n#endif\n\n\ninline uint4 scan4Inclusive(uint4 data4, __local uint *l_Data, uint size){\n    data4.y += data4.x;\n    data4.z += data4.y;\n    data4.w += data4.z;\n\n    //Level-1 exclusive scan\n    uint val = scan1Inclusive(data4.w, l_Data, size / 4) - data4.w;\n\n    return (data4 + (uint4)val);\n}\n\ninline uint4 scan4Exclusive(uint4 data4, __local uint *l_Data, uint size){\n    return scan4Inclusive(data4, l_Data, size) - data4;\n}\n\n__kernel __attribute__((reqd_work_group_size(WORKGROUP_SIZE, 1, 1)))\nvoid scanExclusiveLocal1(\n    __global uint4 *d_Dst,\n    __global uint4 *d_Src,\n    __local uint *l_Data,\n    uint size\n){\n    //Load data\n    uint4 idata4 = d_Src[get_global_id(0)];\n\n    //Calculate exclusive scan\n    uint4 odata4  = scan4Exclusive(idata4, l_Data, size);\n\n    //Write back\n    d_Dst[get_global_id(0)] = odata4;\n}\n\n__kernel __attribute__((reqd_work_group_size(WORKGROUP_SIZE, 1, 1)))\nvoid scanExclusiveLocal2(\n    __global uint *d_Buf,\n    __global uint *d_Dst,\n    __global uint *d_Src,\n    __local uint *l_Data,\n    uint N,\n    uint arrayLength\n){\n    uint data = 0;\n    if(get_global_id(0) < N)\n    data =\n        d_Dst[(4 * WORKGROUP_SIZE - 1) + (4 * WORKGROUP_SIZE) * get_global_id(0)] + \n        d_Src[(4 * WORKGROUP_SIZE - 1) + (4 * WORKGROUP_SIZE) * get_global_id(0)];\n\n    //Compute\n    uint odata = scan1Exclusive(data, l_Data, arrayLength);\n\n    //Avoid out-of-bound access\n    if(get_global_id(0) < N)\n        d_Buf[get_global_id(0)] = odata;\n}\n\n__kernel __attribute__((reqd_work_group_size(WORKGROUP_SIZE, 1, 1)))\nvoid uniformUpdate(\n    __global uint4 *d_Data,\n    __global uint *d_Buf\n){\n    __local uint buf[1];\n\n    uint4 data4 = d_Data[get_global_id(0)];\n\n    if(get_local_id(0) == 0)\n        buf[0] = d_Buf[get_group_id(0)];\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n    data4 += (uint4)buf[0];\n    d_Data[get_global_id(0)] = data4;\n}\n", "oclScan_launcher.cpp": "\n#include \"oclScan_common.h\"\n\nstatic cl_program\n    cpProgram;\n\n//OpenCL scan kernel handles\nstatic cl_kernel\n    ckScanExclusiveLocal1, ckScanExclusiveLocal2, ckUniformUpdate;\n\nstatic cl_mem\n    d_Buffer;\n\n//All three kernels run 512 threads per workgroup\n//Must be a power of two\nstatic const uint  WORKGROUP_SIZE = 256;\nstatic const char *compileOptions = \"-D WORKGROUP_SIZE=256\";\n\nextern \"C\" void initScan(cl_context cxGPUContext, cl_command_queue cqParamCommandQue, const char **argv){\n    cl_int ciErrNum;\n    size_t kernelLength;\n\n    shrLog(\" ...loading Scan.cl\\n\");\n        char *cScan = oclLoadProgSource(shrFindFilePath(\"Scan.cl\", argv[0]), \"// My comment\\n\", &kernelLength);\n        oclCheckError(cScan != NULL, shrTRUE);\n\n    shrLog(\" ...creating scan program\\n\");\n        cpProgram = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&cScan, &kernelLength, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\" ...building scan program\\n\");\n        ciErrNum = clBuildProgram(cpProgram, 0, NULL, compileOptions, NULL, NULL);\n\t\tif (ciErrNum != CL_SUCCESS)\n\t\t{\n\t\t\t// write out standard error, Build Log and PTX, then cleanup and exit\n\t\t\tshrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n\t\t\toclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n\t\t\toclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclScan.ptx\");\n\t\t\toclCheckError(ciErrNum, CL_SUCCESS); \n\t\t}\n\n    shrLog(\" ...creating scan kernels\\n\");\n        ckScanExclusiveLocal1 = clCreateKernel(cpProgram, \"scanExclusiveLocal1\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ckScanExclusiveLocal2 = clCreateKernel(cpProgram, \"scanExclusiveLocal2\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ckUniformUpdate = clCreateKernel(cpProgram, \"uniformUpdate\", &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog( \" ...checking minimum supported workgroup size\\n\");\n        //Check for work group size\n        cl_device_id device;\n        size_t szScanExclusiveLocal1, szScanExclusiveLocal2, szUniformUpdate;\n\n        ciErrNum  = clGetCommandQueueInfo(cqParamCommandQue, CL_QUEUE_DEVICE, sizeof(cl_device_id), &device, NULL);\n        ciErrNum |= clGetKernelWorkGroupInfo(ckScanExclusiveLocal1,  device, CL_KERNEL_WORK_GROUP_SIZE, sizeof(size_t), &szScanExclusiveLocal1, NULL);\n        ciErrNum |= clGetKernelWorkGroupInfo(ckScanExclusiveLocal2, device, CL_KERNEL_WORK_GROUP_SIZE, sizeof(size_t), &szScanExclusiveLocal2, NULL);\n        ciErrNum |= clGetKernelWorkGroupInfo(ckUniformUpdate, device, CL_KERNEL_WORK_GROUP_SIZE, sizeof(size_t), &szUniformUpdate, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        if( (szScanExclusiveLocal1 < WORKGROUP_SIZE) || (szScanExclusiveLocal2 < WORKGROUP_SIZE) || (szUniformUpdate < WORKGROUP_SIZE) ){\n            shrLog(\"\\nERROR !!! Minimum work-group size %u required by this application is not supported on this device.\\n\\n\", WORKGROUP_SIZE);\n            closeScan();\n            free(cScan);\n            shrLogEx(LOGBOTH | CLOSELOG, 0, \"Exiting...\\n\");\n            exit(EXIT_FAILURE);\n        }\n\n    shrLog(\" ...allocating internal buffers\\n\");\n        d_Buffer = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, (MAX_BATCH_ELEMENTS / (4 * WORKGROUP_SIZE)) * sizeof(uint), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    //Discard temp storage\n    free(cScan);\n}\n\nextern \"C\" void closeScan(void){\n    cl_int ciErrNum;\n    ciErrNum  = clReleaseMemObject(d_Buffer);\n    ciErrNum |= clReleaseKernel(ckUniformUpdate);\n    ciErrNum |= clReleaseKernel(ckScanExclusiveLocal2);\n    ciErrNum |= clReleaseKernel(ckScanExclusiveLocal1);\n    ciErrNum |= clReleaseProgram(cpProgram);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n}\n\nextern \"C\" const uint MAX_BATCH_ELEMENTS = 64 * 1048576;\nextern \"C\" const uint MIN_SHORT_ARRAY_SIZE = 4;\nextern \"C\" const uint MAX_SHORT_ARRAY_SIZE = 4 * WORKGROUP_SIZE;\nextern \"C\" const uint MIN_LARGE_ARRAY_SIZE = 8 * WORKGROUP_SIZE;\nextern \"C\" const uint MAX_LARGE_ARRAY_SIZE = 4 * WORKGROUP_SIZE * WORKGROUP_SIZE;\n\nstatic uint iSnapUp(uint dividend, uint divisor){\n    return ((dividend % divisor) == 0) ? dividend : (dividend - dividend % divisor + divisor);\n}\n\nstatic uint factorRadix2(uint& log2L, uint L){\n    if(!L){\n        log2L = 0;\n        return 0;\n    }else{\n        for(log2L = 0; (L & 1) == 0; L >>= 1, log2L++);\n        return L;\n    }\n}\n\nstatic size_t scanExclusiveLocal1(\n    cl_command_queue cqCommandQueue,\n    cl_mem d_Dst,\n    cl_mem d_Src,\n    uint n,\n    uint size\n){\n    cl_int ciErrNum;\n    size_t localWorkSize, globalWorkSize;\n\n    ciErrNum  = clSetKernelArg(ckScanExclusiveLocal1, 0, sizeof(cl_mem), (void *)&d_Dst);\n    ciErrNum |= clSetKernelArg(ckScanExclusiveLocal1, 1, sizeof(cl_mem), (void *)&d_Src);\n    ciErrNum |= clSetKernelArg(ckScanExclusiveLocal1, 2, 2 * WORKGROUP_SIZE * sizeof(uint), NULL);\n    ciErrNum |= clSetKernelArg(ckScanExclusiveLocal1, 3, sizeof(uint), (void *)&size);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    localWorkSize = WORKGROUP_SIZE;\n    globalWorkSize = (n * size) / 4;\n\n    ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckScanExclusiveLocal1, 1, NULL, &globalWorkSize, &localWorkSize, 0, NULL, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    return localWorkSize;\n}\n\nextern \"C\" size_t scanExclusiveShort(\n    cl_command_queue cqCommandQueue,\n    cl_mem d_Dst,\n    cl_mem d_Src,\n    uint batchSize,\n    uint arrayLength\n){\n    //Check power-of-two factorization\n    uint log2L;\n    uint factorizationRemainder = factorRadix2(log2L, arrayLength);\n    oclCheckError( factorizationRemainder == 1, shrTRUE);\n\n    //Check supported size range\n    oclCheckError( (arrayLength >= MIN_SHORT_ARRAY_SIZE) && (arrayLength <= MAX_SHORT_ARRAY_SIZE), shrTRUE );\n\n    //Check total batch size limit\n    oclCheckError( (batchSize * arrayLength) <= MAX_BATCH_ELEMENTS, shrTRUE );\n\n    //Check all work-groups to be fully packed with data\n    oclCheckError( (batchSize * arrayLength) % (4 * WORKGROUP_SIZE) == 0, shrTRUE);\n\n    return scanExclusiveLocal1(\n        cqCommandQueue,\n        d_Dst,\n        d_Src,\n        batchSize,\n        arrayLength\n    );\n}\n\nstatic void scanExclusiveLocal2(\n    cl_command_queue cqCommandQueue,\n    cl_mem d_Buffer,\n    cl_mem d_Dst,\n    cl_mem d_Src,\n    uint n,\n    uint size\n){\n    cl_int ciErrNum;\n    size_t localWorkSize, globalWorkSize;\n\n    uint elements = n * size;\n    ciErrNum  = clSetKernelArg(ckScanExclusiveLocal2, 0, sizeof(cl_mem), (void *)&d_Buffer);\n    ciErrNum |= clSetKernelArg(ckScanExclusiveLocal2, 1, sizeof(cl_mem), (void *)&d_Dst);\n    ciErrNum |= clSetKernelArg(ckScanExclusiveLocal2, 2, sizeof(cl_mem), (void *)&d_Src);\n    ciErrNum |= clSetKernelArg(ckScanExclusiveLocal2, 3, 2 * WORKGROUP_SIZE * sizeof(uint), NULL);\n    ciErrNum |= clSetKernelArg(ckScanExclusiveLocal2, 4, sizeof(uint), (void *)&elements);\n    ciErrNum |= clSetKernelArg(ckScanExclusiveLocal2, 5, sizeof(uint), (void *)&size);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    localWorkSize = WORKGROUP_SIZE;\n    globalWorkSize = iSnapUp(elements, WORKGROUP_SIZE);\n\n    ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckScanExclusiveLocal2, 1, NULL, &globalWorkSize, &localWorkSize, 0, NULL, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n}\n\nstatic size_t uniformUpdate(\n    cl_command_queue cqCommandQueue,\n    cl_mem d_Dst,\n    cl_mem d_Buffer,\n    uint n\n){\n    cl_int ciErrNum;\n    size_t localWorkSize, globalWorkSize;\n\n    ciErrNum  = clSetKernelArg(ckUniformUpdate, 0, sizeof(cl_mem), (void *)&d_Dst);\n    ciErrNum |= clSetKernelArg(ckUniformUpdate, 1, sizeof(cl_mem), (void *)&d_Buffer);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    localWorkSize = WORKGROUP_SIZE;\n    globalWorkSize = n * WORKGROUP_SIZE;\n\n    ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckUniformUpdate, 1, NULL, &globalWorkSize, &localWorkSize, 0, NULL, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    return localWorkSize;\n}\n\nextern \"C\" size_t scanExclusiveLarge(\n    cl_command_queue cqCommandQueue,\n    cl_mem d_Dst,\n    cl_mem d_Src,\n    uint batchSize,\n    uint arrayLength\n){\n    //Check power-of-two factorization\n    uint log2L;\n    uint factorizationRemainder = factorRadix2(log2L, arrayLength);\n    oclCheckError( factorizationRemainder == 1, shrTRUE);\n\n    //Check supported size range\n    oclCheckError( (arrayLength >= MIN_LARGE_ARRAY_SIZE) && (arrayLength <= MAX_LARGE_ARRAY_SIZE), shrTRUE );\n\n    //Check total batch size limit\n    oclCheckError( (batchSize * arrayLength) <= MAX_BATCH_ELEMENTS, shrTRUE );\n\n    scanExclusiveLocal1(\n        cqCommandQueue,\n        d_Dst,\n        d_Src,\n        (batchSize * arrayLength) / (4 * WORKGROUP_SIZE),\n        4 * WORKGROUP_SIZE\n    );\n\n    scanExclusiveLocal2(\n        cqCommandQueue,\n        d_Buffer,\n        d_Dst,\n        d_Src,\n        batchSize,\n        arrayLength / (4 * WORKGROUP_SIZE)\n    );\n\n    return uniformUpdate(\n        cqCommandQueue,\n        d_Dst,\n        d_Buffer,\n        (batchSize * arrayLength) / (4 * WORKGROUP_SIZE)\n    );\n}\n", "main.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n\n#include \"oclScan_common.h\"\n\nint main(int argc, const char **argv)\n{\n    shrQAStart(argc, (char **)argv);\n\n    shrSetLogFileName (\"oclScan.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    cl_platform_id cpPlatform;\n    cl_device_id cdDevice;\n    cl_context cxGPUContext;\n    cl_command_queue cqCommandQueue;\n    cl_mem d_Input, d_Output;\n\n    cl_int ciErrNum;\n    uint *h_Input, *h_OutputCPU, *h_OutputGPU;\n    const uint N = 13 * 1048576 / 2;\n\n    shrLog(\"Allocating and initializing host arrays...\\n\");\n        h_Input     = (uint *)malloc(N * sizeof(uint));\n        h_OutputCPU = (uint *)malloc(N * sizeof(uint));\n        h_OutputGPU = (uint *)malloc(N * sizeof(uint));\n        srand(2009);\n        for(uint i = 0; i < N; i++)\n            h_Input[i] = rand();\n\n    shrLog(\"Initializing OpenCL...\\n\");\n        //Get the NVIDIA platform\n        ciErrNum = oclGetPlatformID(&cpPlatform);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Get a GPU device\n        ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 1, &cdDevice, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Create the context\n        cxGPUContext = clCreateContext(0, 1, &cdDevice, NULL, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        //Create a command-queue\n        cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevice, 0, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Initializing OpenCL scan...\\n\");\n        initScan(cxGPUContext, cqCommandQueue, argv);\n\n    shrLog(\"Creating OpenCL memory objects...\\n\\n\");\n        d_Input = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE | CL_MEM_COPY_HOST_PTR, N * sizeof(uint), h_Input, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_Output = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, N * sizeof(uint), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    int globalFlag = 1; // init pass/fail flag to pass\n    size_t szWorkgroup;\n    const int iCycles = 100;\n    shrLog(\"*** Running GPU scan for short arrays (%d identical iterations)...\\n\\n\", iCycles);\n    for(uint arrayLength = MIN_SHORT_ARRAY_SIZE; arrayLength <= MAX_SHORT_ARRAY_SIZE; arrayLength *= 2)\n    {\n        shrLog(\"Running scan for %u elements (%u arrays)...\\n\", arrayLength, N / arrayLength);\n            clFinish(cqCommandQueue);\n            shrDeltaT(0);\n            for (int i = 0; i<iCycles; i++)\n            {\n                szWorkgroup = scanExclusiveShort(\n                    cqCommandQueue,\n                    d_Output,\n                    d_Input,\n                    N / arrayLength,\n                    arrayLength\n                );\n            }\n            clFinish(cqCommandQueue);\n            double timerValue = shrDeltaT(0)/(double)iCycles;\n\n        shrLog(\"Validating the results...\\n\"); \n            shrLog(\" ...reading back OpenCL memory\\n\");\n                ciErrNum = clEnqueueReadBuffer(cqCommandQueue, d_Output, CL_TRUE, 0, N * sizeof(uint), h_OutputGPU, 0, NULL, NULL);\n                oclCheckError(ciErrNum, CL_SUCCESS);\n\n            shrLog(\" ...scanExclusiveHost()\\n\");\n                scanExclusiveHost(\n                    h_OutputCPU,\n                    h_Input,\n                    N / arrayLength,\n                    arrayLength\n                );\n\n            // Compare GPU results with CPU results and accumulate error for this test\n            shrLog(\" ...comparing the results\\n\");\n                int localFlag = 1;\n                for(uint i = 0; i < N; i++)\n                {\n                    if(h_OutputCPU[i] != h_OutputGPU[i])\n                    {\n                        localFlag = 0;\n                        break;\n                    }\n                }\n\n            // Log message on individual test result, then accumulate to global flag\n            shrLog(\" ...Results %s\\n\\n\", (localFlag == 1) ? \"Match\" : \"DON'T Match !!!\");\n            globalFlag = globalFlag && localFlag;\n\n            #ifdef GPU_PROFILING\n                if (arrayLength == MAX_SHORT_ARRAY_SIZE)\n                {\n                    shrLog(\"\\n\");\n                    shrLogEx(LOGBOTH | MASTER, 0, \"oclScan-Short, Throughput = %.4f MElements/s, Time = %.5f s, Size = %u Elements, NumDevsUsed = %u, Workgroup = %u\\n\", \n                           (1.0e-6 * (double)arrayLength/timerValue), timerValue, arrayLength, 1, szWorkgroup);\n                    shrLog(\"\\n\");\n                }\n            #endif\n    }\n\n    shrLog(\"*** Running GPU scan for large arrays (%d identical iterations)...\\n\\n\", iCycles);\n    for(uint arrayLength = MIN_LARGE_ARRAY_SIZE; arrayLength <= MAX_LARGE_ARRAY_SIZE; arrayLength *= 2)\n    {\n        shrLog(\"Running scan for %u elements (%u arrays)...\\n\", arrayLength, N / arrayLength);\n            clFinish(cqCommandQueue);\n            shrDeltaT(0);\n            for (int i = 0; i<iCycles; i++)\n            {\n                szWorkgroup = scanExclusiveLarge(\n                    cqCommandQueue,\n                    d_Output,\n                    d_Input,\n                    N / arrayLength,\n                    arrayLength\n                );\n            }\n            clFinish(cqCommandQueue);\n            double timerValue = shrDeltaT(0)/(double)iCycles;\n\n        shrLog(\"Validating the results...\\n\"); \n            shrLog(\" ...reading back OpenCL memory\\n\");\n                ciErrNum = clEnqueueReadBuffer(cqCommandQueue, d_Output, CL_TRUE, 0, N * sizeof(uint), h_OutputGPU, 0, NULL, NULL);\n                oclCheckError(ciErrNum, CL_SUCCESS);\n\n            shrLog(\" ...scanExclusiveHost()\\n\");\n                scanExclusiveHost(\n                    h_OutputCPU,\n                    h_Input,\n                    N / arrayLength,\n                    arrayLength\n                );\n\n            // Compare GPU results with CPU results and accumulate error for this test\n            shrLog(\" ...comparing the results\\n\");\n                int localFlag = 1;\n                for(uint i = 0; i < N; i++)\n                {\n                    if(h_OutputCPU[i] != h_OutputGPU[i])\n                    {\n                        localFlag = 0;\n                        break;\n                    }\n                }\n\n            shrLog(\" ...Results %s\\n\\n\", (localFlag == 1) ? \"Match\" : \"DON'T Match !!!\");\n            globalFlag = globalFlag && localFlag;\n\n            #ifdef GPU_PROFILING\n                if (arrayLength == MAX_LARGE_ARRAY_SIZE)\n                {\n                    shrLog(\"\\n\");\n                    shrLogEx(LOGBOTH | MASTER, 0, \"oclScan-Large, Throughput = %.4f MElements/s, Time = %.5f s, Size = %u Elements, NumDevsUsed = %u, Workgroup = %u\\n\", \n                           (1.0e-6 * (double)arrayLength/timerValue), timerValue, arrayLength, 1, szWorkgroup);\n                    shrLog(\"\\n\");\n                }\n            #endif\n    }\n\n    shrLog(\"Shutting down...\\n\");\n        closeScan();\n\n        ciErrNum  = clReleaseMemObject(d_Output);\n        ciErrNum |= clReleaseMemObject(d_Input);\n        ciErrNum |= clReleaseCommandQueue(cqCommandQueue);\n        ciErrNum |= clReleaseContext(cxGPUContext);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        free(h_OutputGPU);\n        free(h_OutputCPU);\n        free(h_Input);\n\n    shrQAFinishExit(argc, (const char **)argv, globalFlag ? QA_PASSED : QA_FAILED);\n    shrEXIT(argc, argv);\n}\n"}, "code_dirs": {"Scan.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclScan", "oclScan_launcher.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclScan/src", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclScan/src"}}
{"kernel_name": "boxFilter", "parallel_api": "cuda", "code": {"boxFilter_kernel.cu": "#ifndef _BOXFILTER_KERNEL_CH_\n#define _BOXFILTER_KERNEL_CH_\n\n#include <helper_functions.h>\n#include <helper_math.h>\n\ncudaTextureObject_t tex;\ncudaTextureObject_t texTempArray;\ncudaTextureObject_t rgbaTex;\ncudaTextureObject_t rgbaTexTempArray;\ncudaArray          *d_array, *d_tempArray;\n\n#define checkCudaErrors(err) __checkCudaErrors(err, __FILE__, __LINE__)\n\ninline void __checkCudaErrors(cudaError err, const char *file, const int line)\n{\n    if (cudaSuccess != err) {\n        fprintf(stderr, \"%s(%i) : CUDA Runtime API error %d: %s.\\n\", file, line, (int)err, cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n}\n\n__device__ void d_boxfilter_x(float *id, float *od, int w, int h, int r)\n{\n    float scale = 1.0f / (float)((r << 1) + 1);\n\n    float t;\n    t = id[0] * r;\n\n    for (int x = 0; x < (r + 1); x++) {\n        t += id[x];\n    }\n\n    od[0] = t * scale;\n\n    for (int x = 1; x < (r + 1); x++) {\n        t += id[x + r];\n        t -= id[0];\n        od[x] = t * scale;\n    }\n\n    for (int x = (r + 1); x < w - r; x++) {\n        t += id[x + r];\n        t -= id[x - r - 1];\n        od[x] = t * scale;\n    }\n\n    for (int x = w - r; x < w; x++) {\n        t += id[w - 1];\n        t -= id[x - r - 1];\n        od[x] = t * scale;\n    }\n}\n\n__device__ void d_boxfilter_y(float *id, float *od, int w, int h, int r)\n{\n    float scale = 1.0f / (float)((r << 1) + 1);\n\n    float t;\n    t = id[0] * r;\n\n    for (int y = 0; y < (r + 1); y++) {\n        t += id[y * w];\n    }\n\n    od[0] = t * scale;\n\n    for (int y = 1; y < (r + 1); y++) {\n        t += id[(y + r) * w];\n        t -= id[0];\n        od[y * w] = t * scale;\n    }\n\n    for (int y = (r + 1); y < (h - r); y++) {\n        t += id[(y + r) * w];\n        t -= id[((y - r) * w) - w];\n        od[y * w] = t * scale;\n    }\n\n    for (int y = h - r; y < h; y++) {\n        t += id[(h - 1) * w];\n        t -= id[((y - r) * w) - w];\n        od[y * w] = t * scale;\n    }\n}\n\n__global__ void d_boxfilter_x_global(float *id, float *od, int w, int h, int r)\n{\n    unsigned int y = blockIdx.x * blockDim.x + threadIdx.x;\n    d_boxfilter_x(&id[y * w], &od[y * w], w, h, r);\n}\n\n__global__ void d_boxfilter_y_global(float *id, float *od, int w, int h, int r)\n{\n    unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;\n    d_boxfilter_y(&id[x], &od[x], w, h, r);\n}\n\n__global__ void d_boxfilter_x_tex(float *od, int w, int h, int r, cudaTextureObject_t tex)\n{\n    float        scale = 1.0f / (float)((r << 1) + 1);\n    unsigned int y     = blockIdx.x * blockDim.x + threadIdx.x;\n\n    float t = 0.0f;\n\n    for (int x = -r; x <= r; x++) {\n        t += tex2D<float>(tex, x, y);\n    }\n\n    od[y * w] = t * scale;\n\n    for (int x = 1; x < w; x++) {\n        t += tex2D<float>(tex, x + r, y);\n        t -= tex2D<float>(tex, x - r - 1, y);\n        od[y * w + x] = t * scale;\n    }\n}\n\n__global__ void d_boxfilter_y_tex(float *od, int w, int h, int r, cudaTextureObject_t tex)\n{\n    float        scale = 1.0f / (float)((r << 1) + 1);\n    unsigned int x     = blockIdx.x * blockDim.x + threadIdx.x;\n\n    float t = 0.0f;\n\n    for (int y = -r; y <= r; y++) {\n        t += tex2D<float>(tex, x, y);\n    }\n\n    od[x] = t * scale;\n\n    for (int y = 1; y < h; y++) {\n        t += tex2D<float>(tex, x, y + r);\n        t -= tex2D<float>(tex, x, y - r - 1);\n        od[y * w + x] = t * scale;\n    }\n}\n\n__device__ unsigned int rgbaFloatToInt(float4 rgba)\n{\n    rgba.x = __saturatef(rgba.x); // clamp to [0.0, 1.0]\n    rgba.y = __saturatef(rgba.y);\n    rgba.z = __saturatef(rgba.z);\n    rgba.w = __saturatef(rgba.w);\n    return ((unsigned int)(rgba.w * 255.0f) << 24) | ((unsigned int)(rgba.z * 255.0f) << 16)\n         | ((unsigned int)(rgba.y * 255.0f) << 8) | ((unsigned int)(rgba.x * 255.0f));\n}\n\n__device__ float4 rgbaIntToFloat(unsigned int c)\n{\n    float4 rgba;\n    rgba.x = (c & 0xff) * 0.003921568627f;         //  /255.0f;\n    rgba.y = ((c >> 8) & 0xff) * 0.003921568627f;  //  /255.0f;\n    rgba.z = ((c >> 16) & 0xff) * 0.003921568627f; //  /255.0f;\n    rgba.w = ((c >> 24) & 0xff) * 0.003921568627f; //  /255.0f;\n    return rgba;\n}\n\n__global__ void d_boxfilter_rgba_x(unsigned int *od, int w, int h, int r, cudaTextureObject_t rgbaTex)\n{\n    float        scale = 1.0f / (float)((r << 1) + 1);\n    unsigned int y     = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (y < h) {\n        float4 t = make_float4(0.0f);\n\n        for (int x = -r; x <= r; x++) {\n            t += tex2D<float4>(rgbaTex, x, y);\n        }\n\n        od[y * w] = rgbaFloatToInt(t * scale);\n\n        for (int x = 1; x < w; x++) {\n            t += tex2D<float4>(rgbaTex, x + r, y);\n            t -= tex2D<float4>(rgbaTex, x - r - 1, y);\n            od[y * w + x] = rgbaFloatToInt(t * scale);\n        }\n    }\n}\n\n__global__ void d_boxfilter_rgba_y(unsigned int *id, unsigned int *od, int w, int h, int r)\n{\n    unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;\n    id             = &id[x];\n    od             = &od[x];\n\n    float scale = 1.0f / (float)((r << 1) + 1);\n\n    float4 t;\n    t = rgbaIntToFloat(id[0]) * r;\n\n    for (int y = 0; y < (r + 1); y++) {\n        t += rgbaIntToFloat(id[y * w]);\n    }\n\n    od[0] = rgbaFloatToInt(t * scale);\n\n    for (int y = 1; y < (r + 1); y++) {\n        t += rgbaIntToFloat(id[(y + r) * w]);\n        t -= rgbaIntToFloat(id[0]);\n        od[y * w] = rgbaFloatToInt(t * scale);\n    }\n\n    for (int y = (r + 1); y < (h - r); y++) {\n        t += rgbaIntToFloat(id[(y + r) * w]);\n        t -= rgbaIntToFloat(id[((y - r) * w) - w]);\n        od[y * w] = rgbaFloatToInt(t * scale);\n    }\n\n    for (int y = h - r; y < h; y++) {\n        t += rgbaIntToFloat(id[(h - 1) * w]);\n        t -= rgbaIntToFloat(id[((y - r) * w) - w]);\n        od[y * w] = rgbaFloatToInt(t * scale);\n    }\n}\n\nextern \"C\" void initTexture(int width, int height, void *pImage, bool useRGBA)\n{\n    cudaChannelFormatDesc channelDesc;\n    if (useRGBA) {\n        channelDesc = cudaCreateChannelDesc(8, 8, 8, 8, cudaChannelFormatKindUnsigned);\n    }\n    else {\n        channelDesc = cudaCreateChannelDesc(32, 0, 0, 0, cudaChannelFormatKindFloat);\n    }\n    checkCudaErrors(cudaMallocArray(&d_array, &channelDesc, width, height));\n\n    size_t bytesPerElem = (useRGBA ? sizeof(uchar4) : sizeof(float));\n    checkCudaErrors(cudaMemcpy2DToArray(\n        d_array, 0, 0, pImage, width * bytesPerElem, width * bytesPerElem, height, cudaMemcpyHostToDevice));\n\n    checkCudaErrors(cudaMallocArray(&d_tempArray, &channelDesc, width, height));\n\n    cudaResourceDesc texRes;\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = d_array;\n\n    cudaTextureDesc texDescr;\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = false;\n    texDescr.filterMode       = cudaFilterModeLinear;\n    texDescr.addressMode[0]   = cudaAddressModeWrap;\n    texDescr.addressMode[1]   = cudaAddressModeWrap;\n    texDescr.readMode         = cudaReadModeNormalizedFloat;\n\n    checkCudaErrors(cudaCreateTextureObject(&rgbaTex, &texRes, &texDescr, NULL));\n\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = d_tempArray;\n\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = false;\n    texDescr.filterMode       = cudaFilterModeLinear;\n    texDescr.addressMode[0]   = cudaAddressModeClamp;\n    texDescr.addressMode[1]   = cudaAddressModeClamp;\n    texDescr.readMode         = cudaReadModeNormalizedFloat;\n\n    checkCudaErrors(cudaCreateTextureObject(&rgbaTexTempArray, &texRes, &texDescr, NULL));\n\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = d_array;\n\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = true;\n    texDescr.filterMode       = cudaFilterModePoint;\n    texDescr.addressMode[0]   = cudaAddressModeWrap;\n    texDescr.addressMode[1]   = cudaAddressModeWrap;\n    texDescr.readMode         = cudaReadModeElementType;\n\n    checkCudaErrors(cudaCreateTextureObject(&tex, &texRes, &texDescr, NULL));\n\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = d_tempArray;\n\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = true;\n    texDescr.filterMode       = cudaFilterModePoint;\n    texDescr.addressMode[0]   = cudaAddressModeWrap;\n    texDescr.addressMode[1]   = cudaAddressModeWrap;\n    texDescr.readMode         = cudaReadModeElementType;\n\n    checkCudaErrors(cudaCreateTextureObject(&texTempArray, &texRes, &texDescr, NULL));\n}\n\nextern \"C\" void freeTextures()\n{\n    checkCudaErrors(cudaDestroyTextureObject(tex));\n    checkCudaErrors(cudaDestroyTextureObject(texTempArray));\n    checkCudaErrors(cudaDestroyTextureObject(rgbaTex));\n    checkCudaErrors(cudaDestroyTextureObject(rgbaTexTempArray));\n    checkCudaErrors(cudaFreeArray(d_array));\n    checkCudaErrors(cudaFreeArray(d_tempArray));\n}\nextern \"C\" double boxFilter(float              *d_temp,\n                            float              *d_dest,\n                            int                 width,\n                            int                 height,\n                            int                 radius,\n                            int                 iterations,\n                            int                 nthreads,\n                            StopWatchInterface *timer)\n{\n    double dKernelTime = 0.0;\n\n    checkCudaErrors(cudaDeviceSynchronize());\n\n    for (int i = 0; i < iterations; i++) {\n        sdkResetTimer(&timer);\n        if (iterations > 1) {\n            d_boxfilter_x_tex<<<height / nthreads, nthreads, 0>>>(d_temp, width, height, radius, texTempArray);\n        }\n        else {\n            d_boxfilter_x_tex<<<height / nthreads, nthreads, 0>>>(d_temp, width, height, radius, tex);\n        }\n\n        d_boxfilter_y_global<<<width / nthreads, nthreads, 0>>>(d_temp, d_dest, width, height, radius);\n\n        checkCudaErrors(cudaDeviceSynchronize());\n        dKernelTime += sdkGetTimerValue(&timer);\n\n        if (iterations > 1) {\n            checkCudaErrors(cudaMemcpy2DToArray(d_tempArray,\n                                                0,\n                                                0,\n                                                d_dest,\n                                                width * sizeof(float),\n                                                width * sizeof(float),\n                                                height,\n                                                cudaMemcpyDeviceToDevice));\n        }\n    }\n\n    return ((dKernelTime / 1000.) / (double)iterations);\n}\n\nextern \"C\" double boxFilterRGBA(unsigned int       *d_temp,\n                                unsigned int       *d_dest,\n                                int                 width,\n                                int                 height,\n                                int                 radius,\n                                int                 iterations,\n                                int                 nthreads,\n                                StopWatchInterface *timer)\n{\n    double dKernelTime;\n\n    for (int i = 0; i < iterations; i++) {\n        dKernelTime = 0.0;\n        checkCudaErrors(cudaDeviceSynchronize());\n        sdkResetTimer(&timer);\n\n        if (iterations > 1) {\n            d_boxfilter_rgba_x<<<height / nthreads, nthreads, 0>>>(d_temp, width, height, radius, rgbaTexTempArray);\n        }\n        else {\n            d_boxfilter_rgba_x<<<height / nthreads, nthreads, 0>>>(d_temp, width, height, radius, rgbaTex);\n        }\n\n        d_boxfilter_rgba_y<<<width / nthreads, nthreads, 0>>>(d_temp, d_dest, width, height, radius);\n\n        checkCudaErrors(cudaDeviceSynchronize());\n        dKernelTime += sdkGetTimerValue(&timer);\n\n        if (iterations > 1) {\n            checkCudaErrors(cudaMemcpy2DToArray(d_tempArray,\n                                                0,\n                                                0,\n                                                d_dest,\n                                                width * sizeof(unsigned int),\n                                                width * sizeof(unsigned int),\n                                                height,\n                                                cudaMemcpyDeviceToDevice));\n        }\n    }\n\n    return ((dKernelTime / 1000.) / (double)iterations);\n}\n\n#endif // #ifndef _BOXFILTER_KERNEL_H_\n", "boxFilter.cpp": "#include <helper_gl.h>\n#if defined(__APPLE__) || defined(__MACOSX)\n#pragma clang diagnostic ignored \"-Wdeprecated-declarations\"\n#include <GLUT/glut.h>\n#ifndef glutCloseFunc\n#define glutCloseFunc glutWMCloseFunc\n#endif\n#else\n#include <GL/freeglut.h>\n#endif\n\n#include <cuda_gl_interop.h>\n#include <cuda_runtime.h>\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n\n#define MAX_EPSILON_ERROR 5.0f\n#define REFRESH_DELAY     10 // ms\n\nconst static char *sSDKsample = \"CUDA Iterative Box Filter\";\n\nconst char *sOriginal[] = {\"teapot1024_14.ppm\", \"teapot1024_22.ppm\", NULL};\n\nconst char *sReference[] = {\"ref_14.ppm\", \"ref_22.ppm\", NULL};\n\nconst char   *image_filename = \"teapot1024.ppm\";\nint           iterations     = 1;\nint           filter_radius  = 14;\nint           nthreads       = 64;\nunsigned int  width, height;\nunsigned int *h_img  = NULL;\nunsigned int *d_temp = NULL;\n\nGLuint                       pbo;\nstruct cudaGraphicsResource *cuda_pbo_resource;\nGLuint                       texid;\nGLuint                       shader;\n\nStopWatchInterface *timer = NULL, *kernel_timer = NULL;\n\nint          fpsCount       = 0;\nint          fpsLimit       = 8;\nint          g_Index        = 0;\nint          g_nFilterSign  = 1;\nfloat        avgFPS         = 0.0f;\nunsigned int frameCount     = 0;\nunsigned int g_TotalErrors  = 0;\nbool         g_bInteractive = false;\n\nint   *pArgc = NULL;\nchar **pArgv = NULL;\n\nextern \"C\" int  runSingleTest(char *ref_file, char *exec_path);\nextern \"C\" int  runBenchmark();\nextern \"C\" void loadImageData(int argc, char **argv);\nextern \"C\" void computeGold(float *id, float *od, int w, int h, int n);\n\nextern \"C\" void   initTexture(int width, int height, void *pImage, bool useRGBA);\nextern \"C\" void   freeTextures();\nextern \"C\" double boxFilter(float              *d_temp,\n                            float              *d_dest,\n                            int                 width,\n                            int                 height,\n                            int                 radius,\n                            int                 iterations,\n                            int                 nthreads,\n                            StopWatchInterface *timer);\n\nextern \"C\" double boxFilterRGBA(unsigned int       *d_temp,\n                                unsigned int       *d_dest,\n                                int                 width,\n                                int                 height,\n                                int                 radius,\n                                int                 iterations,\n                                int                 nthreads,\n                                StopWatchInterface *timer);\n\nvoid varySigma()\n{\n    filter_radius += g_nFilterSign;\n\n    if (filter_radius > 64) {\n        filter_radius = 64;\n        g_nFilterSign = -1;\n    }\n    else if (filter_radius < 0) {\n        filter_radius = 0;\n        g_nFilterSign = 1;\n    }\n}\n\nvoid computeFPS()\n{\n    frameCount++;\n    fpsCount++;\n\n    if (fpsCount == fpsLimit) {\n        avgFPS   = 1.0f / (sdkGetAverageTimerValue(&timer) / 1000.0f);\n        fpsCount = 0;\n        fpsLimit = (int)MAX(avgFPS, 1.0f);\n        sdkResetTimer(&timer);\n    }\n\n    char fps[256];\n    sprintf(fps,\n            \"CUDA Rolling Box Filter <Animation=%s> (radius=%d, passes=%d): \"\n            \"%3.1f fps\",\n            (!g_bInteractive ? \"ON\" : \"OFF\"),\n            filter_radius,\n            iterations,\n            avgFPS);\n    glutSetWindowTitle(fps);\n\n    if (!g_bInteractive) {\n        varySigma();\n    }\n}\n\nvoid display()\n{\n    sdkStartTimer(&timer);\n\n    unsigned int *d_result;\n\n    checkCudaErrors(cudaGraphicsMapResources(1, &cuda_pbo_resource, 0));\n    size_t num_bytes;\n    checkCudaErrors(cudaGraphicsResourceGetMappedPointer((void **)&d_result, &num_bytes, cuda_pbo_resource));\n    boxFilterRGBA(d_temp, d_result, width, height, filter_radius, iterations, nthreads, kernel_timer);\n\n    checkCudaErrors(cudaGraphicsUnmapResources(1, &cuda_pbo_resource, 0));\n\n    {\n        glClear(GL_COLOR_BUFFER_BIT);\n\n        glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n        glBindTexture(GL_TEXTURE_2D, texid);\n        glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, width, height, GL_RGBA, GL_UNSIGNED_BYTE, 0);\n        glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n        glBindProgramARB(GL_FRAGMENT_PROGRAM_ARB, shader);\n        glEnable(GL_FRAGMENT_PROGRAM_ARB);\n        glDisable(GL_DEPTH_TEST);\n\n        glBegin(GL_QUADS);\n        {\n            glTexCoord2f(0.0f, 0.0f);\n            glVertex2f(0.0f, 0.0f);\n            glTexCoord2f(1.0f, 0.0f);\n            glVertex2f(1.0f, 0.0f);\n            glTexCoord2f(1.0f, 1.0f);\n            glVertex2f(1.0f, 1.0f);\n            glTexCoord2f(0.0f, 1.0f);\n            glVertex2f(0.0f, 1.0f);\n        }\n        glEnd();\n        glBindTexture(GL_TEXTURE_2D, 0);\n        glDisable(GL_FRAGMENT_PROGRAM_ARB);\n    }\n\n    glutSwapBuffers();\n    glutReportErrors();\n\n    sdkStopTimer(&timer);\n\n    computeFPS();\n}\n\nvoid keyboard(unsigned char key, int /*x*/, int /*y*/)\n{\n    switch (key) {\n    case 27:\n#if defined(__APPLE__) || defined(MACOSX)\n        exit(EXIT_SUCCESS);\n#else\n        glutDestroyWindow(glutGetWindow());\n        return;\n#endif\n        break;\n\n    case 'a':\n    case 'A':\n        g_bInteractive = !g_bInteractive;\n        printf(\"> Animation is %s\\n\", !g_bInteractive ? \"ON\" : \"OFF\");\n        break;\n\n    case '=':\n    case '+':\n        if (filter_radius < (int)width - 1 && filter_radius < (int)height - 1) {\n            filter_radius++;\n        }\n\n        break;\n\n    case '-':\n        if (filter_radius > 1) {\n            filter_radius--;\n        }\n\n        break;\n\n    case ']':\n        iterations++;\n        break;\n\n    case '[':\n        if (iterations > 1) {\n            iterations--;\n        }\n\n        break;\n\n    default:\n        break;\n    }\n\n    printf(\"radius = %d, iterations = %d\\n\", filter_radius, iterations);\n}\n\nvoid timerEvent(int value)\n{\n    if (glutGetWindow()) {\n        glutPostRedisplay();\n        glutTimerFunc(REFRESH_DELAY, timerEvent, 0);\n    }\n}\n\nvoid reshape(int x, int y)\n{\n    glViewport(0, 0, x, y);\n\n    glMatrixMode(GL_MODELVIEW);\n    glLoadIdentity();\n\n    glMatrixMode(GL_PROJECTION);\n    glLoadIdentity();\n    glOrtho(0.0, 1.0, 0.0, 1.0, 0.0, 1.0);\n}\n\nvoid initCuda(bool useRGBA)\n{\n    checkCudaErrors(cudaMalloc((void **)&d_temp, (width * height * sizeof(unsigned int))));\n\n    initTexture(width, height, h_img, useRGBA);\n\n    sdkCreateTimer(&timer);\n    sdkCreateTimer(&kernel_timer);\n}\n\nvoid cleanup()\n{\n    sdkDeleteTimer(&timer);\n    sdkDeleteTimer(&kernel_timer);\n\n    if (h_img) {\n        free(h_img);\n        h_img = NULL;\n    }\n\n    if (d_temp) {\n        cudaFree(d_temp);\n        d_temp = NULL;\n    }\n\n    freeTextures();\n\n    cudaGraphicsUnregisterResource(cuda_pbo_resource);\n\n    glDeleteBuffers(1, &pbo);\n    glDeleteTextures(1, &texid);\n    glDeleteProgramsARB(1, &shader);\n}\n\nstatic const char *shader_code = \"!!ARBfp1.0\\n\"\n                                 \"TEX result.color, fragment.texcoord, texture[0], 2D; \\n\"\n                                 \"END\";\n\nGLuint compileASMShader(GLenum program_type, const char *code)\n{\n    GLuint program_id;\n    glGenProgramsARB(1, &program_id);\n    glBindProgramARB(program_type, program_id);\n    glProgramStringARB(program_type, GL_PROGRAM_FORMAT_ASCII_ARB, (GLsizei)strlen(code), (GLubyte *)code);\n\n    GLint error_pos;\n    glGetIntegerv(GL_PROGRAM_ERROR_POSITION_ARB, &error_pos);\n\n    if (error_pos != -1) {\n        const GLubyte *error_string;\n        error_string = glGetString(GL_PROGRAM_ERROR_STRING_ARB);\n        printf(\"Program error at position: %d\\n%s\\n\", (int)error_pos, error_string);\n        return 0;\n    }\n\n    return program_id;\n}\n\nvoid initGLResources()\n{\n    glGenBuffers(1, &pbo);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glBufferData(GL_PIXEL_UNPACK_BUFFER_ARB, width * height * sizeof(GLubyte) * 4, h_img, GL_STREAM_DRAW_ARB);\n\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n    checkCudaErrors(cudaGraphicsGLRegisterBuffer(&cuda_pbo_resource, pbo, cudaGraphicsMapFlagsWriteDiscard));\n\n    glGenTextures(1, &texid);\n    glBindTexture(GL_TEXTURE_2D, texid);\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, width, height, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n    glBindTexture(GL_TEXTURE_2D, 0);\n\n    shader = compileASMShader(GL_FRAGMENT_PROGRAM_ARB, shader_code);\n}\n\nvoid initGL(int *argc, char **argv)\n{\n    glutInit(argc, argv);\n    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE);\n    glutInitWindowSize(768, 768);\n    glutCreateWindow(\"CUDA Rolling Box Filter\");\n    glutDisplayFunc(display);\n\n    glutKeyboardFunc(keyboard);\n    glutReshapeFunc(reshape);\n    glutTimerFunc(REFRESH_DELAY, timerEvent, 0);\n\n    if (!isGLVersionSupported(2, 0)\n        || !areGLExtensionsSupported(\"GL_ARB_vertex_buffer_object GL_ARB_pixel_buffer_object\")) {\n        printf(\"Error: failed to get minimal extensions for demo\\n\");\n        printf(\"This sample requires:\\n\");\n        printf(\"  OpenGL version 2.0\\n\");\n        printf(\"  GL_ARB_vertex_buffer_object\\n\");\n        printf(\"  GL_ARB_pixel_buffer_object\\n\");\n        exit(EXIT_FAILURE);\n    }\n}\n\nint runBenchmark()\n{\n    printf(\"[runBenchmark]: [%s]\\n\", sSDKsample);\n\n    initCuda(true);\n\n    unsigned int *d_result;\n    checkCudaErrors(cudaMalloc((void **)&d_result, width * height * sizeof(unsigned int)));\n\n    boxFilterRGBA(d_temp, d_temp, width, height, filter_radius, iterations, nthreads, kernel_timer);\n    checkCudaErrors(cudaDeviceSynchronize());\n\n    sdkStartTimer(&kernel_timer);\n    iterations                = 1;\n    const int iCycles         = 150;\n    double    dProcessingTime = 0.0;\n    printf(\"\\nRunning BoxFilterGPU for %d cycles...\\n\\n\", iCycles);\n\n    for (int i = 0; i < iCycles; i++) {\n        dProcessingTime +=\n            boxFilterRGBA(d_temp, d_temp, width, height, filter_radius, iterations, nthreads, kernel_timer);\n    }\n\n    getLastCudaError(\"Error: boxFilterRGBA Kernel execution FAILED\");\n    checkCudaErrors(cudaDeviceSynchronize());\n    sdkStopTimer(&kernel_timer);\n\n    dProcessingTime /= (double)iCycles;\n\n    printf(\"boxFilter-texture, Throughput = %.4f M RGBA Pixels/s, Time = %.5f s, \"\n           \"Size = %u RGBA Pixels, NumDevsUsed = %u, Workgroup = %u\\n\",\n           (1.0e-6 * width * height) / dProcessingTime,\n           dProcessingTime,\n           (width * height),\n           1,\n           nthreads);\n    printf(\"\\n\");\n\n    return 0;\n}\n\nint runSingleTest(char *ref_file, char *exec_path)\n{\n    int  nTotalErrors = 0;\n    char dump_file[256];\n\n    printf(\"[runSingleTest]: [%s]\\n\", sSDKsample);\n\n    initCuda(true);\n\n    unsigned int *d_result;\n    unsigned int *h_result = (unsigned int *)malloc(width * height * sizeof(unsigned int));\n    checkCudaErrors(cudaMalloc((void **)&d_result, width * height * sizeof(unsigned int)));\n\n    {\n        printf(\"%s (radius=%d) (passes=%d) \", sSDKsample, filter_radius, iterations);\n        boxFilterRGBA(d_temp, d_result, width, height, filter_radius, iterations, nthreads, kernel_timer);\n\n        getLastCudaError(\"Error: boxFilterRGBA Kernel execution FAILED\");\n        checkCudaErrors(cudaDeviceSynchronize());\n\n        cudaMemcpy((unsigned char *)h_result,\n                   (unsigned char *)d_result,\n                   width * height * sizeof(unsigned int),\n                   cudaMemcpyDeviceToHost);\n\n        sprintf(dump_file, \"teapot1024_%02d.ppm\", filter_radius);\n\n        sdkSavePPM4ub((const char *)dump_file, (unsigned char *)h_result, width, height);\n\n        if (!sdkComparePPM(dump_file, sdkFindFilePath(ref_file, exec_path), MAX_EPSILON_ERROR, 0.15f, false)) {\n            printf(\"Image is Different \");\n            nTotalErrors++;\n        }\n        else {\n            printf(\"Image is Matching \");\n        }\n\n        printf(\" <%s>\\n\", ref_file);\n    }\n    printf(\"\\n\");\n\n    free(h_result);\n    checkCudaErrors(cudaFree(d_result));\n\n    return nTotalErrors;\n}\n\nvoid loadImageData(int argc, char **argv)\n{\n    char *image_path = NULL;\n\n    if (argc >= 1) {\n        image_path = sdkFindFilePath(image_filename, argv[0]);\n    }\n\n    if (image_path == 0) {\n        printf(\"Error finding image file '%s'\\n\", image_filename);\n        exit(EXIT_FAILURE);\n    }\n\n    sdkLoadPPM4(image_path, (unsigned char **)&h_img, &width, &height);\n\n    if (!h_img) {\n        printf(\"Error opening file '%s'\\n\", image_path);\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"Loaded '%s', %d x %d pixels\\n\", image_path, width, height);\n}\n\nvoid printHelp()\n{\n    printf(\"boxFilter usage\\n\");\n    printf(\"    -threads=n (specify the # of of threads to use)\\n\");\n    printf(\"    -radius=n  (specify the filter radius n to use)\\n\");\n    printf(\"    -passes=n  (specify the number of passes n to use)\\n\");\n    printf(\"    -file=name (specify reference file for comparison)\\n\");\n}\n\nint main(int argc, char **argv)\n{\n    int   devID    = 0;\n    char *ref_file = NULL;\n\n#if defined(__linux__)\n    setenv(\"DISPLAY\", \":0\", 0);\n#endif\n\n    pArgc = &argc;\n    pArgv = argv;\n\n    printf(\"%s Starting...\\n\\n\", argv[0]);\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"help\")) {\n        printHelp();\n        exit(EXIT_SUCCESS);\n    }\n\n    if (argc > 1) {\n        if (checkCmdLineFlag(argc, (const char **)argv, \"threads\")) {\n            nthreads = getCmdLineArgumentInt(argc, (const char **)argv, \"threads\");\n        }\n\n        if (checkCmdLineFlag(argc, (const char **)argv, \"radius\")) {\n            filter_radius = getCmdLineArgumentInt(argc, (const char **)argv, \"radius\");\n        }\n\n        if (checkCmdLineFlag(argc, (const char **)argv, \"passes\")) {\n            iterations = getCmdLineArgumentInt(argc, (const char **)argv, \"passes\");\n        }\n\n        if (checkCmdLineFlag(argc, (const char **)argv, \"file\")) {\n            getCmdLineArgumentString(argc, (const char **)argv, \"file\", (char **)&ref_file);\n        }\n    }\n\n    loadImageData(argc, argv);\n    devID = findCudaDevice(argc, (const char **)argv);\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"benchmark\")) {\n        g_TotalErrors += runBenchmark();\n        exit(g_TotalErrors == 0 ? EXIT_SUCCESS : EXIT_FAILURE);\n    }\n    else if (checkCmdLineFlag(argc, (const char **)argv, \"radius\")\n             || checkCmdLineFlag(argc, (const char **)argv, \"passes\")) {\n        g_TotalErrors += runSingleTest(ref_file, argv[0]);\n        exit(g_TotalErrors == 0 ? EXIT_SUCCESS : EXIT_FAILURE);\n    }\n    else {\n        printf(\"\\n\");\n\n        initGL(&argc, argv);\n\n        initCuda(true);\n        initGLResources();\n\n#if defined(__APPLE__) || defined(MACOSX)\n        atexit(cleanup);\n#else\n        glutCloseFunc(cleanup);\n#endif\n\n        printf(\"Running Standard Demonstration with GLUT loop...\\n\\n\");\n        printf(\"Press '+' and '-' to change filter width\\n\"\n               \"Press ']' and '[' to change number of iterations\\n\"\n               \"Press 'a' or  'A' to change animation ON/OFF\\n\\n\");\n\n        glutMainLoop();\n    }\n}\n"}, "code_dirs": {"boxFilter_kernel.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/boxFilter", "boxFilter.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/boxFilter"}}
{"kernel_name": "boxFilter", "parallel_api": "ocl", "code": {"BoxFilter.cl": "float4 rgbaUintToFloat4(unsigned int c)\n{\n    float4 rgba;\n    rgba.x = c & 0xff;\n    rgba.y = (c >> 8) & 0xff;\n    rgba.z = (c >> 16) & 0xff;\n    rgba.w = (c >> 24) & 0xff;\n    return rgba;\n}\n\nunsigned int rgbaFloat4ToUint(float4 rgba, float fScale)\n{\n    unsigned int uiPackedPix = 0U;\n    uiPackedPix |= 0x000000FF & (unsigned int)(rgba.x * fScale);\n    uiPackedPix |= 0x0000FF00 & (((unsigned int)(rgba.y * fScale)) << 8);\n    uiPackedPix |= 0x00FF0000 & (((unsigned int)(rgba.z * fScale)) << 16);\n    uiPackedPix |= 0xFF000000 & (((unsigned int)(rgba.w * fScale)) << 24);\n    return uiPackedPix;\n}\n\n\n#ifdef USETEXTURE\n    __kernel void BoxRowsTex( __read_only image2d_t SourceRgbaTex, __global unsigned int* uiDest, sampler_t RowSampler, \n                              unsigned int uiWidth, unsigned int uiHeight, int iRadius, float fScale)\n    {\n\t    size_t globalPosY = get_global_id(0);\n        size_t szBaseOffset = mul24(globalPosY, uiWidth);\n\n        if (globalPosY < uiHeight) \n        {\n            float4 f4Sum = (float4)0.0f;\n\n            for(int x = -iRadius; x <= iRadius; x++)\n            {\n                int2 pos = {x , globalPosY};\n                f4Sum += convert_float4(read_imageui(SourceRgbaTex, RowSampler, pos));  \n            }\n            uiDest[szBaseOffset] = rgbaFloat4ToUint(f4Sum, fScale);\n\n            int2 pos = {0, globalPosY};\n            for(unsigned int x = 1; x < uiWidth; x++)\n            {\n                pos.x = x + iRadius;\n                f4Sum += convert_float4(read_imageui(SourceRgbaTex, RowSampler, pos));  \n\n                pos.x = x - iRadius - 1;\n                f4Sum -= convert_float4(read_imageui(SourceRgbaTex, RowSampler, pos));  \n\n                uiDest[szBaseOffset + x] = rgbaFloat4ToUint(f4Sum, fScale);\n            }\n        }\n    }\n#endif\n\n\n#ifdef USELMEM\n\n    __kernel void BoxRowsLmem( __global const uchar4* uc4Source, __global unsigned int* uiDest,\n                               __local uchar4* uc4LocalData,\n                               unsigned int uiWidth, unsigned int uiHeight, int iRadius, int iRadiusAligned, \n                               float fScale, unsigned int uiNumOutputPix)\n    {\n        int globalPosX = ((int)get_group_id(0) * uiNumOutputPix) + (int)get_local_id(0) - iRadiusAligned;\n        int globalPosY = (int)get_group_id(1);\n        int iGlobalOffset = globalPosY * uiWidth + globalPosX;\n\n        if (globalPosX >= 0 && globalPosX < uiWidth)\n        {\n            uc4LocalData[get_local_id(0)] = uc4Source[iGlobalOffset];\n        }\n        else \n        {\n            uc4LocalData[get_local_id(0)].xyzw = (uchar4)0; \n        }\n\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n        if((globalPosX >= 0) && (globalPosX < uiWidth) && (get_local_id(0) >= iRadiusAligned) && (get_local_id(0) < (iRadiusAligned + (int)uiNumOutputPix)))\n        {\n            float4 f4Sum = (float4)0.0f;\n\n            int iOffsetX = (int)get_local_id(0) - iRadius;\n            int iLimit = iOffsetX + (2 * iRadius) + 1;\n            for(iOffsetX; iOffsetX < iLimit; iOffsetX++)\n            {\n                f4Sum.x += uc4LocalData[iOffsetX].x;\n                f4Sum.y += uc4LocalData[iOffsetX].y;\n                f4Sum.z += uc4LocalData[iOffsetX].z;\n                f4Sum.w += uc4LocalData[iOffsetX].w; \n            }\n\n            uiDest[iGlobalOffset] = rgbaFloat4ToUint(f4Sum, fScale);\n        }\n    }\n#endif\n\n\n__kernel void BoxColumns(__global unsigned int* uiInputImage, __global unsigned int* uiOutputImage, \n                         unsigned int uiWidth, unsigned int uiHeight, int iRadius, float fScale)\n{\n\tsize_t globalPosX = get_global_id(0);\n    uiInputImage = &uiInputImage[globalPosX];\n    uiOutputImage = &uiOutputImage[globalPosX];\n\n    float4 f4Sum;\n    f4Sum = rgbaUintToFloat4(uiInputImage[0]) * (float4)(iRadius);\n    for (int y = 0; y < iRadius + 1; y++) \n    {\n        f4Sum += rgbaUintToFloat4(uiInputImage[y * uiWidth]);\n    }\n    uiOutputImage[0] = rgbaFloat4ToUint(f4Sum, fScale);\n    for(int y = 1; y < iRadius + 1; y++) \n    {\n        f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n        f4Sum -= rgbaUintToFloat4(uiInputImage[0]);\n        uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n    }\n    \n    for(int y = iRadius + 1; y < uiHeight - iRadius; y++) \n    {\n        f4Sum += rgbaUintToFloat4(uiInputImage[(y + iRadius) * uiWidth]);\n        f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n        uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n    }\n\n    for (int y = uiHeight - iRadius; y < uiHeight; y++) \n    {\n        f4Sum += rgbaUintToFloat4(uiInputImage[(uiHeight - 1) * uiWidth]);\n        f4Sum -= rgbaUintToFloat4(uiInputImage[((y - iRadius) * uiWidth) - uiWidth]);\n        uiOutputImage[y * uiWidth] = rgbaFloat4ToUint(f4Sum, fScale);\n    }\n}\n", "oclBoxFilter.cpp": "#include <GL/glew.h>\n#ifdef UNIX\n    #include <GL/glxew.h>\n#endif\n#if defined (_WIN32)\n    #include <GL/wglew.h>\n#endif\n\n#if defined (__APPLE__) || defined(MACOSX)\n    #include <OpenGL/OpenGL.h>\n    #include <GLUT/glut.h>\n#else\n    #include <GL/freeglut.h>\n#endif\n\n#include <memory>\n#include <iostream>\n#include <cassert>\n\n#include <oclUtils.h>\n#include <shrQATest.h>\n\n#ifndef min\n#define min(a,b) (a < b ? a : b);\n#endif\n\nextern \"C\" double BoxFilterHost(unsigned int* uiInputImage, unsigned int* uiTempImage, unsigned int* uiOutputImage, \n                                unsigned int uiWidth, unsigned int uiHeight, int r, float fScale);\n\n#define REFRESH_DELAY\t  10 //ms\n\ncl_uint uiNumOutputPix = 64;\ncl_uint iRadius = 10;\nfloat fScale = 1.0f/(2.0f * iRadius + 1.0f);\ncl_int iRadiusAligned;\n\nconst char* cImageFile = \"lenaRGB.ppm\";\nunsigned int uiImageWidth = 0;\nunsigned int uiImageHeight = 0;\nunsigned int* uiInput = NULL;\nunsigned int* uiTemp = NULL;\n\nint iGLUTWindowHandle;\nint iGLUTMenuHandle;\nint iGraphicsWinPosX = 0;\nint iGraphicsWinPosY = 0;\nint iGraphicsWinWidth = 800;\nint iGraphicsWinHeight = 800;\nint iGraphicsWinWidthNonFS = 800;\nint iGraphicsWinHeightNonFS = 800;\nint iFrameCount = 0;\nint iFrameTrigger = 90;\nint iFramesPerSec = 60;\ndouble dProcessingTime = 0.0;\nbool bGLinteropSupported = false;\nGLint iVsyncState;\n\nconst char* cProcessor [] = {\"OpenCL GPU\", \"Host C++ CPU\"};\nbool bFilter = true;\nbool bFullScreen = false;\nbool bGLinterop = false;\nint iProcFlag = 0;\nshrBOOL bNoPrompt = shrFALSE;\nshrBOOL bQATest = shrFALSE;\nshrBOOL bUseLmem = shrFALSE;\nint iTestSets = 3;\n\nconst char* clSourcefile = \"BoxFilter.cl\";\nchar* cPathAndName = NULL;\nchar* cSourceCL = NULL;\ncl_platform_id cpPlatform;\ncl_context cxGPUContext;\ncl_command_queue cqCommandQueue;\ncl_device_id* cdDevices = NULL;\ncl_uint uiNumDevsUsed = 1;\ncl_program cpProgram;\ncl_kernel ckBoxRowsLmem;\ncl_kernel ckBoxRowsTex;\ncl_kernel ckBoxColumns;\ncl_mem cmDevBufIn;\ncl_mem cmDevBufTemp;\ncl_mem cmDevBufOut;\ncl_mem cmCL_PBO=0;\ncl_image_format InputFormat;\ncl_sampler RowSampler;\nsize_t szBuffBytes;\nsize_t szGlobalWorkSize[2];\nsize_t szLocalWorkSize[2];\nsize_t szMaxWorkgroupSize = 512;\nsize_t szParmDataBytes;\nsize_t szKernelLength;\ncl_int ciErrNum;\n\nGLuint tex_screen;\nGLuint pbo;\n\nconst char* cpExecutableName;\n\nint pArgc = 0;\nchar **pArgv = NULL;\n\ndouble BoxFilterGPU(unsigned int* uiInputImage, cl_mem cmOutputBuffer, \n                    unsigned int uiWidth, unsigned int uiHeight, int r, float fScale);\nvoid ResetKernelArgs(unsigned int uiWidth, unsigned int uiHeight, int r, float fScale);\n\nvoid InitGlut(int* argc, char** argv);\nvoid InitGlew();\nvoid DeInitGL();\nvoid DisplayGL();\nvoid Reshape(int w, int h);\nvoid Idle(void);\nvoid KeyboardGL(unsigned char key, int x, int y);\nvoid MenuGL(int i);\nvoid timerEvent(int value);\n\nvoid createPBO(GLuint* pbo, int image_width, int image_height);\nvoid deletePBO(GLuint* pbo);\nvoid createTexture(GLuint* tex_name, unsigned int size_x, unsigned int size_y);\nvoid deleteTexture(GLuint* tex);\nvoid displayTexture(GLuint tex);\n\nvoid TestNoGL();\nvoid TriggerFPSUpdate();\nstatic inline size_t DivUp(size_t dividend, size_t divisor);\nvoid ShowMenuItems();\nvoid Cleanup(int iExitCode);\nvoid (*pCleanup)(int) = &Cleanup;\n\nint main(int argc, char** argv)\n{\n\tpArgc = argc;\n\tpArgv = argv;\n\n\tshrQAStart(argc, argv);\n\tcpExecutableName = argv[0];\n    shrSetLogFileName (\"oclBoxFilter.txt\");\n    shrLog(\"%s Starting, using %s...\\n\\n\", argv[0], clSourcefile); \n\n    bNoPrompt = shrCheckCmdLineFlag(argc, (const char**)argv, \"noprompt\");\n    bQATest = shrCheckCmdLineFlag(argc, (const char**)argv, \"qatest\");\n    bUseLmem = shrCheckCmdLineFlag(argc, (const char**)argv, \"lmem\");\n    bGLinterop = (shrCheckCmdLineFlag(argc, (const char**)argv, \"GLinterop\") == shrTRUE);\n\n    if (!(bQATest))\n    {\n        ShowMenuItems();\n    }\n\n    cPathAndName = shrFindFilePath(cImageFile, argv[0]);\n    oclCheckErrorEX(cPathAndName != NULL, shrTRUE, pCleanup);\n    ciErrNum = shrLoadPPM4ub(cPathAndName, (unsigned char **)&uiInput, &uiImageWidth, &uiImageHeight);\n    oclCheckErrorEX(ciErrNum, shrTRUE, pCleanup);\n    shrLog(\"Image Width = %i, Height = %i, bpp = %i, Mask Radius = %i\\n\", uiImageWidth, uiImageHeight, sizeof(unsigned int)<<3, iRadius);\n    shrLog(\"Using %s for Row Processing\\n\\n\", bUseLmem ? \"Local Memory (lmem)\" : \"2d Image (Texture)\");\n    \n    szBuffBytes = uiImageWidth * uiImageHeight * sizeof (unsigned int);\n    uiTemp = (unsigned int*)malloc(szBuffBytes);\n    shrLog(\"Allocate Host Image Buffers...\\n\"); \n\n    shrLog(\"%sInitGlut, InitGlew...\\n\", bQATest ? \"Skipping \" : \"Calling \"); \n    if (!(bQATest))\n    {\n        InitGlut(&argc, argv);\n        InitGlew();\n    }\n\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"clGetPlatformID...\\n\"); \n\n    cl_uint uiNumDevices = 0;\n    cl_uint uiTargetDevice = 0;\n    cl_uint uiNumComputeUnits;\n    shrLog(\"Get the Device info and select Device...\\n\");\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiNumDevices);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    cdDevices = (cl_device_id *)malloc(uiNumDevices * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiNumDevices, cdDevices, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Set target device and Query number of compute units on uiTargetDevice\n    shrLog(\"  # of Devices Available = %u\\n\", uiNumDevices); \n    if(shrGetCmdLineArgumentu(argc, (const char**)argv, \"device\", &uiTargetDevice)== shrTRUE) \n    {\n        uiTargetDevice = CLAMP(uiTargetDevice, 0, (uiNumDevices - 1));\n    }\n    shrLog(\"  Using Device %u: \", uiTargetDevice); \n    oclPrintDevName(LOGBOTH, cdDevices[uiTargetDevice]);\n    ciErrNum = clGetDeviceInfo(cdDevices[uiTargetDevice], CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(uiNumComputeUnits), &uiNumComputeUnits, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"\\n  # of Compute Units = %u\\n\", uiNumComputeUnits); \n\n    // Check for GL interop capability (if using GL)\n    if(!bQATest)\n    {\n        char extensions[1024];\n        ciErrNum = clGetDeviceInfo(cdDevices[uiTargetDevice], CL_DEVICE_EXTENSIONS, 1024, extensions, 0);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        \n        #if defined (__APPLE__) || defined(MACOSX)\n            bGLinteropSupported = std::string(extensions).find(\"cl_APPLE_gl_sharing\") != std::string::npos;\n        #else\n            bGLinteropSupported = std::string(extensions).find(\"cl_khr_gl_sharing\") != std::string::npos;\n        #endif\n    }\n\n    //Create the context\n    if(bGLinteropSupported) \n    {\n        // Define OS-specific context properties and create the OpenCL context\n        #if defined (__APPLE__)\n            CGLContextObj kCGLContext = CGLGetCurrentContext();\n            CGLShareGroupObj kCGLShareGroup = CGLGetShareGroup(kCGLContext);\n            cl_context_properties props[] = \n            {\n                CL_CONTEXT_PROPERTY_USE_CGL_SHAREGROUP_APPLE, (cl_context_properties)kCGLShareGroup, \n                0 \n            };\n            cxGPUContext = clCreateContext(props, 0,0, NULL, NULL, &ciErrNum);\n        #else\n            #ifdef UNIX\n                cl_context_properties props[] = \n                {\n                    CL_GL_CONTEXT_KHR, (cl_context_properties)glXGetCurrentContext(), \n                    CL_GLX_DISPLAY_KHR, (cl_context_properties)glXGetCurrentDisplay(), \n                    CL_CONTEXT_PLATFORM, (cl_context_properties)cpPlatform, \n                    0\n                };\n                cxGPUContext = clCreateContext(props, uiNumDevsUsed, &cdDevices[uiTargetDevice], NULL, NULL, &ciErrNum);\n            #else // Win32\n                cl_context_properties props[] = \n                {\n                    CL_GL_CONTEXT_KHR, (cl_context_properties)wglGetCurrentContext(), \n                    CL_WGL_HDC_KHR, (cl_context_properties)wglGetCurrentDC(), \n                    CL_CONTEXT_PLATFORM, (cl_context_properties)cpPlatform, \n                    0\n                };\n                cxGPUContext = clCreateContext(props, uiNumDevsUsed, &cdDevices[uiTargetDevice], NULL, NULL, &ciErrNum);\n            #endif\n        #endif\n        shrLog(\"clCreateContext, GL Interop supported...\\n\"); \n    } \n    else \n    {\n        bGLinterop = false;\n        cxGPUContext = clCreateContext(0, uiNumDevsUsed, &cdDevices[uiTargetDevice], NULL, NULL, &ciErrNum);\n        shrLog(\"clCreateContext, GL Interop %s...\\n\", bQATest ? \"N/A\" : \"not supported\"); \n    }\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Create a command-queue \n    cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevices[uiTargetDevice], 0, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"clCreateCommandQueue...\\n\"); \n\n    // Allocate OpenCL object for the source data\n    if (bUseLmem)\n    {\n        // Buffer in device GMEM\n        cmDevBufIn = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, szBuffBytes, NULL, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clCreateBuffer (Input buffer, device GMEM)...\\n\");\n    }\n    else \n    {\n        // 2D Image (Texture) on device\n        InputFormat.image_channel_order = CL_RGBA;\n        InputFormat.image_channel_data_type = CL_UNSIGNED_INT8;\n        cmDevBufIn = clCreateImage2D(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_USE_HOST_PTR, &InputFormat, \n                                     uiImageWidth, uiImageHeight, \n                                     uiImageWidth * sizeof(unsigned int), uiInput, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clCreateImage2D (Input buffer, device GMEM)...\\n\");\n\n        RowSampler = clCreateSampler(cxGPUContext, false, CL_ADDRESS_CLAMP, CL_FILTER_NEAREST, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clCreateSampler (Non-Normalized Coords, CL_ADDRESS_CLAMP, CL_FILTER_NEAREST)...\\n\");\n    }\n\n    // Allocate the OpenCL intermediate and result buffer memory objects on the device GMEM\n    cmDevBufTemp = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, szBuffBytes, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    cmDevBufOut = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, szBuffBytes, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"clCreateBuffer (Intermediate and Output buffers, device GMEM)...\\n\"); \n\n    // Create OpenCL representation of OpenGL PBO\n    if(bGLinteropSupported)\n    {\n        cmCL_PBO = clCreateFromGLBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, pbo, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clCreateFromGLBuffer (cmCL_PBO)...\\n\"); \n    }\n\n    // Read the OpenCL kernel source in from file\n    free(cPathAndName);\n    cPathAndName = shrFindFilePath(clSourcefile, argv[0]);\n    oclCheckErrorEX(cPathAndName != NULL, shrTRUE, pCleanup);\n    cSourceCL = oclLoadProgSource(cPathAndName, \"// My comment\\n\", &szKernelLength);\n    oclCheckErrorEX(cSourceCL != NULL, shrTRUE, pCleanup);\n    shrLog(\"oclLoadProgSource...\\n\"); \n\n    // Create the program \n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&cSourceCL, &szKernelLength, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"clCreateProgramWithSource...\\n\"); \n\n    std::string sBuildOpts = \" -cl-fast-relaxed-math\"; \n    sBuildOpts  += bUseLmem ? \" -D USELMEM\" : \" -D USETEXTURE\";\n\n    // mac\n    #ifdef MAC\n        sBuildOpts  += \" -DMAC\";\n    #endif\n\n    ciErrNum = clBuildProgram(cpProgram, 0, NULL, sBuildOpts.c_str(), NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, cdDevices[uiTargetDevice]);\n        oclLogPtx(cpProgram, cdDevices[uiTargetDevice], \"oclBoxFilter.ptx\");\n        shrQAFinish(argc, (const char **)argv, QA_FAILED);\n        Cleanup(EXIT_FAILURE);\n    }\n    shrLog(\"clBuildProgram...\\n\"); \n\n    if (bUseLmem)\n    {\n        ckBoxRowsLmem = clCreateKernel(cpProgram, \"BoxRowsLmem\", &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clCreateKernel (BoxRowsLmem)...\\n\"); \n\n        ciErrNum = clGetKernelWorkGroupInfo(ckBoxRowsLmem, cdDevices[uiTargetDevice], \n                                            CL_KERNEL_WORK_GROUP_SIZE, sizeof(size_t), &szMaxWorkgroupSize, NULL);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    }\n    else\n    {\n        ckBoxRowsTex = clCreateKernel(cpProgram, \"BoxRowsTex\", &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clCreateKernel (BoxRowsTex)...\\n\"); \n    }\n    ckBoxColumns = clCreateKernel(cpProgram, \"BoxColumns\", &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"clCreateKernel (BoxColumns)...\\n\"); \n\n    // set the kernel args\n    ResetKernelArgs(uiImageWidth, uiImageHeight, iRadius, fScale);\n\n    // init running timers\n    shrDeltaT(0);   // timer 0 used for computation timing \n    shrDeltaT(1);   // timer 1 used for fps computation\n\n    if (!(bQATest))\n    {\n        glutMainLoop();\n    }\n    else \n    {\n        TestNoGL();\n    }\n\n    shrQAFinish2(bQATest, argc, (const char **)argv, QA_PASSED);\n    Cleanup(EXIT_SUCCESS);\n}\n\nvoid ResetKernelArgs(unsigned int uiWidth, unsigned int uiHeight, int r, float fScale)\n{\n    if (bUseLmem)\n    {\n        // (lmem version)\n        iRadiusAligned = ((r + 15)/16) * 16;\n        if (szMaxWorkgroupSize < (iRadiusAligned + uiNumOutputPix + r))\n        {\n            uiNumOutputPix = (cl_uint)szMaxWorkgroupSize - iRadiusAligned - r;   \n        }\n        ciErrNum = clSetKernelArg(ckBoxRowsLmem, 0, sizeof(cl_mem), (void*)&cmDevBufIn);\n        ciErrNum |= clSetKernelArg(ckBoxRowsLmem, 1, sizeof(cl_mem), (void*)&cmDevBufTemp);\n        ciErrNum |= clSetKernelArg(ckBoxRowsLmem, 2, (iRadiusAligned + uiNumOutputPix + r) * sizeof(cl_uchar4), NULL);\n        ciErrNum |= clSetKernelArg(ckBoxRowsLmem, 3, sizeof(unsigned int), (void*)&uiWidth);\n        ciErrNum |= clSetKernelArg(ckBoxRowsLmem, 4, sizeof(unsigned int), (void*)&uiHeight);\n        ciErrNum |= clSetKernelArg(ckBoxRowsLmem, 5, sizeof(int), (void*)&r);\n        ciErrNum |= clSetKernelArg(ckBoxRowsLmem, 6, sizeof(int), (void*)&iRadiusAligned);\n        ciErrNum |= clSetKernelArg(ckBoxRowsLmem, 7, sizeof(float), (void*)&fScale);\n        ciErrNum |= clSetKernelArg(ckBoxRowsLmem, 8, sizeof(unsigned int), (void*)&uiNumOutputPix);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clSetKernelArg (0-8) ckBoxRowsLmem...\\n\"); \n    }\n    else\n    {\n        // (Image/texture version)\n        ciErrNum = clSetKernelArg(ckBoxRowsTex, 0, sizeof(cl_mem), (void*)&cmDevBufIn);\n        ciErrNum |= clSetKernelArg(ckBoxRowsTex, 1, sizeof(cl_mem), (void*)&cmDevBufTemp);\n        ciErrNum |= clSetKernelArg(ckBoxRowsTex, 2, sizeof(cl_sampler), &RowSampler); \n        ciErrNum |= clSetKernelArg(ckBoxRowsTex, 3, sizeof(unsigned int), (void*)&uiWidth);\n        ciErrNum |= clSetKernelArg(ckBoxRowsTex, 4, sizeof(unsigned int), (void*)&uiHeight);\n        ciErrNum |= clSetKernelArg(ckBoxRowsTex, 5, sizeof(int), (void*)&r);\n        ciErrNum |= clSetKernelArg(ckBoxRowsTex, 6, sizeof(float), (void*)&fScale);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clSetKernelArg (0-6) ckBoxRowsTex...\\n\"); \n    }\n\n    // Set the Argument values for the column kernel\n    ciErrNum  = clSetKernelArg(ckBoxColumns, 0, sizeof(cl_mem), (void*)&cmDevBufTemp);\n    ciErrNum |= clSetKernelArg(ckBoxColumns, 1, sizeof(cl_mem), (void*)&cmDevBufOut);\n    ciErrNum |= clSetKernelArg(ckBoxColumns, 2, sizeof(unsigned int), (void*)&uiWidth);\n    ciErrNum |= clSetKernelArg(ckBoxColumns, 3, sizeof(unsigned int), (void*)&uiHeight);\n    ciErrNum |= clSetKernelArg(ckBoxColumns, 4, sizeof(int), (void*)&r);\n    ciErrNum |= clSetKernelArg(ckBoxColumns, 5, sizeof(float), (void*)&fScale);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"clSetKernelArg (0-5) ckBoxColumns...\\n\\n\"); \n}\n\ndouble BoxFilterGPU(unsigned int* uiInputImage, cl_mem cmOutputBuffer, \n                    unsigned int uiWidth, unsigned int uiHeight, int r, float fScale)\n{\n    ciErrNum = clSetKernelArg(ckBoxColumns, 1, sizeof(cl_mem), (void*)&cmOutputBuffer);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    \n    if (bUseLmem)\n    {\n        // lmem version\n        ciErrNum = clEnqueueWriteBuffer(cqCommandQueue, cmDevBufIn, CL_TRUE, 0, szBuffBytes, uiInputImage, 0, NULL, NULL);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n        szLocalWorkSize[0] = (size_t)(iRadiusAligned + uiNumOutputPix + r);   // Workgroup padded left and right\n        szLocalWorkSize[1] = 1;\n        szGlobalWorkSize[0] = szLocalWorkSize[0] * DivUp((size_t)uiWidth, (size_t)uiNumOutputPix);\n        szGlobalWorkSize[1] = uiHeight;\n    }\n    else\n    {\n        // 2D Image (Texture)\n        const size_t szTexOrigin[3] = {0, 0, 0};                // Offset of input texture origin relative to host image\n        const size_t szTexRegion[3] = {uiWidth, uiHeight, 1};   // Size of texture region to operate on\n        ciErrNum = clEnqueueWriteImage(cqCommandQueue, cmDevBufIn, CL_TRUE, \n                                       szTexOrigin, szTexRegion, 0, 0, uiInputImage, 0, NULL, NULL);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n        szLocalWorkSize[0] = uiNumOutputPix;\n        szLocalWorkSize[1] = 1;\n        szGlobalWorkSize[0]= szLocalWorkSize[0] * DivUp((size_t)uiHeight, szLocalWorkSize[0]);\n        szGlobalWorkSize[1] = 1;\n    }\n\n    clFinish(cqCommandQueue);\n    shrDeltaT(0);\n\n    if (bUseLmem)\n    {\n        // lmem Version\n        ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckBoxRowsLmem, 2, NULL, \n                                          szGlobalWorkSize, szLocalWorkSize, 0, NULL, NULL);\n    }\n    else \n    {\n        // 2D Image (Texture)\n        ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckBoxRowsTex, 2, NULL, \n                                          szGlobalWorkSize, szLocalWorkSize, 0, NULL, NULL);\n    }\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    szLocalWorkSize[0] = 64;\n    szLocalWorkSize[1] = 1;\n    szGlobalWorkSize[0] = szLocalWorkSize[0] * DivUp((size_t)uiWidth, szLocalWorkSize[0]);\n    szGlobalWorkSize[1] = 1;\n\n    ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckBoxColumns, 2, NULL, \n                                      szGlobalWorkSize, szLocalWorkSize, 0, NULL, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    clFinish(cqCommandQueue);\n    return shrDeltaT(0);\n}\n\nvoid InitGlut(int* argc, char **argv)\n{\n    shrLog(\"  glutInit...\\n\"); \n    glutInit(argc, argv);\n    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE);\n    glutInitWindowPosition (glutGet(GLUT_SCREEN_WIDTH)/2 - iGraphicsWinWidth/2, \n                            glutGet(GLUT_SCREEN_HEIGHT)/2 - iGraphicsWinHeight/2);\n    glutInitWindowSize(iGraphicsWinWidth, iGraphicsWinHeight);\n    iGLUTWindowHandle = glutCreateWindow(\"OpenCL GPU BoxFilter Demo\");\n#if !(defined (__APPLE__) || defined(MACOSX))\n    glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_GLUTMAINLOOP_RETURNS);\n#endif\n\n    // register glut callbacks\n    glutKeyboardFunc(KeyboardGL);\n    glutDisplayFunc(DisplayGL);\n    glutReshapeFunc(Reshape);\n    glutIdleFunc(Idle);\n\tglutTimerFunc(REFRESH_DELAY, timerEvent,0);\n\n    iGLUTMenuHandle = glutCreateMenu(MenuGL);\n    glutAddMenuEntry(\"Toggle Filter On/Off <spacebar>\", ' ');\n    glutAddMenuEntry(\"Increase Filter Radius [+]\", '+');\n    glutAddMenuEntry(\"Decrease Filter Radius [-]\", '-');\n    glutAddMenuEntry(\"Toggle Processing between GPU and CPU [p]\", 'p');\n    glutAddMenuEntry(\"Toggle OpenGL interop [g]\", 'g');\n    glutAddMenuEntry(\"Toggle between Full Screen and Windowed [f]\", 'f');\n    glutAddMenuEntry(\"Quit <esc>\", '\\033');\n    glutAttachMenu(GLUT_RIGHT_BUTTON);\n}\n\n\nvoid InitGlew()\n{\n    // Create GL interop buffers\n    shrLog(\"  glewInit...\\n\"); \n    glewInit();\n    shrLog(\"  createPBO...\\n\"); \n    createPBO(&pbo, uiImageWidth, uiImageHeight);\n    shrLog(\"  createTexture...\\n\"); \n    createTexture(&tex_screen, uiImageWidth, uiImageHeight);\n\n    // Disable vertical sync, if supported\n    #ifdef _WIN32\n        if (wglewIsSupported(\"WGL_EXT_swap_control\")) \n        {\n            iVsyncState = wglGetSwapIntervalEXT();\n            wglSwapIntervalEXT(0);\n        }\n    #else\n        #if defined (__APPLE__) || defined(MACOSX)\n            GLint VBL = 0;\n            CGLGetParameter(CGLGetCurrentContext(), kCGLCPSwapInterval, &iVsyncState); \n            CGLSetParameter(CGLGetCurrentContext(), kCGLCPSwapInterval, &VBL); \n        #else\n            if(glxewIsSupported(\"GLX_SGI_swap_control\")) \n            {\n                glXSwapIntervalSGI(0);\t \n            }\n        #endif\n    #endif\n}\n\nvoid DeInitGL()\n{\n    // Restore startup Vsync state, if supported\n    #ifdef _WIN32\n        if (wglewIsSupported(\"WGL_EXT_swap_control\")) \n        {\n            wglSwapIntervalEXT(iVsyncState);\n        }\n    #else\n        #if defined (__APPLE__) || defined(MACOSX)\n            CGLSetParameter(CGLGetCurrentContext(), kCGLCPSwapInterval, &iVsyncState); \n        #endif\n    #endif\n\n    // Delete GL objects\n    if(pbo)deletePBO(&pbo);\n    if(tex_screen)deleteTexture(&tex_screen);\n}\n\nvoid DisplayGL()\n{        \n    if (glutGetWindow() == 0)\n    {\n        shrQAFinish2(false, pArgc, (const char **)pArgv, QA_PASSED);\n        Cleanup(EXIT_SUCCESS);\n    }\n\n    if (bFilter)\n    {\n        if (iProcFlag == 0)\n        {\n            cl_mem cmOutput;\n            if(bGLinterop) \n            {\n                glFinish();\n                clEnqueueAcquireGLObjects(cqCommandQueue, 1, &cmCL_PBO, 0, 0, 0);\n                cmOutput = cmCL_PBO;\n            } \n            else \n            {\n                cmOutput = cmDevBufOut;\n            }\n\n            dProcessingTime += BoxFilterGPU (uiInput, cmOutput, uiImageWidth, uiImageHeight, iRadius, fScale);\n\n            if(bGLinterop) \n            {\n                clEnqueueReleaseGLObjects(cqCommandQueue, 1, &cmCL_PBO, 0, 0, 0);\n                clFinish(cqCommandQueue);\n            } \n            else \n            {\n                glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);    \n                void* uiOutput = glMapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, GL_WRITE_ONLY_ARB);\n\n                ciErrNum = clEnqueueReadBuffer(cqCommandQueue, cmDevBufOut, CL_TRUE, 0, szBuffBytes, uiOutput, 0, NULL, NULL);\n                oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n                glUnmapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB); \n                glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n            }\n        }\n        else \n        {\n            glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);    \n            unsigned int* uiOutput = (unsigned int*)glMapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, GL_WRITE_ONLY_ARB);\n\n            dProcessingTime += BoxFilterHost (uiInput, uiTemp, uiOutput, uiImageWidth, uiImageHeight, iRadius, fScale);\n\n            glUnmapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB); \n            glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n        }\n        \n        glBindTexture(GL_TEXTURE_2D, tex_screen);\n        glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);    \n        glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, uiImageWidth, uiImageHeight, GL_RGBA, GL_UNSIGNED_BYTE, NULL);\n        glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, 0);        \n        glBindTexture(GL_TEXTURE_2D, 0);\n    }\n    else \n    {\n        glBindTexture(GL_TEXTURE_2D, tex_screen);\n        glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, uiImageWidth, uiImageHeight, GL_RGBA, GL_UNSIGNED_BYTE, uiInput);\n        glBindTexture(GL_TEXTURE_2D, 0);\n    }\n\n    displayTexture(tex_screen);\n\n    glutSwapBuffers();\n\n    if (iFrameCount++ > iFrameTrigger)\n    {\n        char cTitle[512];\n\n        iFramesPerSec = (int)((double)iFrameCount / shrDeltaT(1));\n        dProcessingTime /= (double)iFrameCount; \n\n#ifdef GPU_PROFILING\n        if (bFilter)\n        {\n            #ifdef _WIN32\n            sprintf_s(cTitle, 512, \"%s BoxFilter ON | %s | GL Interop %s | W %u , H %u | r = %i | %i fps | Proc. t = %.5f s | %.1f Mpix/s\", \n                cProcessor[iProcFlag], bUseLmem ? \"LMEM\" : \"Texture\", bGLinterop ? \"ON\" : \"OFF\", uiImageWidth, uiImageHeight, iRadius, \n                      iFramesPerSec, dProcessingTime, (1.0e-6 * uiImageWidth * uiImageHeight)/dProcessingTime);  \n            #else\n             sprintf(cTitle, \"%s BoxFilter ON| %s | GL Interop %s | W %u , H %u |  r = %i | %i fps | Proc. t = %.5f s | %.1f Mpix/s\", \n                     cProcessor[iProcFlag], bUseLmem ? \"LMEM\" : \"Texture\", bGLinterop ? \"ON\" : \"OFF\", uiImageWidth, uiImageHeight, iRadius,  \n                     iFramesPerSec, dProcessingTime, (1.0e-6 * uiImageWidth * uiImageHeight)/dProcessingTime);  \n            #endif\n        }\n        else \n        {\n            #ifdef _WIN32\n            sprintf_s(cTitle, 512, \"%s BoxFilter OFF | W %u , H %u | %i fps\", \n                      cProcessor[iProcFlag], uiImageWidth, uiImageHeight, iFramesPerSec);  \n            #else \n            sprintf(cTitle, \"%s BoxFilter OFF | W %u , H %u | %i fps\", \n                    cProcessor[iProcFlag], uiImageWidth, uiImageHeight, iFramesPerSec);  \n            #endif\n        }\n#else\n        if (bFilter)\n        {\n            #ifdef _WIN32\n            sprintf_s(cTitle, 256, \"%s BoxFilter ON | %s | GL Interop %s | W %u , H %u | r = %i\", \n                      cProcessor[iProcFlag], bUseLmem ? \"LMEM\" : \"Texture\", bGLinterop ? \"ON\" : \"OFF\", uiImageWidth, uiImageHeight, iRadius);  \n            #else\n             sprintf(cTitle, \"%s BoxFilter ON | %s | GL Interop %s | W %u , H %u | r = %i\", \n                     cProcessor[iProcFlag], bUseLmem ? \"LMEM\" : \"Texture\", bGLinterop ? \"ON\" : \"OFF\", uiImageWidth, uiImageHeight, iRadius);  \n            #endif\n        }\n        else \n        {\n            #ifdef _WIN32\n            sprintf_s(cTitle, 256, \"%s BoxFilter OFF | W %u , H %u\", \n                    cProcessor[iProcFlag], uiImageWidth, uiImageHeight);  \n            #else \n            sprintf(cTitle, \"%s BoxFilter OFF | W %u , H %u\", \n                    cProcessor[iProcFlag], uiImageWidth, uiImageHeight);  \n            #endif\n        }\n#endif\n        glutSetWindowTitle(cTitle);\n\n        shrLog(\"%s\\n\", cTitle); \n\n        if ((bNoPrompt) && (!--iTestSets))\n        {\n            shrQAFinish2(false, pArgc, (const char **)pArgv, QA_PASSED);\n            Cleanup(EXIT_SUCCESS);\n        }\n\n        iFrameCount = 0; \n        dProcessingTime = 0.0;\n        iFrameTrigger = (iFramesPerSec > 1) ? iFramesPerSec * 2 : 1;\n    }\n}\n\nvoid Reshape(int w, int h)\n{\n    iGraphicsWinHeight = h;\n    iGraphicsWinWidth = w;\n}\n\nvoid timerEvent(int value)\n{\n    glutPostRedisplay();\n\tglutTimerFunc(REFRESH_DELAY, timerEvent,0);\n}\n\nvoid KeyboardGL(unsigned char key, int /*x*/, int /*y*/)\n{\n    switch(key) \n    {\n        case 'P':\n        case 'p':\n            if (iProcFlag == 0)\n            {\n                iProcFlag = 1;\n            }\n            else \n            {\n                iProcFlag = 0;\n            }\n            shrLog(\"\\n%s Processing...\\n\\n\", cProcessor[iProcFlag]);\n            break;\n        case '+':\n        case '=':\n            if ((szMaxWorkgroupSize - (((iRadius + 1 + 15)/16) * 16) - iRadius - 1) > 0)iRadius++;\n            break;\n        case '-':\n        case '_':\n            if (iRadius > 1)iRadius--;\n            break;\n        case 'g':\n        case 'G':\n            if(bGLinteropSupported) \n            {\n                bGLinterop = !bGLinterop;\n                shrLog(\"\\nGL Interop Toggled %s...\\n\", bGLinterop ? \"ON\" : \"OFF\");\n            } \n            else\n            {\n                shrLog(\"\\nGL Interop not supported\\n\");\n            }\n            break;\n        case 'F':\n        case 'f':\n            bFullScreen = !bFullScreen;\n            if (bFullScreen)\n            {\n                iGraphicsWinPosX = glutGet(GLUT_WINDOW_X) - 8;\n                iGraphicsWinPosY = glutGet(GLUT_WINDOW_Y) - 30;\n                iGraphicsWinWidthNonFS  = min(glutGet(GLUT_WINDOW_WIDTH) , glutGet(GLUT_SCREEN_WIDTH) - 2*iGraphicsWinPosX ); \n                iGraphicsWinHeightNonFS = min(glutGet(GLUT_WINDOW_HEIGHT), glutGet(GLUT_SCREEN_HEIGHT)- 2*iGraphicsWinPosY ); \n                printf(\"(x,y)=(%d,%d), (w,h)=(%d,%d)\\n\", iGraphicsWinPosX, iGraphicsWinPosY, iGraphicsWinWidthNonFS, iGraphicsWinHeightNonFS);\n                glutFullScreen();\n            }\n            else\n            {\n                glutPositionWindow(iGraphicsWinPosX, iGraphicsWinPosY);\n                glutReshapeWindow(iGraphicsWinWidthNonFS, iGraphicsWinHeightNonFS);\n            }\n            shrLog(\"\\nMain Graphics %s...\\n\", bFullScreen ? \"FullScreen\" : \"Windowed\");\n            break;\n        case ' ':\n            bFilter = !bFilter;\n            shrLog(\"\\nBoxFilter Toggled %s...\\n\", bFilter ? \"ON\" : \"OFF\");\n            break;\n        case '\\033':  \n        case '\\015':\n        case 'Q':\n        case 'q':\n\t\t\tbNoPrompt = shrTRUE;\n            shrQAFinish2(false, pArgc, (const char **)pArgv, QA_PASSED);\n            Cleanup(EXIT_SUCCESS);\n            break;\n    }\n\n    fScale = 1.0f/(2 * iRadius + 1);\n    ResetKernelArgs(uiImageWidth, uiImageHeight, iRadius, fScale);\n\n    TriggerFPSUpdate();\n}\n\nvoid MenuGL(int i)\n{\n    KeyboardGL((unsigned char) i, 0, 0);\n}\n\nvoid Idle(void)\n{\n}\n\nstatic inline size_t DivUp(size_t dividend, size_t divisor)\n{\n    return (dividend % divisor == 0) ? (dividend / divisor) : (dividend / divisor + 1);\n}\n\nvoid TriggerFPSUpdate()\n{\n    iFrameCount = 0; \n    iFramesPerSec = 1;\n    iFrameTrigger = 2;\n    shrDeltaT(1);\n    shrDeltaT(0);\n    dProcessingTime = 0.0;\n}\n\nvoid TestNoGL()\n{\n    BoxFilterGPU (uiInput, cmDevBufOut, uiImageWidth, uiImageHeight, iRadius, fScale);\n    clFinish(cqCommandQueue);\n\n    const int iCycles = 150;\n    dProcessingTime = 0.0;\n    shrLog(\"\\nRunning BoxFilterGPU for %d cycles...\\n\\n\", iCycles);\n    shrDeltaT(2);\n    for (int i = 0; i < iCycles; i++)\n    {\n        dProcessingTime += BoxFilterGPU (uiInput, cmDevBufOut, uiImageWidth, uiImageHeight, iRadius, fScale);\n    }\n    clFinish(cqCommandQueue);\n\n    double dRoundtripTime = shrDeltaT(2)/(double)iCycles;\n    dProcessingTime /= (double)iCycles;\n\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclBoxFilter-%s, Throughput = %.4f M RGBA Pixels/s, Time = %.5f s, Size = %u RGBA Pixels, NumDevsUsed = %u, Workgroup = %u\\n\", \n                                  bUseLmem ? \"lmem\" : \"texture\",\n                                  (1.0e-6 * uiImageWidth * uiImageHeight)/dProcessingTime, dProcessingTime, \n                                  (uiImageWidth * uiImageHeight), uiNumDevsUsed, szLocalWorkSize[0] * szLocalWorkSize[1]); \n    shrLog(\"\\nRoundTrip Time = %.5f s, Equivalent FPS = %.1f\\n\", dRoundtripTime, 1.0/dRoundtripTime);\n\n    shrQAFinish2(true, pArgc, (const char **)pArgv, QA_PASSED);\n    Cleanup(EXIT_SUCCESS);\n}\n\nvoid ShowMenuItems()\n{\n    shrLog(\"  Right-Click on Mouse for Menu\\n\\n\"); \n    shrLog(\"  or\\n\\n  Press:\\n\\n   <spacebar> to toggle Filter On/Off\\n\\n\");\n    shrLog(\"   \\'F\\' key to toggle between FullScreen and Windowed\\n\\n\");\n    shrLog(\"   \\'+\\' key to Increase filter radius\\n\\n\");\n    shrLog(\"   \\'-\\' key to Decrease filter radius\\n\\n\"); \n    shrLog(\"   \\'G\\' key to toggle between OpenGL interop and no-OpenCL interop\\n\\n\");\n    shrLog(\"   \\'P\\' key to toggle Processing between GPU and CPU\\n\\n   <esc> to Quit\\n\\n\\n\"); \n}\n\nvoid Cleanup(int iExitCode)\n{\n    shrLog(\"\\nStarting Cleanup...\\n\\n\");\n    if(cSourceCL)free(cSourceCL);\n    if(cPathAndName)free(cPathAndName);\n    if(uiInput)free(uiInput);\n    if(uiTemp)free(uiTemp);\n    if(ckBoxColumns)clReleaseKernel(ckBoxColumns);\n    if(ckBoxRowsTex)clReleaseKernel(ckBoxRowsTex);\n    if(ckBoxRowsLmem)clReleaseKernel(ckBoxRowsLmem);\n    if(cpProgram)clReleaseProgram(cpProgram);\n    if(RowSampler)clReleaseSampler(RowSampler);\n    if(cmDevBufIn)clReleaseMemObject(cmDevBufIn);\n    if(cmDevBufTemp)clReleaseMemObject(cmDevBufTemp);\n    if(cmDevBufOut)clReleaseMemObject(cmDevBufOut);\n    if(cmCL_PBO)clReleaseMemObject(cmCL_PBO);\n    if(cqCommandQueue)clReleaseCommandQueue(cqCommandQueue);\n    if(cxGPUContext)clReleaseContext(cxGPUContext);\n    if(cdDevices)free(cdDevices);\n\n    if (!bQATest)\n    {\n        DeInitGL();\n    }\n\n    if ((bNoPrompt)||(bQATest))\n    {\n        shrLogEx(LOGBOTH | CLOSELOG, 0, \"%s Exiting...\\n\", cpExecutableName);\n    }\n    else \n    {\n        shrLogEx(LOGBOTH | CLOSELOG, 0, \"%s Exiting...\\nPress <Enter> to Quit\\n\", cpExecutableName);\n        #ifdef WIN32\n            getchar();\n        #endif\n    }\n    exit (iExitCode);\n}\n\nvoid displayTexture(GLuint texture)\n{\n    \n    glDisable(GL_DEPTH_TEST);\n    glDisable(GL_LIGHTING);\n    glEnable(GL_TEXTURE_2D);\n    glTexEnvf(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_REPLACE);\n    glBindTexture(GL_TEXTURE_2D, texture);\n\n    glMatrixMode(GL_PROJECTION);\n    glPushMatrix();\n    glLoadIdentity();\n    glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0);\n\n    glMatrixMode( GL_MODELVIEW);\n    glLoadIdentity();\n\n    glViewport(0, 0, iGraphicsWinWidth, iGraphicsWinHeight);\n\n    glBegin(GL_QUADS);\n\n    glTexCoord2f(0.0, 0.0);\n    glVertex3f(-1.0, -1.0, 0.5);\n\n    glTexCoord2f(1.0, 0.0);\n    glVertex3f(1.0, -1.0, 0.5);\n\n    glTexCoord2f(1.0, 1.0);\n    glVertex3f(1.0, 1.0, 0.5);\n\n    glTexCoord2f(0.0, 1.0);\n    glVertex3f(-1.0, 1.0, 0.5);\n\n    glEnd();\n\n    glMatrixMode(GL_PROJECTION);\n    glPopMatrix();\n\n    glDisable(GL_TEXTURE_2D);\n    glBindTexture(GL_TEXTURE_2D, 0);\n}\n\nvoid createPBO(GLuint* pbo, int image_width, int image_height)\n{\n    // set up data parameter\n    int num_texels = image_width * image_height;\n    int num_values = num_texels * 4;\n    int size_tex_data = sizeof(GLubyte) * num_values;\n\n    // create buffer object\n    shrLog(\"    glGenBuffers (pbo)...\\n\"); \n    glGenBuffers(1, pbo);\n    shrLog(\"    glBindBuffer (pbo)...\\n\"); \n    glBindBuffer(GL_ARRAY_BUFFER, *pbo);\n\n    // buffer data\n    shrLog(\"    glBufferData...\\n\"); \n    glBufferData(GL_ARRAY_BUFFER, size_tex_data, NULL, GL_DYNAMIC_DRAW);\n    shrLog(\"    glBindBuffer...\\n\"); \n    glBindBuffer(GL_ARRAY_BUFFER, 0);\n}\n\nvoid deletePBO(GLuint* pbo)\n{\n    glBindBuffer(GL_ARRAY_BUFFER, *pbo);\n    glDeleteBuffers(1, pbo);\n    *pbo = 0;\n}\n\nvoid deleteTexture(GLuint* tex)\n{\n    glDeleteTextures(1, tex);\n    *tex = 0;\n}\n\nvoid createTexture(GLuint* tex_name, unsigned int size_x, unsigned int size_y)\n{\n    shrLog(\"    glGenTextures...\\n\"); \n    glGenTextures(1, tex_name);\n    shrLog(\"    glGenTextures...\\n\"); \n    glBindTexture(GL_TEXTURE_2D, *tex_name);\n\n    shrLog(\"    glTexParameteri...\\n\"); \n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\n    shrLog(\"    glTexImage2D...\\n\"); \n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, size_x, size_y, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);\n}\n"}, "code_dirs": {"BoxFilter.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclBoxFilter", "oclBoxFilter.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclBoxFilter"}}
{"kernel_name": "dotProduct", "parallel_api": "cuda", "code": {"scalarProd.cu": "#include <helper_cuda.h>\n#include <helper_functions.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <time.h>\n\nextern \"C\" void scalarProdCPU(float *h_C, float *h_A, float *h_B, int vectorN, int elementN);\n\n#include \"scalarProd_kernel.cuh\"\n\nfloat RandFloat(float low, float high)\n{\n    float t = (float)rand() / (float)RAND_MAX;\n    return (1.0f - t) * low + t * high;\n}\n\nconst int VECTOR_N = 256;\nconst int ELEMENT_N = 4096;\nconst int DATA_N = VECTOR_N * ELEMENT_N;\n\nconst int DATA_SZ   = DATA_N * sizeof(float);\nconst int RESULT_SZ = VECTOR_N * sizeof(float);\n\nint main(int argc, char **argv)\n{\n    float              *h_A, *h_B, *h_C_CPU, *h_C_GPU;\n    float              *d_A, *d_B, *d_C;\n    double              delta, ref, sum_delta, sum_ref, L1norm;\n    StopWatchInterface *hTimer = NULL;\n    int                 i;\n\n    printf(\"%s Starting...\\n\\n\", argv[0]);\n\n    findCudaDevice(argc, (const char **)argv);\n\n    sdkCreateTimer(&hTimer);\n\n    printf(\"Initializing data...\\n\");\n    printf(\"...allocating CPU memory.\\n\");\n    h_A     = (float *)malloc(DATA_SZ);\n    h_B     = (float *)malloc(DATA_SZ);\n    h_C_CPU = (float *)malloc(RESULT_SZ);\n    h_C_GPU = (float *)malloc(RESULT_SZ);\n\n    printf(\"...allocating GPU memory.\\n\");\n    checkCudaErrors(cudaMalloc((void **)&d_A, DATA_SZ));\n    checkCudaErrors(cudaMalloc((void **)&d_B, DATA_SZ));\n    checkCudaErrors(cudaMalloc((void **)&d_C, RESULT_SZ));\n\n    printf(\"...generating input data in CPU mem.\\n\");\n    srand(123);\n\n    for (i = 0; i < DATA_N; i++) {\n        h_A[i] = RandFloat(0.0f, 1.0f);\n        h_B[i] = RandFloat(0.0f, 1.0f);\n    }\n\n    printf(\"...copying input data to GPU mem.\\n\");\n    checkCudaErrors(cudaMemcpy(d_A, h_A, DATA_SZ, cudaMemcpyHostToDevice));\n    checkCudaErrors(cudaMemcpy(d_B, h_B, DATA_SZ, cudaMemcpyHostToDevice));\n    printf(\"Data init done.\\n\");\n\n    printf(\"Executing GPU kernel...\\n\");\n    checkCudaErrors(cudaDeviceSynchronize());\n    sdkResetTimer(&hTimer);\n    sdkStartTimer(&hTimer);\n    scalarProdGPU<<<128, 256>>>(d_C, d_A, d_B, VECTOR_N, ELEMENT_N);\n    getLastCudaError(\"scalarProdGPU() execution failed\\n\");\n    checkCudaErrors(cudaDeviceSynchronize());\n    sdkStopTimer(&hTimer);\n    printf(\"GPU time: %f msecs.\\n\", sdkGetTimerValue(&hTimer));\n\n    printf(\"Reading back GPU result...\\n\");\n    checkCudaErrors(cudaMemcpy(h_C_GPU, d_C, RESULT_SZ, cudaMemcpyDeviceToHost));\n\n    printf(\"Checking GPU results...\\n\");\n    printf(\"..running CPU scalar product calculation\\n\");\n    scalarProdCPU(h_C_CPU, h_A, h_B, VECTOR_N, ELEMENT_N);\n\n    printf(\"...comparing the results\\n\");\n    sum_delta = 0;\n    sum_ref   = 0;\n\n    for (i = 0; i < VECTOR_N; i++) {\n        delta = fabs(h_C_GPU[i] - h_C_CPU[i]);\n        ref   = h_C_CPU[i];\n        sum_delta += delta;\n        sum_ref += ref;\n    }\n\n    L1norm = sum_delta / sum_ref;\n\n    printf(\"Shutting down...\\n\");\n    checkCudaErrors(cudaFree(d_C));\n    checkCudaErrors(cudaFree(d_B));\n    checkCudaErrors(cudaFree(d_A));\n    free(h_C_GPU);\n    free(h_C_CPU);\n    free(h_B);\n    free(h_A);\n    sdkDeleteTimer(&hTimer);\n\n    printf(\"L1 error: %E\\n\", L1norm);\n    printf((L1norm < 1e-6) ? \"Test passed\\n\" : \"Test failed!\\n\");\n    exit(L1norm < 1e-6 ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n", "scalarProd_kernel.cuh": "#include <cooperative_groups.h>\n\nnamespace cg = cooperative_groups;\n#define IMUL(a, b) __mul24(a, b)\n\n\n#define ACCUM_N 1024\n__global__ void scalarProdGPU(float *d_C, float *d_A, float *d_B, int vectorN, int elementN)\n{\n    // Handle to thread block group\n    cg::thread_block cta = cg::this_thread_block();\n    // Accumulators cache\n    __shared__ float accumResult[ACCUM_N];\n    for (int vec = blockIdx.x; vec < vectorN; vec += gridDim.x) {\n        int vectorBase = IMUL(elementN, vec);\n        int vectorEnd  = vectorBase + elementN;\n\n        for (int iAccum = threadIdx.x; iAccum < ACCUM_N; iAccum += blockDim.x) {\n            float sum = 0;\n\n            for (int pos = vectorBase + iAccum; pos < vectorEnd; pos += ACCUM_N)\n                sum += d_A[pos] * d_B[pos];\n\n            accumResult[iAccum] = sum;\n        }\n\n        for (int stride = ACCUM_N / 2; stride > 0; stride >>= 1) {\n            cg::sync(cta);\n\n            for (int iAccum = threadIdx.x; iAccum < stride; iAccum += blockDim.x)\n                accumResult[iAccum] += accumResult[stride + iAccum];\n        }\n\n        cg::sync(cta);\n\n        if (threadIdx.x == 0)\n            d_C[vec] = accumResult[0];\n    }\n}\n"}, "code_dirs": {"scalarProd.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/scalarProd", "scalarProd_kernel.cuh": "/home/erel.kaplan/atca_proj/data_backup/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/scalarProd/scalarProd_kernel.cuh" }}
{"kernel_name": "dotProduct", "parallel_api": "ocl", "code": {"DotProduct.cl": " __kernel void DotProduct (__global float* a, __global float* b, __global float* c, int iNumElements)\n{\n    // find position in global arrays\n    int iGID = get_global_id(0);\n\n    if (iGID >= iNumElements)\n    {   \n        return; \n    }\n\n    // process \n    int iInOffset = iGID << 2;\n    c[iGID] = a[iInOffset] * b[iInOffset] \n               + a[iInOffset + 1] * b[iInOffset + 1]\n               + a[iInOffset + 2] * b[iInOffset + 2]\n               + a[iInOffset + 3] * b[iInOffset + 3];\n}\n", "oclDotProduct.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n\nconst char* cSourceFile = \"DotProduct.cl\";\n\nvoid *srcA, *srcB, *dst;\nvoid* Golden;\n\n// OpenCL Vars\ncl_platform_id cpPlatform;      // OpenCL platform\ncl_device_id   *cdDevices;      // OpenCL device\ncl_context cxGPUContext;        // OpenCL context\ncl_command_queue cqCommandQueue;// OpenCL command que\ncl_program cpProgram;           // OpenCL program\ncl_kernel ckKernel;             // OpenCL kernel\ncl_mem cmDevSrcA;               // OpenCL device source buffer A\ncl_mem cmDevSrcB;               // OpenCL device source buffer B \ncl_mem cmDevDst;                // OpenCL device destination buffer \nsize_t szGlobalWorkSize;        // Total # of work items in the 1D range\nsize_t szLocalWorkSize;\t\t    // # of work items in the 1D work group\t\nsize_t szParmDataBytes;\t\t\t// Byte size of context information\nsize_t szKernelLength;\t\t\t// Byte size of kernel code\ncl_int ciErrNum;\t\t\t    // Error code var\nchar* cPathAndName = NULL;      // var for full paths to data, src, etc.\nchar* cSourceCL = NULL;         // Buffer to hold source for compilation \nconst char* cExecutableName = NULL;\n\n// demo config vars\nint iNumElements= 1277944;\t    // Length of float arrays to process (odd # for illustration)\nshrBOOL bNoPrompt = shrFALSE;  \n\nvoid DotProductHost(const float* pfData1, const float* pfData2, float* pfResult, int iNumElements);\nvoid Cleanup (int iExitCode);\nvoid (*pCleanup)(int) = &Cleanup;\n\nint *gp_argc = NULL;\nchar ***gp_argv = NULL;\n\nint main(int argc, char **argv)\n{\n    gp_argc = &argc;\n    gp_argv = &argv;\n\n    shrQAStart(argc, argv);\n\n    // Get the NVIDIA platform\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    shrLog(\"clGetPlatformID...\\n\"); \n\n    // Get the NVIDIA platform\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    shrLog(\"clGetPlatformID...\\n\"); \n\n    //Get all the devices\n    cl_uint uiNumDevices = 0;           // Number of devices available\n    cl_uint uiTargetDevice = 0;\t        // Default Device to compute on\n    cl_uint uiNumComputeUnits;          // Number of compute units (SM's on NV GPU)\n    shrLog(\"Get the Device info and select Device...\\n\");\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiNumDevices);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    cdDevices = (cl_device_id *)malloc(uiNumDevices * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiNumDevices, cdDevices, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n\n    // Get command line device options and config accordingly\n    shrLog(\"  # of Devices Available = %u\\n\", uiNumDevices); \n    if(shrGetCmdLineArgumentu(argc, (const char**)argv, \"device\", &uiTargetDevice)== shrTRUE) \n    {\n        uiTargetDevice = CLAMP(uiTargetDevice, 0, (uiNumDevices - 1));\n    }\n    shrLog(\"  Using Device %u: \", uiTargetDevice); \n    oclPrintDevName(LOGBOTH, cdDevices[uiTargetDevice]);\n    ciErrNum = clGetDeviceInfo(cdDevices[uiTargetDevice], CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(uiNumComputeUnits), &uiNumComputeUnits, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    shrLog(\"\\n  # of Compute Units = %u\\n\", uiNumComputeUnits); \n\n    // get command line arg for quick test, if provided\n    bNoPrompt = shrCheckCmdLineFlag(argc, (const char**)argv, \"noprompt\");\n\n    // start logs\n\tcExecutableName = argv[0];\n    shrSetLogFileName (\"oclDotProduct.txt\");\n    shrLog(\"%s Starting...\\n\\n# of float elements per Array \\t= %u\\n\", argv[0], iNumElements); \n\n    // set and log Global and Local work size dimensions\n    szLocalWorkSize = 256;\n    szGlobalWorkSize = shrRoundUp((int)szLocalWorkSize, iNumElements);  // rounded up to the nearest multiple of the LocalWorkSize\n    shrLog(\"Global Work Size \\t\\t= %u\\nLocal Work Size \\t\\t= %u\\n# of Work Groups \\t\\t= %u\\n\\n\", \n           szGlobalWorkSize, szLocalWorkSize, (szGlobalWorkSize % szLocalWorkSize + szGlobalWorkSize/szLocalWorkSize)); \n\n    // Allocate and initialize host arrays\n    shrLog( \"Allocate and Init Host Mem...\\n\"); \n    srcA = (void *)malloc(sizeof(cl_float4) * szGlobalWorkSize);\n    srcB = (void *)malloc(sizeof(cl_float4) * szGlobalWorkSize);\n    dst = (void *)malloc(sizeof(cl_float) * szGlobalWorkSize);\n    Golden = (void *)malloc(sizeof(cl_float) * iNumElements);\n    shrFillArray((float*)srcA, 4 * iNumElements);\n    shrFillArray((float*)srcB, 4 * iNumElements);\n\n    // Get the NVIDIA platform\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Get a GPU device\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 1, &cdDevices[uiTargetDevice], NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Create the context\n    cxGPUContext = clCreateContext(0, 1, &cdDevices[uiTargetDevice], NULL, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Create a command-queue\n    shrLog(\"clCreateCommandQueue...\\n\"); \n    cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevices[uiTargetDevice], 0, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Allocate the OpenCL buffer memory objects for source and result on the device GMEM\n    shrLog(\"clCreateBuffer (SrcA, SrcB and Dst in Device GMEM)...\\n\"); \n    cmDevSrcA = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, sizeof(cl_float) * szGlobalWorkSize * 4, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    cmDevSrcB = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, sizeof(cl_float) * szGlobalWorkSize * 4, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    cmDevDst = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, sizeof(cl_float) * szGlobalWorkSize, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Read the OpenCL kernel in from source file\n    shrLog(\"oclLoadProgSource (%s)...\\n\", cSourceFile); \n    cPathAndName = shrFindFilePath(cSourceFile, argv[0]);\n    oclCheckErrorEX(cPathAndName != NULL, shrTRUE, pCleanup);\n    cSourceCL = oclLoadProgSource(cPathAndName, \"\", &szKernelLength);\n    oclCheckErrorEX(cSourceCL != NULL, shrTRUE, pCleanup);\n\n    // Create the program\n    shrLog(\"clCreateProgramWithSource...\\n\"); \n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&cSourceCL, &szKernelLength, &ciErrNum);\n\n        // Build the program with 'mad' Optimization option\n    #ifdef MAC\n        char* flags = \"-cl-fast-relaxed-math -DMAC\";\n    #else\n        char* flags = \"-cl-fast-relaxed-math\";\n    #endif\n    shrLog(\"clBuildProgram...\\n\"); \n    ciErrNum = clBuildProgram(cpProgram, 0, NULL, NULL, NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        // write out standard error, Build Log and PTX, then cleanup and exit\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclDotProduct.ptx\");\n        Cleanup(EXIT_FAILURE); \n    }\n\n    // Create the kernel\n    shrLog(\"clCreateKernel (DotProduct)...\\n\"); \n    ckKernel = clCreateKernel(cpProgram, \"DotProduct\", &ciErrNum);\n\n    // Set the Argument values\n    shrLog(\"clSetKernelArg 0 - 3...\\n\\n\"); \n    ciErrNum = clSetKernelArg(ckKernel, 0, sizeof(cl_mem), (void*)&cmDevSrcA);\n    ciErrNum |= clSetKernelArg(ckKernel, 1, sizeof(cl_mem), (void*)&cmDevSrcB);\n    ciErrNum |= clSetKernelArg(ckKernel, 2, sizeof(cl_mem), (void*)&cmDevDst);\n    ciErrNum |= clSetKernelArg(ckKernel, 3, sizeof(cl_int), (void*)&iNumElements);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    shrLog(\"clEnqueueWriteBuffer (SrcA and SrcB)...\\n\"); \n    ciErrNum = clEnqueueWriteBuffer(cqCommandQueue, cmDevSrcA, CL_FALSE, 0, sizeof(cl_float) * szGlobalWorkSize * 4, srcA, 0, NULL, NULL);\n    ciErrNum |= clEnqueueWriteBuffer(cqCommandQueue, cmDevSrcB, CL_FALSE, 0, sizeof(cl_float) * szGlobalWorkSize * 4, srcB, 0, NULL, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Launch kernel\n    shrLog(\"clEnqueueNDRangeKernel (DotProduct)...\\n\"); \n    ciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 1, NULL, &szGlobalWorkSize, &szLocalWorkSize, 0, NULL, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Read back results and check accumulated errors\n    shrLog(\"clEnqueueReadBuffer (Dst)...\\n\\n\"); \n    ciErrNum = clEnqueueReadBuffer(cqCommandQueue, cmDevDst, CL_TRUE, 0, sizeof(cl_float) * szGlobalWorkSize, dst, 0, NULL, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Compute and compare results for golden-host and report errors and pass/fail\n    shrLog(\"Comparing against Host/C++ computation...\\n\\n\"); \n    DotProductHost ((const float*)srcA, (const float*)srcB, (float*)Golden, iNumElements);\n    shrBOOL bMatch = shrComparefet((const float*)Golden, (const float*)dst, (unsigned int)iNumElements, 0.0f, 0);\n\n    // Cleanup and leave\n    Cleanup (EXIT_SUCCESS);\n}\n\nvoid DotProductHost(const float* pfData1, const float* pfData2, float* pfResult, int iNumElements)\n{\n    int i, j, k;\n    for (i = 0, j = 0; i < iNumElements; i++) \n    {\n        pfResult[i] = 0.0f;\n        for (k = 0; k < 4; k++, j++) \n        {\n            pfResult[i] += pfData1[j] * pfData2[j]; \n        } \n    }\n}\n\nvoid Cleanup(int iExitCode)\n{\n    shrLog(\"Starting Cleanup...\\n\\n\");\n    if(cPathAndName)free(cPathAndName);\n    if(cSourceCL)free(cSourceCL);\n\tif(ckKernel)clReleaseKernel(ckKernel);  \n    if(cpProgram)clReleaseProgram(cpProgram);\n    if(cqCommandQueue)clReleaseCommandQueue(cqCommandQueue);\n    if(cxGPUContext)clReleaseContext(cxGPUContext);\n    if (cmDevSrcA)clReleaseMemObject(cmDevSrcA);\n    if (cmDevSrcB)clReleaseMemObject(cmDevSrcB);\n    if (cmDevDst)clReleaseMemObject(cmDevDst);\n\n    // Free host memory\n    free(srcA); \n    free(srcB);\n    free (dst);\n    free(Golden);\n\n    if (cdDevices) free(cdDevices);\n\n    shrQAFinishExit(*gp_argc, (const char **)*gp_argv, (iExitCode == EXIT_SUCCESS) ? QA_PASSED : QA_FAILED);\n}\n"}, "code_dirs": {"DotProduct.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclDotProduct", "oclDotProduct.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclDotProduct"}}
{"kernel_name": "radixSort", "parallel_api": "cuda", "code": {"radixSortThrust.cu": "#include <algorithm>\n#include <helper_cuda.h>\n#include <limits.h>\n#include <thrust/copy.h>\n#include <thrust/detail/type_traits.h>\n#include <thrust/device_vector.h>\n#include <thrust/generate.h>\n#include <thrust/host_vector.h>\n#include <thrust/random.h>\n#include <thrust/sequence.h>\n#include <thrust/sort.h>\n#include <time.h>\n\ntemplate <typename T, bool floatKeys> bool testSort(int argc, char **argv)\n{\n    int cmdVal;\n    int keybits = 32;\n\n    unsigned int numElements = 1048576;\n    bool         keysOnly    = checkCmdLineFlag(argc, (const char **)argv, \"keysonly\");\n    bool         quiet       = checkCmdLineFlag(argc, (const char **)argv, \"quiet\");\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"n\")) {\n        cmdVal      = getCmdLineArgumentInt(argc, (const char **)argv, \"n\");\n        numElements = cmdVal;\n\n        if (cmdVal < 0) {\n            printf(\"Error: elements must be > 0, elements=%d is invalid\\n\", cmdVal);\n            exit(EXIT_SUCCESS);\n        }\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"keybits\")) {\n        cmdVal  = getCmdLineArgumentInt(argc, (const char **)argv, \"keybits\");\n        keybits = cmdVal;\n\n        if (keybits <= 0) {\n            printf(\"Error: keybits must be > 0, keybits=%d is invalid\\n\", keybits);\n            exit(EXIT_SUCCESS);\n        }\n    }\n\n    unsigned int numIterations = (numElements >= 16777216) ? 10 : 100;\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"iterations\")) {\n        cmdVal        = getCmdLineArgumentInt(argc, (const char **)argv, \"iterations\");\n        numIterations = cmdVal;\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"help\")) {\n        printf(\"Command line:\\nradixSortThrust [-option]\\n\");\n        printf(\"Valid options:\\n\");\n        printf(\"-n=<N>        : number of elements to sort\\n\");\n        printf(\"-keybits=bits : keybits must be > 0\\n\");\n        printf(\"-keysonly     : only sort an array of keys (default sorts key-value \"\n               \"pairs)\\n\");\n        printf(\"-float        : use 32-bit float keys (default is 32-bit unsigned \"\n               \"int)\\n\");\n        printf(\"-quiet        : Output only the number of elements and the time to \"\n               \"sort\\n\");\n        printf(\"-help         : Output a help message\\n\");\n        exit(EXIT_SUCCESS);\n    }\n\n    if (!quiet)\n        printf(\"\\nSorting %d %d-bit %s keys %s\\n\\n\",\n               numElements,\n               keybits,\n               floatKeys ? \"float\" : \"unsigned int\",\n               keysOnly ? \"(only)\" : \"and values\");\n\n    int deviceID = -1;\n\n    if (cudaSuccess == cudaGetDevice(&deviceID)) {\n        cudaDeviceProp devprop;\n        cudaGetDeviceProperties(&devprop, deviceID);\n        unsigned int totalMem = (keysOnly ? 2 : 4) * numElements * sizeof(T);\n\n        if (devprop.totalGlobalMem < totalMem) {\n            printf(\"Error: insufficient amount of memory to sort %d elements.\\n\", numElements);\n            printf(\"%d bytes needed, %d bytes available\\n\", (int)totalMem, (int)devprop.totalGlobalMem);\n            exit(EXIT_SUCCESS);\n        }\n    }\n\n    thrust::host_vector<T>            h_keys(numElements);\n    thrust::host_vector<T>            h_keysSorted(numElements);\n    thrust::host_vector<unsigned int> h_values;\n\n    if (!keysOnly)\n        h_values = thrust::host_vector<unsigned int>(numElements);\n\n    thrust::default_random_engine rng(clock());\n\n    if (floatKeys) {\n        thrust::uniform_real_distribution<float> u01(0, 1);\n\n        for (int i = 0; i < (int)numElements; i++)\n            h_keys[i] = u01(rng);\n    }\n    else {\n        thrust::uniform_int_distribution<unsigned int> u(0, UINT_MAX);\n\n        for (int i = 0; i < (int)numElements; i++)\n            h_keys[i] = u(rng);\n    }\n\n    if (!keysOnly)\n        thrust::sequence(h_values.begin(), h_values.end());\n\n    thrust::device_vector<T>            d_keys;\n    thrust::device_vector<unsigned int> d_values;\n\n    cudaEvent_t start_event, stop_event;\n    checkCudaErrors(cudaEventCreate(&start_event));\n    checkCudaErrors(cudaEventCreate(&stop_event));\n\n    float totalTime = 0;\n\n    for (unsigned int i = 0; i < numIterations; i++) {\n        d_keys = h_keys;\n\n        if (!keysOnly)\n            d_values = h_values;\n\n        checkCudaErrors(cudaEventRecord(start_event, 0));\n\n        if (keysOnly)\n            thrust::sort(d_keys.begin(), d_keys.end());\n        else\n            thrust::sort_by_key(d_keys.begin(), d_keys.end(), d_values.begin());\n\n        checkCudaErrors(cudaEventRecord(stop_event, 0));\n        checkCudaErrors(cudaEventSynchronize(stop_event));\n\n        float time = 0;\n        checkCudaErrors(cudaEventElapsedTime(&time, start_event, stop_event));\n        totalTime += time;\n    }\n\n    totalTime /= (1.0e3f * numIterations);\n    printf(\"radixSortThrust, Throughput = %.4f MElements/s, Time = %.5f s, Size = \"\n           \"%u elements\\n\",\n           1.0e-6f * numElements / totalTime,\n           totalTime,\n           numElements);\n\n    getLastCudaError(\"after radixsort\");\n\n    thrust::copy(d_keys.begin(), d_keys.end(), h_keysSorted.begin());\n\n    if (!keysOnly)\n        thrust::copy(d_values.begin(), d_values.end(), h_values.begin());\n\n    getLastCudaError(\"copying results to host memory\");\n\n    bool bTestResult = thrust::is_sorted(h_keysSorted.begin(), h_keysSorted.end());\n\n    checkCudaErrors(cudaEventDestroy(start_event));\n    checkCudaErrors(cudaEventDestroy(stop_event));\n\n    if (!bTestResult && !quiet) {\n        return false;\n    }\n\n    return bTestResult;\n}\n\nint main(int argc, char **argv)\n{\n    printf(\"%s Starting...\\n\\n\", argv[0]);\n\n    findCudaDevice(argc, (const char **)argv);\n\n    bool bTestResult = false;\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"float\"))\n        bTestResult = testSort<float, true>(argc, argv);\n    else\n        bTestResult = testSort<unsigned int, false>(argc, argv);\n\n    printf(bTestResult ? \"Test passed\\n\" : \"Test failed!\\n\");\n}\n"}, "code_dirs": {"radixSortThrust.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/2_Concepts_and_Techniques/radixSortThrust"}}
{"kernel_name": "radixSort", "parallel_api": "ocl", "code": {"RadixSort.cl": "#define WARP_SIZE 32\nuint scanwarp(uint val, volatile __local uint* sData, int maxlevel)\n{\n    // The following is the same as 2 * RadixSort::WARP_SIZE * warpId + threadInWarp = \n    // 64*(threadIdx.x >> 5) + (threadIdx.x & (RadixSort::WARP_SIZE - 1))\n    int localId = get_local_id(0);\n    int idx = 2 * localId - (localId & (WARP_SIZE - 1));\n    sData[idx] = 0;\n    idx += WARP_SIZE;\n    sData[idx] = val;     \n\n    if (0 <= maxlevel) { sData[idx] += sData[idx - 1]; }\n    if (1 <= maxlevel) { sData[idx] += sData[idx - 2]; }\n    if (2 <= maxlevel) { sData[idx] += sData[idx - 4]; }\n    if (3 <= maxlevel) { sData[idx] += sData[idx - 8]; }\n    if (4 <= maxlevel) { sData[idx] += sData[idx -16]; }\n\n    return sData[idx] - val;  // convert inclusive -> exclusive\n}\n\nuint4 scan4(uint4 idata, __local uint* ptr)\n{    \n    \n    uint idx = get_local_id(0);\n\n    uint4 val4 = idata;\n    uint sum[3];\n    sum[0] = val4.x;\n    sum[1] = val4.y + sum[0];\n    sum[2] = val4.z + sum[1];\n    \n    uint val = val4.w + sum[2];\n    \n    val = scanwarp(val, ptr, 4);\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    if ((idx & (WARP_SIZE - 1)) == WARP_SIZE - 1)\n    {\n        ptr[idx >> 5] = val + val4.w + sum[2];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n\tif (idx < WARP_SIZE)\n\t\tptr[idx] = scanwarp(ptr[idx], ptr, 2);\n    \n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    val += ptr[idx >> 5];\n\n    val4.x = val;\n    val4.y = val + sum[0];\n    val4.z = val + sum[1];\n    val4.w = val + sum[2];\n\n    return val4;\n}\n\nuint4 rank4(uint4 preds, __local uint* sMem, __local uint* numtrue)\n{\n\tint localId = get_local_id(0);\n\tint localSize = get_local_size(0);\n\n\tuint4 address = scan4(preds, sMem);\n\t\n\tif (localId == localSize - 1) \n\t{\n\t\tnumtrue[0] = address.w + preds.w;\n\t}\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\t\n\tuint4 rank;\n\tint idx = localId*4;\n\trank.x = (preds.x) ? address.x : numtrue[0] + idx - address.x;\n\trank.y = (preds.y) ? address.y : numtrue[0] + idx + 1 - address.y;\n\trank.z = (preds.z) ? address.z : numtrue[0] + idx + 2 - address.z;\n\trank.w = (preds.w) ? address.w : numtrue[0] + idx + 3 - address.w;\n\t\n\treturn rank;\n}\n\nvoid radixSortBlockKeysOnly(uint4 *key, uint nbits, uint startbit, __local uint* sMem, __local uint* numtrue)\n{\n\tint localId = get_local_id(0);\n    int localSize = get_local_size(0);\n\t\n\tfor(uint shift = startbit; shift < (startbit + nbits); ++shift)\n\t{\n\t\tuint4 lsb;\n\t\tlsb.x = !(((*key).x >> shift) & 0x1);\n\t\tlsb.y = !(((*key).y >> shift) & 0x1);\n        lsb.z = !(((*key).z >> shift) & 0x1);\n        lsb.w = !(((*key).w >> shift) & 0x1);\n        \n\t\tuint4 r;\n\t\t\n\t\tr = rank4(lsb, sMem, numtrue);\n\n        // This arithmetic strides the ranks across 4 CTA_SIZE regions\n        sMem[(r.x & 3) * localSize + (r.x >> 2)] = (*key).x;\n        sMem[(r.y & 3) * localSize + (r.y >> 2)] = (*key).y;\n        sMem[(r.z & 3) * localSize + (r.z >> 2)] = (*key).z;\n        sMem[(r.w & 3) * localSize + (r.w >> 2)] = (*key).w;\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n        // The above allows us to read without 4-way bank conflicts:\n        (*key).x = sMem[localId];\n        (*key).y = sMem[localId +     localSize];\n        (*key).z = sMem[localId + 2 * localSize];\n        (*key).w = sMem[localId + 3 * localSize];\n\n\t\tbarrier(CLK_LOCAL_MEM_FENCE);\n\t}\n}\n\n__kernel void radixSortBlocksKeysOnly(__global uint4* keysIn, \n\t\t\t\t\t\t\t\t\t  __global uint4* keysOut,\n\t\t\t\t\t\t\t\t\t  uint nbits,\n\t\t\t\t\t\t\t\t\t  uint startbit,\n\t\t\t\t\t\t\t\t\t  uint numElements, \n\t\t\t\t\t\t\t\t\t  uint totalBlocks,\n\t\t\t\t\t\t\t\t\t  __local uint* sMem)\n{\n\tint globalId = get_global_id(0);\n\t__local uint numtrue[1];\n\n\tuint4 key;\n\tkey = keysIn[globalId];\n\t\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\t\n\tradixSortBlockKeysOnly(&key, nbits, startbit, sMem, numtrue);\n\t\n\tkeysOut[globalId] = key;\n}\n\n__kernel void findRadixOffsets(__global uint2* keys,\n\t\t\t\t\t\t\t   __global uint* counters,\n\t\t\t\t\t\t\t   __global uint* blockOffsets,\n\t\t\t\t\t\t\t   uint startbit,\n\t\t\t\t\t\t\t   uint numElements,\n\t\t\t\t\t\t\t   uint totalBlocks,\n\t\t\t\t\t\t\t   __local uint* sRadix1)\n{\n\t__local uint  sStartPointers[16];\n\n    uint groupId = get_group_id(0);\n    uint localId = get_local_id(0);\n    uint groupSize = get_local_size(0);\n\n    uint2 radix2;\n\n    radix2 = keys[get_global_id(0)];\n        \n\n    sRadix1[2 * localId]     = (radix2.x >> startbit) & 0xF;\n    sRadix1[2 * localId + 1] = (radix2.y >> startbit) & 0xF;\n\n    if(localId < 16) \n    {\n        sStartPointers[localId] = 0; \n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    if((localId > 0) && (sRadix1[localId] != sRadix1[localId - 1]) ) \n    {\n        sStartPointers[sRadix1[localId]] = localId;\n    }\n    if(sRadix1[localId + groupSize] != sRadix1[localId + groupSize - 1]) \n    {\n        sStartPointers[sRadix1[localId + groupSize]] = localId + groupSize;\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    if(localId < 16) \n    {\n        blockOffsets[groupId*16 + localId] = sStartPointers[localId];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    if((localId > 0) && (sRadix1[localId] != sRadix1[localId - 1]) ) \n    {\n        sStartPointers[sRadix1[localId - 1]] = \n            localId - sStartPointers[sRadix1[localId - 1]];\n    }\n    if(sRadix1[localId + groupSize] != sRadix1[localId + groupSize - 1] ) \n    {\n        sStartPointers[sRadix1[localId + groupSize - 1]] = \n            localId + groupSize - sStartPointers[sRadix1[localId + groupSize - 1]];\n    }\n        \n\n    if(localId == groupSize - 1) \n    {\n        sStartPointers[sRadix1[2 * groupSize - 1]] = \n            2 * groupSize - sStartPointers[sRadix1[2 * groupSize - 1]];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    if(localId < 16) \n    {\n        counters[localId * totalBlocks + groupId] = sStartPointers[localId];\n    }\n}\n\n__kernel void scanNaive(__global uint *g_odata, \n                        __global uint *g_idata, \n                        uint n,\n                        __local uint* temp)\n{\n\n    int localId = get_local_id(0);\n\n    int pout = 0;\n    int pin = 1;\n\n    temp[pout*n + localId] = (localId > 0) ? g_idata[localId-1] : 0;\n\n    for (int offset = 1; offset < n; offset *= 2)\n    {\n        pout = 1 - pout;\n        pin  = 1 - pout;\n        barrier(CLK_LOCAL_MEM_FENCE);\n\n        temp[pout*n+localId] = temp[pin*n+localId];\n\n        if (localId >= offset)\n            temp[pout*n+localId] += temp[pin*n+localId - offset];\n    }\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    g_odata[localId] = temp[pout*n+localId];\n}\n\n__kernel void reorderDataKeysOnly(__global uint  *outKeys, \n                                  __global uint2  *keys, \n                                  __global uint  *blockOffsets, \n                                  __global uint  *offsets, \n                                  __global uint  *sizes, \n                                  uint startbit,\n                                  uint numElements,\n                                  uint totalBlocks,\n                                  __local uint2* sKeys2)\n{\n    __local uint sOffsets[16];\n    __local uint sBlockOffsets[16];\n\n    __local uint *sKeys1 = (__local uint*)sKeys2; \n\n    uint groupId = get_group_id(0);\n\n\tuint globalId = get_global_id(0);\n    uint localId = get_local_id(0);\n    uint groupSize = get_local_size(0);\n\n    sKeys2[localId]   = keys[globalId];\n\n    if(localId < 16)  \n    {\n        sOffsets[localId]      = offsets[localId * totalBlocks + groupId];\n        sBlockOffsets[localId] = blockOffsets[groupId * 16 + localId];\n    }\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    uint radix = (sKeys1[localId] >> startbit) & 0xF;\n    uint globalOffset = sOffsets[radix] + localId - sBlockOffsets[radix];\n\n    if (globalOffset < numElements)\n    {\n        outKeys[globalOffset]   = sKeys1[localId];\n    }\n\n    radix = (sKeys1[localId + groupSize] >> startbit) & 0xF;\n    globalOffset = sOffsets[radix] + localId + groupSize - sBlockOffsets[radix];\n\n    if (globalOffset < numElements)\n    {\n        outKeys[globalOffset]   = sKeys1[localId + groupSize];\n    }\n \n\n}\n", "oclRadixSort.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n\n#include \"RadixSort.h\"\n\n#define MAX_GPU_COUNT 8\n\nint keybits = 32; // bit size of uint \n\n// forward declarations\nvoid makeRandomUintVector(unsigned int *a, unsigned int numElements, unsigned int keybits);\nbool verifySortUint(unsigned int *keysSorted, \n\t\t\t\t\tunsigned int *valuesSorted, \n\t\t\t\t\tunsigned int *keysUnsorted, \n\t\t\t\t\tunsigned int len);\n\nint main(int argc, const char **argv)\n{\n    cl_platform_id cpPlatform;                      // OpenCL platform\n    cl_uint nDevice;                                // OpenCL device count\n    cl_device_id* cdDevices;                        // OpenCL device list    \n\tcl_context cxGPUContext;                        // OpenCL context\n    cl_command_queue cqCommandQueue[MAX_GPU_COUNT]; // OpenCL command que\n\tcl_int ciErrNum;\n\n    shrQAStart(argc, (char **)argv);\n\n\tshrSetLogFileName (\"oclRadixSort.txt\");\n\tshrLog(\"%s starting...\\n\\n\", argv[0]);\n\n    shrLog(\"clGetPlatformID...\\n\"); \n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"clGetDeviceIDs...\\n\"); \n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &nDevice);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    cdDevices = (cl_device_id *)malloc(nDevice * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, nDevice, cdDevices, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"clCreateContext...\\n\"); \n    cxGPUContext = clCreateContext(0, nDevice, cdDevices, NULL, NULL, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Create command queue...\\n\\n\");\n    int id_device;\n    if(shrGetCmdLineArgumenti(argc, argv, \"device\", &id_device)) // Set up command queue(s) for GPU specified on the command line\n    {\n        // get & log device index # and name\n        cl_device_id cdDevice = cdDevices[id_device];\n\n        // create a command que\n        cqCommandQueue[0] = clCreateCommandQueue(cxGPUContext, cdDevice, 0, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        oclPrintDevInfo(LOGBOTH, cdDevice);\n        nDevice = 1;   \n    } \n    else \n    { // create command queues for all available devices        \n        for (cl_uint i = 0; i < nDevice; i++) \n        {\n            cqCommandQueue[i] = clCreateCommandQueue(cxGPUContext, cdDevices[i], 0, &ciErrNum);\n            oclCheckError(ciErrNum, CL_SUCCESS);\n        }\n        for (cl_uint i = 0; i < nDevice; i++) oclPrintDevInfo(LOGBOTH, cdDevices[i]);\n    }\n\n\tint ctaSize;\n\tif (!shrGetCmdLineArgumenti(argc, argv, \"work-group-size\", &ctaSize)) \n\t{\n\t\tctaSize = 128;\n\t}\n\n    shrLog(\"Running Radix Sort on %d GPU(s) ...\\n\\n\", nDevice);\n\n\tunsigned int numElements = 1048576;//128*128*128*2;\n\n    // Alloc and init some data on the host, then alloc and init GPU buffer  \n    unsigned int **h_keys       = (unsigned int**)malloc(nDevice * sizeof(unsigned int*));\n    unsigned int **h_keysSorted = (unsigned int**)malloc(nDevice * sizeof(unsigned int*));\n    cl_mem       *d_keys        = (cl_mem*       )malloc(nDevice * sizeof(cl_mem));\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n        h_keys[iDevice]       = (unsigned int*)malloc(numElements * sizeof(unsigned int));\n\t    h_keysSorted[iDevice] = (unsigned int*)malloc(numElements * sizeof(unsigned int));\n        makeRandomUintVector(h_keys[iDevice], numElements, keybits);\n\n        d_keys[iDevice] = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, \n            sizeof(unsigned int) * numElements, NULL, &ciErrNum);\n        ciErrNum |= clEnqueueWriteBuffer(cqCommandQueue[iDevice], d_keys[iDevice], CL_TRUE, 0, \n            sizeof(unsigned int) * numElements, h_keys[iDevice], 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }\n\t\n    // instantiate RadixSort objects\n    RadixSort **radixSort = (RadixSort**)malloc(nDevice * sizeof(RadixSort*));\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n\t    radixSort[iDevice] = new RadixSort(cxGPUContext, cqCommandQueue[iDevice], numElements, argv[0], ctaSize, true);\t\t    \n    }\n\n#ifdef GPU_PROFILING\n    int numIterations = 30;\n    for (int i = -1; i < numIterations; i++)\n    {\n        if (i == 0)\n        {\n            for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++) \n            {\n                clFinish(cqCommandQueue[iDevice]);\n            }\n            shrDeltaT(1);\n        }\n#endif\n        for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n        {\n\t        radixSort[iDevice]->sort(d_keys[iDevice], 0, numElements, keybits);\n        }\n#ifdef GPU_PROFILING\n    }\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++) \n    {\n        clFinish(cqCommandQueue[iDevice]);\n    }\n    double gpuTime = shrDeltaT(1)/(double)numIterations;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclRadixSort, Throughput = %.4f MElements/s, Time = %.5f s, Size = %u elements, NumDevsUsed = %d, Workgroup = %d\\n\", \n           (1.0e-6 * (double)(nDevice * numElements)/gpuTime), gpuTime, nDevice * numElements, nDevice, ctaSize);\n#endif\n\n    // copy sorted keys to CPU \n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n\t    clEnqueueReadBuffer(cqCommandQueue[iDevice], d_keys[iDevice], CL_TRUE, 0, sizeof(unsigned int) * numElements, \n            h_keysSorted[iDevice], 0, NULL, NULL);\n    }\n\n\t// Check results\n\tbool passed = true;\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n\t    passed &= verifySortUint(h_keysSorted[iDevice], NULL, h_keys[iDevice], numElements);\n    }\n\n    // cleanup allocs\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n        clReleaseMemObject(d_keys[iDevice]);\n\t    free(h_keys[iDevice]);\n\t    free(h_keysSorted[iDevice]);\n        delete radixSort[iDevice];\n    }\n    free(radixSort);\n    free(h_keys);\n    free(h_keysSorted);\n    \n    // remaining cleanup and exit\n\tfree(cdDevices);\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n\t    clReleaseCommandQueue(cqCommandQueue[iDevice]);\n    }\n    clReleaseContext(cxGPUContext);\n\n    // finish\n    shrQAFinishExit(argc, (const char **)argv, passed ? QA_PASSED : QA_FAILED);\n\n    shrEXIT(argc, argv);\n}\n\nvoid makeRandomUintVector(unsigned int *a, unsigned int numElements, unsigned int keybits)\n{\n    // Fill up with some random data\n    int keyshiftmask = 0;\n    if (keybits > 16) keyshiftmask = (1 << (keybits - 16)) - 1;\n    int keymask = 0xffff;\n    if (keybits < 16) keymask = (1 << keybits) - 1;\n\n    srand(95123);\n    for(unsigned int i=0; i < numElements; ++i)   \n    { \n        a[i] = ((rand() & keyshiftmask)<<16) | (rand() & keymask); \n    }\n}\n\n// assumes the values were initially indices into the array, for simplicity of \n// checking correct order of values\nbool verifySortUint(unsigned int *keysSorted, \n\t\t\t\t\tunsigned int *valuesSorted, \n\t\t\t\t\tunsigned int *keysUnsorted, \n\t\t\t\t\tunsigned int len)\n{\n    bool passed = true;\n    for(unsigned int i=0; i<len-1; ++i)\n    {\n        if( (keysSorted[i])>(keysSorted[i+1]) )\n\t\t{\n\t\t\tshrLog(\"Unordered key[%d]: %d > key[%d]: %d\\n\", i, keysSorted[i], i+1, keysSorted[i+1]);\n\t\t\tpassed = false;\n\t\t\tbreak;\n\t\t}\n    }\n\n    if (valuesSorted)\n    {\n        for(unsigned int i=0; i<len; ++i)\n        {\n            if( keysUnsorted[valuesSorted[i]] != keysSorted[i] )\n            {\n                shrLog(\"Incorrectly sorted value[%u] (%u): %u != %u\\n\", \n\t\t\t\t\ti, valuesSorted[i], keysUnsorted[valuesSorted[i]], keysSorted[i]);\n                passed = false;\n                break;\n            }\n        }\n    }\n\n    return passed;\n}\n"}, "code_dirs": {"RadixSort.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclRadixSort", "oclRadixSort.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclRadixSort/src"}}
{"kernel_name": "mersenneTwister", "parallel_api": "cuda", "code": {"MersenneTwister.cpp": "#include <curand.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include <cuda_runtime.h>\n#include <curand.h>\n#include <helper_cuda.h>\n#include <helper_functions.h>\n\nfloat compareResults(int rand_n, float *h_RandGPU, float *h_RandCPU);\n\nconst int          DEFAULT_RAND_N = 2400000;\nconst unsigned int DEFAULT_SEED   = 777;\n\nint main(int argc, char **argv)\n{\n    printf(\"%s Starting...\\n\\n\", argv[0]);\n\n    int devID = findCudaDevice(argc, (const char **)argv);\n\n    int rand_n = DEFAULT_RAND_N;\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"count\")) {\n        rand_n = getCmdLineArgumentInt(argc, (const char **)argv, \"count\");\n    }\n\n    printf(\"Allocating data for %i samples...\\n\", rand_n);\n\n    int seed = DEFAULT_SEED;\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"seed\")) {\n        seed = getCmdLineArgumentInt(argc, (const char **)argv, \"seed\");\n    }\n\n    printf(\"Seeding with %i ...\\n\", seed);\n\n    cudaStream_t stream;\n    checkCudaErrors(cudaStreamCreateWithFlags(&stream, cudaStreamNonBlocking));\n\n    float *d_Rand;\n    checkCudaErrors(cudaMalloc((void **)&d_Rand, rand_n * sizeof(float)));\n\n    curandGenerator_t prngGPU;\n    checkCudaErrors(curandCreateGenerator(&prngGPU, CURAND_RNG_PSEUDO_MTGP32));\n    checkCudaErrors(curandSetStream(prngGPU, stream));\n    checkCudaErrors(curandSetPseudoRandomGeneratorSeed(prngGPU, seed));\n\n    curandGenerator_t prngCPU;\n    checkCudaErrors(curandCreateGeneratorHost(&prngCPU, CURAND_RNG_PSEUDO_MTGP32));\n    checkCudaErrors(curandSetPseudoRandomGeneratorSeed(prngCPU, seed));\n\n    float *h_RandGPU;\n    checkCudaErrors(cudaMallocHost(&h_RandGPU, rand_n * sizeof(float)));\n\n    printf(\"Generating random numbers on GPU...\\n\\n\");\n    checkCudaErrors(curandGenerateUniform(prngGPU, (float *)d_Rand, rand_n));\n\n    printf(\"\\nReading back the results...\\n\");\n    checkCudaErrors(cudaMemcpyAsync(h_RandGPU, d_Rand, rand_n * sizeof(float), cudaMemcpyDeviceToHost, stream));\n\n    float *h_RandCPU = (float *)malloc(rand_n * sizeof(float));\n\n    printf(\"Generating random numbers on CPU...\\n\\n\");\n    checkCudaErrors(curandGenerateUniform(prngCPU, (float *)h_RandCPU, rand_n));\n\n    checkCudaErrors(cudaStreamSynchronize(stream));\n    printf(\"Comparing CPU/GPU random numbers...\\n\\n\");\n    float L1norm = compareResults(rand_n, h_RandGPU, h_RandCPU);\n\n    const int           numIterations = 10;\n    int                 i;\n    StopWatchInterface *hTimer;\n\n    sdkCreateTimer(&hTimer);\n    sdkResetTimer(&hTimer);\n    sdkStartTimer(&hTimer);\n\n    for (i = 0; i < numIterations; i++) {\n        checkCudaErrors(curandGenerateUniform(prngGPU, (float *)d_Rand, rand_n));\n    }\n\n    checkCudaErrors(cudaStreamSynchronize(stream));\n    sdkStopTimer(&hTimer);\n\n    double gpuTime = 1.0e-3 * sdkGetTimerValue(&hTimer) / (double)numIterations;\n\n    printf(\"MersenneTwisterGP11213, Throughput = %.4f GNumbers/s, Time = %.5f s, \"\n           \"Size = %u Numbers\\n\",\n           1.0e-9 * rand_n / gpuTime,\n           gpuTime,\n           rand_n);\n\n    printf(\"Shutting down...\\n\");\n\n    checkCudaErrors(curandDestroyGenerator(prngGPU));\n    checkCudaErrors(curandDestroyGenerator(prngCPU));\n    checkCudaErrors(cudaStreamDestroy(stream));\n    checkCudaErrors(cudaFree(d_Rand));\n    sdkDeleteTimer(&hTimer);\n    checkCudaErrors(cudaFreeHost(h_RandGPU));\n    free(h_RandCPU);\n\n    exit(L1norm < 1e-6 ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n\nfloat compareResults(int rand_n, float *h_RandGPU, float *h_RandCPU)\n{\n    int   i;\n    float rCPU, rGPU, delta;\n    float max_delta = 0.;\n    float sum_delta = 0.;\n    float sum_ref   = 0.;\n\n    for (i = 0; i < rand_n; i++) {\n        rCPU  = h_RandCPU[i];\n        rGPU  = h_RandGPU[i];\n        delta = fabs(rCPU - rGPU);\n        sum_delta += delta;\n        sum_ref += fabs(rCPU);\n\n        if (delta >= max_delta) {\n            max_delta = delta;\n        }\n    }\n\n    float L1norm = (float)(sum_delta / sum_ref);\n    printf(\"Max absolute error: %E\\n\", max_delta);\n    printf(\"L1 norm: %E\\n\\n\", L1norm);\n\n    return L1norm;\n}\n"}, "code_dirs": {"MersenneTwister.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/4_CUDA_Libraries/MersenneTwisterGP11213"}}
{"kernel_name": "mersenneTwister", "parallel_api": "ocl", "code": {"MersenneTwister.cl": "typedef struct{\n  unsigned int matrix_a;\n  unsigned int mask_b;\n  unsigned int mask_c;\n  unsigned int seed;\n} mt_struct_stripped;\n\n#define   MT_RNG_COUNT 4096\n#define          MT_MM 9\n#define          MT_NN 19\n#define       MT_WMASK 0xFFFFFFFFU\n#define       MT_UMASK 0xFFFFFFFEU\n#define       MT_LMASK 0x1U\n#define      MT_SHIFT0 12\n#define      MT_SHIFTB 7\n#define      MT_SHIFTC 15\n#define      MT_SHIFT1 18\n#define PI 3.14159265358979f\n__kernel void MersenneTwister(__global float* d_Rand, \n\t\t\t      __global mt_struct_stripped* d_MT,\n\t\t\t      int nPerRng)\n{\n    int globalID = get_global_id(0);\n\n    int iState, iState1, iStateM, iOut;\n    unsigned int mti, mti1, mtiM, x;\n    unsigned int mt[MT_NN], matrix_a, mask_b, mask_c; \n\n    //Load bit-vector Mersenne Twister parameters\n    matrix_a = d_MT[globalID].matrix_a;\n    mask_b   = d_MT[globalID].mask_b;\n    mask_c   = d_MT[globalID].mask_c;\n        \n    //Initialize current state\n    mt[0] = d_MT[globalID].seed;\n    for (iState = 1; iState < MT_NN; iState++)\n        mt[iState] = (1812433253U * (mt[iState - 1] ^ (mt[iState - 1] >> 30)) + iState) & MT_WMASK;\n\n    iState = 0;\n    mti1 = mt[0];\n    for (iOut = 0; iOut < nPerRng; iOut++) {\n        iState1 = iState + 1;\n        iStateM = iState + MT_MM;\n        if(iState1 >= MT_NN) iState1 -= MT_NN;\n        if(iStateM >= MT_NN) iStateM -= MT_NN;\n        mti  = mti1;\n        mti1 = mt[iState1];\n        mtiM = mt[iStateM];\n\n\t    // MT recurrence\n        x = (mti & MT_UMASK) | (mti1 & MT_LMASK);\n\t    x = mtiM ^ (x >> 1) ^ ((x & 1) ? matrix_a : 0);\n\n        mt[iState] = x;\n        iState = iState1;\n\n        //Tempering transformation\n        x ^= (x >> MT_SHIFT0);\n        x ^= (x << MT_SHIFTB) & mask_b;\n        x ^= (x << MT_SHIFTC) & mask_c;\n        x ^= (x >> MT_SHIFT1);\n\n        //Convert to (0, 1] float and write to global memory\n        d_Rand[globalID + iOut * MT_RNG_COUNT] = ((float)x + 1.0f) / 4294967296.0f;\n    }\n}\n\nvoid BoxMullerTrans(__global float *u1, __global float *u2)\n{\n    float   r = native_sqrt(-2.0f * log(*u1));\n    float phi = 2 * PI * (*u2);\n    *u1 = r * native_cos(phi);\n    *u2 = r * native_sin(phi);\n}\n\n__kernel void BoxMuller(__global float *d_Rand, int nPerRng) \n{\n    int globalID = get_global_id(0);\n\n    for (int iOut = 0; iOut < nPerRng; iOut += 2)\n        BoxMullerTrans(&d_Rand[globalID + (iOut + 0) * MT_RNG_COUNT],\n\t\t       &d_Rand[globalID + (iOut + 1) * MT_RNG_COUNT]);\n}\n", "oclMersenneTwister.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n#include \"MersenneTwister.h\"\n\n// comment the below line if not doing Box-Muller transformation\n#define DO_BOXMULLER\n#define MAX_GPU_COUNT 8\n\n// Reference CPU MT and Box-Muller transformation \nextern \"C\" void initMTRef(const char *fname);\nextern \"C\" void RandomRef(float *h_Rand, int nPerRng, unsigned int seed);\n#ifdef DO_BOXMULLER\nextern \"C\" void BoxMullerRef(float *h_Rand, int nPerRng);\n#endif\n\nvoid loadMTGPU(const char *fname, \n\t       const unsigned int seed, \n\t       mt_struct_stripped *h_MT,\n\t       const size_t size)\n{\n    FILE* fd = 0;\n    #ifdef _WIN32\n        errno_t err;\n        if ((err = fopen_s(&fd, fname, \"rb\")) != 0)\n    #else\n        if ((fd = fopen(fname, \"rb\")) == 0)\n    #endif\n        {\n            if(fd)\n            {\n                fclose (fd);\n            }\n\t        oclCheckError(0, 1);\n        }\n  \n    for (unsigned int i = 0; i < size; i++)\n        fread(&h_MT[i], sizeof(mt_struct_stripped), 1, fd);\n    fclose(fd);\n\n    for(unsigned int i = 0; i < size; i++)\n        h_MT[i].seed = seed;\n}\n\nint main(int argc, const char **argv)\n{\n    cl_context cxGPUContext;                        // OpenCL context\n    cl_command_queue cqCommandQueue[MAX_GPU_COUNT]; // OpenCL command que\n    cl_platform_id cpPlatform;                      // OpenCL platform\n    cl_uint nDevice;                                // OpenCL device count\n    cl_device_id* cdDevices;                        // OpenCL device list    \n    cl_program cpProgram;                           // OpenCL program\n    cl_kernel ckMersenneTwister = NULL;             // OpenCL kernel\n    cl_kernel ckBoxMuller = NULL;                   // OpenCL kernel\n    cl_mem *d_Rand, *d_MT;                          // OpenCL buffers\n    cl_int ciErr1, ciErr2;                          // Error code var\n    size_t globalWorkSize[1] = {MT_RNG_COUNT};      // 1D var for Total # of work items\n    size_t localWorkSize[1] = {128};                // 1D var for # of work items in the work group\t\n    const int seed = 777;\n    const int nPerRng = 5860;                       // # of recurrence steps, must be even if do Box-Muller transformation\n    const int nRand = MT_RNG_COUNT * nPerRng;       // Output size\n    const char *clSourcefile = \"MersenneTwister.cl\";// kernel file\n\n    shrQAStart(argc, (char **)argv);\n\n    shrSetLogFileName (\"oclMersenneTwister.txt\");\n    shrLog(\"%s Starting, using %s...\\n\\n\", argv[0], clSourcefile); \n\n    shrLog(\"Get platforms...\\n\");\n    ciErr1 = oclGetPlatformID(&cpPlatform);\n    oclCheckError(ciErr1, CL_SUCCESS);\n\n    shrLog(\"Get devices...\\n\");\n    ciErr1 = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &nDevice);\n    oclCheckError(ciErr1, CL_SUCCESS);\n    cdDevices = (cl_device_id *)malloc(nDevice * sizeof(cl_device_id) );\n    ciErr1 = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, nDevice, cdDevices, NULL);\n    oclCheckError(ciErr1, CL_SUCCESS);\n\n    shrLog(\"Create context...\\n\");\n    cxGPUContext = clCreateContext(0, nDevice, cdDevices, NULL, NULL, &ciErr1);\n    oclCheckError(ciErr1, CL_SUCCESS);\n    \n    shrLog(\"clCreateCommandQueue\\n\"); \n    int id_device;\n    if(shrGetCmdLineArgumenti(argc, argv, \"device\", &id_device)) // Set up command queue(s) for GPU specified on the command line\n    {\n        // get & log device index # and name\n        cl_device_id cdDevice = cdDevices[id_device];\n\n        // create a command que\n        cqCommandQueue[0] = clCreateCommandQueue(cxGPUContext, cdDevice, 0, &ciErr1);\n        oclCheckErrorEX(ciErr1, CL_SUCCESS, NULL);\n        oclPrintDevInfo(LOGBOTH, cdDevice);\n        nDevice = 1;   \n    } \n    else \n    { // create command queues for all available devices        \n        for (cl_uint i = 0; i < nDevice; i++) \n        {\n            cqCommandQueue[i] = clCreateCommandQueue(cxGPUContext, cdDevices[i], 0, &ciErr1);\n            oclCheckErrorEX(ciErr1, CL_SUCCESS, NULL);\n        }\n        for (cl_uint i = 0; i < nDevice; i++) oclPrintDevInfo(LOGBOTH, cdDevices[i]);\n    }\n\n    shrLog(\"\\nUsing %d GPU(s)...\\n\\n\", nDevice);\n\n    shrLog(\"Initialization: load MT parameters and init host buffers...\\n\");\n    mt_struct_stripped *h_MT = (mt_struct_stripped*)malloc(sizeof(mt_struct_stripped)*MT_RNG_COUNT); // MT para\n    char *cDatPath = shrFindFilePath(\"MersenneTwister.dat\", argv[0]);\n    shrCheckError(cDatPath != NULL, shrTRUE);\n    loadMTGPU(cDatPath, seed, h_MT, MT_RNG_COUNT);\n    char *cRawPath = shrFindFilePath(\"MersenneTwister.raw\", argv[0]);\n    shrCheckError(cRawPath != NULL, shrTRUE);\n    initMTRef(cRawPath);\n    float **h_RandGPU = (float**)malloc(nDevice*sizeof(float*));\n    float **h_RandCPU = (float**)malloc(nDevice*sizeof(float*));\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n        h_RandGPU[iDevice] = (float*)malloc(sizeof(float)*nRand); // Host buffers for GPU output\n        h_RandCPU[iDevice] = (float*)malloc(sizeof(float)*nRand); // Host buffers for CPU test\n    }\n\n    shrLog(\"Allocate memory...\\n\"); \n    d_MT = (cl_mem*)malloc(nDevice*sizeof(cl_mem));\n    d_Rand = (cl_mem*)malloc(nDevice*sizeof(cl_mem));\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n        d_MT[iDevice] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, sizeof(mt_struct_stripped)*MT_RNG_COUNT, NULL, &ciErr2);\n        ciErr1 |= ciErr2;\n        ciErr1 |= clEnqueueWriteBuffer(cqCommandQueue[iDevice], d_MT[iDevice], CL_TRUE, 0, \n            sizeof(mt_struct_stripped)*MT_RNG_COUNT, h_MT, 0, NULL, NULL);\n        d_Rand[iDevice] = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, sizeof(cl_float) * nRand, NULL, &ciErr2);\n        ciErr1 |= ciErr2;\n        oclCheckError(ciErr1, CL_SUCCESS); \n    }\n\n    shrLog(\"Create and build program from %s...\\n\", clSourcefile);\n    size_t szKernelLength; // Byte size of kernel code\n    char *cSourcePath = shrFindFilePath(clSourcefile, argv[0]);\n    shrCheckError(cSourcePath != NULL, shrTRUE);\n    char *cMersenneTwister = oclLoadProgSource(cSourcePath, \"// My comment\\n\", &szKernelLength);\n    oclCheckError(cMersenneTwister != NULL, shrTRUE);\n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&cMersenneTwister, &szKernelLength, &ciErr1);\n    ciErr1 |= clBuildProgram(cpProgram, 0, NULL, NULL, NULL, NULL);\n    if (ciErr1 != CL_SUCCESS)\n    {\n        // write out standard error, Build Log and PTX, then cleanup and exit\n        shrLogEx(LOGBOTH | ERRORMSG, (double)ciErr1, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"MersenneTwister.ptx\");\n        oclCheckError(ciErr1, CL_SUCCESS); \n    }\n\n    shrLog(\"Call Mersenne Twister kernel on GPU...\\n\\n\"); \n    ckMersenneTwister = clCreateKernel(cpProgram, \"MersenneTwister\", &ciErr1);\n#ifdef DO_BOXMULLER\n    ckBoxMuller = clCreateKernel(cpProgram, \"BoxMuller\", &ciErr1);\n#endif\n\n#ifdef GPU_PROFILING\n    int numIterations = 100;\n    for (int i = -1; i < numIterations; i++)\n    {\n\t\tif (i == 0) \n\t\t{\n\t\t\tfor (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n\t\t\t{\n\t\t\t\tclFinish(cqCommandQueue[iDevice]);\n\t\t\t}\n\t\t\tshrDeltaT(1);\n\t\t}\n#endif\n        for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n        {\n            ciErr1 |= clSetKernelArg(ckMersenneTwister, 0, sizeof(cl_mem), (void*)&d_Rand[iDevice]);\n            ciErr1 |= clSetKernelArg(ckMersenneTwister, 1, sizeof(cl_mem), (void*)&d_MT[iDevice]);\n            ciErr1 |= clSetKernelArg(ckMersenneTwister, 2, sizeof(int),    (void*)&nPerRng);\n            ciErr1 |= clEnqueueNDRangeKernel(cqCommandQueue[iDevice], ckMersenneTwister, 1, NULL, \n                globalWorkSize, localWorkSize, 0, NULL, NULL);\n            oclCheckError(ciErr1, CL_SUCCESS); \n        }\n    \t\n    #ifdef DO_BOXMULLER \n        for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n        {\n            ciErr1 |= clSetKernelArg(ckBoxMuller, 0, sizeof(cl_mem), (void*)&d_Rand[iDevice]);\n            ciErr1 |= clSetKernelArg(ckBoxMuller, 1, sizeof(int),    (void*)&nPerRng);\n            ciErr1 |= clEnqueueNDRangeKernel(cqCommandQueue[iDevice], ckBoxMuller, 1, NULL, \n                globalWorkSize, localWorkSize, 0, NULL, NULL);\n            oclCheckError(ciErr1, CL_SUCCESS); \n        }\n    #endif\n#ifdef GPU_PROFILING\n    }\n\tfor (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n        clFinish(cqCommandQueue[iDevice]);\n    }\n    double gpuTime = shrDeltaT(1)/(double)numIterations;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclMersenneTwister, Throughput = %.4f GNumbers/s, Time = %.5f s, Size = %u Numbers, NumDevsUsed = %u, Workgroup = %u\\n\", \n           ((double)nDevice * (double)nRand * 1.0E-9 / gpuTime), gpuTime, nDevice * nRand, nDevice, localWorkSize[0]);    \n#endif\n\n    shrLog(\"\\nRead back results...\\n\"); \n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n        ciErr1 |= clEnqueueReadBuffer(cqCommandQueue[iDevice], d_Rand[iDevice], CL_TRUE, 0, \n            sizeof(cl_float) * nRand, h_RandGPU[iDevice], 0, NULL, NULL);\n        oclCheckError(ciErr1, CL_SUCCESS); \n    }\n\n    shrLog(\"Compute CPU reference solution...\\n\");\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n        RandomRef(h_RandCPU[iDevice], nPerRng, seed);\n#ifdef DO_BOXMULLER\n        BoxMullerRef(h_RandCPU[iDevice], nPerRng);\n#endif\n    }\n\n    shrLog(\"Compare CPU and GPU results...\\n\");\n    double sum_delta = 0;\n    double sum_ref   = 0;\n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n        for(int i = 0; i < MT_RNG_COUNT; i++)\n            for(int j = 0; j < nPerRng; j++) {\n\t        double rCPU = h_RandCPU[iDevice][i * nPerRng + j];\n\t        double rGPU = h_RandGPU[iDevice][i + j * MT_RNG_COUNT];\n\t        double delta = fabs(rCPU - rGPU);\n\t        sum_delta += delta;\n\t        sum_ref   += fabs(rCPU);\n\t    }\n    }\n    double L1norm = sum_delta / sum_ref;\n    shrLog(\"L1 norm: %E\\n\\n\", L1norm);\n\n    // NOTE:  Most properly this should be done at any of the exit points above, but it is omitted elsewhere for clarity.\n    shrLog(\"Release CPU buffers and OpenCL objects...\\n\"); \n    clReleaseKernel(ckMersenneTwister);\n    #ifdef DO_BOXMULLER\n        clReleaseKernel(ckBoxMuller);\n    #endif    \n    clReleaseProgram(cpProgram);    \n    for (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n    {\n        free(h_RandGPU[iDevice]); \n        free(h_RandCPU[iDevice]);\n        clReleaseMemObject(d_Rand[iDevice]);\n        clReleaseMemObject(d_MT[iDevice]);        \n        clReleaseCommandQueue(cqCommandQueue[iDevice]);\n    }\n    free(h_MT);\n    free(h_RandGPU);\n    free(h_RandCPU);\n    free(d_Rand);\n    free(d_MT);\n    free(cMersenneTwister);\n    free(cSourcePath);\n    free(cRawPath);\n    free(cDatPath);\n    free(cdDevices);\n    clReleaseContext(cxGPUContext);\n\n    // finish\n    shrQAFinishExit(argc, (const char **)argv, (L1norm < 1e-6) ? QA_PASSED : QA_FAILED);\n\n    shrEXIT(argc, argv);\n}\n"}, "code_dirs": {"MersenneTwister.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclMersenneTwister", "oclMersenneTwister.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclMersenneTwister/src"}}
{"kernel_name": "blackScholes", "parallel_api": "cuda", "code": {"BlackScholes.cu": "#include <helper_cuda.h>\n#include <helper_functions.h>\n\nextern \"C\" void BlackScholesCPU(float *h_CallResult,\n                                float *h_PutResult,\n                                float *h_StockPrice,\n                                float *h_OptionStrike,\n                                float *h_OptionYears,\n                                float  Riskfree,\n                                float  Volatility,\n                                int    optN);\n\n#include \"BlackScholes_kernel.cuh\"\n\nfloat RandFloat(float low, float high)\n{\n    float t = (float)rand() / (float)RAND_MAX;\n    return (1.0f - t) * low + t * high;\n}\n\nconst int OPT_N          = 4000000;\nconst int NUM_ITERATIONS = 512;\n\nconst int   OPT_SZ     = OPT_N * sizeof(float);\nconst float RISKFREE   = 0.02f;\nconst float VOLATILITY = 0.30f;\n\n#define DIV_UP(a, b) (((a) + (b) - 1) / (b))\n\nint main(int argc, char **argv)\n{\n    printf(\"[%s] - Starting...\\n\", argv[0]);\n\n    float\n        *h_CallResultCPU,\n        *h_PutResultCPU,\n        *h_CallResultGPU, *h_PutResultGPU,\n        *h_StockPrice, *h_OptionStrike, *h_OptionYears;\n\n    float\n        *d_CallResult,\n        *d_PutResult,\n        *d_StockPrice, *d_OptionStrike, *d_OptionYears;\n\n    double delta, ref, sum_delta, sum_ref, max_delta, L1norm, gpuTime;\n\n    StopWatchInterface *hTimer = NULL;\n    int                 i;\n\n    findCudaDevice(argc, (const char **)argv);\n\n    sdkCreateTimer(&hTimer);\n\n    printf(\"Initializing data...\\n\");\n    printf(\"...allocating CPU memory for options.\\n\");\n    h_CallResultCPU = (float *)malloc(OPT_SZ);\n    h_PutResultCPU  = (float *)malloc(OPT_SZ);\n    h_CallResultGPU = (float *)malloc(OPT_SZ);\n    h_PutResultGPU  = (float *)malloc(OPT_SZ);\n    h_StockPrice    = (float *)malloc(OPT_SZ);\n    h_OptionStrike  = (float *)malloc(OPT_SZ);\n    h_OptionYears   = (float *)malloc(OPT_SZ);\n\n    printf(\"...allocating GPU memory for options.\\n\");\n    checkCudaErrors(cudaMalloc((void **)&d_CallResult, OPT_SZ));\n    checkCudaErrors(cudaMalloc((void **)&d_PutResult, OPT_SZ));\n    checkCudaErrors(cudaMalloc((void **)&d_StockPrice, OPT_SZ));\n    checkCudaErrors(cudaMalloc((void **)&d_OptionStrike, OPT_SZ));\n    checkCudaErrors(cudaMalloc((void **)&d_OptionYears, OPT_SZ));\n\n    printf(\"...generating input data in CPU mem.\\n\");\n    srand(5347);\n\n    for (i = 0; i < OPT_N; i++) {\n        h_CallResultCPU[i] = 0.0f;\n        h_PutResultCPU[i]  = -1.0f;\n        h_StockPrice[i]    = RandFloat(5.0f, 30.0f);\n        h_OptionStrike[i]  = RandFloat(1.0f, 100.0f);\n        h_OptionYears[i]   = RandFloat(0.25f, 10.0f);\n    }\n\n    printf(\"...copying input data to GPU mem.\\n\");\n    checkCudaErrors(cudaMemcpy(d_StockPrice, h_StockPrice, OPT_SZ, cudaMemcpyHostToDevice));\n    checkCudaErrors(cudaMemcpy(d_OptionStrike, h_OptionStrike, OPT_SZ, cudaMemcpyHostToDevice));\n    checkCudaErrors(cudaMemcpy(d_OptionYears, h_OptionYears, OPT_SZ, cudaMemcpyHostToDevice));\n    printf(\"Data init done.\\n\\n\");\n\n    printf(\"Executing Black-Scholes GPU kernel (%i iterations)...\\n\", NUM_ITERATIONS);\n    checkCudaErrors(cudaDeviceSynchronize());\n    sdkResetTimer(&hTimer);\n    sdkStartTimer(&hTimer);\n\n    for (i = 0; i < NUM_ITERATIONS; i++) {\n        BlackScholesGPU<<<DIV_UP((OPT_N / 2), 128), 128 /*480, 128*/>>>((float2 *)d_CallResult,\n                                                                        (float2 *)d_PutResult,\n                                                                        (float2 *)d_StockPrice,\n                                                                        (float2 *)d_OptionStrike,\n                                                                        (float2 *)d_OptionYears,\n                                                                        RISKFREE,\n                                                                        VOLATILITY,\n                                                                        OPT_N);\n        getLastCudaError(\"BlackScholesGPU() execution failed\\n\");\n    }\n\n    checkCudaErrors(cudaDeviceSynchronize());\n    sdkStopTimer(&hTimer);\n    gpuTime = sdkGetTimerValue(&hTimer) / NUM_ITERATIONS;\n\n    printf(\"Options count             : %i     \\n\", 2 * OPT_N);\n    printf(\"BlackScholesGPU() time    : %f msec\\n\", gpuTime);\n    printf(\"Effective memory bandwidth: %f GB/s\\n\", ((double)(5 * OPT_N * sizeof(float)) * 1E-9) / (gpuTime * 1E-3));\n    printf(\"Gigaoptions per second    : %f     \\n\\n\", ((double)(2 * OPT_N) * 1E-9) / (gpuTime * 1E-3));\n\n    printf(\"BlackScholes, Throughput = %.4f GOptions/s, Time = %.5f s, Size = %u \"\n           \"options, NumDevsUsed = %u, Workgroup = %u\\n\",\n           (((double)(2.0 * OPT_N) * 1.0E-9) / (gpuTime * 1.0E-3)),\n           gpuTime * 1e-3,\n           (2 * OPT_N),\n           1,\n           128);\n\n    printf(\"\\nReading back GPU results...\\n\");\n    checkCudaErrors(cudaMemcpy(h_CallResultGPU, d_CallResult, OPT_SZ, cudaMemcpyDeviceToHost));\n    checkCudaErrors(cudaMemcpy(h_PutResultGPU, d_PutResult, OPT_SZ, cudaMemcpyDeviceToHost));\n\n    printf(\"Checking the results...\\n\");\n    printf(\"...running CPU calculations.\\n\\n\");\n    BlackScholesCPU(\n        h_CallResultCPU, h_PutResultCPU, h_StockPrice, h_OptionStrike, h_OptionYears, RISKFREE, VOLATILITY, OPT_N);\n\n    printf(\"Comparing the results...\\n\");\n    sum_delta = 0;\n    sum_ref   = 0;\n    max_delta = 0;\n\n    for (i = 0; i < OPT_N; i++) {\n        ref   = h_CallResultCPU[i];\n        delta = fabs(h_CallResultCPU[i] - h_CallResultGPU[i]);\n\n        if (delta > max_delta) {\n            max_delta = delta;\n        }\n\n        sum_delta += delta;\n        sum_ref += fabs(ref);\n    }\n\n    L1norm = sum_delta / sum_ref;\n    printf(\"L1 norm: %E\\n\", L1norm);\n    printf(\"Max absolute error: %E\\n\\n\", max_delta);\n\n    printf(\"Shutting down...\\n\");\n    printf(\"...releasing GPU memory.\\n\");\n    checkCudaErrors(cudaFree(d_OptionYears));\n    checkCudaErrors(cudaFree(d_OptionStrike));\n    checkCudaErrors(cudaFree(d_StockPrice));\n    checkCudaErrors(cudaFree(d_PutResult));\n    checkCudaErrors(cudaFree(d_CallResult));\n\n    printf(\"...releasing CPU memory.\\n\");\n    free(h_OptionYears);\n    free(h_OptionStrike);\n    free(h_StockPrice);\n    free(h_PutResultGPU);\n    free(h_CallResultGPU);\n    free(h_PutResultCPU);\n    free(h_CallResultCPU);\n    sdkDeleteTimer(&hTimer);\n    printf(\"Shutdown done.\\n\");\n\n    printf(\"\\n[BlackScholes] - Test Summary\\n\");\n\n    if (L1norm > 1e-6) {\n        printf(\"Test failed!\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"\\nNOTE: The CUDA Samples are not meant for performance measurements. \"\n           \"Results may vary when GPU Boost is enabled.\\n\\n\");\n    printf(\"Test passed\\n\");\n    exit(EXIT_SUCCESS);\n}\n", "BlackScholes_kernel.cuh": "__device__ inline float cndGPU(float d)\n{\n    const float A1       = 0.31938153f;\n    const float A2       = -0.356563782f;\n    const float A3       = 1.781477937f;\n    const float A4       = -1.821255978f;\n    const float A5       = 1.330274429f;\n    const float RSQRT2PI = 0.39894228040143267793994605993438f;\n\n    float K = __fdividef(1.0f, (1.0f + 0.2316419f * fabsf(d)));\n\n    float cnd = RSQRT2PI * __expf(-0.5f * d * d) * (K * (A1 + K * (A2 + K * (A3 + K * (A4 + K * A5)))));\n\n    if (d > 0)\n        cnd = 1.0f - cnd;\n\n    return cnd;\n}\n\n__device__ inline void BlackScholesBodyGPU(float &CallResult,\n                                           float &PutResult,\n                                           float  S,\n                                           float  X,\n                                           float  T,\n                                           float  R,\n                                           float  V\n)\n{\n    float sqrtT, expRT;\n    float d1, d2, CNDD1, CNDD2;\n\n    sqrtT = __fdividef(1.0F, rsqrtf(T));\n    d1    = __fdividef(__logf(S / X) + (R + 0.5f * V * V) * T, V * sqrtT);\n    d2    = d1 - V * sqrtT;\n\n    CNDD1 = cndGPU(d1);\n    CNDD2 = cndGPU(d2);\n\n    expRT      = __expf(-R * T);\n    CallResult = S * CNDD1 - X * expRT * CNDD2;\n    PutResult  = X * expRT * (1.0f - CNDD2) - S * (1.0f - CNDD1);\n}\n\n__launch_bounds__(128) __global__ void BlackScholesGPU(float2 *__restrict d_CallResult,\n                                                       float2 *__restrict d_PutResult,\n                                                       float2 *__restrict d_StockPrice,\n                                                       float2 *__restrict d_OptionStrike,\n                                                       float2 *__restrict d_OptionYears,\n                                                       float Riskfree,\n                                                       float Volatility,\n                                                       int   optN)\n{\n    const int opt = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (opt < (optN / 2)) {\n        float callResult1, callResult2;\n        float putResult1, putResult2;\n        BlackScholesBodyGPU(callResult1,\n                            putResult1,\n                            d_StockPrice[opt].x,\n                            d_OptionStrike[opt].x,\n                            d_OptionYears[opt].x,\n                            Riskfree,\n                            Volatility);\n        BlackScholesBodyGPU(callResult2,\n                            putResult2,\n                            d_StockPrice[opt].y,\n                            d_OptionStrike[opt].y,\n                            d_OptionYears[opt].y,\n                            Riskfree,\n                            Volatility);\n        d_CallResult[opt] = make_float2(callResult1, callResult2);\n        d_PutResult[opt]  = make_float2(putResult1, putResult2);\n    }\n}\n"}, "code_dirs": {"BlackScholes.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/BlackScholes", "BlackScholes_kernel.cuh": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/BlackScholes"}}
{"kernel_name": "blackScholes", "parallel_api": "ocl", "code": {"BlackScholes.cl": "#if(0)\n    #define EXP(a) native_exp(a)\n    #define LOG(a) native_log(a)\n    #define SQRT(a) native_sqrt(a)\n#else\n    #define EXP(a) exp(a)\n    #define LOG(a) log(a)\n    #define SQRT(a) sqrt(a)\n#endif\n\nfloat CND(float d);\nvoid BlackScholesBody(__global float *call, __global float *put,  float S,\n\t\t\t\t\t  float X, float T, float R, float V);\n\nfloat CND(float d){\n    const float       A1 = 0.31938153f;\n    const float       A2 = -0.356563782f;\n    const float       A3 = 1.781477937f;\n    const float       A4 = -1.821255978f;\n    const float       A5 = 1.330274429f;\n    const float RSQRT2PI = 0.39894228040143267793994605993438f;\n\n    float\n        K = 1.0f / (1.0f + 0.2316419f * fabs(d));\n\n    float\n        cnd = RSQRT2PI * EXP(- 0.5f * d * d) * \n        (K * (A1 + K * (A2 + K * (A3 + K * (A4 + K * A5)))));\n\n    if(d > 0)\n        cnd = 1.0f - cnd;\n\n    return cnd;\n}\n\nvoid BlackScholesBody(\n    __global float *call, //Call option price\n    __global float *put,  //Put option price\n    float S,              //Current stock price\n    float X,              //Option strike price\n    float T,              //Option years\n    float R,              //Riskless rate of return\n    float V               //Stock volatility\n){\n    float sqrtT = SQRT(T);\n    float    d1 = (LOG(S / X) + (R + 0.5f * V * V) * T) / (V * sqrtT);\n    float    d2 = d1 - V * sqrtT;\n    float CNDD1 = CND(d1);\n    float CNDD2 = CND(d2);\n\n    //Calculate Call and Put simultaneously\n    float expRT = EXP(- R * T);\n    *call = (S * CNDD1 - X * expRT * CNDD2);\n    *put  = (X * expRT * (1.0f - CNDD2) - S * (1.0f - CNDD1));\n}\n\n\n\n__kernel void BlackScholes(\n    __global float *d_Call, //Call option price\n    __global float *d_Put,  //Put option price\n    __global float *d_S,    //Current stock price\n    __global float *d_X,    //Option strike price\n    __global float *d_T,    //Option years\n    float R,                //Riskless rate of return\n    float V,                //Stock volatility\n    unsigned int optN\n){\n    for(unsigned int opt = get_global_id(0); opt < optN; opt += get_global_size(0))\n        BlackScholesBody(\n            &d_Call[opt],\n            &d_Put[opt],\n            d_S[opt],\n            d_X[opt],\n            d_T[opt],\n            R,\n            V\n        );\n}\n", "main.cpp": "\n#include <oclUtils.h>\n#include <shrQATest.h>\n#include \"oclBlackScholes_common.h\"\n\ndouble executionTime(cl_event &event){\n    cl_ulong start, end;\n\n    clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &end, NULL);\n    clGetEventProfilingInfo(event, CL_PROFILING_COMMAND_START, sizeof(cl_ulong), &start, NULL);\n\n    return (double)1.0e-9 * (end - start); // convert nanoseconds to seconds on return\n}\n\nfloat randFloat(float low, float high){\n    float t = (float)rand() / (float)RAND_MAX;\n    return (1.0f - t) * low + t * high;\n}\n\nint main(int argc, char **argv)\n{\n    cl_platform_id   cpPlatform;       //OpenCL platform\n    cl_device_id*    cdDevices = NULL; //OpenCL devices list (array)\n    cl_context       cxGPUContext;     //OpenCL context\n    cl_command_queue cqCommandQueue;   //OpenCL command que\n    cl_mem                             //OpenCL memory buffer objects\n        d_Call,\n        d_Put,\n        d_S,\n        d_X,\n        d_T;\n\n    cl_int ciErrNum;\n\n    float\n        *h_CallCPU,\n        *h_PutCPU,\n        *h_CallGPU,\n        *h_PutGPU,\n        *h_S,\n        *h_X,\n        *h_T;\n\n    const unsigned int   optionCount = 4000000;\n    const float                    R = 0.02f;\n    const float                    V = 0.30f;\n\n    shrQAStart(argc, argv);\n\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    shrLog(\"clGetPlatformID...\\n\"); \n\n    cl_uint uiNumDevices = 0;\n    cl_uint uiTargetDevice = 0;\n    cl_uint uiNumComputeUnits;\n    shrLog(\"Get the Device info and select Device...\\n\");\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiNumDevices);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    cdDevices = (cl_device_id *)malloc(uiNumDevices * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiNumDevices, cdDevices, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n\n    shrLog(\"  # of Devices Available = %u\\n\", uiNumDevices); \n    if(shrGetCmdLineArgumentu(argc, (const char**)argv, \"device\", &uiTargetDevice)== shrTRUE) \n    {\n        uiTargetDevice = CLAMP(uiTargetDevice, 0, (uiNumDevices - 1));\n    }\n    shrLog(\"  Using Device %u: \", uiTargetDevice); \n    oclPrintDevName(LOGBOTH, cdDevices[uiTargetDevice]);\n    ciErrNum = clGetDeviceInfo(cdDevices[uiTargetDevice], CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(uiNumComputeUnits), &uiNumComputeUnits, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, NULL);\n    shrLog(\"\\n  # of Compute Units = %u\\n\", uiNumComputeUnits); \n\n    shrSetLogFileName (\"oclBlackScholes.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    shrLog(\"Allocating and initializing host memory...\\n\");\n        h_CallCPU = (float *)malloc(optionCount * sizeof(float));\n        h_PutCPU  = (float *)malloc(optionCount * sizeof(float));\n        h_CallGPU = (float *)malloc(optionCount * sizeof(float));\n        h_PutGPU  = (float *)malloc(optionCount * sizeof(float));\n        h_S       = (float *)malloc(optionCount * sizeof(float));\n        h_X       = (float *)malloc(optionCount * sizeof(float));\n        h_T       = (float *)malloc(optionCount * sizeof(float));\n\n        srand(2009);\n        for(unsigned int i = 0; i < optionCount; i++){\n            h_CallCPU[i] = -1.0f;\n            h_PutCPU[i]  = -1.0f;\n            h_S[i]       = randFloat(5.0f, 30.0f);\n            h_X[i]       = randFloat(1.0f, 100.0f);\n            h_T[i]       = randFloat(0.25f, 10.0f);\n        }\n\n    shrLog(\"Initializing OpenCL...\\n\");\n        ciErrNum = oclGetPlatformID(&cpPlatform);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 1, &cdDevices[uiTargetDevice], NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        cxGPUContext = clCreateContext(0, 1, &cdDevices[uiTargetDevice], NULL, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevices[uiTargetDevice], CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Creating OpenCL memory objects...\\n\");\n        d_Call = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, optionCount * sizeof(float), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_Put  = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, optionCount * sizeof(float), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_S    = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE | CL_MEM_COPY_HOST_PTR, optionCount * sizeof(float), h_S, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_X    = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE | CL_MEM_COPY_HOST_PTR, optionCount * sizeof(float), h_X, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        d_T    = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE | CL_MEM_COPY_HOST_PTR, optionCount * sizeof(float), h_T, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Starting up BlackScholes...\\n\");\n        initBlackScholes(cxGPUContext, cqCommandQueue, (const char **)argv);\n\n    shrLog(\"Running OpenCL BlackScholes...\\n\\n\");\n        BlackScholes(\n            NULL,\n            d_Call,\n            d_Put,\n            d_S,\n            d_X,\n            d_T,\n            R,\n            V,\n            optionCount\n        );\n\n#ifdef GPU_PROFILING\n    const int numIterations = 16;\n    cl_event startMark, endMark;\n    ciErrNum = clEnqueueMarker(cqCommandQueue, &startMark);\n    ciErrNum |= clFinish(cqCommandQueue);\n    shrCheckError(ciErrNum, CL_SUCCESS);\n    shrDeltaT(0);\n\n    for(int i = 0; i < numIterations; i++){\n        BlackScholes(\n            cqCommandQueue,\n            d_Call,\n            d_Put,\n            d_S,\n            d_X,\n            d_T,\n            R,\n            V,\n            optionCount\n        );\n    }\n\n    ciErrNum  = clEnqueueMarker(cqCommandQueue, &endMark);\n    ciErrNum |= clFinish(cqCommandQueue);\n    shrCheckError(ciErrNum, CL_SUCCESS);\n\n    double gpuTime = shrDeltaT(0) / numIterations;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclBlackScholes, Throughput = %.4f GOptions/s, Time = %.5f s, Size = %u options, NumDevsUsed = %i, Workgroup = %u\\n\", \n        (double)(2.0 * optionCount * 1.0e-9)/gpuTime, gpuTime, (2 * optionCount), 1, 0);\n\n    cl_ulong startTime = 0, endTime = 0;\n    ciErrNum  = clGetEventProfilingInfo(startMark, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &startTime, NULL);\n    ciErrNum |= clGetEventProfilingInfo(endMark, CL_PROFILING_COMMAND_END, sizeof(cl_ulong), &endTime, NULL);\n    shrCheckError(ciErrNum, CL_SUCCESS);\n    shrLog(\"\\nOpenCL time: %.5f s\\n\\n\", 1.0e-9 * ((double)endTime - (double)startTime) / (double)numIterations);\n#endif\n\n    shrLog(\"\\nReading back OpenCL BlackScholes results...\\n\");\n        ciErrNum = clEnqueueReadBuffer(cqCommandQueue, d_Call, CL_TRUE, 0, optionCount * sizeof(float), h_CallGPU, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        ciErrNum = clEnqueueReadBuffer(cqCommandQueue, d_Put, CL_TRUE, 0, optionCount * sizeof(float), h_PutGPU, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n    shrLog(\"Comparing against Host/C++ computation...\\n\"); \n        BlackScholesCPU(h_CallCPU, h_PutCPU, h_S, h_X, h_T, R, V, optionCount);\n        double deltaCall = 0, deltaPut = 0, sumCall = 0, sumPut = 0;\n        double L1call, L1put;\n        for(unsigned int i = 0; i < optionCount; i++)\n        {\n            sumCall += fabs(h_CallCPU[i]);\n            sumPut  += fabs(h_PutCPU[i]);\n            deltaCall += fabs(h_CallCPU[i] - h_CallGPU[i]);\n            deltaPut  += fabs(h_PutCPU[i] - h_PutGPU[i]);\n        }\n        L1call = deltaCall / sumCall; \n        L1put = deltaPut / sumPut;\n        shrLog(\"Relative L1 (call, put) = (%.3e, %.3e)\\n\\n\", L1call, L1put);\n\n    shrLog(\"Shutting down...\\n\");\n        closeBlackScholes();\n        ciErrNum  = clReleaseMemObject(d_T);\n        ciErrNum |= clReleaseMemObject(d_X);\n        ciErrNum |= clReleaseMemObject(d_S);\n        ciErrNum |= clReleaseMemObject(d_Put);\n        ciErrNum |= clReleaseMemObject(d_Call);\n        ciErrNum |= clReleaseCommandQueue(cqCommandQueue);\n        ciErrNum |= clReleaseContext(cxGPUContext);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        free(h_T);\n        free(h_X);\n        free(h_S);\n        free(h_PutGPU);\n        free(h_CallGPU);\n        free(h_PutCPU);\n        free(h_CallCPU);\n\n       if(cdDevices)free(cdDevices);\n\n        shrQAFinishExit(argc, (const char **)argv, ((L1call < 1E-6) && (L1put < 1E-6)) ? QA_PASSED : QA_FAILED );\n}\n"}, "code_dirs": {"BlackScholes.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclBlackScholes", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclBlackScholes/src"}}
{"kernel_name": "dxtc", "parallel_api": "cuda", "code": {"dxtc.cu": "#include <cooperative_groups.h>\n\nnamespace cg = cooperative_groups;\n\n#include <float.h>\n#include <helper_cuda.h>\n#include <helper_functions.h>\n#include <helper_math.h>\n\n#include \"CudaMath.h\"\n#include \"dds.h\"\n#include \"permutations.h\"\n\n// Definitions\n#define INPUT_IMAGE     \"teapot512_std.ppm\"\n#define REFERENCE_IMAGE \"teapot512_ref.dds\"\n\n#define ERROR_THRESHOLD 0.02f\n\n#define NUM_THREADS 64\n\n#define __debugsync()\n\ntemplate <class T> __device__ inline void swap(T &a, T &b)\n{\n    T tmp = a;\n    a     = b;\n    b     = tmp;\n}\n\n__constant__ float3 kColorMetric = {1.0f, 1.0f, 1.0f};\n\n__device__ void sortColors(const float *values, int *ranks, cg::thread_group tile)\n{\n    const int tid = threadIdx.x;\n\n    int rank = 0;\n\n#pragma unroll\n\n    for (int i = 0; i < 16; i++) {\n        rank += (values[i] < values[tid]);\n    }\n\n    ranks[tid] = rank;\n\n    cg::sync(tile);\n\n    for (int i = 0; i < 15; i++) {\n        if (tid > i && ranks[tid] == ranks[i]) {\n            ++ranks[tid];\n        }\n        cg::sync(tile);\n    }\n}\n\n__device__ void loadColorBlock(const uint      *image,\n                               float3           colors[16],\n                               float3           sums[16],\n                               int              xrefs[16],\n                               int              blockOffset,\n                               cg::thread_block cta)\n{\n    const int bid = blockIdx.x + blockOffset;\n    const int idx = threadIdx.x;\n\n    __shared__ float dps[16];\n\n    float3 tmp;\n\n    cg::thread_group tile = cg::tiled_partition(cta, 16);\n\n    if (idx < 16) {\n        uint c = image[(bid) * 16 + idx];\n\n        colors[idx].x = ((c >> 0) & 0xFF) * (1.0f / 255.0f);\n        colors[idx].y = ((c >> 8) & 0xFF) * (1.0f / 255.0f);\n        colors[idx].z = ((c >> 16) & 0xFF) * (1.0f / 255.0f);\n\n        cg::sync(tile);\n        colorSums(colors, sums, tile);\n\n        cg::sync(tile);\n\n        float3 axis = bestFitLine(colors, sums[0], tile);\n\n        cg::sync(tile);\n\n        dps[idx] = dot(colors[idx], axis);\n\n        cg::sync(tile);\n\n        sortColors(dps, xrefs, tile);\n\n        cg::sync(tile);\n\n        tmp = colors[idx];\n\n        cg::sync(tile);\n\n        colors[xrefs[idx]] = tmp;\n    }\n}\n\ninline __device__ float3 roundAndExpand(float3 v, ushort *w)\n{\n    v.x = rintf(__saturatef(v.x) * 31.0f);\n    v.y = rintf(__saturatef(v.y) * 63.0f);\n    v.z = rintf(__saturatef(v.z) * 31.0f);\n\n    *w = ((ushort)v.x << 11) | ((ushort)v.y << 5) | (ushort)v.z;\n    v.x *= 0.03227752766457f;\n    v.y *= 0.01583151765563f;\n    v.z *= 0.03227752766457f;\n    return v;\n}\n\n__constant__ float     alphaTable4[4] = {9.0f, 0.0f, 6.0f, 3.0f};\n__constant__ float     alphaTable3[4] = {4.0f, 0.0f, 2.0f, 2.0f};\n__constant__ const int prods4[4]      = {0x090000, 0x000900, 0x040102, 0x010402};\n__constant__ const int prods3[4]      = {0x040000, 0x000400, 0x040101, 0x010401};\n\n#define USE_TABLES 1\n\nstatic __device__ float\nevalPermutation4(const float3 *colors, uint permutation, ushort *start, ushort *end, float3 color_sum)\n{\n#if USE_TABLES\n    float3 alphax_sum = make_float3(0.0f, 0.0f, 0.0f);\n\n    int akku = 0;\n\n    for (int i = 0; i < 16; i++) {\n        const uint bits = permutation >> (2 * i);\n\n        alphax_sum += alphaTable4[bits & 3] * colors[i];\n        akku += prods4[bits & 3];\n    }\n\n    float  alpha2_sum    = float(akku >> 16);\n    float  beta2_sum     = float((akku >> 8) & 0xff);\n    float  alphabeta_sum = float((akku >> 0) & 0xff);\n    float3 betax_sum     = (9.0f * color_sum) - alphax_sum;\n#else\n    float  alpha2_sum    = 0.0f;\n    float  beta2_sum     = 0.0f;\n    float  alphabeta_sum = 0.0f;\n    float3 alphax_sum    = make_float3(0.0f, 0.0f, 0.0f);\n\n    for (int i = 0; i < 16; i++) {\n        const uint bits = permutation >> (2 * i);\n\n        float beta = (bits & 1);\n\n        if (bits & 2) {\n            beta = (1 + beta) * (1.0f / 3.0f);\n        }\n\n        float alpha = 1.0f - beta;\n\n        alpha2_sum += alpha * alpha;\n        beta2_sum += beta * beta;\n        alphabeta_sum += alpha * beta;\n        alphax_sum += alpha * colors[i];\n    }\n\n    float3 betax_sum = color_sum - alphax_sum;\n#endif\n\n    const float factor = 1.0f / (alpha2_sum * beta2_sum - alphabeta_sum * alphabeta_sum);\n\n    float3 a = (alphax_sum * beta2_sum - betax_sum * alphabeta_sum) * factor;\n    float3 b = (betax_sum * alpha2_sum - alphax_sum * alphabeta_sum) * factor;\n\n    a = roundAndExpand(a, start);\n    b = roundAndExpand(b, end);\n\n    float3 e = a * a * alpha2_sum + b * b * beta2_sum + 2.0f * (a * b * alphabeta_sum - a * alphax_sum - b * betax_sum);\n\n    return (0.111111111111f) * dot(e, kColorMetric);\n}\n\nstatic __device__ float\nevalPermutation3(const float3 *colors, uint permutation, ushort *start, ushort *end, float3 color_sum)\n{\n#if USE_TABLES\n    float3 alphax_sum = make_float3(0.0f, 0.0f, 0.0f);\n\n    int akku = 0;\n\n    for (int i = 0; i < 16; i++) {\n        const uint bits = permutation >> (2 * i);\n\n        alphax_sum += alphaTable3[bits & 3] * colors[i];\n        akku += prods3[bits & 3];\n    }\n\n    float  alpha2_sum    = float(akku >> 16);\n    float  beta2_sum     = float((akku >> 8) & 0xff);\n    float  alphabeta_sum = float((akku >> 0) & 0xff);\n    float3 betax_sum     = (4.0f * color_sum) - alphax_sum;\n#else\n    float  alpha2_sum    = 0.0f;\n    float  beta2_sum     = 0.0f;\n    float  alphabeta_sum = 0.0f;\n    float3 alphax_sum    = make_float3(0.0f, 0.0f, 0.0f);\n\n    for (int i = 0; i < 16; i++) {\n        const uint bits = permutation >> (2 * i);\n\n        float beta = (bits & 1);\n\n        if (bits & 2) {\n            beta = 0.5f;\n        }\n\n        float alpha = 1.0f - beta;\n\n        alpha2_sum += alpha * alpha;\n        beta2_sum += beta * beta;\n        alphabeta_sum += alpha * beta;\n        alphax_sum += alpha * colors[i];\n    }\n\n    float3 betax_sum = color_sum - alphax_sum;\n#endif\n\n    const float factor = 1.0f / (alpha2_sum * beta2_sum - alphabeta_sum * alphabeta_sum);\n\n    float3 a = (alphax_sum * beta2_sum - betax_sum * alphabeta_sum) * factor;\n    float3 b = (betax_sum * alpha2_sum - alphax_sum * alphabeta_sum) * factor;\n\n    a = roundAndExpand(a, start);\n    b = roundAndExpand(b, end);\n\n    float3 e = a * a * alpha2_sum + b * b * beta2_sum + 2.0f * (a * b * alphabeta_sum - a * alphax_sum - b * betax_sum);\n\n    return (0.25f) * dot(e, kColorMetric);\n}\n\n__device__ void evalAllPermutations(const float3    *colors,\n                                    const uint      *permutations,\n                                    ushort          &bestStart,\n                                    ushort          &bestEnd,\n                                    uint            &bestPermutation,\n                                    float           *errors,\n                                    float3           color_sum,\n                                    cg::thread_block cta)\n{\n    const int idx = threadIdx.x;\n\n    float bestError = FLT_MAX;\n\n    __shared__ uint s_permutations[160];\n\n    for (int i = 0; i < 16; i++) {\n        int pidx = idx + NUM_THREADS * i;\n\n        if (pidx >= 992) {\n            break;\n        }\n\n        ushort start, end;\n        uint   permutation = permutations[pidx];\n\n        if (pidx < 160) {\n            s_permutations[pidx] = permutation;\n        }\n\n        float error = evalPermutation4(colors, permutation, &start, &end, color_sum);\n\n        if (error < bestError) {\n            bestError       = error;\n            bestPermutation = permutation;\n            bestStart       = start;\n            bestEnd         = end;\n        }\n    }\n\n    if (bestStart < bestEnd) {\n        swap(bestEnd, bestStart);\n        bestPermutation ^= 0x55555555;\n    }\n\n    cg::sync(cta);\n\n    for (int i = 0; i < 3; i++) {\n        int pidx = idx + NUM_THREADS * i;\n\n        if (pidx >= 160) {\n            break;\n        }\n\n        ushort start, end;\n        uint   permutation = s_permutations[pidx];\n        float  error       = evalPermutation3(colors, permutation, &start, &end, color_sum);\n\n        if (error < bestError) {\n            bestError       = error;\n            bestPermutation = permutation;\n            bestStart       = start;\n            bestEnd         = end;\n\n            if (bestStart > bestEnd) {\n                swap(bestEnd, bestStart);\n                bestPermutation ^= (~bestPermutation >> 1) & 0x55555555;\n            }\n        }\n    }\n\n    errors[idx] = bestError;\n}\n\n__device__ int findMinError(float *errors, cg::thread_block cta)\n{\n    const int      idx = threadIdx.x;\n    __shared__ int indices[NUM_THREADS];\n    indices[idx] = idx;\n\n    cg::sync(cta);\n\n    for (int d = NUM_THREADS / 2; d > 0; d >>= 1) {\n        float err0   = errors[idx];\n        float err1   = (idx + d) < NUM_THREADS ? errors[idx + d] : FLT_MAX;\n        int   index1 = (idx + d) < NUM_THREADS ? indices[idx + d] : 0;\n\n        cg::sync(cta);\n\n        if (err1 < err0) {\n            errors[idx]  = err1;\n            indices[idx] = index1;\n        }\n\n        cg::sync(cta);\n    }\n\n    return indices[0];\n}\n\n__device__ void saveBlockDXT1(ushort start, ushort end, uint permutation, int xrefs[16], uint2 *result, int blockOffset)\n{\n    const int bid = blockIdx.x + blockOffset;\n\n    if (start == end) {\n        permutation = 0;\n    }\n\n    uint indices = 0;\n\n    for (int i = 0; i < 16; i++) {\n        int ref = xrefs[i];\n        indices |= ((permutation >> (2 * ref)) & 3) << (2 * i);\n    }\n\n    result[bid].x = (end << 16) | start;\n\n    result[bid].y = indices;\n}\n\n__global__ void compress(const uint *permutations, const uint *image, uint2 *result, int blockOffset)\n{\n    cg::thread_block cta = cg::this_thread_block();\n\n    const int idx = threadIdx.x;\n\n    __shared__ float3 colors[16];\n    __shared__ float3 sums[16];\n    __shared__ int    xrefs[16];\n\n    loadColorBlock(image, colors, sums, xrefs, blockOffset, cta);\n\n    cg::sync(cta);\n\n    ushort bestStart, bestEnd;\n    uint   bestPermutation;\n\n    __shared__ float errors[NUM_THREADS];\n\n    evalAllPermutations(colors, permutations, bestStart, bestEnd, bestPermutation, errors, sums[0], cta);\n\n    const int minIdx = findMinError(errors, cta);\n\n    cg::sync(cta);\n\n    if (idx == minIdx) {\n        saveBlockDXT1(bestStart, bestEnd, bestPermutation, xrefs, result, blockOffset);\n    }\n}\n\nunion Color32\n{\n    struct\n    {\n        unsigned char b, g, r, a;\n    };\n    unsigned int u;\n};\n\nunion Color16\n{\n    struct\n    {\n        unsigned short b : 5;\n        unsigned short g : 6;\n        unsigned short r : 5;\n    };\n    unsigned short u;\n};\n\nstruct BlockDXT1\n{\n    Color16 col0;\n    Color16 col1;\n    union\n    {\n        unsigned char row[4];\n        unsigned int  indices;\n    };\n\n    void decompress(Color32 colors[16]) const;\n};\n\nvoid BlockDXT1::decompress(Color32 *colors) const\n{\n    Color32 palette[4];\n\n    palette[0].b = (col0.b << 3) | (col0.b >> 2);\n    palette[0].g = (col0.g << 2) | (col0.g >> 4);\n    palette[0].r = (col0.r << 3) | (col0.r >> 2);\n    palette[0].a = 0xFF;\n\n    palette[1].r = (col1.r << 3) | (col1.r >> 2);\n    palette[1].g = (col1.g << 2) | (col1.g >> 4);\n    palette[1].b = (col1.b << 3) | (col1.b >> 2);\n    palette[1].a = 0xFF;\n\n    if (col0.u > col1.u) {\n        palette[2].r = (2 * palette[0].r + palette[1].r) / 3;\n        palette[2].g = (2 * palette[0].g + palette[1].g) / 3;\n        palette[2].b = (2 * palette[0].b + palette[1].b) / 3;\n        palette[2].a = 0xFF;\n\n        palette[3].r = (2 * palette[1].r + palette[0].r) / 3;\n        palette[3].g = (2 * palette[1].g + palette[0].g) / 3;\n        palette[3].b = (2 * palette[1].b + palette[0].b) / 3;\n        palette[3].a = 0xFF;\n    }\n    else {\n        palette[2].r = (palette[0].r + palette[1].r) / 2;\n        palette[2].g = (palette[0].g + palette[1].g) / 2;\n        palette[2].b = (palette[0].b + palette[1].b) / 2;\n        palette[2].a = 0xFF;\n\n        palette[3].r = 0x00;\n        palette[3].g = 0x00;\n        palette[3].b = 0x00;\n        palette[3].a = 0x00;\n    }\n\n    for (int i = 0; i < 16; i++) {\n        colors[i] = palette[(indices >> (2 * i)) & 0x3];\n    }\n}\n\nstatic int compareColors(const Color32 *b0, const Color32 *b1)\n{\n    int sum = 0;\n\n    for (int i = 0; i < 16; i++) {\n        int r = (b0[i].r - b1[i].r);\n        int g = (b0[i].g - b1[i].g);\n        int b = (b0[i].b - b1[i].b);\n        sum += r * r + g * g + b * b;\n    }\n\n    return sum;\n}\n\nstatic int compareBlock(const BlockDXT1 *b0, const BlockDXT1 *b1)\n{\n    Color32 colors0[16];\n    Color32 colors1[16];\n\n    if (memcmp(b0, b1, sizeof(BlockDXT1)) == 0) {\n        return 0;\n    }\n    else {\n        b0->decompress(colors0);\n        b1->decompress(colors1);\n\n        return compareColors(colors0, colors1);\n    }\n}\n\nint main(int argc, char **argv)\n{\n    printf(\"%s Starting...\\n\\n\", argv[0]);\n\n    findCudaDevice(argc, (const char **)argv);\n\n    unsigned char *data = NULL;\n    uint           W, H;\n\n    char *image_path = sdkFindFilePath(INPUT_IMAGE, argv[0]);\n\n    if (image_path == 0) {\n        printf(\"Error, unable to find source image  <%s>\\n\", image_path);\n        exit(EXIT_FAILURE);\n    }\n\n    if (!sdkLoadPPM4ub(image_path, &data, &W, &H)) {\n        printf(\"Error, unable to open source image file <%s>\\n\", image_path);\n\n        exit(EXIT_FAILURE);\n    }\n\n    uint w = W, h = H;\n\n    printf(\"Image Loaded '%s', %d x %d pixels\\n\\n\", image_path, w, h);\n\n    const uint memSize = w * h * 4;\n    assert(0 != memSize);\n    uint *block_image = (uint *)malloc(memSize);\n\n    for (uint by = 0; by < h / 4; by++) {\n        for (uint bx = 0; bx < w / 4; bx++) {\n            for (int i = 0; i < 16; i++) {\n                const int x                             = i & 3;\n                const int y                             = i / 4;\n                block_image[(by * w / 4 + bx) * 16 + i] = ((uint *)data)[(by * 4 + y) * 4 * (W / 4) + bx * 4 + x];\n            }\n        }\n    }\n\n    uint *d_data = NULL;\n    checkCudaErrors(cudaMalloc((void **)&d_data, memSize));\n\n    uint      *d_result       = NULL;\n    const uint compressedSize = (w / 4) * (h / 4) * 8;\n    checkCudaErrors(cudaMalloc((void **)&d_result, compressedSize));\n    uint *h_result = (uint *)malloc(compressedSize);\n\n    uint permutations[1024];\n    computePermutations(permutations);\n\n    uint *d_permutations = NULL;\n    checkCudaErrors(cudaMalloc((void **)&d_permutations, 1024 * sizeof(uint)));\n    checkCudaErrors(cudaMemcpy(d_permutations, permutations, 1024 * sizeof(uint), cudaMemcpyHostToDevice));\n\n    StopWatchInterface *timer = NULL;\n    sdkCreateTimer(&timer);\n\n    checkCudaErrors(cudaMemcpy(d_data, block_image, memSize, cudaMemcpyHostToDevice));\n\n    uint blocks = ((w + 3) / 4) * ((h + 3) / 4); \n\n    int            devID;\n    cudaDeviceProp deviceProp;\n\n    checkCudaErrors(cudaGetDevice(&devID));\n    checkCudaErrors(cudaGetDeviceProperties(&deviceProp, devID));\n\n    int blocksPerLaunch = min(blocks, 768 * deviceProp.multiProcessorCount);\n\n    printf(\"Running DXT Compression on %u x %u image...\\n\", w, h);\n    printf(\"\\n%u Blocks, %u Threads per Block, %u Threads in Grid...\\n\\n\", blocks, NUM_THREADS, blocks * NUM_THREADS);\n    int numIterations = 1;\n\n    for (int i = -1; i < numIterations; ++i) {\n        if (i == 0) {\n            checkCudaErrors(cudaDeviceSynchronize());\n            sdkStartTimer(&timer);\n        }\n\n        for (int j = 0; j < (int)blocks; j += blocksPerLaunch) {\n            compress<<<min(blocksPerLaunch, blocks - j), NUM_THREADS>>>(d_permutations, d_data, (uint2 *)d_result, j);\n        }\n    }\n\n    getLastCudaError(\"compress\");\n\n    checkCudaErrors(cudaDeviceSynchronize());\n    sdkStopTimer(&timer);\n    double dAvgTime = 1.0e-3 * sdkGetTimerValue(&timer) / (double)numIterations;\n    printf(\"dxtc, Throughput = %.4f MPixels/s, Time = %.5f s, Size = %u Pixels, \"\n           \"NumDevsUsed = %i, Workgroup = %d\\n\",\n           (1.0e-6 * (double)(W * H) / dAvgTime),\n           dAvgTime,\n           (W * H),\n           1,\n           NUM_THREADS);\n\n    checkCudaErrors(cudaMemcpy(h_result, d_result, compressedSize, cudaMemcpyDeviceToHost));\n\n    char output_filename[1024];\n    strcpy(output_filename, image_path);\n    strcpy(output_filename + strlen(image_path) - 3, \"dds\");\n    FILE *fp = fopen(output_filename, \"wb\");\n\n    if (fp == 0) {\n        printf(\"Error, unable to open output image <%s>\\n\", output_filename);\n        exit(EXIT_FAILURE);\n    }\n\n    DDSHeader header;\n    header.fourcc      = FOURCC_DDS;\n    header.size        = 124;\n    header.flags       = (DDSD_WIDTH | DDSD_HEIGHT | DDSD_CAPS | DDSD_PIXELFORMAT | DDSD_LINEARSIZE);\n    header.height      = h;\n    header.width       = w;\n    header.pitch       = compressedSize;\n    header.depth       = 0;\n    header.mipmapcount = 0;\n    memset(header.reserved, 0, sizeof(header.reserved));\n    header.pf.size     = 32;\n    header.pf.flags    = DDPF_FOURCC;\n    header.pf.fourcc   = FOURCC_DXT1;\n    header.pf.bitcount = 0;\n    header.pf.rmask    = 0;\n    header.pf.gmask    = 0;\n    header.pf.bmask    = 0;\n    header.pf.amask    = 0;\n    header.caps.caps1  = DDSCAPS_TEXTURE;\n    header.caps.caps2  = 0;\n    header.caps.caps3  = 0;\n    header.caps.caps4  = 0;\n    header.notused     = 0;\n    fwrite(&header, sizeof(DDSHeader), 1, fp);\n    fwrite(h_result, compressedSize, 1, fp);\n    fclose(fp);\n\n    const char *reference_image_path = sdkFindFilePath(REFERENCE_IMAGE, argv[0]);\n\n    if (reference_image_path == 0) {\n        printf(\"Error, unable to find reference image\\n\");\n\n        exit(EXIT_FAILURE);\n    }\n\n    fp = fopen(reference_image_path, \"rb\");\n\n    if (fp == 0) {\n        printf(\"Error, unable to open reference image\\n\");\n\n        exit(EXIT_FAILURE);\n    }\n\n    fseek(fp, sizeof(DDSHeader), SEEK_SET);\n    uint  referenceSize = (W / 4) * (H / 4) * 8;\n    uint *reference     = (uint *)malloc(referenceSize);\n    fread(reference, referenceSize, 1, fp);\n    fclose(fp);\n\n    printf(\"\\nChecking accuracy...\\n\");\n    float rms = 0;\n\n    for (uint y = 0; y < h; y += 4) {\n        for (uint x = 0; x < w; x += 4) {\n            uint referenceBlockIdx = ((y / 4) * (W / 4) + (x / 4));\n            uint resultBlockIdx    = ((y / 4) * (w / 4) + (x / 4));\n\n            int cmp =\n                compareBlock(((BlockDXT1 *)h_result) + resultBlockIdx, ((BlockDXT1 *)reference) + referenceBlockIdx);\n\n            if (cmp != 0.0f) {\n                printf(\"Deviation at (%4d,%4d):\\t%f rms\\n\", x / 4, y / 4, float(cmp) / 16 / 3);\n            }\n\n            rms += cmp;\n        }\n    }\n\n    rms /= w * h * 3;\n\n    checkCudaErrors(cudaFree(d_permutations));\n    checkCudaErrors(cudaFree(d_data));\n    checkCudaErrors(cudaFree(d_result));\n    free(image_path);\n    free(data);\n    free(block_image);\n    free(h_result);\n    free(reference);\n    sdkDeleteTimer(&timer);\n\n    printf(\"RMS(reference, result) = %f\\n\\n\", rms);\n    printf(rms <= ERROR_THRESHOLD ? \"Test passed\\n\" : \"Test failed!\\n\");\n    return rms > ERROR_THRESHOLD;\n}\n"}, "code_dirs": {"dxtc.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/dxtc"}}
{"kernel_name": "dxtc", "parallel_api": "ocl", "code": {"DXTCompression.cl": "#pragma OPENCL EXTENSION cl_khr_byte_addressable_store : enable\n\n#define NUM_THREADS   64      // Number of threads per work group.\n\nfloat4 firstEigenVector( __local float* matrix )\n{\n    // 8 iterations seems to be more than enough.\n\n    float4 v = (float4)(1.0f, 1.0f, 1.0f, 0.0f);\n    #pragma unroll\n    for(int i = 0; i < 8; i++) {\n      float x = v.x * matrix[0] + v.y * matrix[1] + v.z * matrix[2];\n      float y = v.x * matrix[1] + v.y * matrix[3] + v.z * matrix[4];\n      float z = v.x * matrix[2] + v.y * matrix[4] + v.z * matrix[5];\n      float m = max(max(x, y), z);        \n      float iv = 1.0f / m;\n      \n      v.x = x * iv;\n      v.y = y * iv;\n      v.z = z * iv;      \n    }\n\n    return v;\n}\n\nvoid colorSums(__local const float4 * colors, __local float4 * sums)\n{\n    const int idx = get_local_id(0);\n\n    sums[idx] = colors[idx];\n    sums[idx] += sums[idx^8];\n    sums[idx] += sums[idx^4];\n    sums[idx] += sums[idx^2];\n    sums[idx] += sums[idx^1];\n}\n\nfloat4 bestFitLine(__local const float4 * colors, float4 color_sum, __local float* covariance)\n{\n    // Compute covariance matrix of the given colors.\n    const int idx = get_local_id(0);\n\n    float4 diff = colors[idx] - color_sum * 0.0625f; // * 1.0f / 16.0f\n\n    covariance[6 * idx + 0] = diff.x * diff.x;    // 0, 6, 12, 2, 8, 14, 4, 10, 0\n    covariance[6 * idx + 1] = diff.x * diff.y;\n    covariance[6 * idx + 2] = diff.x * diff.z;\n    covariance[6 * idx + 3] = diff.y * diff.y;\n    covariance[6 * idx + 4] = diff.y * diff.z;\n    covariance[6 * idx + 5] = diff.z * diff.z;\n\n    #pragma unroll\n    for(int d = 8; d > 0; d >>= 1)\n    {\n        if (idx < d)\n        {\n            covariance[6 * idx + 0] += covariance[6 * (idx+d) + 0];\n            covariance[6 * idx + 1] += covariance[6 * (idx+d) + 1];\n            covariance[6 * idx + 2] += covariance[6 * (idx+d) + 2];\n            covariance[6 * idx + 3] += covariance[6 * (idx+d) + 3];\n            covariance[6 * idx + 4] += covariance[6 * (idx+d) + 4];\n            covariance[6 * idx + 5] += covariance[6 * (idx+d) + 5];\n        }\n    }\n\n    // Compute first eigen vector.\n    return firstEigenVector(covariance);\n}\n\nvoid sortColors(__local const float * values, __local int * ranks)\n{\n    const int tid = get_local_id(0);\n\n    int rank = 0;\n\n    #pragma unroll\n    for (int i = 0; i < 16; i++)\n    {\n        rank += (values[i] < values[tid]);\n    }\n    \n    ranks[tid] = rank;\n\n    // Resolve elements with the same index.\n    #pragma unroll\n    for (int i = 0; i < 15; i++)\n    {\n        if (tid > i && ranks[tid] == ranks[i]) ++ranks[tid];\n    }\n}\n\nvoid loadColorBlock(__global const uint * image, __local float4 * colors, __local float4 * sums, __local int * xrefs, __local float* temp, int groupOffset)\n{\n    const int bid = get_group_id(0) + groupOffset;\n    const int idx = get_local_id(0);\n\n    float4 tmp;\n\n    if (idx < 16)\n    {\n        // Read color and copy to shared mem.\n        uint c = image[(bid) * 16 + idx];\n    \n        colors[idx].x = ((c >> 0) & 0xFF) * 0.003921568627f;    // * (1.0f / 255.0f);\n        colors[idx].y = ((c >> 8) & 0xFF) * 0.003921568627f;    // * (1.0f / 255.0f);\n        colors[idx].z = ((c >> 16) & 0xFF) * 0.003921568627f;   //* (1.0f / 255.0f);\n\n        // No need to synchronize, 16 < warp size.\t\n\n        // Sort colors along the best fit line.\n\t    colorSums(colors, sums);\n\t    float4 axis = bestFitLine(colors, sums[idx], temp);\n            \n        temp[idx] = colors[idx].x * axis.x + colors[idx].y * axis.y + colors[idx].z * axis.z;\n        \n        sortColors(temp, xrefs);\n        \n        tmp = colors[idx];\n\n        colors[xrefs[idx]] = tmp;\n    }\n}\n\nfloat4 roundAndExpand(float4 v, ushort * w)\n{\n    ushort x = rint(clamp(v.x, 0.0f, 1.0f) * 31.0f);\n    ushort y = rint(clamp(v.y, 0.0f, 1.0f) * 63.0f);\n    ushort z = rint(clamp(v.z, 0.0f, 1.0f) * 31.0f);\n\n    *w = ((x << 11) | (y << 5) | z);\n    v.x = x * 0.03227752766457f; // approximate integer bit expansion.\n    v.y = y * 0.01583151765563f;\n    v.z = z * 0.03227752766457f;\n    return v;\n}\n\nfloat evalPermutation(__local const float4* colors, uint permutation, ushort* start, ushort* end, float4 color_sum,\n                       __constant float* alphaTable4, __constant int* prods4, float weight)\n{\n    float4 alphax_sum = (float4)(0.0f, 0.0f, 0.0f,0.0f);\n    int akku = 0;\n\n    // Compute alpha & beta for this permutation.\n    #pragma unroll\n    for (int i = 0; i < 16; i++)\n    {\n        const uint bits = permutation >> (2*i);\n\n        alphax_sum += alphaTable4[bits & 3] * colors[i];\n        akku += prods4[bits & 3];\n    }\n\n    float alpha2_sum = (akku >> 16);\n    float beta2_sum = ((akku >> 8) & 0xff);\n    float alphabeta_sum = ((akku >> 0) & 0xff);\n    float4 betax_sum = weight * color_sum - alphax_sum;\n\n    //// Compute endpoints using least squares.\n \n    // alpha2, beta2, alphabeta and factor could be precomputed for each permutation, but it's faster to recompute them.\n    const float factor = 1.0f / (alpha2_sum * beta2_sum - alphabeta_sum * alphabeta_sum);\n\n    float4 a = (alphax_sum * beta2_sum - betax_sum * alphabeta_sum) * factor;\n    float4 b = (betax_sum * alpha2_sum - alphax_sum * alphabeta_sum) * factor;\n    \n    // Round a, b to the closest 5-6-5 color and expand...\n    a = roundAndExpand(a, start);\n    b = roundAndExpand(b, end);\n\n    // compute the error\n    float4 e = a * a * alpha2_sum + b * b * beta2_sum + 2.0f * (a * b * alphabeta_sum - a * alphax_sum - b * betax_sum);\n\n    return (1.0f/weight) * (e.x + e.y + e.z);\n}\n\nfloat evalPermutation3(__local const float4 * colors, uint permutation, ushort * start, ushort * end, float4 color_sum,\n                       __constant float* alphaTable3, __constant int* prods3)\n{\n    float4 alphax_sum = (float4)(0.0f, 0.0f, 0.0f, 0.0f);\n    int akku = 0;\n\n    // Compute alpha & beta for this permutation.\n    #pragma unroll\n    for (int i = 0; i < 16; i++)\n    {\n        const uint bits = permutation >> (2*i);\n\n        alphax_sum += alphaTable3[bits & 3] * colors[i];\n        akku += prods3[bits & 3];\n    }\n\n    float alpha2_sum = (akku >> 16);\n    float beta2_sum = ((akku >> 8) & 0xff);\n    float alphabeta_sum = ((akku >> 0) & 0xff);\n    float4 betax_sum = 4.0f * color_sum - alphax_sum;\n\n    const float factor = 1.0f / (alpha2_sum * beta2_sum - alphabeta_sum * alphabeta_sum);\n\n    float4 a = (alphax_sum * beta2_sum - betax_sum * alphabeta_sum) * factor;\n    float4 b = (betax_sum * alpha2_sum - alphax_sum * alphabeta_sum) * factor;\n    \n    // Round a, b to the closest 5-6-5 color and expand...\n    a = roundAndExpand(a, start);\n    b = roundAndExpand(b, end);\n\n    // compute the error\n    float4 e = a * a * alpha2_sum + b * b * beta2_sum + 2.0f * (a * b * alphabeta_sum - a * alphax_sum - b * betax_sum);\n\n    return (0.25f) * (e.x + e.y + e.z);\n}\n\nuint4 evalAllPermutations(__local const float4 * colors, __global const unsigned int * permutations,\t\t\t \n\t\t\t  __local float *errors, float4 color_sum, __local uint * s_permutations, \n              __constant float* alphaTable4, __constant int* prods4,\n              __constant float* alphaTable3, __constant int* prods3)\n{\n    const int idx = get_local_id(0);\n\n    uint bestStart;\n    uint bestEnd;\n    uint bestPermutation;\n    uint temp;\n\n  \n    float bestError = FLT_MAX;\n    \n    #pragma unroll\n    for(int i = 0; i < 16; i++)\n    {\n      int pidx = idx + NUM_THREADS * i;\n        if (pidx >= 992) break;\n        \n        ushort start, end;\n        uint permutation = permutations[pidx];\n        if (pidx < 160) s_permutations[pidx] = permutation;\n                \n        float error = evalPermutation(colors, permutation, &start, &end, color_sum, alphaTable4, prods4, 9.0f);        \n        if (error < bestError)\n        {\n            bestError = error;\n            bestPermutation = permutation;\n            bestStart = start;\n            bestEnd = end;\n        }\n    }\n\n    if (bestStart < bestEnd)\n    {\n        temp = bestEnd;\n        bestEnd = bestStart;\n        bestStart = temp;\n        \n        bestPermutation ^= 0x55555555;    // Flip indices.\n    }\n\n    #pragma unroll\n    for(int i = 0; i < 3; i++)\n    {\n        int pidx = idx + NUM_THREADS * i;\n        if (pidx >= 160) break;\n        \n        ushort start, end;\n        uint permutation = s_permutations[pidx];\n        float error = evalPermutation(colors, permutation, &start, &end, color_sum, alphaTable3, prods3, 4.0f);\n        if (error < bestError)\n        {\n            bestError = error;\n            bestPermutation = permutation;\n            bestStart = start;\n            bestEnd = end;\n            \n            if (bestStart > bestEnd)\n            {\n                temp = bestEnd;\n                bestEnd = bestStart;\n                bestStart = temp;\n\n                bestPermutation ^= (~bestPermutation >> 1) & 0x55555555;    // Flip indices.\n            }\n        }\n    }\n\n    errors[idx] = bestError;\n    \n    uint4 result = (uint4)(bestStart, bestEnd, bestPermutation, 0);\n    return result;\n}\n\nint findMinError(__local float * errors, __local int * indices)\n{\n    const int idx = get_local_id(0);\n\n    indices[idx] = idx;\n\n    #pragma unroll\n    for(int d = NUM_THREADS/2; d > 32; d >>= 1)\n    {\n        barrier(CLK_LOCAL_MEM_FENCE);\n        \n        if (idx < d)\n        {\n            float err0 = errors[idx];\n            float err1 = errors[idx + d];\n            \n            if (err1 < err0) {\n                errors[idx] = err1;\n                indices[idx] = indices[idx + d];\n            }\n        }\n    }\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    // unroll last 6 iterations\n    if (idx < 32)\n    {\n        if (errors[idx + 32] < errors[idx]) {\n            errors[idx] = errors[idx + 32];\n            indices[idx] = indices[idx + 32];\n        }\n        if (errors[idx + 16] < errors[idx]) {\n            errors[idx] = errors[idx + 16];\n            indices[idx] = indices[idx + 16];\n        }\n        if (errors[idx + 8] < errors[idx]) {\n            errors[idx] = errors[idx + 8];\n            indices[idx] = indices[idx + 8];\n        }\n        if (errors[idx + 4] < errors[idx]) {\n            errors[idx] = errors[idx + 4];\n            indices[idx] = indices[idx + 4];\n        }\n        if (errors[idx + 2] < errors[idx]) {\n            errors[idx] = errors[idx + 2];\n            indices[idx] = indices[idx + 2];\n        }\n        if (errors[idx + 1] < errors[idx]) {\n            errors[idx] = errors[idx + 1];\n            indices[idx] = indices[idx + 1];\n        }\n    }\n\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    return indices[0];\n}\n\n\n//Save DXT block\nvoid saveBlockDXT1(uint start, uint end, uint permutation, __local int* xrefs, __global uint2 * result, int groupOffset)\n{\n    const int bid = get_group_id(0) + groupOffset;\n\n    if (start == end)\n    {\n        permutation = 0;\n    }\n    \n    // Reorder permutation.\n    uint indices = 0;\n    #pragma unroll\n    for(int i = 0; i < 16; i++)\n    {\n        int ref = xrefs[i];\n        indices |= ((permutation >> (2 * ref)) & 3) << (2 * i);\n    }\n    \n    // Write endpoints.\n    result[bid].x = (end << 16) | start;\n    \n    // Write palette indices.\n    result[bid].y = indices;\n}\n\n__kernel void compress(__global const uint * permutations, __global const uint * image, \n\t\t       __global uint2 * result, \n               __constant float* alphaTable4, __constant int* prods4,\n               __constant float* alphaTable3, __constant int* prods3,\n\t\t\t   int groupOffset)\n{\n\t__local float4 colors[16];\n\t__local float4 sums[16];\n\t__local int s_int[64];\n\t__local float s_float[16*6];\n\t__local uint s_permutations[160];\n\t__local int xrefs[16];\n\n\tconst int idx = get_local_id(0);\n    \n    loadColorBlock(image, colors, sums, xrefs, s_float, groupOffset);\n    \n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    uint4 best = evalAllPermutations(colors, permutations,s_float, sums[0], s_permutations, alphaTable4, prods4, alphaTable3, prods3);\n\n    // Use a parallel reduction to find minimum error.\n    const int minIdx = findMinError(s_float, s_int);    \n\n    barrier(CLK_LOCAL_MEM_FENCE);\n    \n    // Only write the result of the winner thread.\n    if (idx == minIdx)\n    {\n        saveBlockDXT1(best.x, best.y, best.z, xrefs, result, groupOffset);\n    }\n}\n", "oclDXTCompression.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n\n#include \"dds.h\"\n#include \"permutations.h\"\n#include \"block.h\"\n\nconst char *image_filename = \"lena_std.ppm\";\nconst char *refimage_filename = \"lena_ref.dds\";\n\nunsigned int width, height;\ncl_uint* h_img = NULL;\n\n#define ERROR_THRESHOLD 0.02f\n\n#define NUM_THREADS   64      // Number of threads per work group.\n\n// constants for this demo\nconst cl_float alphaTable4[4] = {9.0f, 0.0f, 6.0f, 3.0f};\nconst cl_float alphaTable3[4] = {4.0f, 0.0f, 2.0f, 2.0f};\nconst cl_int prods4[4] = {0x090000, 0x000900, 0x040102, 0x010402};\nconst cl_int prods3[4] = {0x040000, 0x000400, 0x040101, 0x010401};\n\nint main(int argc, char** argv) \n{\n    shrQAStart(argc, argv);\n\n    shrSetLogFileName (\"oclDXTCompression.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    cl_platform_id cpPlatform = NULL;\n    cl_uint uiNumDevices = 0;\n    cl_device_id *cdDevices = NULL;\n    cl_context cxGPUContext;\n    cl_command_queue cqCommandQueue;\n    cl_program cpProgram;\n    cl_kernel ckKernel;\n    cl_mem cmMemObjs[3];\n    cl_mem cmAlphaTable4, cmProds4;\n    cl_mem cmAlphaTable3, cmProds3;\n    size_t szGlobalWorkSize[1];\n    size_t szLocalWorkSize[1];\n    cl_int ciErrNum;\n\n    char *filename;\n    if (shrGetCmdLineArgumentstr(argc, (const char **)argv, \"image\", &filename)) {\n        image_filename = filename;\n    }\n    // load image\n    const char* image_path = shrFindFilePath(image_filename, argv[0]);\n    oclCheckError(image_path != NULL, shrTRUE);\n    shrLoadPPM4ub(image_path, (unsigned char **)&h_img, &width, &height);\n    oclCheckError(h_img != NULL, shrTRUE);\n    shrLog(\"Loaded '%s', %d x %d pixels\\n\\n\", image_path, width, height);\n\n    // Convert linear image to block linear. \n    const uint memSize = width * height * sizeof(cl_uint);\n    uint* block_image = (uint*)malloc(memSize);\n\n    // Convert linear image to block linear. \n    for(uint by = 0; by < height/4; by++) {\n        for(uint bx = 0; bx < width/4; bx++) {\n            for (int i = 0; i < 16; i++) {\n                const int x = i & 3;\n                const int y = i / 4;\n                block_image[(by * width/4 + bx) * 16 + i] = \n                    ((uint *)h_img)[(by * 4 + y) * 4 * (width/4) + bx * 4 + x];\n            }\n        }\n    }\n\n    // Get the NVIDIA platform\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // Get the platform's GPU devices\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiNumDevices);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    cdDevices = (cl_device_id *)malloc(uiNumDevices * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiNumDevices, cdDevices, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // Create the context\n    cxGPUContext = clCreateContext(0, uiNumDevices, cdDevices, NULL, NULL, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // get and log device\n    cl_device_id device;\n    if( shrCheckCmdLineFlag(argc, (const char **)argv, \"device\") ) {\n      int device_nr = 0;\n      shrGetCmdLineArgumenti(argc, (const char **)argv, \"device\", &device_nr);\n      device = oclGetDev(cxGPUContext, device_nr);\n      if( device == (cl_device_id)-1 ) {\n          shrLog(\" Invalid GPU Device: devID=%d.  %d valid GPU devices detected\\n\\n\", device_nr, uiNumDevices);\n\t\t  shrLog(\" exiting...\\n\");\n          return -1;\n      }\n    } else {\n      device = oclGetMaxFlopsDev(cxGPUContext);\n    }\n\n    oclPrintDevName(LOGBOTH, device);\n    shrLog(\"\\n\");\n\n    // create a command-queue\n    cqCommandQueue = clCreateCommandQueue(cxGPUContext, device, 0, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // Memory Setup\n\n    // Constants\n    cmAlphaTable4 = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, 4 * sizeof(cl_float), (void*)&alphaTable4[0], &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    cmProds4 = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, 4 * sizeof(cl_int), (void*)&prods4[0], &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    cmAlphaTable3 = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, 4 * sizeof(cl_float), (void*)&alphaTable3[0], &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    cmProds3 = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, 4 * sizeof(cl_int), (void*)&prods3[0], &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // Compute permutations.\n    cl_uint permutations[1024];\n    computePermutations(permutations);\n\n    // Upload permutations.\n    cmMemObjs[0] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,\n                                  sizeof(cl_uint) * 1024, permutations, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // Image\n    cmMemObjs[1] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, memSize, NULL, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    \n    // Result\n    const uint compressedSize = (width / 4) * (height / 4) * 8;\n    cmMemObjs[2] = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, compressedSize, NULL , &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    \n    unsigned int * h_result = (uint*)malloc(compressedSize);\n\n    // Program Setup\n    size_t program_length;\n    const char* source_path = shrFindFilePath(\"DXTCompression.cl\", argv[0]);\n    oclCheckError(source_path != NULL, shrTRUE);\n    char *source = oclLoadProgSource(source_path, \"\", &program_length);\n    oclCheckError(source != NULL, shrTRUE);\n\n    // create the program\n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1,\n        (const char **) &source, &program_length, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // build the program\n    ciErrNum = clBuildProgram(cpProgram, 0, NULL, \"-cl-fast-relaxed-math\", NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        // write out standard error, Build Log and PTX, then cleanup and exit\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclDXTCompression.ptx\");\n        oclCheckError(ciErrNum, CL_SUCCESS); \n    }\n\n    // create the kernel\n    ckKernel = clCreateKernel(cpProgram, \"compress\", &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // set the args values\n    ciErrNum  = clSetKernelArg(ckKernel, 0, sizeof(cl_mem), (void *) &cmMemObjs[0]);\n    ciErrNum |= clSetKernelArg(ckKernel, 1, sizeof(cl_mem), (void *) &cmMemObjs[1]);\n    ciErrNum |= clSetKernelArg(ckKernel, 2, sizeof(cl_mem), (void *) &cmMemObjs[2]);\n    ciErrNum |= clSetKernelArg(ckKernel, 3, sizeof(cl_mem), (void*)&cmAlphaTable4);\n    ciErrNum |= clSetKernelArg(ckKernel, 4, sizeof(cl_mem), (void*)&cmProds4);\n    ciErrNum |= clSetKernelArg(ckKernel, 5, sizeof(cl_mem), (void*)&cmAlphaTable3);\n    ciErrNum |= clSetKernelArg(ckKernel, 6, sizeof(cl_mem), (void*)&cmProds3);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // Copy input data host to device\n    clEnqueueWriteBuffer(cqCommandQueue, cmMemObjs[1], CL_FALSE, 0, sizeof(cl_uint) * width * height, block_image, 0,0,0);\n\n    // Determine launch configuration and run timed computation numIterations times\n\tint blocks = ((width + 3) / 4) * ((height + 3) / 4); // rounds up by 1 block in each dim if %4 != 0\n\n\t// Restrict the numbers of blocks to launch on low end GPUs to avoid kernel timeout\n\tcl_uint compute_units;\n    clGetDeviceInfo(device, CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(compute_units), &compute_units, NULL);\n\tint blocksPerLaunch = MIN(blocks, 768 * (int)compute_units);\n\n    // set work-item dimensions\n    szGlobalWorkSize[0] = blocksPerLaunch * NUM_THREADS;\n    szLocalWorkSize[0]= NUM_THREADS;\n\n#ifdef GPU_PROFILING\n    shrLog(\"\\nRunning DXT Compression on %u x %u image...\\n\", width, height);\n    shrLog(\"\\n%u Workgroups, %u Work Items per Workgroup, %u Work Items in NDRange...\\n\\n\", \n           blocks, NUM_THREADS, blocks * NUM_THREADS);\n\n    int numIterations = 50;\n    for (int i = -1; i < numIterations; ++i) {\n        if (i == 0) { // start timing only after the first warmup iteration\n            clFinish(cqCommandQueue); // flush command queue\n            shrDeltaT(0); // start timer\n        }\n#endif\n        // execute kernel\n\t\tfor( int j=0; j<blocks; j+= blocksPerLaunch ) {\n\t\t\tclSetKernelArg(ckKernel, 7, sizeof(int), &j);\n\t\t\tszGlobalWorkSize[0] = MIN( blocksPerLaunch, blocks-j ) * NUM_THREADS;\n\t\t\tciErrNum = clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 1, NULL,\n\t\t\t\t                              szGlobalWorkSize, szLocalWorkSize, \n\t\t\t\t\t                          0, NULL, NULL);\n\t\t\toclCheckError(ciErrNum, CL_SUCCESS);\n\t\t}\n\n#ifdef GPU_PROFILING\n    }\n    clFinish(cqCommandQueue);\n    double dAvgTime = shrDeltaT(0) / (double)numIterations;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclDXTCompression, Throughput = %.4f MPixels/s, Time = %.5f s, Size = %u Pixels, NumDevsUsed = %i, Workgroup = %d\\n\", \n           (1.0e-6 * (double)(width * height)/ dAvgTime), dAvgTime, (width * height), 1, szLocalWorkSize[0]); \n#endif\n\n    // blocking read output\n    ciErrNum = clEnqueueReadBuffer(cqCommandQueue, cmMemObjs[2], CL_TRUE, 0,\n                                   compressedSize, h_result, 0, NULL, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // Write DDS file.\n    FILE* fp = NULL;\n    char output_filename[1024];\n    #ifdef WIN32\n        strcpy_s(output_filename, 1024, image_path);\n        strcpy_s(output_filename + strlen(image_path) - 3, 1024 - strlen(image_path) + 3, \"dds\");\n        fopen_s(&fp, output_filename, \"wb\");\n    #else\n        strcpy(output_filename, image_path);\n        strcpy(output_filename + strlen(image_path) - 3, \"dds\");\n        fp = fopen(output_filename, \"wb\");\n    #endif\n    oclCheckError(fp != NULL, shrTRUE);\n\n    DDSHeader header;\n    header.fourcc = FOURCC_DDS;\n    header.size = 124;\n    header.flags  = (DDSD_WIDTH|DDSD_HEIGHT|DDSD_CAPS|DDSD_PIXELFORMAT|DDSD_LINEARSIZE);\n    header.height = height;\n    header.width = width;\n    header.pitch = compressedSize;\n    header.depth = 0;\n    header.mipmapcount = 0;\n    memset(header.reserved, 0, sizeof(header.reserved));\n    header.pf.size = 32;\n    header.pf.flags = DDPF_FOURCC;\n    header.pf.fourcc = FOURCC_DXT1;\n    header.pf.bitcount = 0;\n    header.pf.rmask = 0;\n    header.pf.gmask = 0;\n    header.pf.bmask = 0;\n    header.pf.amask = 0;\n    header.caps.caps1 = DDSCAPS_TEXTURE;\n    header.caps.caps2 = 0;\n    header.caps.caps3 = 0;\n    header.caps.caps4 = 0;\n    header.notused = 0;\n\n    fwrite(&header, sizeof(DDSHeader), 1, fp);\n    fwrite(h_result, compressedSize, 1, fp);\n\n    fclose(fp);\n\n    // Make sure the generated image matches the reference image (regression check)\n    shrLog(\"\\nComparing against Host/C++ computation...\\n\");     \n    const char* reference_image_path = shrFindFilePath(refimage_filename, argv[0]);\n    oclCheckError(reference_image_path != NULL, shrTRUE);\n\n    // read in the reference image from file\n    #ifdef WIN32\n        fopen_s(&fp, reference_image_path, \"rb\");\n    #else\n        fp = fopen(reference_image_path, \"rb\");\n    #endif\n    oclCheckError(fp != NULL, shrTRUE);\n    fseek(fp, sizeof(DDSHeader), SEEK_SET);\n    uint referenceSize = (width / 4) * (height / 4) * 8;\n    uint * reference = (uint *)malloc(referenceSize);\n    fread(reference, referenceSize, 1, fp);\n    fclose(fp);\n\n    // compare the reference image data to the sample/generated image\n    float rms = 0;\n    for (uint y = 0; y < height; y += 4)\n    {\n        for (uint x = 0; x < width; x += 4)\n        {\n            // binary comparison of data\n            uint referenceBlockIdx = ((y/4) * (width/4) + (x/4));\n            uint resultBlockIdx = ((y/4) * (width/4) + (x/4));\n            int cmp = compareBlock(((BlockDXT1 *)h_result) + resultBlockIdx, ((BlockDXT1 *)reference) + referenceBlockIdx);\n\n            // log deviations, if any\n            if (cmp != 0.0f) \n            {\n                compareBlock(((BlockDXT1 *)h_result) + resultBlockIdx, ((BlockDXT1 *)reference) + referenceBlockIdx);\n                shrLog(\"Deviation at (%d, %d):\\t%f rms\\n\", x/4, y/4, float(cmp)/16/3);\n            }\n            rms += cmp;\n        }\n    }\n    rms /= width * height * 3;\n    shrLog(\"RMS(reference, result) = %f\\n\\n\", rms);\n\n    // Free OpenCL resources\n    oclDeleteMemObjs(cmMemObjs, 3);\n    clReleaseMemObject(cmAlphaTable4);\n    clReleaseMemObject(cmProds4);\n    clReleaseMemObject(cmAlphaTable3);\n    clReleaseMemObject(cmProds3);\n    clReleaseKernel(ckKernel);\n    clReleaseProgram(cpProgram);\n    clReleaseCommandQueue(cqCommandQueue);\n    clReleaseContext(cxGPUContext);\n\n    // Free host memory\n    free(source);\n    free(h_img);\n\n    // finish\n    shrQAFinishExit(argc, (const char **)argv, (rms <= ERROR_THRESHOLD) ? QA_PASSED : QA_FAILED);\n}\n"}, "code_dirs": {"DXTCompression.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclDXTCompression", "oclDXTCompression.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclDXTCompression"}}
{"kernel_name": "quasirandomGenerator", "parallel_api": "cuda", "code": {"quasirandomGenerator_kernel.cu": "#ifndef QUASIRANDOMGENERATOR_KERNEL_CUH\n#define QUASIRANDOMGENERATOR_KERNEL_CUH\n\n#include <helper_cuda.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#include \"quasirandomGenerator_common.h\"\n\n#define MUL(a, b) __umul24(a, b)\n\nstatic __constant__ unsigned int c_Table[QRNG_DIMENSIONS][QRNG_RESOLUTION];\n\nstatic __global__ void quasirandomGeneratorKernel(float *d_Output, unsigned int seed, unsigned int N)\n{\n    unsigned int *dimBase = &c_Table[threadIdx.y][0];\n    unsigned int  tid     = MUL(blockDim.x, blockIdx.x) + threadIdx.x;\n    unsigned int  threadN = MUL(blockDim.x, gridDim.x);\n\n    for (unsigned int pos = tid; pos < N; pos += threadN) {\n        unsigned int result = 0;\n        unsigned int data   = seed + pos;\n\n        for (int bit = 0; bit < QRNG_RESOLUTION; bit++, data >>= 1)\n            if (data & 1) {\n                result ^= dimBase[bit];\n            }\n\n        d_Output[MUL(threadIdx.y, N) + pos] = (float)(result + 1) * INT_SCALE;\n    }\n}\n\nextern \"C\" void initTableGPU(unsigned int tableCPU[QRNG_DIMENSIONS][QRNG_RESOLUTION])\n{\n    checkCudaErrors(cudaMemcpyToSymbol(c_Table, tableCPU, QRNG_DIMENSIONS * QRNG_RESOLUTION * sizeof(unsigned int)));\n}\n\nextern \"C\" void quasirandomGeneratorGPU(float *d_Output, unsigned int seed, unsigned int N)\n{\n    dim3 threads(128, QRNG_DIMENSIONS);\n    quasirandomGeneratorKernel<<<128, threads>>>(d_Output, seed, N);\n    getLastCudaError(\"quasirandomGeneratorKernel() execution failed.\\n\");\n}\n\n__device__ inline float MoroInvCNDgpu(unsigned int x)\n{\n    const float a1 = 2.50662823884f;\n    const float a2 = -18.61500062529f;\n    const float a3 = 41.39119773534f;\n    const float a4 = -25.44106049637f;\n    const float b1 = -8.4735109309f;\n    const float b2 = 23.08336743743f;\n    const float b3 = -21.06224101826f;\n    const float b4 = 3.13082909833f;\n    const float c1 = 0.337475482272615f;\n    const float c2 = 0.976169019091719f;\n    const float c3 = 0.160797971491821f;\n    const float c4 = 2.76438810333863E-02f;\n    const float c5 = 3.8405729373609E-03f;\n    const float c6 = 3.951896511919E-04f;\n    const float c7 = 3.21767881768E-05f;\n    const float c8 = 2.888167364E-07f;\n    const float c9 = 3.960315187E-07f;\n\n    float z;\n\n    bool negate = false;\n\n    if (x >= 0x80000000UL) {\n        x      = 0xffffffffUL - x;\n        negate = true;\n    }\n\n    const float x1 = 1.0f / static_cast<float>(0xffffffffUL);\n    const float x2 = x1 / 2.0f;\n    float       p1 = x * x1 + x2;\n    float p2 = p1 - 0.5f;\n\n    if (p2 > -0.42f) {\n        z = p2 * p2;\n        z = p2 * (((a4 * z + a3) * z + a2) * z + a1) / ((((b4 * z + b3) * z + b2) * z + b1) * z + 1.0f);\n    }\n    else {\n        z = __logf(-__logf(p1));\n        z = -(c1 + z * (c2 + z * (c3 + z * (c4 + z * (c5 + z * (c6 + z * (c7 + z * (c8 + z * c9))))))));\n    }\n\n    return negate ? -z : z;\n}\n\nstatic __global__ void inverseCNDKernel(float *d_Output, unsigned int *d_Input, unsigned int pathN)\n{\n    unsigned int distance = ((unsigned int)-1) / (pathN + 1);\n    unsigned int tid      = MUL(blockDim.x, blockIdx.x) + threadIdx.x;\n    unsigned int threadN  = MUL(blockDim.x, gridDim.x);\n\n    if (d_Input) {\n        for (unsigned int pos = tid; pos < pathN; pos += threadN) {\n            unsigned int d = d_Input[pos];\n            d_Output[pos]  = (float)MoroInvCNDgpu(d);\n        }\n    }\n    else {\n        for (unsigned int pos = tid; pos < pathN; pos += threadN) {\n            unsigned int d = (pos + 1) * distance;\n            d_Output[pos]  = (float)MoroInvCNDgpu(d);\n        }\n    }\n}\n\nextern \"C\" void inverseCNDgpu(float *d_Output, unsigned int *d_Input, unsigned int N)\n{\n    inverseCNDKernel<<<128, 128>>>(d_Output, d_Input, N);\n    getLastCudaError(\"inverseCNDKernel() execution failed.\\n\");\n}\n\n#endif\n", "quasirandomGenerator.cpp": "#include <cuda_runtime.h>\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n\n#include \"quasirandomGenerator_common.h\"\n\nextern \"C\" void initQuasirandomGenerator(unsigned int table[QRNG_DIMENSIONS][QRNG_RESOLUTION]);\n\nextern \"C\" float getQuasirandomValue(unsigned int table[QRNG_DIMENSIONS][QRNG_RESOLUTION], int i, int dim);\n\nextern \"C\" double getQuasirandomValue63(INT64 i, int dim);\nextern \"C\" double MoroInvCNDcpu(unsigned int p);\n\nextern \"C\" void initTableGPU(unsigned int tableCPU[QRNG_DIMENSIONS][QRNG_RESOLUTION]);\nextern \"C\" void quasirandomGeneratorGPU(float *d_Output, unsigned int seed, unsigned int N);\nextern \"C\" void inverseCNDgpu(float *d_Output, unsigned int *d_Input, unsigned int N);\n\nconst int N = 1048576;\n\nint main(int argc, char **argv)\n{\n    printf(\"%s Starting...\\n\\n\", argv[0]);\n\n    unsigned int tableCPU[QRNG_DIMENSIONS][QRNG_RESOLUTION];\n\n    float *h_OutputGPU, *d_Output;\n\n    int    dim, pos;\n    double delta, ref, sumDelta, sumRef, L1norm, gpuTime;\n\n    StopWatchInterface *hTimer = NULL;\n\n    if (sizeof(INT64) != 8) {\n        printf(\"sizeof(INT64) != 8\\n\");\n        return 0;\n    }\n\n    sdkCreateTimer(&hTimer);\n\n    printf(\"Allocating GPU memory...\\n\");\n    checkCudaErrors(cudaMalloc((void **)&d_Output, QRNG_DIMENSIONS * N * sizeof(float)));\n\n    printf(\"Allocating CPU memory...\\n\");\n    h_OutputGPU = (float *)malloc(QRNG_DIMENSIONS * N * sizeof(float));\n\n    printf(\"Initializing QRNG tables...\\n\\n\");\n    initQuasirandomGenerator(tableCPU);\n\n    initTableGPU(tableCPU);\n\n    printf(\"Testing QRNG...\\n\\n\");\n    checkCudaErrors(cudaMemset(d_Output, 0, QRNG_DIMENSIONS * N * sizeof(float)));\n    int numIterations = 20;\n\n    for (int i = -1; i < numIterations; i++) {\n        if (i == 0) {\n            checkCudaErrors(cudaDeviceSynchronize());\n            sdkResetTimer(&hTimer);\n            sdkStartTimer(&hTimer);\n        }\n\n        quasirandomGeneratorGPU(d_Output, 0, N);\n    }\n\n    checkCudaErrors(cudaDeviceSynchronize());\n    sdkStopTimer(&hTimer);\n    gpuTime = sdkGetTimerValue(&hTimer) / (double)numIterations * 1e-3;\n    printf(\"quasirandomGenerator, Throughput = %.4f GNumbers/s, Time = %.5f s, Size \"\n           \"= %u Numbers, NumDevsUsed = %u, Workgroup = %u\\n\",\n           (double)QRNG_DIMENSIONS * (double)N * 1.0E-9 / gpuTime,\n           gpuTime,\n           QRNG_DIMENSIONS * N,\n           1,\n           128 * QRNG_DIMENSIONS);\n\n    printf(\"\\nReading GPU results...\\n\");\n    checkCudaErrors(cudaMemcpy(h_OutputGPU, d_Output, QRNG_DIMENSIONS * N * sizeof(float), cudaMemcpyDeviceToHost));\n\n    printf(\"Comparing to the CPU results...\\n\\n\");\n    sumDelta = 0;\n    sumRef   = 0;\n\n    for (dim = 0; dim < QRNG_DIMENSIONS; dim++)\n        for (pos = 0; pos < N; pos++) {\n            ref   = getQuasirandomValue63(pos, dim);\n            delta = (double)h_OutputGPU[dim * N + pos] - ref;\n            sumDelta += fabs(delta);\n            sumRef += fabs(ref);\n        }\n\n    printf(\"L1 norm: %E\\n\", sumDelta / sumRef);\n\n    printf(\"\\nTesting inverseCNDgpu()...\\n\\n\");\n    checkCudaErrors(cudaMemset(d_Output, 0, QRNG_DIMENSIONS * N * sizeof(float)));\n\n    for (int i = -1; i < numIterations; i++) {\n        if (i == 0) {\n            checkCudaErrors(cudaDeviceSynchronize());\n            sdkResetTimer(&hTimer);\n            sdkStartTimer(&hTimer);\n        }\n\n        inverseCNDgpu(d_Output, NULL, QRNG_DIMENSIONS * N);\n    }\n\n    checkCudaErrors(cudaDeviceSynchronize());\n    sdkStopTimer(&hTimer);\n    gpuTime = sdkGetTimerValue(&hTimer) / (double)numIterations * 1e-3;\n    printf(\"quasirandomGenerator-inverse, Throughput = %.4f GNumbers/s, Time = %.5f \"\n           \"s, Size = %u Numbers, NumDevsUsed = %u, Workgroup = %u\\n\",\n           (double)QRNG_DIMENSIONS * (double)N * 1E-9 / gpuTime,\n           gpuTime,\n           QRNG_DIMENSIONS * N,\n           1,\n           128);\n\n    printf(\"Reading GPU results...\\n\");\n    checkCudaErrors(cudaMemcpy(h_OutputGPU, d_Output, QRNG_DIMENSIONS * N * sizeof(float), cudaMemcpyDeviceToHost));\n\n    printf(\"\\nComparing to the CPU results...\\n\");\n    sumDelta              = 0;\n    sumRef                = 0;\n    unsigned int distance = ((unsigned int)-1) / (QRNG_DIMENSIONS * N + 1);\n\n    for (pos = 0; pos < QRNG_DIMENSIONS * N; pos++) {\n        unsigned int d = (pos + 1) * distance;\n        ref            = MoroInvCNDcpu(d);\n        delta          = (double)h_OutputGPU[pos] - ref;\n        sumDelta += fabs(delta);\n        sumRef += fabs(ref);\n    }\n\n    printf(\"L1 norm: %E\\n\\n\", L1norm = sumDelta / sumRef);\n\n    printf(\"Shutting down...\\n\");\n    sdkDeleteTimer(&hTimer);\n    free(h_OutputGPU);\n    checkCudaErrors(cudaFree(d_Output));\n\n    exit(L1norm < 1e-6 ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n"}, "code_dirs": {"quasirandomGenerator_kernel.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/quasirandomGenerator", "quasirandomGenerator.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/quasirandomGenerator"}}
{"kernel_name": "quasirandomGenerator", "parallel_api": "ocl", "code": {"QuasirandomGenerator.cl": "\n#define QRNG_DIMENSIONS 3\n#define QRNG_RESOLUTION 31\n#define INT_SCALE (1.0f / (float)0x80000001U)\n\n__kernel void QuasirandomGenerator(__global float *d_Output,\n                                   __constant unsigned int *c_Table,\n\t\t\t\t                   unsigned int seed,\n\t\t\t\t                   unsigned int N)\n{\n    unsigned int globalID_x   = get_global_id(0);\n    unsigned int localID_y    = get_local_id(1);\n    unsigned int globalSize_x = get_global_size(0);\n \n    for (unsigned int pos = globalID_x; pos < N; pos += globalSize_x) {\n        unsigned int result = 0;\n        unsigned int data = seed + pos;\n\n        for(int bit = 0; bit < QRNG_RESOLUTION; bit++, data >>= 1)\n            if(data & 1) result ^= c_Table[bit+localID_y*QRNG_RESOLUTION];\n\n        d_Output[mul24(localID_y,N) + pos] = (float)(result + 1) * INT_SCALE;\n    }\n}\n\nfloat MoroInvCNDgpu(unsigned int x)\n{\n    const float a1 = 2.50662823884f;\n    const float a2 = -18.61500062529f;\n    const float a3 = 41.39119773534f;\n    const float a4 = -25.44106049637f;\n    const float b1 = -8.4735109309f;\n    const float b2 = 23.08336743743f;\n    const float b3 = -21.06224101826f;\n    const float b4 = 3.13082909833f;\n    const float c1 = 0.337475482272615f;\n    const float c2 = 0.976169019091719f;\n    const float c3 = 0.160797971491821f;\n    const float c4 = 2.76438810333863E-02f;\n    const float c5 = 3.8405729373609E-03f;\n    const float c6 = 3.951896511919E-04f;\n    const float c7 = 3.21767881768E-05f;\n    const float c8 = 2.888167364E-07f;\n    const float c9 = 3.960315187E-07f;\n\n    float z;\n\n    bool negate = false;\n    \n    if (x >= 0x80000000UL)\n    {\n        x = 0xffffffffUL - x;\n        negate = true;\n    }\n\n    const float x1 = 1.0f / (float)0xffffffffUL;\n    const float x2 = x1 / 2.0f;\n    float p1 = x * x1 + x2;\n    float p2 = p1 - 0.5f;\n\n    if (p2 > -0.42f)\n    {\n        z = p2 * p2;\n        z = p2 * (((a4 * z + a3) * z + a2) * z + a1) / ((((b4 * z + b3) * z + b2) * z + b1) * z + 1.0f);\n    }\n    // Special case (Chebychev) for tail\n    else\n    {\n        z = log(-log(p1));\n        z = - (c1 + z * (c2 + z * (c3 + z * (c4 + z * (c5 + z * (c6 + z * (c7 + z * (c8 + z * c9))))))));\n    }\n\n    return negate ? -z : z;\n}\n\n__kernel void InverseCND(__global float *d_Output,\n\t                     const unsigned int pathN,\n                         const unsigned int iDevice,\n                         const unsigned int nDevice)\n{\n    const unsigned int distance = ((unsigned int)-1) / (pathN * nDevice + 1);\n    const unsigned int globalID   = get_global_id(0);\n    const unsigned int globalSize = get_global_size(0);\n\n    for(unsigned int pos = globalID; pos < pathN; pos += globalSize){\n        unsigned int d = (iDevice*pathN + pos + 1) * distance;\n        d_Output[pos] = MoroInvCNDgpu(d);\n    }\n}\n", "oclQuasirandomGenerator.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n\n#include \"oclQuasirandomGenerator_common.h\"\n\n// forward declarations\nextern \"C\" void initQuasirandomGenerator(\n    unsigned int table[QRNG_DIMENSIONS][QRNG_RESOLUTION]\n    );\nextern \"C\" double getQuasirandomValue63(INT64 i, int dim);\nextern \"C\" double MoroInvCNDcpu(unsigned int x);\n\n// OpenCL wrappers\nvoid QuasirandomGeneratorGPU(cl_command_queue cqCommandQueue,\n\t\t\t                 cl_kernel ckQuasirandomGenerator,\n                             cl_mem d_Output,\n                             cl_mem c_Table,\n                             unsigned int seed,\n                             unsigned int N,\n                             size_t szWgXDim);\nvoid InverseCNDGPU(cl_command_queue cqCommandQueue, \n\t\t   cl_kernel ckInverseCNDGPU, \n\t\t   cl_mem d_Output, \n\t\t   unsigned int pathN,\n           unsigned int iDevice,\n           unsigned int nDevice,\n           size_t szWgXDim);\n\n// size of output random array\nunsigned int N = 1048576;\n\nint main(int argc, const char **argv)\n{\n    cl_context cxGPUContext;                          // OpenCL context\n    cl_command_queue cqCommandQueue[MAX_GPU_COUNT];   // OpenCL command que\n    cl_platform_id cpPlatform;                        // OpenCL platform\n    cl_uint nDevice;                                  // OpenCL device count\n    cl_device_id *cdDevices;                          // OpenCL device list    \n    cl_program cpProgram;                             // OpenCL program\n    cl_kernel ckQuasirandomGenerator, ckInverseCNDGPU;// OpenCL kernel\n    cl_mem *d_Output, *c_Table;                       // OpenCL buffers\n    float *h_OutputGPU;\n    cl_int ciErr;                                     // Error code var\n    unsigned int dim, pos;\n    double delta, ref, sumDelta, sumRef, L1norm;\n    unsigned int tableCPU[QRNG_DIMENSIONS][QRNG_RESOLUTION];\n    bool bPassFlag = false;\n\n    shrQAStart(argc, (char **)argv);\n\n    // Start logs \n    shrSetLogFileName(\"oclQuasirandomGenerator.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    //Get the NVIDIA platform\n    shrLog(\"clGetPlatformID...\\n\"); \n    ciErr = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n\n    //Get the devices\n    shrLog(\"clGetDeviceIDs...\\n\"); \n    ciErr = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &nDevice);\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n    cdDevices = (cl_device_id *)malloc(nDevice * sizeof(cl_device_id) );\n    ciErr = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, nDevice, cdDevices, NULL);\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n\n    //Create the context\n    shrLog(\"clCreateContext...\\n\"); \n    cxGPUContext = clCreateContext(0, nDevice, cdDevices, NULL, NULL, &ciErr);\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n    \n    cl_uint id_device;\n    if(shrGetCmdLineArgumentu(argc, argv, \"device\", &id_device)) // Set up command queue(s) for GPU specified on the command line\n    {\n\t\tif( id_device >= nDevice || id_device < 0 ) {\n\t\t\tshrLog(\"Invalid Device %u\\n\", id_device);\n\t\t\tshrEXIT(argc, argv);\n\t\t}\n        // get & log device index # and name\n        cdDevices[0] = cdDevices[id_device];\n\n        // create a command que\n        cqCommandQueue[0] = clCreateCommandQueue(cxGPUContext, cdDevices[0], 0, &ciErr);\n        oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n        oclPrintDevInfo(LOGBOTH, cdDevices[0]);\n        nDevice = 1;   \n    }  \n    else \n    { // create command queues for all available devices        \n        for (cl_uint i = 0; i < nDevice; i++) \n        {\n            cqCommandQueue[i] = clCreateCommandQueue(cxGPUContext, cdDevices[i], 0, &ciErr);\n            oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n        }\n        for (cl_uint i = 0; i < nDevice; i++) oclPrintDevInfo(LOGBOTH, cdDevices[i]);\n    }\n\n    shrLog(\"\\nUsing %d GPU(s)...\\n\\n\", nDevice); \n\n    // adjust array size to be mutiple of N\n    N = nDevice*(N/nDevice);\n\n    shrLog(\"Allocate memory...\\n\"); \n    d_Output = (cl_mem*)malloc(nDevice*sizeof(cl_mem));\n    c_Table = (cl_mem*)malloc(nDevice*sizeof(cl_mem));\n    for (cl_uint i = 0; i < nDevice; i++)\n    {\n        d_Output[i] = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, QRNG_DIMENSIONS * N / nDevice * sizeof(cl_float), NULL, &ciErr);\n        oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n    }\n    h_OutputGPU = (float *)malloc(QRNG_DIMENSIONS * N * sizeof(cl_float));\n\n    shrLog(\"Initializing QRNG tables...\\n\");\n    initQuasirandomGenerator(tableCPU);\n    for (cl_uint i = 0; i < nDevice; i++)\n    {\n        c_Table[i] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, QRNG_DIMENSIONS * QRNG_RESOLUTION * sizeof(unsigned int), \n    \t\t     NULL, &ciErr);\n        ciErr |= ciErr;\n        ciErr |= clEnqueueWriteBuffer(cqCommandQueue[i], c_Table[i], CL_TRUE, 0, \n            QRNG_DIMENSIONS * QRNG_RESOLUTION * sizeof(unsigned int), tableCPU, 0, NULL, NULL);\n    }\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n\n    shrLog(\"Create and build program...\\n\");\n    size_t szKernelLength; // Byte size of kernel code\n    char *progSource = oclLoadProgSource(shrFindFilePath(\"QuasirandomGenerator.cl\", argv[0]), \"// My comment\\n\", &szKernelLength);\n\toclCheckErrorEX(progSource == NULL, false, NULL);\n\n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&progSource, &szKernelLength, &ciErr);\n    ciErr |= clBuildProgram(cpProgram, 0, NULL, NULL, NULL, NULL);\n    if (ciErr != CL_SUCCESS)\n    {\n        // write out standard error, Build Log and PTX, then cleanup and exit\n        shrLogEx(LOGBOTH | ERRORMSG, (double)ciErr, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"QuasirandomGenerator.ptx\");\n        oclCheckError(ciErr, CL_SUCCESS); \n    }\n\n    shrLog(\"Create QuasirandomGenerator kernel...\\n\"); \n    ckQuasirandomGenerator = clCreateKernel(cpProgram, \"QuasirandomGenerator\", &ciErr);\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL); \n\n    shrLog(\"Create InverseCND kernel...\\n\\n\"); \n    ckInverseCNDGPU = clCreateKernel(cpProgram, \"InverseCND\", &ciErr);\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL); \n\n    shrLog(\">>>Launch QuasirandomGenerator kernel...\\n\\n\"); \n\n    // determine work group sizes for each device\n\tsize_t* szWorkgroup = new size_t[nDevice]; \n\tfor (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n\t{\n        ciErr |= clGetKernelWorkGroupInfo(ckQuasirandomGenerator, cdDevices[iDevice], \n                                        CL_KERNEL_WORK_GROUP_SIZE, sizeof(size_t), &szWorkgroup[iDevice], NULL);\n      \n\t\tszWorkgroup[iDevice] = 64 * ((szWorkgroup[iDevice] / QRNG_DIMENSIONS)/64);\n    }\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n\n#ifdef GPU_PROFILING\n    int numIterations = 100;\n    for (int i = -1; i< numIterations; i++)\n    {\n\t\tif (i == 0)\n\t\t{\n\t\t\tfor (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n\t\t\t{\n\t\t\t\tclFinish(cqCommandQueue[iDevice]);\n\t\t\t}\n\t\t\tshrDeltaT(1);\n\t\t}\n#endif\n \n        for (cl_uint i = 0; i < nDevice; i++)\n        {\n            QuasirandomGeneratorGPU(cqCommandQueue[i], ckQuasirandomGenerator, d_Output[i], c_Table[i], 0, N/nDevice, szWorkgroup[i]);    \n        }\n\n#ifdef GPU_PROFILING\n    }\n    for (cl_uint i = 0; i < nDevice; i++)\n    {\n        clFinish(cqCommandQueue[i]);\n    }\n    double gpuTime = shrDeltaT(1)/(double)numIterations;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclQuasirandomGenerator, Throughput = %.4f GNumbers/s, Time = %.5f s, Size = %u Numbers, NumDevsUsed = %u, Workgroup = %u\\n\", \n           (double)QRNG_DIMENSIONS * (double)N * 1.0E-9 / gpuTime, gpuTime, QRNG_DIMENSIONS * N, nDevice, szWorkgroup[0]);\n#endif\n\n    shrLog(\"\\nRead back results...\\n\"); \n    int offset = 0;\n    for (cl_uint i = 0; i < nDevice; i++)\n    {\n        ciErr |= clEnqueueReadBuffer(cqCommandQueue[i], d_Output[i], CL_TRUE, 0, sizeof(cl_float) * QRNG_DIMENSIONS * N / nDevice, \n            h_OutputGPU + offset, 0, NULL, NULL);\n        offset += QRNG_DIMENSIONS * N / nDevice;\n    }\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL); \n\n    shrLog(\"Comparing to the CPU results...\\n\\n\");\n    sumDelta = 0;\n    sumRef   = 0;\n    for (cl_uint i = 0; i < nDevice; i++)\n    {\n        for(dim = 0; dim < QRNG_DIMENSIONS; dim++)\n        {\n            for(pos = 0; pos < N / nDevice; pos++) \n            {\n\t            ref       = getQuasirandomValue63(pos, dim);\n\t            delta     = (double)h_OutputGPU[i*QRNG_DIMENSIONS*N/nDevice + dim * N / nDevice + pos] - ref;\n\t            sumDelta += fabs(delta);\n\t            sumRef   += fabs(ref);\n\t        }\n        }\n    }\n    L1norm = sumDelta / sumRef;\n    shrLog(\"  L1 norm: %E\\n\", L1norm);\n    shrLog(\"  ckQuasirandomGenerator deviations %s Allowable Tolerance\\n\\n\\n\", (L1norm < 1e-6) ? \"WITHIN\" : \"ABOVE\");\n    bPassFlag = (L1norm < 1e-6);\n\n    shrLog(\">>>Launch InverseCND kernel...\\n\\n\"); \n\n    // determine work group sizes for each device\n\tfor (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n\t{\n        ciErr |= clGetKernelWorkGroupInfo(ckInverseCNDGPU, cdDevices[iDevice], \n                                        CL_KERNEL_WORK_GROUP_SIZE, sizeof(size_t), &szWorkgroup[iDevice], NULL);\n        if (szWorkgroup[iDevice] >= 128)\n        {\n            szWorkgroup[iDevice] = 128;\n        }\n        else\n        {\n            szWorkgroup[iDevice] = 64 * (szWorkgroup[iDevice] / 64);\n        }\n    }\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL);\n\n#ifdef GPU_PROFILING\n    for (int i = -1; i< numIterations; i++)\n    {\n\t\tif (i == 0) \n\t\t{\n\t\t\tfor (cl_uint iDevice = 0; iDevice < nDevice; iDevice++)\n\t\t\t{\n\t\t\t\tclFinish(cqCommandQueue[iDevice]);\n\t\t\t}\n\t\t\tshrDeltaT(1);\n\t\t}\n#endif\n        for (cl_uint i = 0; i < nDevice; i++)\n        {\n            InverseCNDGPU(cqCommandQueue[i], ckInverseCNDGPU, d_Output[i], QRNG_DIMENSIONS * N / nDevice, i, nDevice, szWorkgroup[i]);    \n        }\n#ifdef GPU_PROFILING\n    }\n\n\tfor (cl_uint i = 0; i < nDevice; i++)\n    {\n        clFinish(cqCommandQueue[i]);\n    }\n    gpuTime = shrDeltaT(1)/(double)numIterations;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclQuasirandomGenerator-inverse, Throughput = %.4f GNumbers/s, Time = %.5f s, Size = %u Numbers, NumDevsUsed = %u, Workgroup = %u\\n\", \n           (double)QRNG_DIMENSIONS * (double)N * 1.0E-9 / gpuTime, gpuTime, QRNG_DIMENSIONS * N, nDevice, szWorkgroup[0]);    \n#endif\n\n    shrLog(\"\\nRead back results...\\n\"); \n    offset = 0;\n    for (cl_uint i = 0; i < nDevice; i++)\n    {\n        ciErr |= clEnqueueReadBuffer(cqCommandQueue[i], d_Output[i], CL_TRUE, 0, \n            sizeof(cl_float) * QRNG_DIMENSIONS * N / nDevice, h_OutputGPU + offset, 0, NULL, NULL);\n        offset += QRNG_DIMENSIONS * N / nDevice;\n        oclCheckErrorEX(ciErr, CL_SUCCESS, NULL); \n    }\n\n    shrLog(\"Comparing to the CPU results...\\n\\n\");\n    sumDelta = 0;\n    sumRef   = 0;\n    unsigned int distance = ((unsigned int)-1) / (QRNG_DIMENSIONS * N + 1);\n    for(pos = 0; pos < QRNG_DIMENSIONS * N; pos++){\n        unsigned int d = (pos + 1) * distance;\n        ref       = MoroInvCNDcpu(d);\n        delta     = (double)h_OutputGPU[pos] - ref;\n        sumDelta += fabs(delta);\n        sumRef   += fabs(ref);\n    }\n    L1norm = sumDelta / sumRef;\n    shrLog(\"  L1 norm: %E\\n\", L1norm);\n    shrLog(\"  ckInverseCNDGPU deviations %s Allowable Tolerance\\n\\n\\n\", (L1norm < 1e-6) ? \"WITHIN\" : \"ABOVE\");\n    bPassFlag &= (L1norm < 1e-6);\n\n    // NOTE:  Most properly this should be done at any of the exit points above, but it is omitted elsewhere for clarity.\n    shrLog(\"Release CPU buffers and OpenCL objects...\\n\\n\"); \n    free(h_OutputGPU); \n    free(progSource);\n    free(cdDevices);\n    for (cl_uint i = 0; i < nDevice; i++)\n    {\n        clReleaseMemObject(d_Output[i]);\n        clReleaseMemObject(c_Table[i]);\n        clReleaseCommandQueue(cqCommandQueue[i]);\n    }\n    clReleaseKernel(ckQuasirandomGenerator);\n    clReleaseKernel(ckInverseCNDGPU);\n    clReleaseProgram(cpProgram);\n    clReleaseContext(cxGPUContext);\n    delete(szWorkgroup);\n\n    // finish\n    shrQAFinishExit(argc, (const char **)argv, bPassFlag ? QA_PASSED : QA_FAILED);\n\n    shrEXIT(argc, argv);\n}\n\nvoid QuasirandomGeneratorGPU(cl_command_queue cqCommandQueue,\n\t\t\t     cl_kernel ckQuasirandomGenerator,\n\t\t\t     cl_mem d_Output,\n\t\t\t     cl_mem c_Table,\n\t\t\t     unsigned int seed,\n\t\t\t     unsigned int N,\n                 size_t szWgXDim)\n{\n    cl_int ciErr;\n    size_t globalWorkSize[2] = {shrRoundUp(szWgXDim, 128*128), QRNG_DIMENSIONS};\n    size_t localWorkSize[2] = {szWgXDim, QRNG_DIMENSIONS};\n    \n    ciErr  = clSetKernelArg(ckQuasirandomGenerator, 0, sizeof(cl_mem),       (void*)&d_Output);\n    ciErr |= clSetKernelArg(ckQuasirandomGenerator, 1, sizeof(cl_mem),       (void*)&c_Table );\n    ciErr |= clSetKernelArg(ckQuasirandomGenerator, 2, sizeof(unsigned int), (void*)&seed    );\n    ciErr |= clSetKernelArg(ckQuasirandomGenerator, 3, sizeof(unsigned int), (void*)&N       );\n    ciErr |= clEnqueueNDRangeKernel(cqCommandQueue, ckQuasirandomGenerator, 2, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);  \n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL); \n}\n\nvoid InverseCNDGPU(cl_command_queue cqCommandQueue, \n\t\t   cl_kernel ckInverseCNDGPU, \n\t\t   cl_mem d_Output, \n\t\t   unsigned int pathN,\n           unsigned int iDevice,\n           unsigned int nDevice,\n           size_t szWgXDim)\n{\n    cl_int ciErr;\n    size_t globalWorkSize[1] = {shrRoundUp(szWgXDim, 128*128)};\n    size_t localWorkSize[1] = {szWgXDim};\n\n    ciErr  = clSetKernelArg(ckInverseCNDGPU, 0, sizeof(cl_mem),       (void*)&d_Output);\n    ciErr |= clSetKernelArg(ckInverseCNDGPU, 1, sizeof(unsigned int), (void*)&pathN   );\n    ciErr |= clSetKernelArg(ckInverseCNDGPU, 2, sizeof(unsigned int), (void*)&iDevice );\n    ciErr |= clSetKernelArg(ckInverseCNDGPU, 3, sizeof(unsigned int), (void*)&nDevice );\n    ciErr |= clEnqueueNDRangeKernel(cqCommandQueue, ckInverseCNDGPU, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL);\n    oclCheckErrorEX(ciErr, CL_SUCCESS, NULL); \n}\n"}, "code_dirs": {"QuasirandomGenerator.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclQuasirandomGenerator", "oclQuasirandomGenerator.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclQuasirandomGenerator"}}
{"kernel_name": "volumeRender", "parallel_api": "cuda", "code": {"volumeRender_kernel.cu": "#ifndef _VOLUMERENDER_KERNEL_CU_\n#define _VOLUMERENDER_KERNEL_CU_\n\n#include <helper_cuda.h>\n#include <helper_math.h>\n\ntypedef unsigned int  uint;\ntypedef unsigned char uchar;\n\ncudaArray *d_volumeArray = 0;\ncudaArray *d_transferFuncArray;\n\ntypedef unsigned char VolumeType;\n\ncudaTextureObject_t texObject;\ncudaTextureObject_t transferTex;\n\ntypedef struct\n{\n    float4 m[3];\n} float3x4;\n\n__constant__ float3x4 c_invViewMatrix;\n\nstruct Ray\n{\n    float3 o;\n    float3 d;\n};\n\n__device__ int intersectBox(Ray r, float3 boxmin, float3 boxmax, float *tnear, float *tfar)\n{\n    float3 invR = make_float3(1.0f) / r.d;\n    float3 tbot = invR * (boxmin - r.o);\n    float3 ttop = invR * (boxmax - r.o);\n\n    float3 tmin = fminf(ttop, tbot);\n    float3 tmax = fmaxf(ttop, tbot);\n\n    float largest_tmin  = fmaxf(fmaxf(tmin.x, tmin.y), fmaxf(tmin.x, tmin.z));\n    float smallest_tmax = fminf(fminf(tmax.x, tmax.y), fminf(tmax.x, tmax.z));\n\n    *tnear = largest_tmin;\n    *tfar  = smallest_tmax;\n\n    return smallest_tmax > largest_tmin;\n}\n\n__device__ float3 mul(const float3x4 &M, const float3 &v)\n{\n    float3 r;\n    r.x = dot(v, make_float3(M.m[0]));\n    r.y = dot(v, make_float3(M.m[1]));\n    r.z = dot(v, make_float3(M.m[2]));\n    return r;\n}\n\n__device__ float4 mul(const float3x4 &M, const float4 &v)\n{\n    float4 r;\n    r.x = dot(v, M.m[0]);\n    r.y = dot(v, M.m[1]);\n    r.z = dot(v, M.m[2]);\n    r.w = 1.0f;\n    return r;\n}\n\n__device__ uint rgbaFloatToInt(float4 rgba)\n{\n    rgba.x = __saturatef(rgba.x);\n    rgba.y = __saturatef(rgba.y);\n    rgba.z = __saturatef(rgba.z);\n    rgba.w = __saturatef(rgba.w);\n    return (uint(rgba.w * 255) << 24) | (uint(rgba.z * 255) << 16) | (uint(rgba.y * 255) << 8) | uint(rgba.x * 255);\n}\n\n__global__ void d_render(uint               *d_output,\n                         uint                imageW,\n                         uint                imageH,\n                         float               density,\n                         float               brightness,\n                         float               transferOffset,\n                         float               transferScale,\n                         cudaTextureObject_t tex,\n                         cudaTextureObject_t transferTex)\n{\n    const int    maxSteps         = 500;\n    const float  tstep            = 0.01f;\n    const float  opacityThreshold = 0.95f;\n    const float3 boxMin           = make_float3(-1.0f, -1.0f, -1.0f);\n    const float3 boxMax           = make_float3(1.0f, 1.0f, 1.0f);\n\n    uint x = blockIdx.x * blockDim.x + threadIdx.x;\n    uint y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if ((x >= imageW) || (y >= imageH))\n        return;\n\n    float u = (x / (float)imageW) * 2.0f - 1.0f;\n    float v = (y / (float)imageH) * 2.0f - 1.0f;\n\n    Ray eyeRay;\n    eyeRay.o = make_float3(mul(c_invViewMatrix, make_float4(0.0f, 0.0f, 0.0f, 1.0f)));\n    eyeRay.d = normalize(make_float3(u, v, -2.0f));\n    eyeRay.d = mul(c_invViewMatrix, eyeRay.d);\n\n    float tnear, tfar;\n    int   hit = intersectBox(eyeRay, boxMin, boxMax, &tnear, &tfar);\n\n    if (!hit)\n        return;\n\n    if (tnear < 0.0f)\n        tnear = 0.0f;\n\n    float4 sum  = make_float4(0.0f);\n    float  t    = tnear;\n    float3 pos  = eyeRay.o + eyeRay.d * tnear;\n    float3 step = eyeRay.d * tstep;\n\n    for (int i = 0; i < maxSteps; i++) {\n        float sample = tex3D<float>(tex, pos.x * 0.5f + 0.5f, pos.y * 0.5f + 0.5f, pos.z * 0.5f + 0.5f);\n\n        float4 col = tex1D<float4>(transferTex, (sample - transferOffset) * transferScale);\n        col.w *= density;\n\n        col.x *= col.w;\n        col.y *= col.w;\n        col.z *= col.w;\n        sum = sum + col * (1.0f - sum.w);\n\n        if (sum.w > opacityThreshold)\n            break;\n\n        t += tstep;\n\n        if (t > tfar)\n            break;\n\n        pos += step;\n    }\n\n    sum *= brightness;\n\n    d_output[y * imageW + x] = rgbaFloatToInt(sum);\n}\n\nextern \"C\" void setTextureFilterMode(bool bLinearFilter)\n{\n    if (texObject) {\n        checkCudaErrors(cudaDestroyTextureObject(texObject));\n    }\n    cudaResourceDesc texRes;\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = d_volumeArray;\n\n    cudaTextureDesc texDescr;\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = true;\n    texDescr.filterMode       = bLinearFilter ? cudaFilterModeLinear : cudaFilterModePoint;\n\n    texDescr.addressMode[0] = cudaAddressModeWrap;\n    texDescr.addressMode[1] = cudaAddressModeWrap;\n    texDescr.addressMode[2] = cudaAddressModeWrap;\n\n    texDescr.readMode = cudaReadModeNormalizedFloat;\n\n    checkCudaErrors(cudaCreateTextureObject(&texObject, &texRes, &texDescr, NULL));\n}\n\nextern \"C\" void initCuda(void *h_volume, cudaExtent volumeSize)\n{\n    cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc<VolumeType>();\n    checkCudaErrors(cudaMalloc3DArray(&d_volumeArray, &channelDesc, volumeSize));\n\n    cudaMemcpy3DParms copyParams = {0};\n    copyParams.srcPtr =\n        make_cudaPitchedPtr(h_volume, volumeSize.width * sizeof(VolumeType), volumeSize.width, volumeSize.height);\n    copyParams.dstArray = d_volumeArray;\n    copyParams.extent   = volumeSize;\n    copyParams.kind     = cudaMemcpyHostToDevice;\n    checkCudaErrors(cudaMemcpy3D(&copyParams));\n\n    cudaResourceDesc texRes;\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = d_volumeArray;\n\n    cudaTextureDesc texDescr;\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = true;\n    texDescr.filterMode       = cudaFilterModeLinear;\n\n    texDescr.addressMode[0] = cudaAddressModeClamp;\n    texDescr.addressMode[1] = cudaAddressModeClamp;\n    texDescr.addressMode[2] = cudaAddressModeClamp;\n\n    texDescr.readMode = cudaReadModeNormalizedFloat;\n\n    checkCudaErrors(cudaCreateTextureObject(&texObject, &texRes, &texDescr, NULL));\n\n    // create transfer function texture\n    float4 transferFunc[] = {\n        {\n            0.0,\n            0.0,\n            0.0,\n            0.0,\n        },\n        {\n            1.0,\n            0.0,\n            0.0,\n            1.0,\n        },\n        {\n            1.0,\n            0.5,\n            0.0,\n            1.0,\n        },\n        {\n            1.0,\n            1.0,\n            0.0,\n            1.0,\n        },\n        {\n            0.0,\n            1.0,\n            0.0,\n            1.0,\n        },\n        {\n            0.0,\n            1.0,\n            1.0,\n            1.0,\n        },\n        {\n            0.0,\n            0.0,\n            1.0,\n            1.0,\n        },\n        {\n            1.0,\n            0.0,\n            1.0,\n            1.0,\n        },\n        {\n            0.0,\n            0.0,\n            0.0,\n            0.0,\n        },\n    };\n\n    cudaChannelFormatDesc channelDesc2 = cudaCreateChannelDesc<float4>();\n    cudaArray            *d_transferFuncArray;\n    checkCudaErrors(cudaMallocArray(&d_transferFuncArray, &channelDesc2, sizeof(transferFunc) / sizeof(float4), 1));\n    checkCudaErrors(cudaMemcpy2DToArray(\n        d_transferFuncArray, 0, 0, transferFunc, 0, sizeof(transferFunc), 1, cudaMemcpyHostToDevice));\n\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = d_transferFuncArray;\n\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = true;\n    texDescr.filterMode       = cudaFilterModeLinear;\n\n    texDescr.addressMode[0] = cudaAddressModeClamp;\n\n    texDescr.readMode = cudaReadModeElementType;\n\n    checkCudaErrors(cudaCreateTextureObject(&transferTex, &texRes, &texDescr, NULL));\n}\n\nextern \"C\" void freeCudaBuffers()\n{\n    checkCudaErrors(cudaDestroyTextureObject(texObject));\n    checkCudaErrors(cudaDestroyTextureObject(transferTex));\n    checkCudaErrors(cudaFreeArray(d_volumeArray));\n    checkCudaErrors(cudaFreeArray(d_transferFuncArray));\n}\n\nextern \"C\" void render_kernel(dim3  gridSize,\n                              dim3  blockSize,\n                              uint *d_output,\n                              uint  imageW,\n                              uint  imageH,\n                              float density,\n                              float brightness,\n                              float transferOffset,\n                              float transferScale)\n{\n    d_render<<<gridSize, blockSize>>>(\n        d_output, imageW, imageH, density, brightness, transferOffset, transferScale, texObject, transferTex);\n}\n\nextern \"C\" void copyInvViewMatrix(float *invViewMatrix, size_t sizeofMatrix)\n{\n    checkCudaErrors(cudaMemcpyToSymbol(c_invViewMatrix, invViewMatrix, sizeofMatrix));\n}\n\n#endif // #ifndef _VOLUMERENDER_KERNEL_CU_\n", "volumeRender.cpp": "#include <helper_gl.h>\n#if defined(__APPLE__) || defined(MACOSX)\n#pragma clang diagnostic ignored \"-Wdeprecated-declarations\"\n#include <GLUT/glut.h>\n#ifndef glutCloseFunc\n#define glutCloseFunc glutWMCloseFunc\n#endif\n#else\n#include <GL/freeglut.h>\n#endif\n\n#include <cuda_gl_interop.h>\n#include <cuda_profiler_api.h>\n#include <cuda_runtime.h>\n#include <driver_functions.h>\n#include <vector_functions.h>\n#include <vector_types.h>\n\n#include <helper_cuda.h>\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n#include <helper_timer.h>\n\ntypedef unsigned int  uint;\ntypedef unsigned char uchar;\n\n#define MAX_EPSILON_ERROR 5.00f\n#define THRESHOLD         0.30f\n\nconst char *sOriginal[] = {\"volume.ppm\", NULL};\n\nconst char *sReference[] = {\"ref_volume.ppm\", NULL};\n\nconst char *sSDKsample = \"CUDA 3D Volume Render\";\n\nconst char           *volumeFilename = \"Bucky.raw\";\ncudaExtent            volumeSize     = make_cudaExtent(32, 32, 32);\ntypedef unsigned char VolumeType;\n\nuint width = 512, height = 512;\ndim3 blockSize(16, 16);\ndim3 gridSize;\n\nfloat3 viewRotation;\nfloat3 viewTranslation = make_float3(0.0, 0.0, -4.0f);\nfloat  invViewMatrix[12];\n\nfloat density         = 0.05f;\nfloat brightness      = 1.0f;\nfloat transferOffset  = 0.0f;\nfloat transferScale   = 1.0f;\nbool  linearFiltering = true;\n\nGLuint                       pbo = 0;\nGLuint                       tex = 0;\nstruct cudaGraphicsResource *cuda_pbo_resource;\n\nStopWatchInterface *timer = 0;\n\nconst int    frameCheckNumber = 2;\nint          fpsCount         = 0;\nint          fpsLimit         = 1;\nint          g_Index          = 0;\nunsigned int frameCount       = 0;\n\nint   *pArgc;\nchar **pArgv;\n\n#ifndef MAX\n#define MAX(a, b) ((a > b) ? a : b)\n#endif\n\nextern \"C\" void setTextureFilterMode(bool bLinearFilter);\nextern \"C\" void initCuda(void *h_volume, cudaExtent volumeSize);\nextern \"C\" void freeCudaBuffers();\nextern \"C\" void render_kernel(dim3  gridSize,\n                              dim3  blockSize,\n                              uint *d_output,\n                              uint  imageW,\n                              uint  imageH,\n                              float density,\n                              float brightness,\n                              float transferOffset,\n                              float transferScale);\nextern \"C\" void copyInvViewMatrix(float *invViewMatrix, size_t sizeofMatrix);\n\nvoid initPixelBuffer();\n\nvoid computeFPS()\n{\n    frameCount++;\n    fpsCount++;\n\n    if (fpsCount == fpsLimit) {\n        char  fps[256];\n        float ifps = 1.f / (sdkGetAverageTimerValue(&timer) / 1000.f);\n        sprintf(fps, \"Volume Render: %3.1f fps\", ifps);\n\n        glutSetWindowTitle(fps);\n        fpsCount = 0;\n\n        fpsLimit = (int)MAX(1.f, ifps);\n        sdkResetTimer(&timer);\n    }\n}\n\nvoid render()\n{\n    copyInvViewMatrix(invViewMatrix, sizeof(float4) * 3);\n\n    uint *d_output;\n    checkCudaErrors(cudaGraphicsMapResources(1, &cuda_pbo_resource, 0));\n    size_t num_bytes;\n    checkCudaErrors(cudaGraphicsResourceGetMappedPointer((void **)&d_output, &num_bytes, cuda_pbo_resource));\n\n    checkCudaErrors(cudaMemset(d_output, 0, width * height * 4));\n\n    render_kernel(gridSize, blockSize, d_output, width, height, density, brightness, transferOffset, transferScale);\n\n    getLastCudaError(\"kernel failed\");\n\n    checkCudaErrors(cudaGraphicsUnmapResources(1, &cuda_pbo_resource, 0));\n}\n\nvoid display()\n{\n    sdkStartTimer(&timer);\n\n    GLfloat modelView[16];\n    glMatrixMode(GL_MODELVIEW);\n    glPushMatrix();\n    glLoadIdentity();\n    glRotatef(-viewRotation.x, 1.0, 0.0, 0.0);\n    glRotatef(-viewRotation.y, 0.0, 1.0, 0.0);\n    glTranslatef(-viewTranslation.x, -viewTranslation.y, -viewTranslation.z);\n    glGetFloatv(GL_MODELVIEW_MATRIX, modelView);\n    glPopMatrix();\n\n    invViewMatrix[0]  = modelView[0];\n    invViewMatrix[1]  = modelView[4];\n    invViewMatrix[2]  = modelView[8];\n    invViewMatrix[3]  = modelView[12];\n    invViewMatrix[4]  = modelView[1];\n    invViewMatrix[5]  = modelView[5];\n    invViewMatrix[6]  = modelView[9];\n    invViewMatrix[7]  = modelView[13];\n    invViewMatrix[8]  = modelView[2];\n    invViewMatrix[9]  = modelView[6];\n    invViewMatrix[10] = modelView[10];\n    invViewMatrix[11] = modelView[14];\n\n    render();\n\n    glClear(GL_COLOR_BUFFER_BIT);\n\n    glDisable(GL_DEPTH_TEST);\n\n    glPixelStorei(GL_UNPACK_ALIGNMENT, 1);\n#if 0\n    glRasterPos2i(0, 0);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glDrawPixels(width, height, GL_RGBA, GL_UNSIGNED_BYTE, 0);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n#else\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glBindTexture(GL_TEXTURE_2D, tex);\n    glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, width, height, GL_RGBA, GL_UNSIGNED_BYTE, 0);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n    glEnable(GL_TEXTURE_2D);\n    glBegin(GL_QUADS);\n    glTexCoord2f(0, 0);\n    glVertex2f(0, 0);\n    glTexCoord2f(1, 0);\n    glVertex2f(1, 0);\n    glTexCoord2f(1, 1);\n    glVertex2f(1, 1);\n    glTexCoord2f(0, 1);\n    glVertex2f(0, 1);\n    glEnd();\n\n    glDisable(GL_TEXTURE_2D);\n    glBindTexture(GL_TEXTURE_2D, 0);\n#endif\n\n    glutSwapBuffers();\n    glutReportErrors();\n\n    sdkStopTimer(&timer);\n\n    computeFPS();\n}\n\nvoid idle() { glutPostRedisplay(); }\n\nvoid keyboard(unsigned char key, int x, int y)\n{\n    switch (key) {\n    case 27:\n#if defined(__APPLE__) || defined(MACOSX)\n        exit(EXIT_SUCCESS);\n#else\n        glutDestroyWindow(glutGetWindow());\n        return;\n#endif\n        break;\n\n    case 'f':\n        linearFiltering = !linearFiltering;\n        setTextureFilterMode(linearFiltering);\n        break;\n\n    case '+':\n        density += 0.01f;\n        break;\n\n    case '-':\n        density -= 0.01f;\n        break;\n\n    case ']':\n        brightness += 0.1f;\n        break;\n\n    case '[':\n        brightness -= 0.1f;\n        break;\n\n    case ';':\n        transferOffset += 0.01f;\n        break;\n\n    case '\\'':\n        transferOffset -= 0.01f;\n        break;\n\n    case '.':\n        transferScale += 0.01f;\n        break;\n\n    case ',':\n        transferScale -= 0.01f;\n        break;\n\n    default:\n        break;\n    }\n\n    printf(\"density = %.2f, brightness = %.2f, transferOffset = %.2f, transferScale \"\n           \"= %.2f\\n\",\n           density,\n           brightness,\n           transferOffset,\n           transferScale);\n    glutPostRedisplay();\n}\n\nint ox, oy;\nint buttonState = 0;\n\nvoid mouse(int button, int state, int x, int y)\n{\n    if (state == GLUT_DOWN) {\n        buttonState |= 1 << button;\n    }\n    else if (state == GLUT_UP) {\n        buttonState = 0;\n    }\n\n    ox = x;\n    oy = y;\n    glutPostRedisplay();\n}\n\nvoid motion(int x, int y)\n{\n    float dx, dy;\n    dx = (float)(x - ox);\n    dy = (float)(y - oy);\n\n    if (buttonState == 4) {\n        viewTranslation.z += dy / 100.0f;\n    }\n    else if (buttonState == 2) {\n        viewTranslation.x += dx / 100.0f;\n        viewTranslation.y -= dy / 100.0f;\n    }\n    else if (buttonState == 1) {\n        viewRotation.x += dy / 5.0f;\n        viewRotation.y += dx / 5.0f;\n    }\n\n    ox = x;\n    oy = y;\n    glutPostRedisplay();\n}\n\nint iDivUp(int a, int b) { return (a % b != 0) ? (a / b + 1) : (a / b); }\n\nvoid reshape(int w, int h)\n{\n    width  = w;\n    height = h;\n    initPixelBuffer();\n\n    gridSize = dim3(iDivUp(width, blockSize.x), iDivUp(height, blockSize.y));\n\n    glViewport(0, 0, w, h);\n\n    glMatrixMode(GL_MODELVIEW);\n    glLoadIdentity();\n\n    glMatrixMode(GL_PROJECTION);\n    glLoadIdentity();\n    glOrtho(0.0, 1.0, 0.0, 1.0, 0.0, 1.0);\n}\n\nvoid cleanup()\n{\n    sdkDeleteTimer(&timer);\n\n    freeCudaBuffers();\n\n    if (pbo) {\n        cudaGraphicsUnregisterResource(cuda_pbo_resource);\n        glDeleteBuffers(1, &pbo);\n        glDeleteTextures(1, &tex);\n    }\n    checkCudaErrors(cudaProfilerStop());\n}\n\nvoid initGL(int *argc, char **argv)\n{\n    glutInit(argc, argv);\n    glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE);\n    glutInitWindowSize(width, height);\n    glutCreateWindow(\"CUDA volume rendering\");\n\n    if (!isGLVersionSupported(2, 0) || !areGLExtensionsSupported(\"GL_ARB_pixel_buffer_object\")) {\n        printf(\"Required OpenGL extensions are missing.\");\n        exit(EXIT_SUCCESS);\n    }\n}\n\nvoid initPixelBuffer()\n{\n    if (pbo) {\n        checkCudaErrors(cudaGraphicsUnregisterResource(cuda_pbo_resource));\n\n        glDeleteBuffers(1, &pbo);\n        glDeleteTextures(1, &tex);\n    }\n\n    glGenBuffers(1, &pbo);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glBufferData(GL_PIXEL_UNPACK_BUFFER_ARB, width * height * sizeof(GLubyte) * 4, 0, GL_STREAM_DRAW_ARB);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n    checkCudaErrors(cudaGraphicsGLRegisterBuffer(&cuda_pbo_resource, pbo, cudaGraphicsMapFlagsWriteDiscard));\n\n    glGenTextures(1, &tex);\n    glBindTexture(GL_TEXTURE_2D, tex);\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, width, height, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n    glBindTexture(GL_TEXTURE_2D, 0);\n}\n\nvoid *loadRawFile(char *filename, size_t size)\n{\n    FILE *fp = fopen(filename, \"rb\");\n\n    if (!fp) {\n        fprintf(stderr, \"Error opening file '%s'\\n\", filename);\n        return 0;\n    }\n\n    void  *data = malloc(size);\n    size_t read = fread(data, 1, size, fp);\n    fclose(fp);\n\n#if defined(_MSC_VER_)\n    printf(\"Read '%s', %Iu bytes\\n\", filename, read);\n#else\n    printf(\"Read '%s', %zu bytes\\n\", filename, read);\n#endif\n\n    return data;\n}\n\nvoid runSingleTest(const char *ref_file, const char *exec_path)\n{\n    bool bTestResult = true;\n\n    uint *d_output;\n    checkCudaErrors(cudaMalloc((void **)&d_output, width * height * sizeof(uint)));\n    checkCudaErrors(cudaMemset(d_output, 0, width * height * sizeof(uint)));\n\n    float modelView[16] = {\n        1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f, 4.0f, 1.0f};\n\n    invViewMatrix[0]  = modelView[0];\n    invViewMatrix[1]  = modelView[4];\n    invViewMatrix[2]  = modelView[8];\n    invViewMatrix[3]  = modelView[12];\n    invViewMatrix[4]  = modelView[1];\n    invViewMatrix[5]  = modelView[5];\n    invViewMatrix[6]  = modelView[9];\n    invViewMatrix[7]  = modelView[13];\n    invViewMatrix[8]  = modelView[2];\n    invViewMatrix[9]  = modelView[6];\n    invViewMatrix[10] = modelView[10];\n    invViewMatrix[11] = modelView[14];\n\n    copyInvViewMatrix(invViewMatrix, sizeof(float4) * 3);\n\n    int nIter = 10;\n\n    for (int i = -1; i < nIter; i++) {\n        if (i == 0) {\n            cudaDeviceSynchronize();\n            sdkStartTimer(&timer);\n        }\n\n        render_kernel(gridSize, blockSize, d_output, width, height, density, brightness, transferOffset, transferScale);\n    }\n\n    cudaDeviceSynchronize();\n    sdkStopTimer(&timer);\n\n    double dAvgTime = sdkGetTimerValue(&timer) / (nIter * 1000.0);\n    printf(\"volumeRender, Throughput = %.4f MTexels/s, Time = %.5f s, Size = %u \"\n           \"Texels, NumDevsUsed = %u, Workgroup = %u\\n\",\n           (1.0e-6 * width * height) / dAvgTime,\n           dAvgTime,\n           (width * height),\n           1,\n           blockSize.x * blockSize.y);\n\n    getLastCudaError(\"Error: render_kernel() execution FAILED\");\n    checkCudaErrors(cudaDeviceSynchronize());\n\n    unsigned char *h_output = (unsigned char *)malloc(width * height * 4);\n    checkCudaErrors(cudaMemcpy(h_output, d_output, width * height * 4, cudaMemcpyDeviceToHost));\n\n    sdkSavePPM4ub(\"volume.ppm\", h_output, width, height);\n    bTestResult = sdkComparePPM(\"volume.ppm\", sdkFindFilePath(ref_file, exec_path), MAX_EPSILON_ERROR, THRESHOLD, true);\n\n    cudaFree(d_output);\n    free(h_output);\n    cleanup();\n\n    exit(bTestResult ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n\nint main(int argc, char **argv)\n{\n    pArgc = &argc;\n    pArgv = argv;\n\n    char *ref_file = NULL;\n\n#if defined(__linux__)\n    setenv(\"DISPLAY\", \":0\", 0);\n#endif\n\n    printf(\"%s Starting...\\n\\n\", sSDKsample);\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"file\")) {\n        getCmdLineArgumentString(argc, (const char **)argv, \"file\", &ref_file);\n        fpsLimit = frameCheckNumber;\n    }\n\n    if (ref_file) {\n        findCudaDevice(argc, (const char **)argv);\n    }\n    else {\n        initGL(&argc, argv);\n\n        findCudaDevice(argc, (const char **)argv);\n    }\n\n    char *filename;\n\n    if (getCmdLineArgumentString(argc, (const char **)argv, \"volume\", &filename)) {\n        volumeFilename = filename;\n    }\n\n    int n;\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"size\")) {\n        n                = getCmdLineArgumentInt(argc, (const char **)argv, \"size\");\n        volumeSize.width = volumeSize.height = volumeSize.depth = n;\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"xsize\")) {\n        n                = getCmdLineArgumentInt(argc, (const char **)argv, \"xsize\");\n        volumeSize.width = n;\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"ysize\")) {\n        n                 = getCmdLineArgumentInt(argc, (const char **)argv, \"ysize\");\n        volumeSize.height = n;\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"zsize\")) {\n        n                = getCmdLineArgumentInt(argc, (const char **)argv, \"zsize\");\n        volumeSize.depth = n;\n    }\n\n    char *path = sdkFindFilePath(volumeFilename, argv[0]);\n\n    if (path == 0) {\n        printf(\"Error finding file '%s'\\n\", volumeFilename);\n        exit(EXIT_FAILURE);\n    }\n\n    size_t size     = volumeSize.width * volumeSize.height * volumeSize.depth * sizeof(VolumeType);\n    void  *h_volume = loadRawFile(path, size);\n\n    initCuda(h_volume, volumeSize);\n    free(h_volume);\n\n    sdkCreateTimer(&timer);\n\n    printf(\"Press '+' and '-' to change density (0.01 increments)\\n\"\n           \"      ']' and '[' to change brightness\\n\"\n           \"      ';' and ''' to modify transfer function offset\\n\"\n           \"      '.' and ',' to modify transfer function scale\\n\\n\");\n\n    gridSize = dim3(iDivUp(width, blockSize.x), iDivUp(height, blockSize.y));\n\n    if (ref_file) {\n        runSingleTest(ref_file, argv[0]);\n    }\n    else {\n        glutDisplayFunc(display);\n        glutKeyboardFunc(keyboard);\n        glutMouseFunc(mouse);\n        glutMotionFunc(motion);\n        glutReshapeFunc(reshape);\n        glutIdleFunc(idle);\n\n        initPixelBuffer();\n\n#if defined(__APPLE__) || defined(MACOSX)\n        atexit(cleanup);\n#else\n        glutCloseFunc(cleanup);\n#endif\n\n        glutMainLoop();\n    }\n}\n"}, "code_dirs": {"volumeRender_kernel.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/volumeRender", "volumeRender.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/volumeRender"}}
{"kernel_name": "volumeRender", "parallel_api": "ocl", "code": {"volumeRender.cl": "#define maxSteps 500\n#define tstep 0.01f\n\nint intersectBox(float4 r_o, float4 r_d, float4 boxmin, float4 boxmax, float *tnear, float *tfar)\n{\n    // compute intersection of ray with all six bbox planes\n    float4 invR = (float4)(1.0f,1.0f,1.0f,1.0f) / r_d;\n    float4 tbot = invR * (boxmin - r_o);\n    float4 ttop = invR * (boxmax - r_o);\n\n    // re-order intersections to find smallest and largest on each axis\n    float4 tmin = min(ttop, tbot);\n    float4 tmax = max(ttop, tbot);\n\n    // find the largest tmin and the smallest tmax\n    float largest_tmin = max(max(tmin.x, tmin.y), max(tmin.x, tmin.z));\n    float smallest_tmax = min(min(tmax.x, tmax.y), min(tmax.x, tmax.z));\n\n\t*tnear = largest_tmin;\n\t*tfar = smallest_tmax;\n\n\treturn smallest_tmax > largest_tmin;\n}\n\nuint rgbaFloatToInt(float4 rgba)\n{\n    rgba.x = clamp(rgba.x,0.0f,1.0f);  \n    rgba.y = clamp(rgba.y,0.0f,1.0f);  \n    rgba.z = clamp(rgba.z,0.0f,1.0f);  \n    rgba.w = clamp(rgba.w,0.0f,1.0f);  \n    return ((uint)(rgba.w*255.0f)<<24) | ((uint)(rgba.z*255.0f)<<16) | ((uint)(rgba.y*255.0f)<<8) | (uint)(rgba.x*255.0f);\n}\n\n__kernel void\nd_render(__global uint *d_output, \n         uint imageW, uint imageH,\n         float density, float brightness,\n         float transferOffset, float transferScale,\n         __constant float* invViewMatrix\n #ifdef IMAGE_SUPPORT\n          ,__read_only image3d_t volume,\n          __read_only image2d_t transferFunc,\n          sampler_t volumeSampler,\n          sampler_t transferFuncSampler\n #endif\n         )\n\n{\t\n    uint x = get_global_id(0);\n    uint y = get_global_id(1);\n\n    float u = (x / (float) imageW)*2.0f-1.0f;\n    float v = (y / (float) imageH)*2.0f-1.0f;\n\n    //float tstep = 0.01f;\n    float4 boxMin = (float4)(-1.0f, -1.0f, -1.0f,1.0f);\n    float4 boxMax = (float4)(1.0f, 1.0f, 1.0f,1.0f);\n\n    // calculate eye ray in world space\n    float4 eyeRay_o;\n    float4 eyeRay_d;\n\n    eyeRay_o = (float4)(invViewMatrix[3], invViewMatrix[7], invViewMatrix[11], 1.0f);   \n\n    float4 temp = normalize(((float4)(u, v, -2.0f,0.0f)));\n    eyeRay_d.x = dot(temp, ((float4)(invViewMatrix[0],invViewMatrix[1],invViewMatrix[2],invViewMatrix[3])));\n    eyeRay_d.y = dot(temp, ((float4)(invViewMatrix[4],invViewMatrix[5],invViewMatrix[6],invViewMatrix[7])));\n    eyeRay_d.z = dot(temp, ((float4)(invViewMatrix[8],invViewMatrix[9],invViewMatrix[10],invViewMatrix[11])));\n    eyeRay_d.w = 0.0f;\n\n    // find intersection with box\n\tfloat tnear, tfar;\n\tint hit = intersectBox(eyeRay_o, eyeRay_d, boxMin, boxMax, &tnear, &tfar);\n    if (!hit) {\n        if ((x < imageW) && (y < imageH)) {\n            // write output color\n            uint i =(y * imageW) + x;\n            d_output[i] = 0;\n        }\n        return;\n    }\n\tif (tnear < 0.0f) tnear = 0.0f;     // clamp to near plane\n\n    // march along ray from back to front, accumulating color\n    temp = (float4)(0.0f,0.0f,0.0f,0.0f);\n    float t = tfar;\n\n    for(uint i=0; i<maxSteps; i++) {\t\t\n        float4 pos = eyeRay_o + eyeRay_d*t;\n        pos = pos*0.5f+0.5f;    // map position to [0, 1] coordinates\n\n        // read from 3D texture        \n#ifdef IMAGE_SUPPORT        \n        float4 sample = read_imagef(volume, volumeSampler, pos);\n        \n        // lookup in transfer function texture\n        float2 transfer_pos = (float2)((sample.x-transferOffset)*transferScale, 0.5f);\n        float4 col = read_imagef(transferFunc, transferFuncSampler, transfer_pos);\n#else\n        float4 col = (float4)(pos.x,pos.y,pos.z,.25f);\n#endif\n\n\n        // accumulate result\n        float a = col.w*density;\n        temp = mix(temp, col, (float4)(a, a, a, a));\n\n        t -= tstep;\n        if (t < tnear) break;\n    }\n    temp *= brightness;\n\n    if ((x < imageW) && (y < imageH)) {\n        // write output color\n        uint i =(y * imageW) + x;\n        d_output[i] = rgbaFloatToInt(temp);\n    }\n}\n\n", "oclVolumeRender.cpp": "#include <GL/glew.h>\n#if defined(__APPLE__) || defined(__MACOSX)\n    #include <OpenGL/OpenGL.h>\n    #include <GLUT/glut.h>\n#else\n    #include <GL/freeglut.h>\n    #ifdef UNIX\n       #include <GL/glx.h>\n    #endif\n#endif\n\n// Includes\n#include <iostream>\n#include <string>\n\n// Utilities, OpenCL and system includes\n#include <oclUtils.h>\n#include <shrQATest.h>\n\n#if defined (__APPLE__) || defined(MACOSX)\n   #define GL_SHARING_EXTENSION \"cl_APPLE_gl_sharing\"\n#else\n   #define GL_SHARING_EXTENSION \"cl_khr_gl_sharing\"\n#endif\n\n#define REFRESH_DELAY\t  10 //ms\n\nint *pArgc = NULL;\nchar **pArgv = NULL;\n\ntypedef unsigned int uint;\ntypedef unsigned char uchar;\n\nconst char *volumeFilename = \"Bucky.raw\";\nsize_t volumeSize[3] = {32, 32, 32};\n\nuint width = 512, height = 512;\nsize_t gridSize[2] = {width, height};\n\n#define LOCAL_SIZE_X 16\n#define LOCAL_SIZE_Y 16\n\nfloat viewRotation[3];\nfloat viewTranslation[3] = {0.0, 0.0, -4.0f};\nfloat invViewMatrix[12];\n\nfloat density = 0.05f;\nfloat brightness = 1.0f;\nfloat transferOffset = 0.0f;\nfloat transferScale = 1.0f;\nbool linearFiltering = true;\n\nGLuint pbo = 0;                 // OpenGL pixel buffer object\nint iGLUTWindowHandle;          // handle to the GLUT window\n\n// OpenCL vars\ncl_platform_id cpPlatform;\ncl_uint uiNumDevices;\ncl_device_id* cdDevices;\ncl_uint uiDeviceUsed;\ncl_uint uiDevCount;\ncl_context cxGPUContext;\ncl_device_id device;\ncl_command_queue cqCommandQueue;\ncl_program cpProgram;\ncl_kernel ckKernel;\ncl_int ciErrNum;\ncl_mem pbo_cl;\ncl_mem d_volumeArray;\ncl_mem d_transferFuncArray;\ncl_mem d_invViewMatrix;\nchar* cPathAndName = NULL;          // var for full paths to data, src, etc.\nchar* cSourceCL;                    // Buffer to hold source for compilation \nconst char* cExecutableName = NULL;\ncl_bool g_bImageSupport;\ncl_sampler volumeSamplerLinear;\ncl_sampler volumeSamplerNearest;\ncl_sampler transferFuncSampler;\ncl_bool g_glInterop = false;\n\nint iFrameCount = 0;                // FPS count for averaging\nint iFrameTrigger = 20;             // FPS trigger for sampling\nint iFramesPerSec = 0;              // frames per second\nint iTestSets = 3;\nint g_Index = 0;\nshrBOOL bNoPrompt = shrFALSE;\t\t// false = normal GL loop, true = Finite period of GL loop (a few seconds)\nshrBOOL bQATest = shrFALSE;\t\t\t// false = normal GL loop, true = run No-GL test sequence  \nbool g_bFBODisplay = false;\nint ox, oy;                         // mouse location vars\nint buttonState = 0;                \n\nvoid initPixelBuffer();\nvoid render();\nvoid createCLContext(int argc, const char** argv);\nvoid initCLVolume(uchar *h_volume);\n\nvoid InitGL(int* argc, char** argv);\nvoid DisplayGL();\nvoid Reshape(int w, int h);\nvoid Idle(void);\nvoid KeyboardGL(unsigned char key, int x, int y);\nvoid timerEvent(int value);\nvoid motion(int x, int y);\nvoid mouse(int button, int state, int x, int y);\n\nvoid Cleanup(int iExitCode);\nvoid (*pCleanup)(int) = &Cleanup;\nvoid TestNoGL();\n\nint main(int argc, char** argv) \n{\n\tpArgc = &argc;\n\tpArgv = argv;\n\n\tshrQAStart(argc, argv);\n\n    // start logs\n\tcExecutableName = argv[0];\n    shrSetLogFileName (\"oclVolumeRender.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n    shrLog(\"Press <f> to toggle filtering ON/OFF\\n\"\n\t\t                 \"       '-' and '+' to change density (0.01 increments)\\n\"\n                         \"       ']' and '[' to change brightness\\n\"\n                         \"       ';' and ''' to modify transfer function offset\\n\"\n                         \"       '.' and ',' to modify transfer function scale\\n\\n\");\n\n    // get command line arg for quick test, if provided\n    // process command line arguments\n    if (argc > 1) \n    {\n        bQATest = shrCheckCmdLineFlag(argc, (const char**)argv, \"qatest\");\n        bNoPrompt = shrCheckCmdLineFlag(argc, (const char**)argv, \"noprompt\");\n    }\n\n    // First initialize OpenGL context, so we can properly setup the OpenGL / OpenCL interop.\n    if(!bQATest) \n    {\n        InitGL(&argc, argv); \n    }\n\n    // Create OpenCL context, get device info, select device, select options for image/texture and CL-GL interop\n    createCLContext(argc, (const char**)argv);\n\n    // Print device info\n    clGetDeviceInfo(cdDevices[uiDeviceUsed], CL_DEVICE_IMAGE_SUPPORT, sizeof(g_bImageSupport), &g_bImageSupport, NULL);\n    shrLog(\"%s...\\n\\n\", g_bImageSupport ? \"Using Image (Texture)\" : \"No Image (Texuture) Support\");      \n    shrLog(\"Detailed Device info:\\n\\n\");\n    oclPrintDevInfo(LOGBOTH, cdDevices[uiDeviceUsed]);\n\n    // create a command-queue\n    cqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevices[uiDeviceUsed], 0, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Program Setup\n    size_t program_length;\n    cPathAndName = shrFindFilePath(\"volumeRender.cl\", argv[0]);\n    oclCheckErrorEX(cPathAndName != NULL, shrTRUE, pCleanup);\n    cSourceCL = oclLoadProgSource(cPathAndName, \"\", &program_length);\n    oclCheckErrorEX(cSourceCL != NULL, shrTRUE, pCleanup);\n\n    // create the program\n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1,\n\t\t\t\t\t  (const char **)&cSourceCL, &program_length, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    \n    // build the program\n    std::string buildOpts = \"-cl-fast-relaxed-math\";\n    buildOpts += g_bImageSupport ? \" -DIMAGE_SUPPORT\" : \"\";\n    ciErrNum = clBuildProgram(cpProgram, 0, NULL, buildOpts.c_str(), NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        // write out standard error, Build Log and PTX, then cleanup and return error\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclVolumeRender.ptx\");\n        Cleanup(EXIT_FAILURE); \n    }\n\n    // create the kernel\n    ckKernel = clCreateKernel(cpProgram, \"d_render\", &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // parse arguments\n    char *filename;\n    if (shrGetCmdLineArgumentstr(argc, (const char**)argv, \"file\", &filename)) {\n        volumeFilename = filename;\n    }\n    int n;\n    if (shrGetCmdLineArgumenti(argc, (const char**)argv, \"size\", &n)) {\n        volumeSize[0] = volumeSize[1] = volumeSize[2] = n;\n    }\n    if (shrGetCmdLineArgumenti(argc, (const char**)argv, \"xsize\", &n)) {\n        volumeSize[0] = n;\n    }\n    if (shrGetCmdLineArgumenti(argc, (const char**)argv, \"ysize\", &n)) {\n        volumeSize[1] = n;\n    }\n    if (shrGetCmdLineArgumenti(argc, (const char**)argv, \"zsize\", &n)) {\n         volumeSize[2] = n;\n    }\n\n    // load volume data\n    free(cPathAndName);\n    cPathAndName = shrFindFilePath(volumeFilename, argv[0]);\n    oclCheckErrorEX(cPathAndName != NULL, shrTRUE, pCleanup);\n    size_t size = volumeSize[0] * volumeSize[1] * volumeSize[2];\n    uchar* h_volume = shrLoadRawFile(cPathAndName, size);\n    oclCheckErrorEX(h_volume != NULL, true, pCleanup);\n    shrLog(\" Raw file data loaded...\\n\\n\");\n\n    // Init OpenCL\n    initCLVolume(h_volume);\n    free (h_volume);\n\n    // init timer 1 for fps measurement \n    shrDeltaT(1);  \n    \n    if(!bQATest) \n    {\n        initPixelBuffer();\n        glutMainLoop();\n    } \n    else \n    {\n        TestNoGL();\n    }\n\n    // Normally unused return path\n    Cleanup(EXIT_SUCCESS);\n}\n\nvoid render()\n{\n    ciErrNum = CL_SUCCESS;\n\n    // Transfer ownership of buffer from GL to CL\n\n\tif( g_glInterop ) {\n\t\t// Acquire PBO for OpenCL writing\n\t\tglFlush();\n\t\tciErrNum |= clEnqueueAcquireGLObjects(cqCommandQueue, 1, &pbo_cl, 0, 0, 0);\n\t}\n\n\tciErrNum |= clEnqueueWriteBuffer(cqCommandQueue,d_invViewMatrix,CL_FALSE, 0,12*sizeof(float), invViewMatrix, 0, 0, 0);\t\n\n    // execute OpenCL kernel, writing results to PBO\n    size_t localSize[] = {LOCAL_SIZE_X,LOCAL_SIZE_Y};\n\n    ciErrNum |= clSetKernelArg(ckKernel, 3, sizeof(float), &density);\n    ciErrNum |= clSetKernelArg(ckKernel, 4, sizeof(float), &brightness);\n    ciErrNum |= clSetKernelArg(ckKernel, 5, sizeof(float), &transferOffset);\n    ciErrNum |= clSetKernelArg(ckKernel, 6, sizeof(float), &transferScale);\n    ciErrNum |= clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 2, NULL, gridSize, localSize, 0, 0, 0);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n\tif( g_glInterop ) {\n\t\t// Transfer ownership of buffer back from CL to GL    \n\t\tciErrNum |= clEnqueueReleaseGLObjects(cqCommandQueue, 1, &pbo_cl, 0, 0, 0);\n\t\toclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\t\tclFinish( cqCommandQueue );\n\t} else {\n\t\tglBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);    \n\n\t\t// map the buffer object into client's memory\n\t\tGLubyte* ptr = (GLubyte*)glMapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB,\n\t\t\tGL_WRITE_ONLY_ARB);\n\t\tclEnqueueReadBuffer(cqCommandQueue, pbo_cl, CL_TRUE, 0, sizeof(unsigned int) * height * width, ptr, 0, NULL, NULL);        \n\t\toclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\t\tglUnmapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB); \n\t}\n}\n\nvoid DisplayGL()\n{\n    // use OpenGL to build view matrix\n    GLfloat modelView[16];\n    glMatrixMode(GL_MODELVIEW);\n    glPushMatrix();\n    glLoadIdentity();\n    glRotatef(-viewRotation[0], 1.0, 0.0, 0.0);\n    glRotatef(-viewRotation[1], 0.0, 1.0, 0.0);\n    glTranslatef(-viewTranslation[0], -viewTranslation[1], -viewTranslation[2]);\n    glGetFloatv(GL_MODELVIEW_MATRIX, modelView);\n    glPopMatrix();\n\n    invViewMatrix[0] = modelView[0]; invViewMatrix[1] = modelView[4]; invViewMatrix[2] = modelView[8]; invViewMatrix[3] = modelView[12];\n    invViewMatrix[4] = modelView[1]; invViewMatrix[5] = modelView[5]; invViewMatrix[6] = modelView[9]; invViewMatrix[7] = modelView[13];\n    invViewMatrix[8] = modelView[2]; invViewMatrix[9] = modelView[6]; invViewMatrix[10] = modelView[10]; invViewMatrix[11] = modelView[14];\n\n    // start timer 0 if it's update time\n    double dProcessingTime = 0.0;\n    if (iFrameCount >= iFrameTrigger)\n    {\n        shrDeltaT(0); \n    }\n\n     // process \n    render();\n\n    // get processing time from timer 0, if it's update time\n    if (iFrameCount >= iFrameTrigger)\n    {\n        dProcessingTime = shrDeltaT(0); \n    }\n\n    // draw image from PBO\n    glClear(GL_COLOR_BUFFER_BIT);\n    glDisable(GL_DEPTH_TEST);\n    glRasterPos2i(0, 0);\n    glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n    glDrawPixels(width, height, GL_RGBA, GL_UNSIGNED_BYTE, 0);\n    glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n    // flip backbuffer to screen\n    glutSwapBuffers();\n\n    // Increment the frame counter, and do fps and Q/A stuff if it's time\n    if (iFrameCount++ > iFrameTrigger) \n    {\n        // set GLUT Window Title\n        char cFPS[256];\n        iFramesPerSec = (int)((double)iFrameCount/shrDeltaT(1));\n#ifdef GPU_PROFILING\n        #ifdef _WIN32\n            sprintf_s(cFPS, 256, \"Volume Render %ux%u | %i fps | Proc.t = %.3f s | %.3f MP/s\", \n                width, height, iFramesPerSec, dProcessingTime, (1.0e-6 * width * height)/dProcessingTime);\n        #else \n            sprintf(cFPS, \"Volume Render %ux%u |  %i fps | Proc. t = %.3f s | %.3f MP/s\", \n                width, height, iFramesPerSec, dProcessingTime, (1.0e-6 * width * height)/dProcessingTime);\n        #endif\n#else\n        #ifdef _WIN32\n            sprintf_s(cFPS, 256, \"Volume Render | W: %u  H: %u\", width, height);\n        #else \n            sprintf(cFPS, \"Volume Render | W: %u  H: %u\", width, height);\n        #endif\n#endif\n        glutSetWindowTitle(cFPS);\n\n        // Log fps and processing info to console and file \n        shrLog(\" %s\\n\", cFPS); \n\n        // if doing quick test, exit\n        if ((bNoPrompt) && (!--iTestSets))\n        {\n            // Cleanup up and quit\n            Cleanup(EXIT_SUCCESS);\n        }\n\n        // reset framecount, trigger and timer\n        iFrameCount = 0; \n        iFrameTrigger = (iFramesPerSec > 1) ? iFramesPerSec * 2 : 1;\n    }\n}\n\nvoid Idle()\n{\n}\n\nvoid timerEvent(int value)\n{\n    glutPostRedisplay();\n\tglutTimerFunc(REFRESH_DELAY, timerEvent,0);\n}\n\nvoid KeyboardGL(unsigned char key, int /*x*/, int /*y*/)\n{\n    switch(key) \n    {\n        case '-':\n            density -= 0.01f;\n            break;\n        case '+':\n            density += 0.01f;\n            break;\n\n        case ']':\n            brightness += 0.1f;\n            break;\n        case '[':\n            brightness -= 0.1f;\n            break;\n\n        case ';':\n            transferOffset += 0.01f;\n            break;\n        case '\\'':\n            transferOffset -= 0.01f;\n            break;\n\n        case '.':\n            transferScale += 0.01f;\n            break;\n        case ',':\n            transferScale -= 0.01f;\n            break;\n        case '\\033': // escape quits\n        case '\\015': // Enter quits    \n        case 'Q':    // Q quits\n        case 'q':    // q (or escape) quits\n            // Cleanup up and quit\n            bNoPrompt = shrTRUE;\n            Cleanup(EXIT_SUCCESS);\n            break;\n        case 'F':\n        case 'f':\n                    linearFiltering = !linearFiltering;\n                    ciErrNum = clSetKernelArg(ckKernel, 10, sizeof(cl_sampler), linearFiltering ? &volumeSamplerLinear : &volumeSamplerNearest);\n                    shrLog(\"\\nLinear Filtering Toggled %s...\\n\", linearFiltering ? \"ON\" : \"OFF\");\n                    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n                    break;\n        default:\n            break;\n    }\n    shrLog(\"density = %.2f, brightness = %.2f, transferOffset = %.2f, transferScale = %.2f\\n\", density, brightness, transferOffset, transferScale);\n}\n\nvoid mouse(int button, int state, int x, int y)\n{\n    if (state == GLUT_DOWN)\n        buttonState |= 1<<button;\n    else if (state == GLUT_UP)\n        buttonState = 0;\n\n    ox = x; \n    oy = y;\n}\n\nvoid motion(int x, int y)\n{\n    float dx, dy;\n    dx = (float)(x - ox);\n    dy = (float)(y - oy);\n\n    if (buttonState == 3) {\n        // left+middle = zoom\n        viewTranslation[2] += dy / 100.0f;\n    } \n    else if (buttonState & 2) {\n        // middle = translate\n        viewTranslation[0] += dx / 100.0f;\n        viewTranslation[1] -= dy / 100.0f;\n    }\n    else if (buttonState & 1) {\n        // left = rotate\n        viewRotation[0] += dy / 5.0f;\n        viewRotation[1] += dx / 5.0f;\n    }\n\n    ox = x; \n    oy = y;\n}\n\nvoid Reshape(int x, int y)\n{\n    width = x; height = y;\n    initPixelBuffer();\n\n    glViewport(0, 0, x, y);\n\n    glMatrixMode(GL_MODELVIEW);\n    glLoadIdentity();\n\n    glMatrixMode(GL_PROJECTION);\n    glLoadIdentity();\n    glOrtho(0.0, 1.0, 0.0, 1.0, 0.0, 1.0); \n}\n\nvoid createCLContext(int argc, const char** argv) {\n    //Get the NVIDIA platform\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Get the number of GPU devices available to the platform\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiDevCount);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Create the device list\n    cdDevices = new cl_device_id [uiDevCount];\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiDevCount, cdDevices, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    // Get device requested on command line, if any\n    uiDeviceUsed = 0;\n    unsigned int uiEndDev = uiDevCount - 1;\n    if(shrGetCmdLineArgumentu(argc, argv, \"device\", &uiDeviceUsed ))\n    {\n      uiDeviceUsed = CLAMP(uiDeviceUsed, 0, uiEndDev);\n      uiEndDev = uiDeviceUsed; \n    } \n\n\t// Check if the requested device (or any of the devices if none requested) supports context sharing with OpenGL\n    if(g_glInterop && !bQATest)\n    {\n        bool bSharingSupported = false;\n        for(unsigned int i = uiDeviceUsed; (!bSharingSupported && (i <= uiEndDev)); ++i) \n        {\n            size_t extensionSize;\n            ciErrNum = clGetDeviceInfo(cdDevices[i], CL_DEVICE_EXTENSIONS, 0, NULL, &extensionSize );\n            oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n            if(extensionSize > 0) \n            {\n                char* extensions = (char*)malloc(extensionSize);\n                ciErrNum = clGetDeviceInfo(cdDevices[i], CL_DEVICE_EXTENSIONS, extensionSize, extensions, &extensionSize);\n                oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n                std::string stdDevString(extensions);\n                free(extensions);\n\n                size_t szOldPos = 0;\n                size_t szSpacePos = stdDevString.find(' ', szOldPos); // extensions string is space delimited\n                while (szSpacePos != stdDevString.npos)\n                {\n                    if( strcmp(GL_SHARING_EXTENSION, stdDevString.substr(szOldPos, szSpacePos - szOldPos).c_str()) == 0 ) \n                    {\n                        // Device supports context sharing with OpenGL\n                        uiDeviceUsed = i;\n                        bSharingSupported = true;\n                        break;\n                    }\n                    do \n                    {\n                        szOldPos = szSpacePos + 1;\n                        szSpacePos = stdDevString.find(' ', szOldPos);\n                    } \n                    while (szSpacePos == szOldPos);\n                }\n            }\n        }\n        shrLog(\"%s...\\n\", bSharingSupported ? \"Using CL-GL Interop\" : \"No device found that supports CL/GL context sharing\");  \n        oclCheckErrorEX(bSharingSupported, true, pCleanup);\n\n        #if defined (__APPLE__)\n            CGLContextObj kCGLContext = CGLGetCurrentContext();\n            CGLShareGroupObj kCGLShareGroup = CGLGetShareGroup(kCGLContext);\n            cl_context_properties props[] = \n            {\n                CL_CONTEXT_PROPERTY_USE_CGL_SHAREGROUP_APPLE, (cl_context_properties)kCGLShareGroup, \n                0 \n            };\n            cxGPUContext = clCreateContext(props, 0,0, NULL, NULL, &ciErrNum);\n        #else\n            #ifdef UNIX\n                cl_context_properties props[] = \n                {\n                    CL_GL_CONTEXT_KHR, (cl_context_properties)glXGetCurrentContext(), \n                    CL_GLX_DISPLAY_KHR, (cl_context_properties)glXGetCurrentDisplay(), \n                    CL_CONTEXT_PLATFORM, (cl_context_properties)cpPlatform, \n                    0\n                };\n                cxGPUContext = clCreateContext(props, 1, &cdDevices[uiDeviceUsed], NULL, NULL, &ciErrNum);\n            #else // Win32\n                cl_context_properties props[] = \n                {\n                    CL_GL_CONTEXT_KHR, (cl_context_properties)wglGetCurrentContext(), \n                    CL_WGL_HDC_KHR, (cl_context_properties)wglGetCurrentDC(), \n                    CL_CONTEXT_PLATFORM, (cl_context_properties)cpPlatform, \n                    0\n                };\n                cxGPUContext = clCreateContext(props, 1, &cdDevices[uiDeviceUsed], NULL, NULL, &ciErrNum);\n            #endif\n        #endif\n    }\n    else \n    {\n        cl_context_properties props[] = {CL_CONTEXT_PLATFORM, (cl_context_properties)cpPlatform, 0};\n        cxGPUContext = clCreateContext(props, 1, &cdDevices[uiDeviceUsed], NULL, NULL, &ciErrNum);\n\n\t\tg_glInterop = false;\n    }\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n}\n\nvoid initCLVolume(uchar *h_volume)\n{\n    ciErrNum = CL_SUCCESS;\n\n\tif (g_bImageSupport) \n    {\n\t\t// create 3D array and copy data to device\n\t\tcl_image_format volume_format;\n        volume_format.image_channel_order = CL_RGBA;\n        volume_format.image_channel_data_type = CL_UNORM_INT8;\n        uchar* h_tempVolume = (uchar*)malloc(volumeSize[0] * volumeSize[1] * volumeSize[2] * 4 );\n        for(int i = 0; i <(int)(volumeSize[0] * volumeSize[1] * volumeSize[2]); i++)\n        {\n            h_tempVolume[4 * i] = h_volume[i];\n        }\n        d_volumeArray = clCreateImage3D(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, &volume_format, \n                                        volumeSize[0], volumeSize[1], volumeSize[2],\n                                        (volumeSize[0] * 4), (volumeSize[0] * volumeSize[1] * 4),\n                                        h_tempVolume, &ciErrNum);\n\t\toclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        free (h_tempVolume);\n\n\t\t// create transfer function texture\n\t\tfloat transferFunc[] = {\n\t\t\t 0.0, 0.0, 0.0, 0.0, \n\t\t\t 1.0, 0.0, 0.0, 1.0, \n\t\t\t 1.0, 0.5, 0.0, 1.0, \n\t\t\t 1.0, 1.0, 0.0, 1.0, \n\t\t\t 0.0, 1.0, 0.0, 1.0, \n\t\t\t 0.0, 1.0, 1.0, 1.0, \n\t\t\t 0.0, 0.0, 1.0, 1.0, \n\t\t\t 1.0, 0.0, 1.0, 1.0, \n\t\t\t 0.0, 0.0, 0.0, 0.0, \n\t\t};\n\n\t\tcl_image_format transferFunc_format;\n\t\ttransferFunc_format.image_channel_order = CL_RGBA;\n\t\ttransferFunc_format.image_channel_data_type = CL_FLOAT;\n\t\td_transferFuncArray = clCreateImage2D(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, &transferFunc_format,\n\t\t\t\t\t\t\t\t\t\t\t  9, 1, sizeof(float) * 9 * 4,\n\t\t\t\t\t\t\t\t\t\t\t  transferFunc, &ciErrNum);                                          \n\t\toclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n        // Create samplers for transfer function, linear interpolation and nearest interpolation \n        transferFuncSampler = clCreateSampler(cxGPUContext, true, CL_ADDRESS_CLAMP_TO_EDGE, CL_FILTER_LINEAR, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        volumeSamplerLinear = clCreateSampler(cxGPUContext, true, CL_ADDRESS_REPEAT, CL_FILTER_LINEAR, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        volumeSamplerNearest = clCreateSampler(cxGPUContext, true, CL_ADDRESS_REPEAT, CL_FILTER_NEAREST, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n        // set image and sampler args\n        ciErrNum = clSetKernelArg(ckKernel, 8, sizeof(cl_mem), (void *) &d_volumeArray);\n\t\tciErrNum |= clSetKernelArg(ckKernel, 9, sizeof(cl_mem), (void *) &d_transferFuncArray);\n        ciErrNum |= clSetKernelArg(ckKernel, 10, sizeof(cl_sampler), linearFiltering ? &volumeSamplerLinear : &volumeSamplerNearest);\n        ciErrNum |= clSetKernelArg(ckKernel, 11, sizeof(cl_sampler), &transferFuncSampler);\n\t\toclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\t}\n\n    // init invViewMatrix\n    d_invViewMatrix = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, 12 * sizeof(float), 0, &ciErrNum);\n    ciErrNum |= clSetKernelArg(ckKernel, 7, sizeof(cl_mem), (void *) &d_invViewMatrix);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n}\n\nvoid InitGL(int* argc, char **argv)\n{\n    // initialize GLUT \n    glutInit(argc, argv);\n    glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE);\n    glutInitWindowPosition (glutGet(GLUT_SCREEN_WIDTH)/2 - width/2, \n                            glutGet(GLUT_SCREEN_HEIGHT)/2 - height/2);\n    glutInitWindowSize(width, height);\n    iGLUTWindowHandle = glutCreateWindow(\"OpenCL volume rendering\");\n#if !(defined (__APPLE__) || defined(MACOSX))\n    glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_GLUTMAINLOOP_RETURNS);\n#endif\n\n    // register glut callbacks\n    glutDisplayFunc(DisplayGL);\n    glutKeyboardFunc(KeyboardGL);\n    glutMouseFunc(mouse);\n    glutMotionFunc(motion);\n    glutReshapeFunc(Reshape);\n    glutIdleFunc(Idle);\n\tglutTimerFunc(REFRESH_DELAY, timerEvent,0);\n\n\t// initialize necessary OpenGL extensions\n    glewInit();\n    GLboolean bGLEW = glewIsSupported(\"GL_VERSION_2_0 GL_ARB_pixel_buffer_object\"); \n    oclCheckErrorEX(bGLEW, shrTRUE, pCleanup);\n\n\tg_glInterop = true;\n}\n\nvoid initPixelBuffer()\n{\n     ciErrNum = CL_SUCCESS;\n\n    if (pbo) {\n        // delete old buffer\n        clReleaseMemObject(pbo_cl);\n        glDeleteBuffersARB(1, &pbo);\n    }\n\n    // create pixel buffer object for display\n    glGenBuffersARB(1, &pbo);\n\tglBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo);\n\tglBufferDataARB(GL_PIXEL_UNPACK_BUFFER_ARB, width * height * sizeof(GLubyte) * 4, 0, GL_STREAM_DRAW_ARB);\n\tglBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\n\tif( g_glInterop ) {\n\t\t// create OpenCL buffer from GL PBO\n\t\tpbo_cl = clCreateFromGLBuffer(cxGPUContext,CL_MEM_WRITE_ONLY, pbo, &ciErrNum);\n\t\toclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\t} else {\n\t\tpbo_cl = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, width * height * sizeof(GLubyte) * 4, NULL, &ciErrNum);\n\t}\n\n    // calculate new grid size\n\tgridSize[0] = shrRoundUp(LOCAL_SIZE_X,width);\n\tgridSize[1] = shrRoundUp(LOCAL_SIZE_Y,height);\n\n    ciErrNum |= clSetKernelArg(ckKernel, 0, sizeof(cl_mem), (void *) &pbo_cl);\n    ciErrNum |= clSetKernelArg(ckKernel, 1, sizeof(unsigned int), &width);\n    ciErrNum |= clSetKernelArg(ckKernel, 2, sizeof(unsigned int), &height);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n}\n\nvoid TestNoGL()\n{\n    // execute OpenCL kernel without GL interaction\n    float modelView[16] = \n        {\n            1.0f, 0.0f, 0.0f, 0.0f,\n            0.0f, 1.0f, 0.0f, 0.0f,\n            0.0f, 0.0f, 1.0f, 0.0f,\n            0.0f, 0.0f, 4.0f, 1.0f\n        };\n    \n    invViewMatrix[0] = modelView[0]; invViewMatrix[1] = modelView[4]; invViewMatrix[2] = modelView[8]; invViewMatrix[3] = modelView[12];\n    invViewMatrix[4] = modelView[1]; invViewMatrix[5] = modelView[5]; invViewMatrix[6] = modelView[9]; invViewMatrix[7] = modelView[13];\n    invViewMatrix[8] = modelView[2]; invViewMatrix[9] = modelView[6]; invViewMatrix[10] = modelView[10]; invViewMatrix[11] = modelView[14];\n    \n    pbo_cl = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY,  width*height*sizeof(GLubyte)*4, NULL, &ciErrNum);\n    ciErrNum |= clEnqueueWriteBuffer(cqCommandQueue,d_invViewMatrix,CL_FALSE, 0,12*sizeof(float), invViewMatrix, 0, 0, 0);\n\n    gridSize[0] = width;\n    gridSize[1] = height;\n\n    ciErrNum |= clSetKernelArg(ckKernel, 0, sizeof(cl_mem), (void *) &pbo_cl);\n    ciErrNum |= clSetKernelArg(ckKernel, 1, sizeof(unsigned int), &width);\n    ciErrNum |= clSetKernelArg(ckKernel, 2, sizeof(unsigned int), &height);\n    ciErrNum |= clSetKernelArg(ckKernel, 3, sizeof(float), &density);\n    ciErrNum |= clSetKernelArg(ckKernel, 4, sizeof(float), &brightness);\n    ciErrNum |= clSetKernelArg(ckKernel, 5, sizeof(float), &transferOffset);\n    ciErrNum |= clSetKernelArg(ckKernel, 6, sizeof(float), &transferScale);\n    \n    // Warmup\n    int iCycles = 20;\n    size_t localSize[] = {LOCAL_SIZE_X,LOCAL_SIZE_Y};\n    for (int i = 0; i < iCycles ; i++)\n    {\n        ciErrNum |= clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 2, NULL, gridSize, localSize, 0, 0, 0);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    }\n    clFinish(cqCommandQueue);\n    \n    // Start timer 0 and process n loops on the GPU \n    shrDeltaT(0); \n    for (int i = 0; i < iCycles ; i++)\n    {\n        ciErrNum |= clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 2, NULL, gridSize, localSize, 0, 0, 0);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    }\n    clFinish(cqCommandQueue);\n    \n    // Get elapsed time and throughput, then log to sample and master logs\n    double dAvgTime = shrDeltaT(0)/(double)iCycles;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclVolumeRender, Throughput = %.4f MTexels/s, Time = %.5f s, Size = %u Texels, NumDevsUsed = %u, Workgroup = %u\\n\", \n           (1.0e-6 * width * height)/dAvgTime, dAvgTime, (width * height), 1, localSize[0] * localSize[1]); \n\n    // Cleanup and exit\n    Cleanup(EXIT_SUCCESS);\n}\n    \nvoid Cleanup(int iExitCode)\n{\n    // cleanup allocated objects\n    shrLog(\"\\nStarting Cleanup...\\n\\n\");\n    if(cPathAndName)free(cPathAndName);\n    if(cSourceCL)free(cSourceCL);\n\tif(ckKernel)clReleaseKernel(ckKernel);  \n    if(cpProgram)clReleaseProgram(cpProgram);\n    if(volumeSamplerLinear)clReleaseSampler(volumeSamplerLinear);\n    if(volumeSamplerNearest)clReleaseSampler(volumeSamplerNearest);\n    if(transferFuncSampler)clReleaseSampler(transferFuncSampler);\n    if(d_volumeArray)clReleaseMemObject(d_volumeArray);\n    if(d_transferFuncArray)clReleaseMemObject(d_transferFuncArray);\n    if(pbo_cl)clReleaseMemObject(pbo_cl);    \n    if(d_invViewMatrix)clReleaseMemObject(d_invViewMatrix);    \n    if(cqCommandQueue)clReleaseCommandQueue(cqCommandQueue);\n    if(cxGPUContext)clReleaseContext(cxGPUContext);\n\tif(!bQATest) \n    {\n        glDeleteBuffersARB(1, &pbo);\n    }\n    shrQAFinish2(bQATest, *pArgc, (const char **)pArgv, (iExitCode == 0) ? QA_PASSED : QA_FAILED); \n\n    // finalize logs and leave\n    if (bNoPrompt || bQATest)\n    {\n        shrLogEx(LOGBOTH | CLOSELOG, 0, \"%s Exiting...\\n\", cExecutableName);\n    }\n    else \n    {\n        shrLogEx(LOGBOTH | CLOSELOG, 0, \"%s Exiting...\\nPress <Enter> to Quit\\n\", cExecutableName);\n        #ifdef WIN32\n            getchar();\n        #endif\n    }\n    exit (iExitCode);\n}\n"}, "code_dirs": {"volumeRender.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclVolumeRender", "oclVolumeRender.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclVolumeRender"}}
{"kernel_name": "sobelFilter", "parallel_api": "cuda", "code": {"SobelFilter_kernels.cu": "#include <cooperative_groups.h>\n#include <cuda_runtime.h>\n#include <stdio.h>\n#include <stdlib.h>\n\nnamespace cg = cooperative_groups;\n\n#include <helper_string.h>\n\n#include \"SobelFilter_kernels.h\"\n\ncudaTextureObject_t             texObject;\nextern __shared__ unsigned char LocalBlock[];\nstatic cudaArray               *array = NULL;\n\n#define RADIUS 1\n\n#ifdef FIXED_BLOCKWIDTH\n#define BlockWidth  80\n#define SharedPitch 384\n#endif\n\n#define checkCudaErrors(err) __checkCudaErrors(err, __FILE__, __LINE__)\n\ninline void __checkCudaErrors(cudaError err, const char *file, const int line)\n{\n    if (cudaSuccess != err) {\n        fprintf(stderr, \"%s(%i) : CUDA Runtime API error %d: %s.\\n\", file, line, (int)err, cudaGetErrorString(err));\n        exit(EXIT_FAILURE);\n    }\n}\n\n__device__ unsigned char ComputeSobel(unsigned char ul,\n                                      unsigned char um,\n                                      unsigned char ur,\n                                      unsigned char ml,\n                                      unsigned char mm,\n                                      unsigned char mr,\n                                      unsigned char ll,\n                                      unsigned char lm,\n                                      unsigned char lr,\n                                      float         fScale)\n{\n    short Horz = ur + 2 * mr + lr - ul - 2 * ml - ll;\n    short Vert = ul + 2 * um + ur - ll - 2 * lm - lr;\n    short Sum  = (short)(fScale * (abs((int)Horz) + abs((int)Vert)));\n\n    if (Sum < 0) {\n        return 0;\n    }\n    else if (Sum > 0xff) {\n        return 0xff;\n    }\n\n    return (unsigned char)Sum;\n}\n\n__global__ void SobelShared(uchar4        *pSobelOriginal,\n                            unsigned short SobelPitch,\n#ifndef FIXED_BLOCKWIDTH\n                            short BlockWidth,\n                            short SharedPitch,\n#endif\n                            short               w,\n                            short               h,\n                            float               fScale,\n                            cudaTextureObject_t tex)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    short            u   = 4 * blockIdx.x * BlockWidth;\n    short            v   = blockIdx.y * blockDim.y + threadIdx.y;\n    short            ib;\n\n    int SharedIdx = threadIdx.y * SharedPitch;\n\n    for (ib = threadIdx.x; ib < BlockWidth + 2 * RADIUS; ib += blockDim.x) {\n        LocalBlock[SharedIdx + 4 * ib + 0] =\n            tex2D<unsigned char>(tex, (float)(u + 4 * ib - RADIUS + 0), (float)(v - RADIUS));\n        LocalBlock[SharedIdx + 4 * ib + 1] =\n            tex2D<unsigned char>(tex, (float)(u + 4 * ib - RADIUS + 1), (float)(v - RADIUS));\n        LocalBlock[SharedIdx + 4 * ib + 2] =\n            tex2D<unsigned char>(tex, (float)(u + 4 * ib - RADIUS + 2), (float)(v - RADIUS));\n        LocalBlock[SharedIdx + 4 * ib + 3] =\n            tex2D<unsigned char>(tex, (float)(u + 4 * ib - RADIUS + 3), (float)(v - RADIUS));\n    }\n\n    if (threadIdx.y < RADIUS * 2) {\n        SharedIdx = (blockDim.y + threadIdx.y) * SharedPitch;\n\n        for (ib = threadIdx.x; ib < BlockWidth + 2 * RADIUS; ib += blockDim.x) {\n            LocalBlock[SharedIdx + 4 * ib + 0] =\n                tex2D<unsigned char>(tex, (float)(u + 4 * ib - RADIUS + 0), (float)(v + blockDim.y - RADIUS));\n            LocalBlock[SharedIdx + 4 * ib + 1] =\n                tex2D<unsigned char>(tex, (float)(u + 4 * ib - RADIUS + 1), (float)(v + blockDim.y - RADIUS));\n            LocalBlock[SharedIdx + 4 * ib + 2] =\n                tex2D<unsigned char>(tex, (float)(u + 4 * ib - RADIUS + 2), (float)(v + blockDim.y - RADIUS));\n            LocalBlock[SharedIdx + 4 * ib + 3] =\n                tex2D<unsigned char>(tex, (float)(u + 4 * ib - RADIUS + 3), (float)(v + blockDim.y - RADIUS));\n        }\n    }\n\n    cg::sync(cta);\n\n    u >>= 2;\n    uchar4 *pSobel = (uchar4 *)(((char *)pSobelOriginal) + v * SobelPitch);\n    SharedIdx      = threadIdx.y * SharedPitch;\n\n    for (ib = threadIdx.x; ib < BlockWidth; ib += blockDim.x) {\n        unsigned char pix00 = LocalBlock[SharedIdx + 4 * ib + 0 * SharedPitch + 0];\n        unsigned char pix01 = LocalBlock[SharedIdx + 4 * ib + 0 * SharedPitch + 1];\n        unsigned char pix02 = LocalBlock[SharedIdx + 4 * ib + 0 * SharedPitch + 2];\n        unsigned char pix10 = LocalBlock[SharedIdx + 4 * ib + 1 * SharedPitch + 0];\n        unsigned char pix11 = LocalBlock[SharedIdx + 4 * ib + 1 * SharedPitch + 1];\n        unsigned char pix12 = LocalBlock[SharedIdx + 4 * ib + 1 * SharedPitch + 2];\n        unsigned char pix20 = LocalBlock[SharedIdx + 4 * ib + 2 * SharedPitch + 0];\n        unsigned char pix21 = LocalBlock[SharedIdx + 4 * ib + 2 * SharedPitch + 1];\n        unsigned char pix22 = LocalBlock[SharedIdx + 4 * ib + 2 * SharedPitch + 2];\n\n        uchar4 out;\n\n        out.x = ComputeSobel(pix00, pix01, pix02, pix10, pix11, pix12, pix20, pix21, pix22, fScale);\n\n        pix00 = LocalBlock[SharedIdx + 4 * ib + 0 * SharedPitch + 3];\n        pix10 = LocalBlock[SharedIdx + 4 * ib + 1 * SharedPitch + 3];\n        pix20 = LocalBlock[SharedIdx + 4 * ib + 2 * SharedPitch + 3];\n        out.y = ComputeSobel(pix01, pix02, pix00, pix11, pix12, pix10, pix21, pix22, pix20, fScale);\n\n        pix01 = LocalBlock[SharedIdx + 4 * ib + 0 * SharedPitch + 4];\n        pix11 = LocalBlock[SharedIdx + 4 * ib + 1 * SharedPitch + 4];\n        pix21 = LocalBlock[SharedIdx + 4 * ib + 2 * SharedPitch + 4];\n        out.z = ComputeSobel(pix02, pix00, pix01, pix12, pix10, pix11, pix22, pix20, pix21, fScale);\n\n        pix02 = LocalBlock[SharedIdx + 4 * ib + 0 * SharedPitch + 5];\n        pix12 = LocalBlock[SharedIdx + 4 * ib + 1 * SharedPitch + 5];\n        pix22 = LocalBlock[SharedIdx + 4 * ib + 2 * SharedPitch + 5];\n        out.w = ComputeSobel(pix00, pix01, pix02, pix10, pix11, pix12, pix20, pix21, pix22, fScale);\n\n        if (u + ib < w / 4 && v < h) {\n            pSobel[u + ib] = out;\n        }\n    }\n\n    cg::sync(cta);\n}\n\n__global__ void\nSobelCopyImage(Pixel *pSobelOriginal, unsigned int Pitch, int w, int h, float fscale, cudaTextureObject_t tex)\n{\n    unsigned char *pSobel = (unsigned char *)(((char *)pSobelOriginal) + blockIdx.x * Pitch);\n\n    for (int i = threadIdx.x; i < w; i += blockDim.x) {\n        pSobel[i] = min(max((tex2D<unsigned char>(tex, (float)i, (float)blockIdx.x) * fscale), 0.f), 255.f);\n    }\n}\n\n__global__ void SobelTex(Pixel *pSobelOriginal, unsigned int Pitch, int w, int h, float fScale, cudaTextureObject_t tex)\n{\n    unsigned char *pSobel = (unsigned char *)(((char *)pSobelOriginal) + blockIdx.x * Pitch);\n\n    for (int i = threadIdx.x; i < w; i += blockDim.x) {\n        unsigned char pix00 = tex2D<unsigned char>(tex, (float)i - 1, (float)blockIdx.x - 1);\n        unsigned char pix01 = tex2D<unsigned char>(tex, (float)i + 0, (float)blockIdx.x - 1);\n        unsigned char pix02 = tex2D<unsigned char>(tex, (float)i + 1, (float)blockIdx.x - 1);\n        unsigned char pix10 = tex2D<unsigned char>(tex, (float)i - 1, (float)blockIdx.x + 0);\n        unsigned char pix11 = tex2D<unsigned char>(tex, (float)i + 0, (float)blockIdx.x + 0);\n        unsigned char pix12 = tex2D<unsigned char>(tex, (float)i + 1, (float)blockIdx.x + 0);\n        unsigned char pix20 = tex2D<unsigned char>(tex, (float)i - 1, (float)blockIdx.x + 1);\n        unsigned char pix21 = tex2D<unsigned char>(tex, (float)i + 0, (float)blockIdx.x + 1);\n        unsigned char pix22 = tex2D<unsigned char>(tex, (float)i + 1, (float)blockIdx.x + 1);\n        pSobel[i]           = ComputeSobel(pix00, pix01, pix02, pix10, pix11, pix12, pix20, pix21, pix22, fScale);\n    }\n}\n\nextern \"C\" void setupTexture(int iw, int ih, Pixel *data, int Bpp)\n{\n    cudaChannelFormatDesc desc;\n\n    if (Bpp == 1) {\n        desc = cudaCreateChannelDesc<unsigned char>();\n    }\n    else {\n        desc = cudaCreateChannelDesc<uchar4>();\n    }\n\n    checkCudaErrors(cudaMallocArray(&array, &desc, iw, ih));\n    checkCudaErrors(cudaMemcpy2DToArray(\n        array, 0, 0, data, iw * Bpp * sizeof(Pixel), iw * Bpp * sizeof(Pixel), ih, cudaMemcpyHostToDevice));\n\n    cudaResourceDesc texRes;\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = array;\n\n    cudaTextureDesc texDescr;\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = false;\n    texDescr.filterMode       = cudaFilterModePoint;\n    texDescr.addressMode[0]   = cudaAddressModeWrap;\n    texDescr.readMode         = cudaReadModeElementType;\n\n    checkCudaErrors(cudaCreateTextureObject(&texObject, &texRes, &texDescr, NULL));\n}\n\nextern \"C\" void deleteTexture(void)\n{\n    checkCudaErrors(cudaFreeArray(array));\n    checkCudaErrors(cudaDestroyTextureObject(texObject));\n}\n\nextern \"C\" void sobelFilter(Pixel *odata, int iw, int ih, enum SobelDisplayMode mode, float fScale)\n{\n    switch (mode) {\n    case SOBELDISPLAY_IMAGE:\n        SobelCopyImage<<<ih, 384>>>(odata, iw, iw, ih, fScale, texObject);\n        break;\n\n    case SOBELDISPLAY_SOBELTEX:\n        SobelTex<<<ih, 384>>>(odata, iw, iw, ih, fScale, texObject);\n        break;\n\n    case SOBELDISPLAY_SOBELSHARED: {\n        dim3 threads(16, 4);\n#ifndef FIXED_BLOCKWIDTH\n        int BlockWidth = 80;\n#endif\n        dim3 blocks =\n            dim3(iw / (4 * BlockWidth) + (0 != iw % (4 * BlockWidth)), ih / threads.y + (0 != ih % threads.y));\n        int SharedPitch = ~0x3f & (4 * (BlockWidth + 2 * RADIUS) + 0x3f);\n        int sharedMem   = SharedPitch * (threads.y + 2 * RADIUS);\n\n        iw &= ~3;\n\n        SobelShared<<<blocks, threads, sharedMem>>>((uchar4 *)odata,\n                                                    iw,\n#ifndef FIXED_BLOCKWIDTH\n                                                    BlockWidth,\n                                                    SharedPitch,\n#endif\n                                                    iw,\n                                                    ih,\n                                                    fScale,\n                                                    texObject);\n    } break;\n    }\n}\n", "SobelFilter.cpp": "#include <helper_gl.h>\n#if defined(__APPLE__) || defined(MACOSX)\n#pragma clang diagnostic ignored \"-Wdeprecated-declarations\"\n#include <GLUT/glut.h>\n#ifndef glutCloseFunc\n#define glutCloseFunc glutWMCloseFunc\n#endif\n#else\n#include <GL/freeglut.h>\n#endif\n\n#include <cuda_gl_interop.h>\n#include <cuda_runtime.h>\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include \"SobelFilter_kernels.h\"\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n\nconst char *filterMode[] = {\"No Filtering\", \"Sobel Texture\", \"Sobel SMEM+Texture\", NULL};\n\nvoid cleanup(void);\nvoid initializeData(char *file);\n\n#define MAX_EPSILON_ERROR 5.0f\n#define REFRESH_DELAY     10 // ms\n\nconst char *sSDKsample = \"CUDA Sobel Edge-Detection\";\n\nstatic int wWidth   = 512;\nstatic int wHeight  = 512;\nstatic int imWidth  = 0;\nstatic int imHeight = 0;\n\nconst int           frameCheckNumber = 4;\nint                 fpsCount         = 0;\nint                 fpsLimit         = 8;\nunsigned int        frameCount       = 0;\nunsigned int        g_TotalErrors    = 0;\nStopWatchInterface *timer            = NULL;\nunsigned int        g_Bpp;\nunsigned int        g_Index = 0;\n\nbool g_bQAReadback = false;\n\nstatic GLuint                pbo_buffer = 0;\nstruct cudaGraphicsResource *cuda_pbo_resource;\n\nstatic GLuint         texid      = 0;\nunsigned char        *pixels     = NULL;\nfloat                 imageScale = 1.f;\nenum SobelDisplayMode g_SobelDisplayMode;\n\nint   *pArgc = NULL;\nchar **pArgv = NULL;\n\nextern \"C\" void runAutoTest(int argc, char **argv);\n\n#define OFFSET(i) ((char *)NULL + (i))\n#define MAX(a, b) ((a > b) ? a : b)\n\nvoid computeFPS()\n{\n    frameCount++;\n    fpsCount++;\n\n    if (fpsCount == fpsLimit) {\n        char  fps[256];\n        float ifps = 1.f / (sdkGetAverageTimerValue(&timer) / 1000.f);\n        sprintf(fps, \"CUDA Edge Detection (%s): %3.1f fps\", filterMode[g_SobelDisplayMode], ifps);\n\n        glutSetWindowTitle(fps);\n        fpsCount = 0;\n\n        sdkResetTimer(&timer);\n    }\n}\n\nvoid display(void)\n{\n    sdkStartTimer(&timer);\n\n    Pixel *data = NULL;\n\n    checkCudaErrors(cudaGraphicsMapResources(1, &cuda_pbo_resource, 0));\n    size_t num_bytes;\n    checkCudaErrors(cudaGraphicsResourceGetMappedPointer((void **)&data, &num_bytes, cuda_pbo_resource));\n\n    sobelFilter(data, imWidth, imHeight, g_SobelDisplayMode, imageScale);\n    checkCudaErrors(cudaGraphicsUnmapResources(1, &cuda_pbo_resource, 0));\n\n    glClear(GL_COLOR_BUFFER_BIT);\n\n    glBindTexture(GL_TEXTURE_2D, texid);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER, pbo_buffer);\n    glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, imWidth, imHeight, GL_LUMINANCE, GL_UNSIGNED_BYTE, OFFSET(0));\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER, 0);\n\n    glDisable(GL_DEPTH_TEST);\n    glEnable(GL_TEXTURE_2D);\n    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);\n    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);\n    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);\n    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);\n\n    glBegin(GL_QUADS);\n    glVertex2f(0, 0);\n    glTexCoord2f(0, 0);\n    glVertex2f(0, 1);\n    glTexCoord2f(1, 0);\n    glVertex2f(1, 1);\n    glTexCoord2f(1, 1);\n    glVertex2f(1, 0);\n    glTexCoord2f(0, 1);\n    glEnd();\n    glBindTexture(GL_TEXTURE_2D, 0);\n    glutSwapBuffers();\n\n    sdkStopTimer(&timer);\n\n    computeFPS();\n}\n\nvoid timerEvent(int value)\n{\n    if (glutGetWindow()) {\n        glutPostRedisplay();\n        glutTimerFunc(REFRESH_DELAY, timerEvent, 0);\n    }\n}\n\nvoid keyboard(unsigned char key, int /*x*/, int /*y*/)\n{\n    char temp[256];\n\n    switch (key) {\n    case 27:\n    case 'q':\n    case 'Q':\n        printf(\"Shutting down...\\n\");\n#if defined(__APPLE__) || defined(MACOSX)\n        exit(EXIT_SUCCESS);\n#else\n        glutDestroyWindow(glutGetWindow());\n        return;\n#endif\n        break;\n\n    case '-':\n        imageScale -= 0.1f;\n        printf(\"brightness = %4.2f\\n\", imageScale);\n        break;\n\n    case '=':\n        imageScale += 0.1f;\n        printf(\"brightness = %4.2f\\n\", imageScale);\n        break;\n\n    case 'i':\n    case 'I':\n        g_SobelDisplayMode = SOBELDISPLAY_IMAGE;\n        sprintf(temp, \"CUDA Edge Detection (%s)\", filterMode[g_SobelDisplayMode]);\n        glutSetWindowTitle(temp);\n        break;\n\n    case 's':\n    case 'S':\n        g_SobelDisplayMode = SOBELDISPLAY_SOBELSHARED;\n        sprintf(temp, \"CUDA Edge Detection (%s)\", filterMode[g_SobelDisplayMode]);\n        glutSetWindowTitle(temp);\n        break;\n\n    case 't':\n    case 'T':\n        g_SobelDisplayMode = SOBELDISPLAY_SOBELTEX;\n        sprintf(temp, \"CUDA Edge Detection (%s)\", filterMode[g_SobelDisplayMode]);\n        glutSetWindowTitle(temp);\n        break;\n\n    default:\n        break;\n    }\n}\n\nvoid reshape(int x, int y)\n{\n    glViewport(0, 0, x, y);\n    glMatrixMode(GL_PROJECTION);\n    glLoadIdentity();\n    glOrtho(0, 1, 0, 1, 0, 1);\n    glMatrixMode(GL_MODELVIEW);\n    glLoadIdentity();\n}\n\nvoid cleanup(void)\n{\n    cudaGraphicsUnregisterResource(cuda_pbo_resource);\n\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER, 0);\n    glDeleteBuffers(1, &pbo_buffer);\n    glDeleteTextures(1, &texid);\n    deleteTexture();\n\n    sdkDeleteTimer(&timer);\n}\n\nvoid initializeData(char *file)\n{\n    GLint        bsize;\n    unsigned int w, h;\n    size_t       file_length = strlen(file);\n\n    if (!strcmp(&file[file_length - 3], \"pgm\")) {\n        if (sdkLoadPGM<unsigned char>(file, &pixels, &w, &h) != true) {\n            printf(\"Failed to load PGM image file: %s\\n\", file);\n            exit(EXIT_FAILURE);\n        }\n\n        g_Bpp = 1;\n    }\n    else if (!strcmp(&file[file_length - 3], \"ppm\")) {\n        if (sdkLoadPPM4(file, &pixels, &w, &h) != true) {\n            printf(\"Failed to load PPM image file: %s\\n\", file);\n            exit(EXIT_FAILURE);\n        }\n\n        g_Bpp = 4;\n    }\n    else {\n        exit(EXIT_FAILURE);\n    }\n\n    imWidth  = (int)w;\n    imHeight = (int)h;\n    setupTexture(imWidth, imHeight, pixels, g_Bpp);\n\n    memset(pixels, 0x0, g_Bpp * sizeof(Pixel) * imWidth * imHeight);\n\n    if (!g_bQAReadback) {\n        glGenBuffers(1, &pbo_buffer);\n        glBindBuffer(GL_PIXEL_UNPACK_BUFFER, pbo_buffer);\n        glBufferData(GL_PIXEL_UNPACK_BUFFER, g_Bpp * sizeof(Pixel) * imWidth * imHeight, pixels, GL_STREAM_DRAW);\n\n        glGetBufferParameteriv(GL_PIXEL_UNPACK_BUFFER, GL_BUFFER_SIZE, &bsize);\n\n        if ((GLuint)bsize != (g_Bpp * sizeof(Pixel) * imWidth * imHeight)) {\n            printf(\"Buffer object (%d) has incorrect size (%d).\\n\", (unsigned)pbo_buffer, (unsigned)bsize);\n\n            exit(EXIT_FAILURE);\n        }\n\n        glBindBuffer(GL_PIXEL_UNPACK_BUFFER, 0);\n\n        checkCudaErrors(cudaGraphicsGLRegisterBuffer(&cuda_pbo_resource, pbo_buffer, cudaGraphicsMapFlagsWriteDiscard));\n\n        glGenTextures(1, &texid);\n        glBindTexture(GL_TEXTURE_2D, texid);\n        glTexImage2D(GL_TEXTURE_2D,\n                     0,\n                     ((g_Bpp == 1) ? GL_LUMINANCE : GL_BGRA),\n                     imWidth,\n                     imHeight,\n                     0,\n                     GL_LUMINANCE,\n                     GL_UNSIGNED_BYTE,\n                     NULL);\n        glBindTexture(GL_TEXTURE_2D, 0);\n\n        glPixelStorei(GL_UNPACK_ALIGNMENT, 1);\n        glPixelStorei(GL_PACK_ALIGNMENT, 1);\n    }\n}\n\nvoid loadDefaultImage(char *loc_exec)\n{\n    printf(\"Reading image: teapot.pgm\\n\");\n    const char *image_filename = \"teapot.pgm\";\n    char       *image_path     = sdkFindFilePath(image_filename, loc_exec);\n\n    if (image_path == NULL) {\n        printf(\"Failed to read image file: <%s>\\n\", image_filename);\n        exit(EXIT_FAILURE);\n    }\n\n    initializeData(image_path);\n    free(image_path);\n}\n\nvoid initGL(int *argc, char **argv)\n{\n    glutInit(argc, argv);\n    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE);\n    glutInitWindowSize(wWidth, wHeight);\n    glutCreateWindow(\"CUDA Edge Detection\");\n\n    if (!isGLVersionSupported(1, 5)\n        || !areGLExtensionsSupported(\"GL_ARB_vertex_buffer_object GL_ARB_pixel_buffer_object\")) {\n        fprintf(stderr, \"Error: failed to get minimal extensions for demo\\n\");\n        fprintf(stderr, \"This sample requires:\\n\");\n        fprintf(stderr, \"  OpenGL version 1.5\\n\");\n        fprintf(stderr, \"  GL_ARB_vertex_buffer_object\\n\");\n        fprintf(stderr, \"  GL_ARB_pixel_buffer_object\\n\");\n        exit(EXIT_FAILURE);\n    }\n}\n\nvoid runAutoTest(int argc, char *argv[])\n{\n    printf(\"[%s] (automated testing w/ readback)\\n\", sSDKsample);\n    int devID = findCudaDevice(argc, (const char **)argv);\n\n    loadDefaultImage(argv[0]);\n\n    Pixel *d_result;\n    checkCudaErrors(cudaMalloc((void **)&d_result, imWidth * imHeight * sizeof(Pixel)));\n\n    char *ref_file = NULL;\n    char  dump_file[256];\n\n    int mode = 0;\n    mode     = getCmdLineArgumentInt(argc, (const char **)argv, \"mode\");\n    getCmdLineArgumentString(argc, (const char **)argv, \"file\", &ref_file);\n\n    switch (mode) {\n    case 0:\n        g_SobelDisplayMode = SOBELDISPLAY_IMAGE;\n        sprintf(dump_file, \"teapot_orig.pgm\");\n        break;\n\n    case 1:\n        g_SobelDisplayMode = SOBELDISPLAY_SOBELTEX;\n        sprintf(dump_file, \"teapot_tex.pgm\");\n        break;\n\n    case 2:\n        g_SobelDisplayMode = SOBELDISPLAY_SOBELSHARED;\n        sprintf(dump_file, \"teapot_shared.pgm\");\n        break;\n\n    default:\n        printf(\"Invalid Filter Mode File\\n\");\n        exit(EXIT_FAILURE);\n        break;\n    }\n\n    printf(\"AutoTest: %s <%s>\\n\", sSDKsample, filterMode[g_SobelDisplayMode]);\n    sobelFilter(d_result, imWidth, imHeight, g_SobelDisplayMode, imageScale);\n    checkCudaErrors(cudaDeviceSynchronize());\n\n    unsigned char *h_result = (unsigned char *)malloc(imWidth * imHeight * sizeof(Pixel));\n    checkCudaErrors(cudaMemcpy(h_result, d_result, imWidth * imHeight * sizeof(Pixel), cudaMemcpyDeviceToHost));\n    sdkSavePGM(dump_file, h_result, imWidth, imHeight);\n\n    if (!sdkComparePGM(dump_file, sdkFindFilePath(ref_file, argv[0]), MAX_EPSILON_ERROR, 0.15f, false)) {\n        g_TotalErrors++;\n    }\n\n    checkCudaErrors(cudaFree(d_result));\n    free(h_result);\n\n    if (g_TotalErrors != 0) {\n        printf(\"Test failed!\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"Test passed!\\n\");\n    exit(EXIT_SUCCESS);\n}\n\nint main(int argc, char **argv)\n{\n    pArgc = &argc;\n    pArgv = argv;\n\n#if defined(__linux__)\n    setenv(\"DISPLAY\", \":0\", 0);\n#endif\n\n    printf(\"%s Starting...\\n\\n\", sSDKsample);\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"help\")) {\n        printf(\"\\nUsage: SobelFilter <options>\\n\");\n        printf(\"\\t\\t-mode=n (0=original, 1=texture, 2=smem + texture)\\n\");\n        printf(\"\\t\\t-file=ref_orig.pgm (ref_tex.pgm, ref_shared.pgm)\\n\\n\");\n        exit(EXIT_SUCCESS);\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"file\")) {\n        g_bQAReadback = true;\n        runAutoTest(argc, argv);\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"device\")) {\n        printf(\"   This SDK does not explicitly support -device=n when running with \"\n               \"OpenGL.\\n\");\n        printf(\"   When specifying -device=n (n=0,1,2,....) the sample must not use \"\n               \"OpenGL.\\n\");\n        printf(\"   See details below to run without OpenGL:\\n\\n\");\n        printf(\" > %s -device=n\\n\\n\", argv[0]);\n        printf(\"exiting...\\n\");\n        exit(EXIT_SUCCESS);\n    }\n\n    initGL(&argc, argv);\n    findCudaDevice(argc, (const char **)argv);\n\n    sdkCreateTimer(&timer);\n    sdkResetTimer(&timer);\n\n    glutDisplayFunc(display);\n    glutKeyboardFunc(keyboard);\n    glutReshapeFunc(reshape);\n\n    loadDefaultImage(argv[0]);\n\n    printf(\"I: display Image (no filtering)\\n\");\n    printf(\"T: display Sobel Edge Detection (Using Texture)\\n\");\n    printf(\"S: display Sobel Edge Detection (Using SMEM+Texture)\\n\");\n    printf(\"Use the '-' and '=' keys to change the brightness.\\n\");\n    fflush(stdout);\n\n#if defined(__APPLE__) || defined(MACOSX)\n    atexit(cleanup);\n#else\n    glutCloseFunc(cleanup);\n#endif\n\n    glutTimerFunc(REFRESH_DELAY, timerEvent, 0);\n    glutMainLoop();\n}\n"}, "code_dirs": {"SobelFilter_kernels.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/SobelFilter", "SobelFilter.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/SobelFilter"}}
{"kernel_name": "sobelFilter", "parallel_api": "ocl", "code": {"SobelFilter.cl": "__kernel void ckSobel(__global uchar4* uc4Source, __global unsigned int* uiDest,\n                      __local uchar4* uc4LocalData, int iLocalPixPitch, \n                      int iImageWidth, int iDevImageHeight, float fThresh)\n{\n    // Get parent image x and y pixel coordinates from global ID, and compute offset into parent GMEM data\n    int iImagePosX = get_global_id(0);\n    int iDevYPrime = get_global_id(1) - 1;  // Shift offset up 1 radius (1 row) for reads\n    int iDevGMEMOffset = mul24(iDevYPrime, (int)get_global_size(0)) + iImagePosX; \n\n    // Compute initial offset of current pixel within work group LMEM block\n    int iLocalPixOffset = mul24((int)get_local_id(1), iLocalPixPitch) + get_local_id(0) + 1;\n\n    // Main read of GMEM data into LMEM\n    if((iDevYPrime > -1) && (iDevYPrime < iDevImageHeight) && (iImagePosX < iImageWidth))\n    {\n        uc4LocalData[iLocalPixOffset] = uc4Source[iDevGMEMOffset];\n    }\n    else \n    {\n        uc4LocalData[iLocalPixOffset] = (uchar4)0; \n    }\n\n    // Work items with y ID < 2 read bottom 2 rows of LMEM \n    if (get_local_id(1) < 2)\n    {\n        // Increase local offset by 1 workgroup LMEM block height\n        // to read in top rows from the next block region down\n        iLocalPixOffset += mul24((int)get_local_size(1), iLocalPixPitch);\n\n        // If source offset is within the image boundaries\n        if (((iDevYPrime + get_local_size(1)) < iDevImageHeight) && (iImagePosX < iImageWidth))\n        {\n            // Read in top rows from the next block region down\n            uc4LocalData[iLocalPixOffset] = uc4Source[iDevGMEMOffset + mul24(get_local_size(1), get_global_size(0))];\n        }\n        else \n        {\n            uc4LocalData[iLocalPixOffset] = (uchar4)0; \n        }\n    }\n\n    // Work items with x ID at right workgroup edge will read Left apron pixel\n    if (get_local_id(0) == (get_local_size(0) - 1))\n    {\n        // set local offset to read data from the next region over\n        iLocalPixOffset = mul24((int)get_local_id(1), iLocalPixPitch);\n\n        // If source offset is within the image boundaries and not at the leftmost workgroup\n        if ((iDevYPrime > -1) && (iDevYPrime < iDevImageHeight) && (get_group_id(0) > 0))\n        {\n            // Read data into the LMEM apron from the GMEM at the left edge of the next block region over\n            uc4LocalData[iLocalPixOffset] = uc4Source[mul24(iDevYPrime, (int)get_global_size(0)) + mul24(get_group_id(0), get_local_size(0)) - 1];\n        }\n        else \n        {\n            uc4LocalData[iLocalPixOffset] = (uchar4)0; \n        }\n\n        // If in the bottom 2 rows of workgroup block \n        if (get_local_id(1) < 2)\n        {\n            // Increase local offset by 1 workgroup LMEM block height\n            // to read in top rows from the next block region down\n            iLocalPixOffset += mul24((int)get_local_size(1), iLocalPixPitch);\n\n            // If source offset in the next block down isn't off the image and not at the leftmost workgroup\n            if (((iDevYPrime + get_local_size(1)) < iDevImageHeight) && (get_group_id(0) > 0))\n            {\n                // read in from GMEM (reaching down 1 workgroup LMEM block height and left 1 pixel)\n                uc4LocalData[iLocalPixOffset] = uc4Source[mul24((iDevYPrime + (int)get_local_size(1)), (int)get_global_size(0)) + mul24(get_group_id(0), get_local_size(0)) - 1];\n            }\n            else \n            {\n                uc4LocalData[iLocalPixOffset] = (uchar4)0; \n            }\n        }\n    } \n    else if (get_local_id(0) == 0) // Work items with x ID at left workgroup edge will read right apron pixel\n    {\n        // set local offset \n        iLocalPixOffset = mul24(((int)get_local_id(1) + 1), iLocalPixPitch) - 1;\n\n        if ((iDevYPrime > -1) && (iDevYPrime < iDevImageHeight) && (mul24(((int)get_group_id(0) + 1), (int)get_local_size(0)) < iImageWidth))\n        {\n            // read in from GMEM (reaching left 1 pixel) if source offset is within image boundaries\n            uc4LocalData[iLocalPixOffset] = uc4Source[mul24(iDevYPrime, (int)get_global_size(0)) + mul24((get_group_id(0) + 1), get_local_size(0))];\n        }\n        else \n        {\n            uc4LocalData[iLocalPixOffset] = (uchar4)0; \n        }\n\n        // Read bottom 2 rows of workgroup LMEM block\n        if (get_local_id(1) < 2)\n        {\n            // increase local offset by 1 workgroup LMEM block height\n            iLocalPixOffset += (mul24((int)get_local_size(1), iLocalPixPitch));\n\n            if (((iDevYPrime + get_local_size(1)) < iDevImageHeight) && (mul24((get_group_id(0) + 1), get_local_size(0)) < iImageWidth) )\n            {\n                // read in from GMEM (reaching down 1 workgroup LMEM block height and left 1 pixel) if source offset is within image boundaries\n                uc4LocalData[iLocalPixOffset] = uc4Source[mul24((iDevYPrime + (int)get_local_size(1)), (int)get_global_size(0)) + mul24((get_group_id(0) + 1), get_local_size(0))];\n            }\n            else \n            {\n                uc4LocalData[iLocalPixOffset] = (uchar4)0; \n            }\n        }\n    }\n\n    // Synchronize the read into LMEM\n    barrier(CLK_LOCAL_MEM_FENCE);\n\n    // Init summation registers to zero\n    float fTemp = 0.0f; \n    float fHSum [3] = {0.0f, 0.0f, 0.0f};\n    float fVSum [3] = {0.0f, 0.0f, 0.0f};\n\n    // set local offset\n    iLocalPixOffset = mul24((int)get_local_id(1), iLocalPixPitch) + get_local_id(0);\n\n    // NW\n\tfHSum[0] += (float)uc4LocalData[iLocalPixOffset].x;    // horizontal gradient of Red\n\tfHSum[1] += (float)uc4LocalData[iLocalPixOffset].y;    // horizontal gradient of Green\n\tfHSum[2] += (float)uc4LocalData[iLocalPixOffset].z;    // horizontal gradient of Blue\n    fVSum[0] -= (float)uc4LocalData[iLocalPixOffset].x;    // vertical gradient of Red\n\tfVSum[1] -= (float)uc4LocalData[iLocalPixOffset].y;    // vertical gradient of Green\n\tfVSum[2] -= (float)uc4LocalData[iLocalPixOffset++].z;  // vertical gradient of Blue\n\n    // N\n\tfVSum[0] -= (float)(uc4LocalData[iLocalPixOffset].x << 1);  // vertical gradient of Red\n\tfVSum[1] -= (float)(uc4LocalData[iLocalPixOffset].y << 1);  // vertical gradient of Green\n\tfVSum[2] -= (float)(uc4LocalData[iLocalPixOffset++].z << 1);// vertical gradient of Blue\n\n    // NE\n\tfHSum[0] -= (float)uc4LocalData[iLocalPixOffset].x;    // horizontal gradient of Red\n\tfHSum[1] -= (float)uc4LocalData[iLocalPixOffset].y;    // horizontal gradient of Green\n\tfHSum[2] -= (float)uc4LocalData[iLocalPixOffset].z;    // horizontal gradient of Blue\n\tfVSum[0] -= (float)uc4LocalData[iLocalPixOffset].x;    // vertical gradient of Red\n\tfVSum[1] -= (float)uc4LocalData[iLocalPixOffset].y;    // vertical gradient of Green\n\tfVSum[2] -= (float)uc4LocalData[iLocalPixOffset].z;    // vertical gradient of Blue\n\n    // increment LMEM block to next row, and unwind increments\n    iLocalPixOffset += (iLocalPixPitch - 2);    \n                \n    // W\n\tfHSum[0] += (float)(uc4LocalData[iLocalPixOffset].x << 1);  // vertical gradient of Red\n\tfHSum[1] += (float)(uc4LocalData[iLocalPixOffset].y << 1);  // vertical gradient of Green\n\tfHSum[2] += (float)(uc4LocalData[iLocalPixOffset++].z << 1);// vertical gradient of Blue\n\n    // C\n    iLocalPixOffset++;\n\n    // E\n\tfHSum[0] -= (float)(uc4LocalData[iLocalPixOffset].x << 1);  // vertical gradient of Red\n\tfHSum[1] -= (float)(uc4LocalData[iLocalPixOffset].y << 1);  // vertical gradient of Green\n\tfHSum[2] -= (float)(uc4LocalData[iLocalPixOffset].z << 1);  // vertical gradient of Blue\n\n    // increment LMEM block to next row, and unwind increments\n    iLocalPixOffset += (iLocalPixPitch - 2);    \n\n    // SW\n\tfHSum[0] += (float)uc4LocalData[iLocalPixOffset].x;    // horizontal gradient of Red\n\tfHSum[1] += (float)uc4LocalData[iLocalPixOffset].y;    // horizontal gradient of Green\n\tfHSum[2] += (float)uc4LocalData[iLocalPixOffset].z;    // horizontal gradient of Blue\n\tfVSum[0] += (float)uc4LocalData[iLocalPixOffset].x;    // vertical gradient of Red\n\tfVSum[1] += (float)uc4LocalData[iLocalPixOffset].y;    // vertical gradient of Green\n\tfVSum[2] += (float)uc4LocalData[iLocalPixOffset++].z;  // vertical gradient of Blue\n\n    // S\n\tfVSum[0] += (float)(uc4LocalData[iLocalPixOffset].x << 1);  // vertical gradient of Red\n\tfVSum[1] += (float)(uc4LocalData[iLocalPixOffset].y << 1);  // vertical gradient of Green\n\tfVSum[2] += (float)(uc4LocalData[iLocalPixOffset++].z << 1);// vertical gradient of Blue\n\n    // SE\n\tfHSum[0] -= (float)uc4LocalData[iLocalPixOffset].x;    // horizontal gradient of Red\n\tfHSum[1] -= (float)uc4LocalData[iLocalPixOffset].y;    // horizontal gradient of Green\n\tfHSum[2] -= (float)uc4LocalData[iLocalPixOffset].z;    // horizontal gradient of Blue\n\tfVSum[0] += (float)uc4LocalData[iLocalPixOffset].x;    // vertical gradient of Red\n\tfVSum[1] += (float)uc4LocalData[iLocalPixOffset].y;    // vertical gradient of Green\n\tfVSum[2] += (float)uc4LocalData[iLocalPixOffset].z;    // vertical gradient of Blue\n\n\t// Weighted combination of Root-Sum-Square per-color-band H & V gradients for each of RGB\n\tfTemp =  0.30f * sqrt((fHSum[0] * fHSum[0]) + (fVSum[0] * fVSum[0]));\n\tfTemp += 0.55f * sqrt((fHSum[1] * fHSum[1]) + (fVSum[1] * fVSum[1]));\n\tfTemp += 0.15f * sqrt((fHSum[2] * fHSum[2]) + (fVSum[2] * fVSum[2]));\n\n    // threshold and clamp\n    if (fTemp < fThresh)\n    {\n        fTemp = 0.0f;\n    }\n    else if (fTemp > 255.0f)\n    {\n        fTemp = 255.0f;\n    }\n\n    // pack into a monochrome uint \n    unsigned int uiPackedPix = 0x000000FF & (unsigned int)fTemp;\n    uiPackedPix |= 0x0000FF00 & (((unsigned int)fTemp) << 8);\n    uiPackedPix |= 0x00FF0000 & (((unsigned int)fTemp) << 16);\n\n    // Write out to GMEM with restored offset\n    if((iDevYPrime + 1 < iDevImageHeight) && (iImagePosX < iImageWidth))\n    {\n        uiDest[iDevGMEMOffset + get_global_size(0)] = uiPackedPix;\n    }\n}\n", "oclSobelFilter.cpp": "#include <GL/glew.h>\n#ifdef UNIX\n    #include <GL/glxew.h>\n#endif\n#if defined (_WIN32)\n    #include <GL/wglew.h>\n#endif\n\n#if defined (__APPLE__) || defined(MACOSX)\n    #include <OpenGL/OpenGL.h>\n    #include <GLUT/glut.h>\n#else\n    #include <GL/freeglut.h>\n#endif\n\n#include \"DeviceManager.h\"\n\n#include <oclUtils.h>\n#include <shrQATest.h>\n\n#ifndef min\n#define min(a,b) (a < b ? a : b)\n#endif\n\nint *pArgc = NULL;\nchar **pArgv = NULL;\n\nextern \"C\" double SobelFilterHost(unsigned int* uiInputImage, unsigned int* uiOutputImage, \n                                  unsigned int uiWidth, unsigned int uiHeight, float fThresh);\n\n#define REFRESH_DELAY\t  10 //ms\n\nint iBlockDimX = 16;\nint iBlockDimY = 4;\nfloat fThresh = 80.0f;\n\nconst char* cImageFile = \"StoneRGB.ppm\";\nunsigned int uiImageWidth = 1920;\nunsigned int uiImageHeight = 1080;\n\nint iGLUTWindowHandle;\nint iGLUTMenuHandle;\nint iGraphicsWinPosX = 0;\nint iGraphicsWinPosY = 0;\nint iGraphicsWinWidth = 1024;\nint iGraphicsWinHeight = ((float)uiImageHeight / (float)uiImageWidth) * iGraphicsWinWidth;\nfloat fZoom = 1.0f;\nint iFrameCount = 0;\nint iFrameTrigger = 90;\nint iFramesPerSec = 60;\ndouble dProcessingTime = 0.0;\nbool bFullScreen = false;\nGLint iVsyncState;\n\nconst char* cProcessor [] = {\"OpenCL GPU\", \"Host C++ CPU\"};\nbool bFilter = true;\nint iProcFlag = 0;\nbool bNoPrompt = shrFALSE;\nbool bQATest = shrFALSE;\nint iTestSets = 3;\n\nconst char* clSourcefile = \"SobelFilter.cl\";\nchar* cPathAndName = NULL;\nchar* cSourceCL = NULL;\ncl_platform_id cpPlatform;\ncl_context cxGPUContext;\ncl_command_queue* cqCommandQueue;\ncl_uint* uiInHostPixOffsets;\ncl_uint* uiOutHostPixOffsets;\ncl_program cpProgram;\ncl_kernel* ckSobel;\ncl_mem cmPinnedBufIn;\ncl_mem cmPinnedBufOut;\ncl_mem* cmDevBufIn;\ncl_mem* cmDevBufOut;\ncl_uint* uiInput = NULL;\ncl_uint* uiOutput = NULL;\nsize_t szBuffBytes;\nsize_t* szAllocDevBytes;\ncl_uint* uiDevImageHeight;\nsize_t szGlobalWorkSize[2];\nsize_t szLocalWorkSize[2];\nsize_t szParmDataBytes;\nsize_t szKernelLength;\ncl_int ciErrNum;\nconst char* cExecutableName = NULL;\n\nDeviceManager* GpuDevMngr; \n\ndouble SobelFilterGPU(unsigned int* uiInputImage, unsigned int* uiOutputImage);\n\nvoid InitGL(int* argc, char** argv);\nvoid DeInitGL();\nvoid DisplayGL();\nvoid Reshape(int w, int h);\nvoid Idle(void);\nvoid KeyboardGL(unsigned char key, int x, int y);\nvoid MenuGL(int i);\nvoid timerEvent(int value);\n\nvoid TestNoGL();\nvoid TriggerFPSUpdate();\nvoid GetDeviceLoadProportions(float* fLoadProportions, cl_device_id* cdDevices, cl_uint uiDevCount);\nvoid ShowMenuItems();\nvoid Cleanup(int iExitCode);\nvoid (*pCleanup)(int) = &Cleanup;\n\nint main(int argc, char** argv)\n{\n\tpArgc = &argc;\n\tpArgv = argv;\n\n\tshrQAStart(argc, argv);\n\n\tcExecutableName = argv[0];\n    shrSetLogFileName (\"oclSobelFilter.txt\");\n    shrLog(\"%s Starting (Using %s)...\\n\\n\", argv[0], clSourcefile); \n\n    bNoPrompt = (bool)shrCheckCmdLineFlag(argc, (const char**)argv, \"noprompt\");\n    bQATest   = (bool)shrCheckCmdLineFlag(argc, (const char**)argv, \"qatest\");\n\n    if (!(bQATest))\n    {\n        ShowMenuItems();\n    }\n\n    cPathAndName = shrFindFilePath(cImageFile, argv[0]);\n    oclCheckErrorEX(cPathAndName != NULL, shrTRUE, pCleanup);\n    shrLog(\"Image File\\t = %s\\nImage Dimensions = %u w x %u h x %u bpp\\n\\n\", cPathAndName, uiImageWidth, uiImageHeight, sizeof(unsigned int)<<3);\n\n    shrLog(\"%sInitGL...\\n\\n\", bQATest ? \"Skipping \" : \"Calling \"); \n    if (!(bQATest))\n    {\n        InitGL(&argc, argv);\n    }\n\n    char cBuffer[1024];\n    bool bNV = false;\n    shrLog(\"Get Platform ID... \");\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    ciErrNum = clGetPlatformInfo (cpPlatform, CL_PLATFORM_NAME, sizeof(cBuffer), cBuffer, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"%s\\n\\n\", cBuffer);\n    bNV = (strstr(cBuffer, \"NVIDIA\") != NULL);\n\n    shrLog(\"Get Device Info...\\n\");\n    cl_uint uiNumAllDevs = 0;\n    GpuDevMngr = new DeviceManager(cpPlatform, &uiNumAllDevs, pCleanup);\n\n    cl_int iSelectedDevice = 0;\n    if((shrGetCmdLineArgumenti(argc, (const char**)argv, \"device\", &iSelectedDevice)) || (uiNumAllDevs == 1)) \n    {\n        GpuDevMngr->uiUsefulDevCt = 1;  \n        iSelectedDevice = CLAMP((cl_uint)iSelectedDevice, 0, (uiNumAllDevs - 1));\n        GpuDevMngr->uiUsefulDevs[0] = iSelectedDevice;\n        GpuDevMngr->fLoadProportions[0] = 1.0f;\n        shrLog(\"  Using 1 Selected Device for Sobel Filter Computation...\\n\"); \n \n    } \n    else \n    {\n        ciErrNum = GpuDevMngr->GetDevLoadProportions(bNV);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        if (GpuDevMngr->uiUsefulDevCt == 1)\n        {\n            iSelectedDevice = GpuDevMngr->uiUsefulDevs[0];\n        }\n        shrLog(\"    Using %u Device(s) for Sobel Filter Computation\\n\", GpuDevMngr->uiUsefulDevCt); \n    }\n\n    shrLog(\"\\nclCreateContext...\\n\\n\");\n    cxGPUContext = clCreateContext(0, uiNumAllDevs, GpuDevMngr->cdDevices, NULL, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    cqCommandQueue = new cl_command_queue[GpuDevMngr->uiUsefulDevCt];\n    ckSobel = new cl_kernel[GpuDevMngr->uiUsefulDevCt];\n    cmDevBufIn = new cl_mem[GpuDevMngr->uiUsefulDevCt];\n    cmDevBufOut = new cl_mem[GpuDevMngr->uiUsefulDevCt];\n    szAllocDevBytes = new size_t[GpuDevMngr->uiUsefulDevCt];\n    uiInHostPixOffsets = new cl_uint[GpuDevMngr->uiUsefulDevCt];\n    uiOutHostPixOffsets = new cl_uint[GpuDevMngr->uiUsefulDevCt];\n    uiDevImageHeight = new cl_uint[GpuDevMngr->uiUsefulDevCt];\n\n    shrLog(\"clCreateCommandQueue...\\n\");\n    for (cl_uint i = 0; i < GpuDevMngr->uiUsefulDevCt; i++) \n    {\n        cqCommandQueue[i] = clCreateCommandQueue(cxGPUContext, GpuDevMngr->cdDevices[GpuDevMngr->uiUsefulDevs[i]], 0, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"  CommandQueue %u, Device %u, Device Load Proportion = %.2f, \", i, GpuDevMngr->uiUsefulDevs[i], GpuDevMngr->fLoadProportions[i]); \n        oclPrintDevName(LOGBOTH, GpuDevMngr->cdDevices[GpuDevMngr->uiUsefulDevs[i]]);  \n        shrLog(\"\\n\");\n    }\n\n    szBuffBytes = uiImageWidth * uiImageHeight * sizeof (unsigned int);\n    cmPinnedBufIn = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE | CL_MEM_ALLOC_HOST_PTR, szBuffBytes, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    cmPinnedBufOut = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE | CL_MEM_ALLOC_HOST_PTR, szBuffBytes, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"\\nclCreateBuffer (Input and Output Pinned Host buffers)...\\n\"); \n\n    uiInput = (cl_uint*)clEnqueueMapBuffer(cqCommandQueue[0], cmPinnedBufIn, CL_TRUE, CL_MAP_WRITE, 0, szBuffBytes, 0, NULL, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    uiOutput = (cl_uint*)clEnqueueMapBuffer(cqCommandQueue[0], cmPinnedBufOut, CL_TRUE, CL_MAP_READ, 0, szBuffBytes, 0, NULL, NULL, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"clEnqueueMapBuffer (Pointer to Input and Output pinned host buffers)...\\n\"); \n\n    ciErrNum = shrLoadPPM4ub(cPathAndName, (unsigned char **)&uiInput, &uiImageWidth, &uiImageHeight);\n    oclCheckErrorEX(ciErrNum, shrTRUE, pCleanup);\n    shrLog(\"Load Input Image to Input pinned host buffer...\\n\"); \n\n    free(cPathAndName);\n    cPathAndName = shrFindFilePath(clSourcefile, argv[0]);\n    oclCheckErrorEX(cPathAndName != NULL, shrTRUE, pCleanup);\n    cSourceCL = oclLoadProgSource(cPathAndName, \"// My comment\\n\", &szKernelLength);\n    oclCheckErrorEX(cSourceCL != NULL, shrTRUE, pCleanup);\n    shrLog(\"Load OpenCL Prog Source from File...\\n\"); \n\n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1, (const char **)&cSourceCL, &szKernelLength, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    shrLog(\"clCreateProgramWithSource...\\n\"); \n\n#ifdef MAC\n    char *flags = \"-cl-fast-relaxed-math -DMAC\";\n#else\n    char *flags = \"-cl-fast-relaxed-math\";\n#endif\n\n    ciErrNum = clBuildProgram(cpProgram, 0, NULL, flags, NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclSobelFilter.ptx\");\n        Cleanup(EXIT_FAILURE);\n    }\n    shrLog(\"clBuildProgram...\\n\\n\"); \n\n    unsigned uiSumHeight = 0;\n    for (cl_uint i = 0; i < GpuDevMngr->uiUsefulDevCt; i++)\n    {\n        ckSobel[i] = clCreateKernel(cpProgram, \"ckSobel\", &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clCreateKernel (ckSobel), Device %u...\\n\", i); \n\n        if (GpuDevMngr->uiUsefulDevCt == 1)\n        {\n            uiDevImageHeight[i] = uiImageHeight; \n            uiInHostPixOffsets[i] = 0;\n            uiOutHostPixOffsets[i] = 0;\n            szAllocDevBytes[i] = uiDevImageHeight[i] * uiImageWidth * sizeof(cl_uint);\n        }\n        else if (i == 0)\n        {\n            uiInHostPixOffsets[i] = 0;\n            uiOutHostPixOffsets[i] = 0;\n            uiDevImageHeight[i] = (cl_uint)(GpuDevMngr->fLoadProportions[GpuDevMngr->uiUsefulDevs[i]] * (float)uiImageHeight);     // height is proportional to dev perf \n            uiSumHeight += uiDevImageHeight[i];\n            uiDevImageHeight[i] += 1;\n            szAllocDevBytes[i] = uiDevImageHeight[i] * uiImageWidth * sizeof(cl_uint);\n        }\n        else if (i < (GpuDevMngr->uiUsefulDevCt - 1))\n        {\n            uiInHostPixOffsets[i] = (uiSumHeight - 1) * uiImageWidth;\n            uiOutHostPixOffsets[i] = uiInHostPixOffsets[i] + uiImageWidth;\n            uiDevImageHeight[i] = (cl_uint)(GpuDevMngr->fLoadProportions[GpuDevMngr->uiUsefulDevs[i]] * (float)uiImageHeight);     // height is proportional to dev perf \n            uiSumHeight += uiDevImageHeight[i];\n            uiDevImageHeight[i] += 2;\n            szAllocDevBytes[i] = uiDevImageHeight[i] * uiImageWidth * sizeof(cl_uint);\n        }\n        else \n        {\n            uiInHostPixOffsets[i] = (uiSumHeight - 1) * uiImageWidth;\n            uiOutHostPixOffsets[i] = uiInHostPixOffsets[i] + uiImageWidth;\n            uiDevImageHeight[i] = uiImageHeight - uiSumHeight;                              // \"leftover\" rows \n            uiSumHeight += uiDevImageHeight[i];\n            uiDevImageHeight[i] += 1;\n            szAllocDevBytes[i] = uiDevImageHeight[i] * uiImageWidth * sizeof(cl_uint);\n        }\n        shrLog(\"Image Height (rows) for Device %u = %u...\\n\", i, uiDevImageHeight[i]); \n\n        cmDevBufIn[i] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, szAllocDevBytes[i], NULL, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        cmDevBufOut[i] = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, szAllocDevBytes[i], NULL, &ciErrNum);\n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clCreateBuffer (Input and Output GMEM buffers, Device %u)...\\n\", i); \n\n        int iLocalPixPitch = iBlockDimX + 2;\n        ciErrNum = clSetKernelArg(ckSobel[i], 0, sizeof(cl_mem), (void*)&cmDevBufIn[i]);\n        ciErrNum |= clSetKernelArg(ckSobel[i], 1, sizeof(cl_mem), (void*)&cmDevBufOut[i]);\n        ciErrNum |= clSetKernelArg(ckSobel[i], 2, (iLocalPixPitch * (iBlockDimY + 2) * sizeof(cl_uchar4)), NULL);\n        ciErrNum |= clSetKernelArg(ckSobel[i], 3, sizeof(cl_int), (void*)&iLocalPixPitch);\n        ciErrNum |= clSetKernelArg(ckSobel[i], 4, sizeof(cl_uint), (void*)&uiImageWidth);\n        ciErrNum |= clSetKernelArg(ckSobel[i], 6, sizeof(cl_float), (void*)&fThresh);        \n        oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n        shrLog(\"clSetKernelArg (0-4), Device %u...\\n\\n\", i); \n    }\n\n    szLocalWorkSize[0] = iBlockDimX;\n    szLocalWorkSize[1] = iBlockDimY;\n    szGlobalWorkSize[0] = shrRoundUp((int)szLocalWorkSize[0], uiImageWidth); \n\n    shrDeltaT(0);\n    shrDeltaT(1);\n\n    if (!(bQATest))\n    {\n        glutMainLoop();\n    }\n    else \n    {\n        TestNoGL();\n    }\n\n    Cleanup(EXIT_SUCCESS);\n}\n\ndouble SobelFilterGPU(cl_uint* uiInputImage, cl_uint* uiOutputImage)\n{\n    ciErrNum = CL_SUCCESS;\n    for (cl_uint i = 0; i < GpuDevMngr->uiUsefulDevCt; i++)\n    {\n        ciErrNum |= clEnqueueWriteBuffer(cqCommandQueue[i], cmDevBufIn[i], CL_FALSE, 0, szAllocDevBytes[i], \n                                        (void*)&uiInputImage[uiInHostPixOffsets[i]], 0, NULL, NULL);\n    }\n\n    for (cl_uint j = 0; j < GpuDevMngr->uiUsefulDevCt; j++)\n    {\n        ciErrNum |= clFinish(cqCommandQueue[j]);\n    }\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    shrDeltaT(0);\n    for (cl_uint i = 0; i < GpuDevMngr->uiUsefulDevCt; i++)\n    {\n        if (GpuDevMngr->uiUsefulDevCt == 1)\n        {\n            szGlobalWorkSize[1] = shrRoundUp((int)szLocalWorkSize[1], (int)uiDevImageHeight[i]);\n        }\n        else if (i == 0)\n        {\n            szGlobalWorkSize[1] = shrRoundUp((int)szLocalWorkSize[1], (int)uiDevImageHeight[i]);\n        }\n        else if (i < (GpuDevMngr->uiUsefulDevCt - 1))\n        {\n            szGlobalWorkSize[1] = shrRoundUp((int)szLocalWorkSize[1], (int)uiDevImageHeight[i]);\n        }\n        else \n        {   \n            szGlobalWorkSize[1] = shrRoundUp((int)szLocalWorkSize[1], (int)uiDevImageHeight[i]);\n        }\n\n        ciErrNum |= clSetKernelArg(ckSobel[i], 5, sizeof(cl_uint), (void*)&uiDevImageHeight[i]);\n\n        ciErrNum |= clEnqueueNDRangeKernel(cqCommandQueue[i], ckSobel[i], 2, NULL, szGlobalWorkSize, szLocalWorkSize, 0, NULL, NULL);\n\n        ciErrNum |= clFlush(cqCommandQueue[i]);\n    }\n\n    for (cl_uint j = 0; j < GpuDevMngr->uiUsefulDevCt; j++)\n    {\n        ciErrNum |= clFinish(cqCommandQueue[j]);\n    }\n    double dKernelTime = shrDeltaT(0);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    for (cl_uint i = 0; i < GpuDevMngr->uiUsefulDevCt; i++)\n    {\n        size_t szReturnBytes;\n        cl_uint uiOutDevByteOffset;        \n        if (GpuDevMngr->uiUsefulDevCt == 1)\n        {\n            szReturnBytes = szBuffBytes;\n            uiOutDevByteOffset = 0;\n        } \n        else if (i == 0)\n        {\n            szReturnBytes = szAllocDevBytes[i] - (uiImageWidth * sizeof(cl_uint));\n            uiOutDevByteOffset = 0;\n        }\n        else if (i < (GpuDevMngr->uiUsefulDevCt - 1))\n        {\n            szReturnBytes = szAllocDevBytes[i] - ((uiImageWidth * sizeof(cl_uint)) * 2);\n            uiOutDevByteOffset = uiImageWidth * sizeof(cl_uint);\n        }        \n        else \n        {   \n            szReturnBytes = szAllocDevBytes[i] - (uiImageWidth * sizeof(cl_uint));\n            uiOutDevByteOffset = uiImageWidth * sizeof(cl_uint);\n        }        \n        \n        ciErrNum |= clEnqueueReadBuffer(cqCommandQueue[i], cmDevBufOut[i], CL_FALSE, uiOutDevByteOffset, szReturnBytes, \n                                       (void*)&uiOutputImage[uiOutHostPixOffsets[i]], 0, NULL, NULL);\n    }\n\n    for (cl_uint j = 0; j < GpuDevMngr->uiUsefulDevCt; j++)\n    {\n        ciErrNum |= clFinish(cqCommandQueue[j]);\n    }\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    return dKernelTime;\n}\n\nvoid InitGL(int* argc, char **argv)\n{\n    glutInit(argc, argv);\n    glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE);\n    glutInitWindowPosition (glutGet(GLUT_SCREEN_WIDTH)/2 - iGraphicsWinWidth/2, \n                            glutGet(GLUT_SCREEN_HEIGHT)/2 - iGraphicsWinHeight/2);\n    glutInitWindowSize(iGraphicsWinWidth, iGraphicsWinHeight);\n    iGLUTWindowHandle = glutCreateWindow(\"OpenCL for GPU RGB Sobel Filter Demo\");\n#if !(defined (__APPLE__) || defined(MACOSX))\n    glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_GLUTMAINLOOP_RETURNS);\n#endif\n\n    glutKeyboardFunc(KeyboardGL);\n    glutDisplayFunc(DisplayGL);\n    glutReshapeFunc(Reshape);\n    glutIdleFunc(Idle);\n\tglutTimerFunc(REFRESH_DELAY, timerEvent,0);\n\n    iGLUTMenuHandle = glutCreateMenu(MenuGL);\n    glutAddMenuEntry(\"Toggle Filter On/Off <spacebar>\", ' ');\n    glutAddMenuEntry(\"Toggle Processing between GPU and CPU [p]\", 'p');\n    glutAddMenuEntry(\"Toggle between Full Screen and Windowed [f]\", 'f');\n    glutAddMenuEntry(\"Increase Threshold [+]\", '+');\n    glutAddMenuEntry(\"Decrease Threshold [-]\", '-');\n    glutAddMenuEntry(\"Quit <esc>\", '\\033');\n    glutAttachMenu(GLUT_RIGHT_BUTTON);\n\n    glClearColor(0.f, 0.f, 0.f, 0.f);\n\n    float fAspects[2] = {(float)glutGet(GLUT_WINDOW_WIDTH)/(float)uiImageWidth , (float)glutGet(GLUT_WINDOW_HEIGHT)/(float)uiImageHeight};\n    fZoom = fAspects[0] > fAspects[1] ? fAspects[1] : fAspects[0];\n    glPixelZoom(fZoom, fZoom);\n\n    glewInit();\n\n    #ifdef _WIN32\n        if (wglewIsSupported(\"WGL_EXT_swap_control\")) \n        {\n            iVsyncState = wglGetSwapIntervalEXT();\n            wglSwapIntervalEXT(0);\n        }\n    #else\n        #if defined (__APPLE__) || defined(MACOSX)\n            GLint VBL = 0;\n            CGLGetParameter(CGLGetCurrentContext(), kCGLCPSwapInterval, &iVsyncState); \n            CGLSetParameter(CGLGetCurrentContext(), kCGLCPSwapInterval, &VBL); \n        #else        \n            if(glxewIsSupported(\"GLX_SGI_swap_control\"))\n            {\n                glXSwapIntervalSGI(0);\t \n            }\n        #endif\n    #endif\n}\n\nvoid DeInitGL()\n{\n    #ifdef _WIN32\n        if (wglewIsSupported(\"WGL_EXT_swap_control\")) \n        {\n            wglSwapIntervalEXT(iVsyncState);\n        }\n    #else\n        #if defined (__APPLE__) || defined(MACOSX)\n            CGLSetParameter(CGLGetCurrentContext(), kCGLCPSwapInterval, &iVsyncState); \n        #endif\n    #endif\n\n}\n\nvoid DisplayGL()\n{\n    glClear(GL_COLOR_BUFFER_BIT);\n    if (bFilter)\n    {\n        if (iProcFlag == 0)\n        {\n            dProcessingTime += SobelFilterGPU (uiInput, uiOutput);\n        }\n        else \n        {\n            dProcessingTime += SobelFilterHost (uiInput, uiOutput, uiImageWidth, uiImageHeight, fThresh);\n        }\n\n        glDrawPixels(uiImageWidth, uiImageHeight, GL_RGBA, GL_UNSIGNED_BYTE, uiOutput); \n    }\n    else \n    {\n        glDrawPixels(uiImageWidth, uiImageHeight, GL_RGBA, GL_UNSIGNED_BYTE, uiInput); \n    }\n\n    glutSwapBuffers();\n\n    if (iFrameCount++ > iFrameTrigger)\n    {\n        char\n        iFramesPerSec = (int)((double)iFrameCount / shrDeltaT(1));\n        dProcessingTime /= (double)iFrameCount; \n        \n#ifdef GPU_PROFILING\n        if (bFilter)\n        {\n            #ifdef _WIN32\n            sprintf_s(cTitle, 256, \"%s RGB Sobel Filter ON | W: %u , H: %u | Thresh. = %.1f | # GPUs = %u | %i fps | Proc. t = %.5f s | %.1f Mpix/s\", \n                            cProcessor[iProcFlag], uiImageWidth, uiImageHeight, fThresh, GpuDevMngr->uiUsefulDevCt, iFramesPerSec, \n                            dProcessingTime, (1.0e-6 * uiImageWidth * uiImageHeight)/dProcessingTime);  \n            #else\n                sprintf(cTitle, \"%s RGB Sobel Filter ON | W: %u , H: %u | Thresh. = %.1f | # GPUs = %u | %i fps | Proc. t = %.5f s | %.1f Mpix/s\", \n                            cProcessor[iProcFlag], uiImageWidth, uiImageHeight, fThresh, GpuDevMngr->uiUsefulDevCt, iFramesPerSec, \n                            dProcessingTime, (1.0e-6 * uiImageWidth * uiImageHeight)/dProcessingTime);  \n            #endif\n        }\n        else \n        {\n            #ifdef _WIN32\n                sprintf_s(cTitle, 256, \"RGB Sobel Filter OFF | W: %u , H: %u | %i fps\", \n                            uiImageWidth, uiImageHeight, iFramesPerSec);  \n            #else \n                sprintf(cTitle, \"RGB Sobel Filter OFF | W: %u , H: %u | %i fps\", \n                            uiImageWidth, uiImageHeight, iFramesPerSec);  \n            #endif\n        }\n#else\n        if (bFilter)\n        {\n            #ifdef _WIN32\n                sprintf_s(cTitle, 256, \"%s RGB Sobel Filter ON | W: %u , H: %u | Thresh. = %.1f\", \n                            cProcessor[iProcFlag], uiImageWidth, uiImageHeight, fThresh);  \n            #else\n                sprintf(cTitle, \"%s RGB Sobel Filter ON | W: %u , H: %u | Thresh. = %.1f\", \n                            cProcessor[iProcFlag], uiImageWidth, uiImageHeight, fThresh);  \n            #endif\n        }\n        else \n        {\n            #ifdef _WIN32\n                sprintf_s(cTitle, 256, \"RGB Sobel Filter OFF | W: %u , H: %u\", \n                            uiImageWidth, uiImageHeight);  \n            #else \n                sprintf(cTitle, \"RGB Sobel Filter OFF | W: %u , H: %u\", \n                            uiImageWidth, uiImageHeight);  \n            #endif\n        }\n#endif\n        glutSetWindowTitle(cTitle);\n\n        shrLog(\"%s\\n\", cTitle); \n\n        if ((bNoPrompt) && (!--iTestSets))\n        {\n            Cleanup(EXIT_SUCCESS);\n        }\n\n        iFrameCount = 0; \n        dProcessingTime = 0.0;\n        iFrameTrigger = (iFramesPerSec > 1) ? iFramesPerSec * 2 : 1;\n    }\n}\n\nvoid Reshape(int w, int h)\n{\n    glPixelZoom((float)w/uiImageWidth , (float)h/uiImageHeight);\n}\n\nvoid timerEvent(int value)\n{\n    glutPostRedisplay();\n\tglutTimerFunc(REFRESH_DELAY, timerEvent,0);\n}\n\nvoid KeyboardGL(unsigned char key, int /*x*/, int /*y*/)\n{\n    switch(key) \n    {\n        case 'P':\n        case 'p':\n            if (iProcFlag == 0)\n            {\n                iProcFlag = 1;\n            }\n            else \n            {\n                iProcFlag = 0;\n            }\n            shrLog(\"\\n%s Processing...\\n\", cProcessor[iProcFlag]);\n            break;\n        case 'F':\n        case 'f':\n            bFullScreen = !bFullScreen;\n            if (bFullScreen)\n            {\n                iGraphicsWinPosX = glutGet(GLUT_WINDOW_X) - 8;\n                iGraphicsWinPosY = glutGet(GLUT_WINDOW_Y) - 30;\n                iGraphicsWinWidth  = min(glutGet(GLUT_WINDOW_WIDTH) , glutGet(GLUT_SCREEN_WIDTH) - 2*iGraphicsWinPosX ); \n                iGraphicsWinHeight = min(glutGet(GLUT_WINDOW_HEIGHT), glutGet(GLUT_SCREEN_HEIGHT)- 2*iGraphicsWinPosY ); \n                printf(\"(x,y)=(%d,%d), (w,h)=(%d,%d)\\n\", iGraphicsWinPosX, iGraphicsWinPosY, iGraphicsWinWidth, iGraphicsWinHeight);\n                glutFullScreen();\n            }\n            else\n            {\n                glutPositionWindow(iGraphicsWinPosX, iGraphicsWinPosY);\n                glutReshapeWindow(iGraphicsWinWidth, iGraphicsWinHeight);\n            }\n            shrLog(\"\\nMain Graphics %s...\\n\", bFullScreen ? \"FullScreen\" : \"Windowed\");\n            break;\n        case ' ':\n            bFilter = !bFilter;\n            shrLog(\"\\nSobel Filter Toggled %s...\\n\", bFilter ? \"ON\" : \"OFF\");\n            break;\n        case '+':\n        case '=':\n        case '-':\n        case '_':\n            if(key == '+' || key == '=')\n            {\n                fThresh += 10.0f;\n            }\n            else\n            {\n                fThresh -= 10.0f;\n            }\n\n            fThresh = CLAMP(fThresh, 0.0f, 255.0f);\n            for (cl_uint i = 0; i < GpuDevMngr->uiUsefulDevCt; i++)\n            {\n                ciErrNum = clSetKernelArg(ckSobel[i], 6, sizeof(cl_float), (void*)&fThresh);\n            }\n            oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n            shrLog(\"\\nThreshold changed to %.1f...\\n\", fThresh);\n            break;\n        case '\\033':\n        case '\\015':\n        case 'Q':\n        case 'q':\n            bNoPrompt = shrTRUE;\n            Cleanup(EXIT_SUCCESS);\n            break;\n    }\n\n    TriggerFPSUpdate();\n}\n\nvoid MenuGL(int i)\n{\n    KeyboardGL((unsigned char) i, 0, 0);\n}\n\nvoid Idle(void)\n{\n}\n\nvoid TriggerFPSUpdate()\n{\n    iFrameCount = 0; \n    iFramesPerSec = 1;\n    iFrameTrigger = 2;\n    shrDeltaT(1);\n    shrDeltaT(0);\n    dProcessingTime = 0.0;\n}\n\nvoid TestNoGL()\n{\n    SobelFilterGPU (uiInput, uiOutput);\n\n    const int iCycles = 150;\n    dProcessingTime = 0.0;\n    shrLog(\"\\nRunning SobelFilterGPU for %d cycles...\\n\\n\", iCycles);\n    shrDeltaT(2); \n    for (int i = 0; i < iCycles; i++)\n    {\n        dProcessingTime += SobelFilterGPU (uiInput, uiOutput);\n    }\n\n    double dRoundtripTime = shrDeltaT(2)/(double)iCycles;\n    dProcessingTime /= (double)iCycles;\n\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclSobelFilter, Throughput = %.4f M RGB Pixels/s, Time = %.5f s, Size = %u RGB Pixels, NumDevsUsed = %u, Workgroup = %u\\n\", \n           (1.0e-6 * uiImageWidth * uiImageHeight)/dProcessingTime, dProcessingTime, (uiImageWidth * uiImageHeight), GpuDevMngr->uiUsefulDevCt, szLocalWorkSize[0] * szLocalWorkSize[1]); \n    shrLog(\"\\nRoundTrip Time = %.5f s, Equivalent FPS = %.1f\\n\\n\", dRoundtripTime, 1.0/dRoundtripTime);\n\n    cl_uint* uiGolden = (cl_uint*)malloc(szBuffBytes);\n    SobelFilterHost(uiInput, uiGolden, uiImageWidth, uiImageHeight, fThresh);\n\n    shrLog(\"Comparing GPU Result to CPU Result...\\n\"); \n    shrBOOL bMatch = shrCompareuit(uiGolden, uiOutput, (uiImageWidth * uiImageHeight), 1.0f, 0.0001f);\n    shrLog(\"\\nGPU Result %s CPU Result within tolerance...\\n\", (bMatch == shrTRUE) ? \"matches\" : \"DOESN'T match\"); \n\n    free(uiGolden);\n    Cleanup((bMatch == shrTRUE) ? EXIT_SUCCESS : EXIT_FAILURE);\n}\n\nvoid ShowMenuItems()\n{\n    shrLog(\"  Right Click on Mouse for Menu\\n\\n\"); \n    shrLog(\"  or\\n\\nPress:\\n\\n\");\n\tshrLog(\"  <spacebar> to toggle Filter On/Off\\n\");\n\tshrLog(\"  <F> key to toggle between FullScreen and Windowed\\n\");\n    shrLog(\"  <P> key to toggle Processing between GPU and CPU\\n\");\n\tshrLog(\"  <-/+> Change Threshold (-/+ 10.0)\\n\");\n\tshrLog(\"  <ESC> to Quit\\n\\n\"); \n}\n\nvoid Cleanup(int iExitCode)\n{\n    shrLog(\"\\nStarting Cleanup...\\n\\n\");\n\n    if(cpProgram)clReleaseProgram(cpProgram);\n    for (cl_uint i = 0; i < GpuDevMngr->uiUsefulDevCt; i++)\n    {\n        if(ckSobel[i])clReleaseKernel(ckSobel[i]);\n        if(cmDevBufIn[i])clReleaseMemObject(cmDevBufIn[i]);\n        if(cmDevBufOut[i])clReleaseMemObject(cmDevBufOut[i]);\n    }\n    if(uiInput)clEnqueueUnmapMemObject(cqCommandQueue[0], cmPinnedBufIn, (void*)uiInput, 0, NULL, NULL);\n    if(uiOutput)clEnqueueUnmapMemObject(cqCommandQueue[0], cmPinnedBufOut, (void*)uiOutput, 0, NULL, NULL);\n    if(cmPinnedBufIn)clReleaseMemObject(cmPinnedBufIn);\n    if(cmPinnedBufOut)clReleaseMemObject(cmPinnedBufOut);\n    for (cl_uint i = 0; i < GpuDevMngr->uiUsefulDevCt; i++)\n    {\n        if(cqCommandQueue[i])clReleaseCommandQueue(cqCommandQueue[i]);\n    }\n    if(cxGPUContext)clReleaseContext(cxGPUContext);\n\n    if(cSourceCL)free(cSourceCL);\n    if(cPathAndName)free(cPathAndName);\n    if(cmDevBufIn) delete [] cmDevBufIn;\n    if(cmDevBufOut) delete [] cmDevBufOut;\n    if(szAllocDevBytes) delete [] szAllocDevBytes;\n    if(uiInHostPixOffsets) delete [] uiInHostPixOffsets;\n    if(uiOutHostPixOffsets) delete [] uiOutHostPixOffsets;\n    if(uiDevImageHeight) delete [] uiDevImageHeight;\n    if(GpuDevMngr) delete GpuDevMngr;\n    if(cqCommandQueue) delete [] cqCommandQueue;\n\n    if (!bQATest)\n    {\n        DeInitGL();\n    }\n\n    shrLogEx(LOGBOTH | CLOSELOG, 0, \"%s Exiting...\\n\", cExecutableName);\n\n    shrQAFinishExit2(bQATest, *pArgc, (const char **)pArgv, ( iExitCode == EXIT_SUCCESS ) ? QA_PASSED : QA_FAILED);\n}\n"}, "code_dirs": {"SobelFilter.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclSobelFilter", "oclSobelFilter.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclSobelFilter"}}
{"kernel_name": "postProcessGL", "parallel_api": "cuda", "code": {"postProcessGL.cu": "#include <cooperative_groups.h>\n\nnamespace cg = cooperative_groups;\n\n#include <helper_cuda.h>\n\ncudaTextureObject_t inTexObject;\n\n__device__ float clamp(float x, float a, float b) { return max(a, min(b, x)); }\n\n__device__ int clamp(int x, int a, int b) { return max(a, min(b, x)); }\n\n__device__ int rgbToInt(float r, float g, float b)\n{\n    r = clamp(r, 0.0f, 255.0f);\n    g = clamp(g, 0.0f, 255.0f);\n    b = clamp(b, 0.0f, 255.0f);\n    return (int(b) << 16) | (int(g) << 8) | int(r);\n}\n\n__device__ uchar4 getPixel(int x, int y, cudaTextureObject_t inTex)\n{\n#ifndef USE_TEXTURE_RGBA8UI\n    float4 res   = tex2D<float4>(inTex, x, y);\n    uchar4 ucres = make_uchar4(res.x * 255.0f, res.y * 255.0f, res.z * 255.0f, res.w * 255.0f);\n#else\n    uchar4 ucres = tex2D<uchar4>(inTex, x, y);\n#endif\n    return ucres;\n}\n\n#define SMEM(X, Y) sdata[(Y) * tilew + (X)]\n\n__global__ void cudaProcess(unsigned int       *g_odata,\n                            int                 imgw,\n                            int                 imgh,\n                            int                 tilew,\n                            int                 r,\n                            float               threshold,\n                            float               highlight,\n                            cudaTextureObject_t inTex)\n{\n    cg::thread_block         cta = cg::this_thread_block();\n    extern __shared__ uchar4 sdata[];\n\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n    int bw = blockDim.x;\n    int bh = blockDim.y;\n    int x  = blockIdx.x * bw + tx;\n    int y  = blockIdx.y * bh + ty;\n\n#if 0\n    uchar4 c4 = getPixel(x, y);\n    g_odata[y*imgw+x] = rgbToInt(c4.z, c4.y, c4.x);\n#else\n    SMEM(r + tx, r + ty) = getPixel(x, y, inTex);\n\n    if (threadIdx.x < r) {\n        SMEM(tx, r + ty) = getPixel(x - r, y, inTex);\n        SMEM(r + bw + tx, r + ty) = getPixel(x + bw, y, inTex);\n    }\n\n    if (threadIdx.y < r) {\n        SMEM(r + tx, ty) = getPixel(x, y - r, inTex);\n        SMEM(r + tx, r + bh + ty) = getPixel(x, y + bh, inTex);\n    }\n\n    if ((threadIdx.x < r) && (threadIdx.y < r)) {\n        SMEM(tx, ty) = getPixel(x - r, y - r, inTex);\n        SMEM(tx, r + bh + ty) = getPixel(x - r, y + bh, inTex);\n        SMEM(r + bw + tx, ty) = getPixel(x + bh, y - r, inTex);\n        SMEM(r + bw + tx, r + bh + ty) = getPixel(x + bw, y + bh, inTex);\n    }\n\n    c\n    float rsum    = 0.0f;\n    float gsum    = 0.0f;\n    float bsum    = 0.0f;\n    float samples = 0.0f;\n\n    for (int dy = -r; dy <= r; dy++) {\n        for (int dx = -r; dx <= r; dx++) {\n#if 0\n            uchar4 pixel = getPixel(x+dx, y+dy);\n#else\n            uchar4 pixel = SMEM(r + tx + dx, r + ty + dy);\n#endif\n\n            float l = dx * dx + dy * dy;\n\n            if (l <= r * r) {\n                float r = float(pixel.x);\n                float g = float(pixel.y);\n                float b = float(pixel.z);\n#if 1\n                float lum = (r + g + b) / (255 * 3);\n\n                if (lum > threshold) {\n                    r *= highlight;\n                    g *= highlight;\n                    b *= highlight;\n                }\n\n#endif\n                rsum += r;\n                gsum += g;\n                bsum += b;\n                samples += 1.0f;\n            }\n        }\n    }\n\n    rsum /= samples;\n    gsum /= samples;\n    bsum /= samples;\n    g_odata[y * imgw + x] = rgbToInt(rsum, gsum, bsum);\n#endif\n}\n\nextern \"C\" void launch_cudaProcess(dim3          grid,\n                                   dim3          block,\n                                   int           sbytes,\n                                   cudaArray    *g_data_array,\n                                   unsigned int *g_odata,\n                                   int           imgw,\n                                   int           imgh,\n                                   int           tilew,\n                                   int           radius,\n                                   float         threshold,\n                                   float         highlight)\n{\n    struct cudaChannelFormatDesc desc;\n    checkCudaErrors(cudaGetChannelDesc(&desc, g_data_array));\n\n    cudaResourceDesc texRes;\n    memset(&texRes, 0, sizeof(cudaResourceDesc));\n\n    texRes.resType         = cudaResourceTypeArray;\n    texRes.res.array.array = g_data_array;\n\n    cudaTextureDesc texDescr;\n    memset(&texDescr, 0, sizeof(cudaTextureDesc));\n\n    texDescr.normalizedCoords = false;\n    texDescr.filterMode       = cudaFilterModePoint;\n    texDescr.addressMode[0]   = cudaAddressModeWrap;\n    texDescr.readMode         = cudaReadModeElementType;\n\n    checkCudaErrors(cudaCreateTextureObject(&inTexObject, &texRes, &texDescr, NULL));\n\n#if 0\n    printf(\"CUDA Array channel descriptor, bits per component:\\n\");\n    printf(\"X %d Y %d Z %d W %d, kind %d\\n\",\n           desc.x,desc.y,desc.z,desc.w,desc.f);\n\n    printf(\"Possible values for channel format kind: i %d, u%d, f%d:\\n\",\n           cudaChannelFormatKindSigned, cudaChannelFormatKindUnsigned,\n           cudaChannelFormatKindFloat);\n#endif\n\n#ifdef GPU_PROFILING\n    StopWatchInterface *timer = 0;\n    sdkCreateTimer(&timer);\n\n    int nIter = 30;\n\n    for (int i = -1; i < nIter; ++i) {\n        if (i == 0) {\n            sdkStartTimer(&timer);\n        }\n\n#endif\n\n        cudaProcess<<<grid, block, sbytes>>>(\n            g_odata, imgw, imgh, block.x + (2 * radius), radius, 0.8f, 4.0f, inTexObject);\n\n#ifdef GPU_PROFILING\n    }\n\n    cudaDeviceSynchronize();\n    sdkStopTimer(&timer);\n    double dSeconds   = sdkGetTimerValue(&timer) / ((double)nIter * 1000.0);\n    double dNumTexels = (double)imgw * (double)imgh;\n    double mtexps     = 1.0e-6 * dNumTexels / dSeconds;\n\n    if (radius == 4) {\n        printf(\"\\n\");\n        printf(\"postprocessGL, Throughput = %.4f MTexels/s, Time = %.5f s, Size = \"\n               \"%.0f Texels, NumDevsUsed = %d, Workgroup = %u\\n\",\n               mtexps,\n               dSeconds,\n               dNumTexels,\n               1,\n               block.x * block.y);\n    }\n\n#endif\n}\n", "main.cpp": "#define USE_TEXSUBIMAGE2D\n\n#if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)\n#define WINDOWS_LEAN_AND_MEAN\n#define NOMINMAX\n#include <windows.h>\n#pragma warning(disable : 4996)\n#endif\n\n#include <helper_gl.h>\n#if defined(__APPLE__) || defined(MACOSX)\n#pragma clang diagnostic ignored \"-Wdeprecated-declarations\"\n#include <GLUT/glut.h>\n#define USE_TEXSUBIMAGE2D\n#else\n#include <GL/freeglut.h>\n#endif\n#include <cuda_gl_interop.h>\n#include <cuda_runtime.h>\n\n#include <helper_cuda.h>\n#include <helper_functions.h>\n#include <rendercheck_gl.h>\n\n#define MAX_EPSILON   10\n#define REFRESH_DELAY 10 // ms\nconst char *sSDKname = \"postProcessGL\";\n\nunsigned int g_TotalErrors = 0;\n\nCheckRender *g_CheckRender = NULL;\nunsigned int window_width      = 512;\nunsigned int window_height     = 512;\nunsigned int image_width       = 512;\nunsigned int image_height      = 512;\nint          iGLUTWindowHandle = 0; // handle to the GLUT window\n\n#ifdef USE_TEXSUBIMAGE2D\nGLuint                       pbo_dest;\nstruct cudaGraphicsResource *cuda_pbo_dest_resource;\n#else\nunsigned int                *cuda_dest_resource;\nGLuint                       shDrawTex; // draws a texture\nstruct cudaGraphicsResource *cuda_tex_result_resource;\n#endif\nextern cudaTextureObject_t inTexObject;\nGLuint                       fbo_source;\nstruct cudaGraphicsResource *cuda_tex_screen_resource;\nunsigned int size_tex_data;\nunsigned int num_texels;\nunsigned int num_values;\nGLuint framebuffer;    // to bind the proper targets\nGLuint depth_buffer;   // for proper depth test while rendering the scene\nGLuint tex_screen;     // where we render the image\nGLuint tex_cudaResult; // where we will copy the CUDA result\n\nfloat rotate[3];\n\nchar *ref_file        = NULL;\nbool  enable_cuda     = true;\nbool  animate         = true;\nint   blur_radius     = 8;\nint   max_blur_radius = 16;\n\nint   *pArgc = NULL;\nchar **pArgv = NULL;\n\n\nstatic int          fpsCount = 0;\nstatic int          fpsLimit = 1;\nStopWatchInterface *timer    = NULL;\n\n#ifndef USE_TEXTURE_RGBA8UI\n#pragma message(\"Note: Using Texture fmt GL_RGBA16F_ARB\")\n#else\n#pragma message(\"Note: Using Texture RGBA8UI + GLSL for teapot rendering\")\n#endif\nGLuint shDrawPot; // colors the teapot\n\n\nextern \"C\" void launch_cudaProcess(dim3          grid,\n                                   dim3          block,\n                                   int           sbytes,\n                                   cudaArray    *g_data,\n                                   unsigned int *g_odata,\n                                   int           imgw,\n                                   int           imgh,\n                                   int           tilew,\n                                   int           radius,\n                                   float         threshold,\n                                   float         highlight);\n\n\nvoid runStdProgram(int argc, char **argv);\nvoid FreeResource();\nvoid Cleanup(int iExitCode);\n\n\nbool initGL(int *argc, char **argv);\n\n#ifdef USE_TEXSUBIMAGE2D\nvoid createPBO(GLuint *pbo, struct cudaGraphicsResource **pbo_resource);\nvoid deletePBO(GLuint *pbo);\n#endif\n\nvoid createTextureDst(GLuint *tex_cudaResult, unsigned int size_x, unsigned int size_y);\nvoid createTextureSrc(GLuint *tex_screen, unsigned int size_x, unsigned int size_y);\nvoid deleteTexture(GLuint *tex);\nvoid createDepthBuffer(GLuint *depth, unsigned int size_x, unsigned int size_y);\nvoid deleteDepthBuffer(GLuint *depth);\nvoid createFramebuffer(GLuint *fbo, GLuint color, GLuint depth);\nvoid deleteFramebuffer(GLuint *fbo);\n\n\nvoid display();\nvoid idle();\nvoid keyboard(unsigned char key, int x, int y);\nvoid reshape(int w, int h);\nvoid mainMenu(int i);\n\nvoid process(int width, int height, int radius)\n{\n    cudaArray    *in_array;\n    unsigned int *out_data;\n\n#ifdef USE_TEXSUBIMAGE2D\n    checkCudaErrors(cudaGraphicsMapResources(1, &cuda_pbo_dest_resource, 0));\n    size_t num_bytes;\n    checkCudaErrors(cudaGraphicsResourceGetMappedPointer((void **)&out_data, &num_bytes, cuda_pbo_dest_resource));\n\n\n#else\n    out_data = cuda_dest_resource;\n#endif\n    checkCudaErrors(cudaGraphicsMapResources(1, &cuda_tex_screen_resource, 0));\n\n    checkCudaErrors(cudaGraphicsSubResourceGetMappedArray(&in_array, cuda_tex_screen_resource, 0, 0));\n    dim3 block(16, 16, 1);\n\n    dim3 grid(width / block.x, height / block.y, 1);\n    int  sbytes = (block.x + (2 * radius)) * (block.y + (2 * radius)) * sizeof(unsigned int);\n\n\n    launch_cudaProcess(\n        grid, block, sbytes, in_array, out_data, width, height, block.x + (2 * radius), radius, 0.8f, 4.0f);\n\n    checkCudaErrors(cudaGraphicsUnmapResources(1, &cuda_tex_screen_resource, 0));\n#ifdef USE_TEXSUBIMAGE2D\n    checkCudaErrors(cudaGraphicsUnmapResources(1, &cuda_pbo_dest_resource, 0));\n#endif\n    checkCudaErrors(cudaDestroyTextureObject(inTexObject));\n}\n\n#ifdef USE_TEXSUBIMAGE2D\n\n\n\nvoid createPBO(GLuint *pbo, struct cudaGraphicsResource **pbo_resource)\n{\n\n    num_texels    = image_width * image_height;\n    num_values    = num_texels * 4;\n    size_tex_data = sizeof(GLubyte) * num_values;\n    void *data    = malloc(size_tex_data);\n    glGenBuffers(1, pbo);\n    glBindBuffer(GL_ARRAY_BUFFER, *pbo);\n    glBufferData(GL_ARRAY_BUFFER, size_tex_data, data, GL_DYNAMIC_DRAW);\n    free(data);\n\n    glBindBuffer(GL_ARRAY_BUFFER, 0);\n\n\n    checkCudaErrors(cudaGraphicsGLRegisterBuffer(pbo_resource, *pbo, cudaGraphicsMapFlagsNone));\n    SDK_CHECK_ERROR_GL();\n}\n\nvoid deletePBO(GLuint *pbo)\n{\n    glDeleteBuffers(1, pbo);\n    SDK_CHECK_ERROR_GL();\n    *pbo = 0;\n}\n#endif\n\nconst GLenum fbo_targets[] = {GL_COLOR_ATTACHMENT0_EXT,\n                              GL_COLOR_ATTACHMENT1_EXT,\n                              GL_COLOR_ATTACHMENT2_EXT,\n                              GL_COLOR_ATTACHMENT3_EXT};\n\n#ifndef USE_TEXSUBIMAGE2D\nstatic const char *glsl_drawtex_vertshader_src = \"void main(void)\\n\"\n                                                 \"{\\n\"\n                                                 \"\tgl_Position = gl_Vertex;\\n\"\n                                                 \"\tgl_TexCoord[0].xy = gl_MultiTexCoord0.xy;\\n\"\n                                                 \"}\\n\";\n\nstatic const char *glsl_drawtex_fragshader_src = \"#version 130\\n\"\n                                                 \"uniform usampler2D texImage;\\n\"\n                                                 \"void main()\\n\"\n                                                 \"{\\n\"\n                                                 \"   vec4 c = texture(texImage, gl_TexCoord[0].xy);\\n\"\n                                                 \"\tgl_FragColor = c / 255.0;\\n\"\n                                                 \"}\\n\";\n#endif\n\nstatic const char *glsl_drawpot_fragshader_src =\n\n#if defined(__APPLE__) || defined(MACOSX)\n    \"void main()\\n\"\n    \"{\"\n    \"  gl_FragColor = vec4(gl_Color * 255.0);\\n\"\n    \"}\\n\";\n#else\n    \"#version 130\\n\"\n    \"in vec4 inColor;\\n\"\n    \"out uvec4 FragColor;\\n\"\n    \"void main()\\n\"\n    \"{\"\n    \"  FragColor = uvec4(inColor.xyz * 255.0, 255.0);\\n\"\n    \"}\\n\";\n#endif\n\nvoid renderScene(bool colorScale)\n{\n    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);\n\n    if (colorScale) {\n        glUseProgram(shDrawPot);\n        glBindFragDataLocationEXT(shDrawPot, 0, \"FragColor\");\n        SDK_CHECK_ERROR_GL();\n    }\n\n    glMatrixMode(GL_MODELVIEW);\n    glLoadIdentity();\n    glTranslatef(0.0, 0.0, -3.0);\n    glRotatef(rotate[0], 1.0, 0.0, 0.0);\n    glRotatef(rotate[1], 0.0, 1.0, 0.0);\n    glRotatef(rotate[2], 0.0, 0.0, 1.0);\n\n    glViewport(0, 0, 512, 512);\n\n    glEnable(GL_LIGHTING);\n    glEnable(GL_DEPTH_TEST);\n\n    glutSolidTeapot(1.0);\n\n    if (colorScale) {\n        glUseProgram(0);\n    }\n\n    SDK_CHECK_ERROR_GL();\n}\n\n\nvoid processImage()\n{\n\n    process(image_width, image_height, blur_radius);\n#ifdef USE_TEXSUBIMAGE2D\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo_dest);\n\n    glBindTexture(GL_TEXTURE_2D, tex_cudaResult);\n    glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, image_width, image_height, GL_RGBA, GL_UNSIGNED_BYTE, NULL);\n    SDK_CHECK_ERROR_GL();\n    glBindBuffer(GL_PIXEL_PACK_BUFFER_ARB, 0);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n#else\n\n\n    cudaArray *texture_ptr;\n    checkCudaErrors(cudaGraphicsMapResources(1, &cuda_tex_result_resource, 0));\n    checkCudaErrors(cudaGraphicsSubResourceGetMappedArray(&texture_ptr, cuda_tex_result_resource, 0, 0));\n\n    int num_texels    = image_width * image_height;\n    int num_values    = num_texels * 4;\n    int size_tex_data = sizeof(GLubyte) * num_values;\n    checkCudaErrors(cudaMemcpyToArray(texture_ptr, 0, 0, cuda_dest_resource, size_tex_data, cudaMemcpyDeviceToDevice));\n\n    checkCudaErrors(cudaGraphicsUnmapResources(1, &cuda_tex_result_resource, 0));\n#endif\n}\nvoid displayImage(GLuint texture)\n{\n    glBindTexture(GL_TEXTURE_2D, texture);\n    glEnable(GL_TEXTURE_2D);\n    glDisable(GL_DEPTH_TEST);\n    glDisable(GL_LIGHTING);\n    glTexEnvf(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_REPLACE);\n\n    glMatrixMode(GL_PROJECTION);\n    glPushMatrix();\n    glLoadIdentity();\n    glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0);\n\n    glMatrixMode(GL_MODELVIEW);\n    glLoadIdentity();\n\n    glViewport(0, 0, window_width, window_height);\n\n\n#ifndef USE_TEXSUBIMAGE2D\n    glUseProgram(shDrawTex);\n    GLint id = glGetUniformLocation(shDrawTex, \"texImage\");\n    glUniform1i(id, 0); // texture unit 0 to \"texImage\"\n    SDK_CHECK_ERROR_GL();\n#endif\n\n    glBegin(GL_QUADS);\n    glTexCoord2f(0.0, 0.0);\n    glVertex3f(-1.0, -1.0, 0.5);\n    glTexCoord2f(1.0, 0.0);\n    glVertex3f(1.0, -1.0, 0.5);\n    glTexCoord2f(1.0, 1.0);\n    glVertex3f(1.0, 1.0, 0.5);\n    glTexCoord2f(0.0, 1.0);\n    glVertex3f(-1.0, 1.0, 0.5);\n    glEnd();\n\n    glMatrixMode(GL_PROJECTION);\n    glPopMatrix();\n\n    glDisable(GL_TEXTURE_2D);\n\n#ifndef USE_TEXSUBIMAGE2D\n    glUseProgram(0);\n#endif\n    SDK_CHECK_ERROR_GL();\n}\nvoid display()\n{\n    sdkStartTimer(&timer);\n\n    if (enable_cuda) {\n        glBindFramebufferEXT(GL_FRAMEBUFFER_EXT, framebuffer);\n#ifndef USE_TEXTURE_RGBA8UI\n        renderScene(false);\n#else\n        renderScene(true); // output of fragment * by 255 (for RGBA8UI texture)\n#endif\n        processImage();\n        glBindFramebufferEXT(GL_FRAMEBUFFER_EXT, 0);\n        displayImage(tex_cudaResult);\n    }\n    else {\n        renderScene(false);\n    }\n    cudaDeviceSynchronize();\n    sdkStopTimer(&timer);\n    glutSwapBuffers();\n    if (ref_file && g_CheckRender && g_CheckRender->IsQAReadback()) {\n        static int pass = 0;\n        if (pass > 0) {\n            g_CheckRender->readback(window_width, window_height);\n            char currentOutputPPM[256];\n            sprintf(currentOutputPPM, \"teapot_%d.ppm\", blur_radius);\n            g_CheckRender->savePPM(currentOutputPPM, true, NULL);\n\n            if (!g_CheckRender->PPMvsPPM(currentOutputPPM, sdkFindFilePath(ref_file, pArgv[0]), MAX_EPSILON, 0.30f)) {\n                g_TotalErrors++;\n            }\n\n            Cleanup((g_TotalErrors == 0) ? EXIT_SUCCESS : EXIT_FAILURE);\n        }\n\n        pass++;\n    }\n    if (++fpsCount == fpsLimit) {\n        char  cTitle[256];\n        float fps = 1000.0f / sdkGetAverageTimerValue(&timer);\n        sprintf(cTitle, \"CUDA GL Post Processing (%d x %d): %.1f fps\", window_width, window_height, fps);\n        glutSetWindowTitle(cTitle);\n\n        fpsCount = 0;\n        fpsLimit = (int)((fps > 1.0f) ? fps : 1.0f);\n        sdkResetTimer(&timer);\n    }\n}\n\nvoid timerEvent(int value)\n{\n    if (animate) {\n        rotate[0] += 0.2f;\n\n        if (rotate[0] > 360.0f) {\n            rotate[0] -= 360.0f;\n        }\n\n        rotate[1] += 0.6f;\n\n        if (rotate[1] > 360.0f) {\n            rotate[1] -= 360.0f;\n        }\n\n        rotate[2] += 1.0f;\n\n        if (rotate[2] > 360.0f) {\n            rotate[2] -= 360.0f;\n        }\n    }\n\n    glutPostRedisplay();\n    glutTimerFunc(REFRESH_DELAY, timerEvent, 0);\n}\n\n\n\n\nvoid keyboard(unsigned char key, int /*x*/, int /*y*/)\n{\n    switch (key) {\n    case (27):\n        Cleanup(EXIT_SUCCESS);\n        break;\n\n    case ' ':\n        enable_cuda ^= 1;\n#ifdef USE_TEXTURE_RGBA8UI\n\n        if (enable_cuda) {\n            glClearColorIuiEXT(128, 128, 128, 255);\n        }\n        else {\n            glClearColor(0.5, 0.5, 0.5, 1.0);\n        }\n\n#endif\n        break;\n\n    case 'a':\n        animate ^= 1;\n        break;\n\n    case '=':\n    case '+':\n        if (blur_radius < 16) {\n            blur_radius++;\n        }\n\n        printf(\"radius = %d\\n\", blur_radius);\n        break;\n\n    case '-':\n        if (blur_radius > 1) {\n            blur_radius--;\n        }\n\n        printf(\"radius = %d\\n\", blur_radius);\n        break;\n    }\n}\n\nvoid reshape(int w, int h)\n{\n    window_width  = w;\n    window_height = h;\n}\n\nvoid mainMenu(int i) { keyboard((unsigned char)i, 0, 0); }\nvoid createTextureSrc(GLuint *tex_screen, unsigned int size_x, unsigned int size_y)\n{\n\n    glGenTextures(1, tex_screen);\n    glBindTexture(GL_TEXTURE_2D, *tex_screen);\n\n\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n#ifndef USE_TEXTURE_RGBA8UI\n    printf(\"Creating a Texture render target GL_RGBA16F_ARB\\n\");\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA16F_ARB, size_x, size_y, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);\n#else\n    printf(\"Creating a Texture render target GL_RGBA8UI_EXT\\n\");\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8UI_EXT, size_x, size_y, 0, GL_RGBA_INTEGER_EXT, GL_UNSIGNED_BYTE, NULL);\n#endif\n    SDK_CHECK_ERROR_GL();\n\n    checkCudaErrors(cudaGraphicsGLRegisterImage(\n        &cuda_tex_screen_resource, *tex_screen, GL_TEXTURE_2D, cudaGraphicsMapFlagsReadOnly));\n}\nvoid createTextureDst(GLuint *tex_cudaResult, unsigned int size_x, unsigned int size_y)\n{\n    glGenTextures(1, tex_cudaResult);\n    glBindTexture(GL_TEXTURE_2D, *tex_cudaResult);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\n#ifdef USE_TEXSUBIMAGE2D\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8, size_x, size_y, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);\n    SDK_CHECK_ERROR_GL();\n#else\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA8UI_EXT, size_x, size_y, 0, GL_RGBA_INTEGER_EXT, GL_UNSIGNED_BYTE, NULL);\n    SDK_CHECK_ERROR_GL();\n\n    checkCudaErrors(cudaGraphicsGLRegisterImage(\n        &cuda_tex_result_resource, *tex_cudaResult, GL_TEXTURE_2D, cudaGraphicsMapFlagsWriteDiscard));\n#endif\n}\nvoid deleteTexture(GLuint *tex)\n{\n    glDeleteTextures(1, tex);\n    SDK_CHECK_ERROR_GL();\n\n    *tex = 0;\n}\nvoid createDepthBuffer(GLuint *depth, unsigned int size_x, unsigned int size_y)\n{\n    glGenRenderbuffersEXT(1, depth);\n    glBindRenderbufferEXT(GL_RENDERBUFFER_EXT, *depth);\n    glRenderbufferStorageEXT(GL_RENDERBUFFER_EXT, GL_DEPTH_COMPONENT24, size_x, size_y);\n    glBindRenderbufferEXT(GL_RENDERBUFFER_EXT, 0);\n    SDK_CHECK_ERROR_GL();\n}\nvoid deleteDepthBuffer(GLuint *depth)\n{\n    glDeleteRenderbuffersEXT(1, depth);\n    SDK_CHECK_ERROR_GL();\n\n    *depth = 0;\n}\nvoid createFramebuffer(GLuint *fbo, GLuint color, GLuint depth)\n{\n    glGenFramebuffersEXT(1, fbo);\n    glBindFramebufferEXT(GL_FRAMEBUFFER_EXT, *fbo);\n    glFramebufferTexture2DEXT(GL_FRAMEBUFFER_EXT, GL_COLOR_ATTACHMENT0_EXT, GL_TEXTURE_2D, color, 0);\n    glFramebufferRenderbufferEXT(GL_FRAMEBUFFER_EXT, GL_DEPTH_ATTACHMENT_EXT, GL_RENDERBUFFER_EXT, depth);\n    glBindFramebufferEXT(GL_FRAMEBUFFER_EXT, 0);\n\n    SDK_CHECK_ERROR_GL();\n}\nvoid deleteFramebuffer(GLuint *fbo)\n{\n    glDeleteFramebuffersEXT(1, fbo);\n    SDK_CHECK_ERROR_GL();\n\n    *fbo = 0;\n}\nint main(int argc, char **argv)\n{\n#if defined(__linux__)\n    char *Xstatus = getenv(\"DISPLAY\");\n    if (Xstatus == NULL) {\n        printf(\"Waiving execution as X server is not running\\n\");\n        exit(EXIT_WAIVED);\n    }\n    setenv(\"DISPLAY\", \":0\", 0);\n#endif\n    printf(\"%s Starting...\\n\\n\", argv[0]);\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"radius\") && checkCmdLineFlag(argc, (const char **)argv, \"file\")) {\n        getCmdLineArgumentString(argc, (const char **)argv, \"file\", &ref_file);\n        blur_radius = getCmdLineArgumentInt(argc, (const char **)argv, \"radius\");\n    }\n    pArgc = &argc;\n    pArgv = argv;\n    if (checkCmdLineFlag(argc, (const char **)argv, \"device\")) {\n        printf(\"[%s]\\n\", argv[0]);\n        printf(\"   Does not explicitly support -device=n\\n\");\n        printf(\"   This sample requires OpenGL.  Only -file=<reference> -radius=<n> \"\n               \"are supported\\n\");\n        printf(\"exiting...\\n\");\n        exit(EXIT_WAIVED);\n    }\n\n    if (ref_file) {\n        printf(\"(Test with OpenGL verification)\\n\");\n        animate = false;\n\n        runStdProgram(argc, argv);\n    }\n    else {\n        printf(\"(Interactive OpenGL Demo)\\n\");\n        animate = true;\n\n        runStdProgram(argc, argv);\n    }\n\n    exit(EXIT_SUCCESS);\n}\nvoid FreeResource()\n{\n    sdkDeleteTimer(&timer);\n    checkCudaErrors(cudaGraphicsUnregisterResource(cuda_tex_screen_resource));\n#ifdef USE_TEXSUBIMAGE2D\n    checkCudaErrors(cudaGraphicsUnregisterResource(cuda_pbo_dest_resource));\n    deletePBO(&pbo_dest);\n#else\n    cudaFree(cuda_dest_resource);\n#endif\n    deleteTexture(&tex_screen);\n    deleteTexture(&tex_cudaResult);\n    deleteDepthBuffer(&depth_buffer);\n    deleteFramebuffer(&framebuffer);\n\n    if (iGLUTWindowHandle) {\n        glutDestroyWindow(iGLUTWindowHandle);\n    }\n    printf(\"postProcessGL.exe Exiting...\\n\");\n}\n\nvoid Cleanup(int iExitCode)\n{\n    FreeResource();\n    printf(\"Images are %s\\n\", (iExitCode == EXIT_SUCCESS) ? \"Matching\" : \"Not Matching\");\n    exit(EXIT_SUCCESS);\n}\nGLuint compileGLSLprogram(const char *vertex_shader_src, const char *fragment_shader_src)\n{\n    GLuint v, f, p = 0;\n\n    p = glCreateProgram();\n\n    if (vertex_shader_src) {\n        v = glCreateShader(GL_VERTEX_SHADER);\n        glShaderSource(v, 1, &vertex_shader_src, NULL);\n        glCompileShader(v);\n        GLint compiled = 0;\n        glGetShaderiv(v, GL_COMPILE_STATUS, &compiled);\n\n        if (!compiled) {\n            char temp[256] = \"\";\n            glGetShaderInfoLog(v, 256, NULL, temp);\n            printf(\"Vtx Compile failed:\\n%s\\n\", temp);\n            glDeleteShader(v);\n            return 0;\n        }\n        else {\n            glAttachShader(p, v);\n        }\n    }\n    if (fragment_shader_src) {\n        f = glCreateShader(GL_FRAGMENT_SHADER);\n        glShaderSource(f, 1, &fragment_shader_src, NULL);\n        glCompileShader(f);\n        GLint compiled = 0;\n        glGetShaderiv(f, GL_COMPILE_STATUS, &compiled);\n\n        if (!compiled) {\n            char temp[256] = \"\";\n            glGetShaderInfoLog(f, 256, NULL, temp);\n            printf(\"frag Compile failed:\\n%s\\n\", temp);\n            glDeleteShader(f);\n            return 0;\n        }\n        else {\n            glAttachShader(p, f);\n        }\n    }\n    glLinkProgram(p);\n    int infologLength = 0;\n    int charsWritten  = 0;\n\n    GLint linked = 0;\n    glGetProgramiv(p, GL_LINK_STATUS, &linked);\n\n    if (linked == 0) {\n        glGetProgramiv(p, GL_INFO_LOG_LENGTH, (GLint *)&infologLength);\n\n        if (infologLength > 0) {\n            char *infoLog = (char *)malloc(infologLength);\n            glGetProgramInfoLog(p, infologLength, (GLsizei *)&charsWritten, infoLog);\n            printf(\"Shader compilation error: %s\\n\", infoLog);\n            free(infoLog);\n        }\n    }\n\n    return p;\n}\n#ifndef USE_TEXSUBIMAGE2D\nvoid initCUDABuffers()\n{\n\n    num_texels    = image_width * image_height;\n    num_values    = num_texels * 4;\n    size_tex_data = sizeof(GLubyte) * num_values;\n    checkCudaErrors(cudaMalloc((void **)&cuda_dest_resource, size_tex_data));\n}\n#endif\n\nvoid initGLBuffers()\n{\n\n#ifdef USE_TEXSUBIMAGE2D\n    createPBO(&pbo_dest, &cuda_pbo_dest_resource);\n#endif\n    createTextureDst(&tex_cudaResult, image_width, image_height);\n\n    createTextureSrc(&tex_screen, image_width, image_height);\n    createDepthBuffer(&depth_buffer, image_width, image_height);\n\n    createFramebuffer(&framebuffer, tex_screen, depth_buffer);\n    shDrawPot = compileGLSLprogram(NULL, glsl_drawpot_fragshader_src);\n\n#ifndef USE_TEXSUBIMAGE2D\n    shDrawTex = compileGLSLprogram(glsl_drawtex_vertshader_src, glsl_drawtex_fragshader_src);\n#endif\n    SDK_CHECK_ERROR_GL();\n}\nvoid runStdProgram(int argc, char **argv)\n{\n    if (false == initGL(&argc, argv)) {\n        return;\n    }\n    findCudaDevice(argc, (const char **)argv);\n\n    sdkCreateTimer(&timer);\n    sdkResetTimer(&timer);\n    glutDisplayFunc(display);\n    glutKeyboardFunc(keyboard);\n    glutReshapeFunc(reshape);\n    glutTimerFunc(REFRESH_DELAY, timerEvent, 0);\n\n\n    glutCreateMenu(mainMenu);\n    glutAddMenuEntry(\"Toggle CUDA Post Processing (on/off) [ ]\", ' ');\n    glutAddMenuEntry(\"Toggle Animation (on/off) [a]\", 'a');\n    glutAddMenuEntry(\"Increase Blur Radius [=]\", '=');\n    glutAddMenuEntry(\"Decrease Blur Radius [-]\", '-');\n    glutAddMenuEntry(\"Quit (esc)\", '\\033');\n    glutAttachMenu(GLUT_RIGHT_BUTTON);\n\n    initGLBuffers();\n#ifndef USE_TEXSUBIMAGE2D\n    initCUDABuffers();\n#endif\n\n\n    if (ref_file) {\n        g_CheckRender = new CheckBackBuffer(window_width, window_height, 4);\n        g_CheckRender->setPixelFormat(GL_RGBA);\n        g_CheckRender->setExecPath(argv[0]);\n        g_CheckRender->EnableQAReadback(true);\n    }\n\n    printf(\"\\n\"\n           \"\\tControls\\n\"\n           \"\\t(right click mouse button for Menu)\\n\"\n           \"\\t[ ] : Toggle CUDA Post Processing (on/off)\\n\"\n           \"\\t[a] : Toggle Animation (on/off)\\n\"\n           \"\\t[=] : Increase Blur Radius\\n\"\n           \"\\t[-] : Decrease Blur Radius\\n\"\n           \"\\t[esc] - Quit\\n\\n\");\n\n\n    glutMainLoop();\n\n    Cleanup(EXIT_SUCCESS);\n}\nbool initGL(int *argc, char **argv)\n{\n\n    glutInit(argc, argv);\n    glutInitDisplayMode(GLUT_RGBA | GLUT_ALPHA | GLUT_DOUBLE | GLUT_DEPTH);\n    glutInitWindowSize(window_width, window_height);\n    iGLUTWindowHandle = glutCreateWindow(\"CUDA OpenGL post-processing\");\n    if (!isGLVersionSupported(2, 0)\n        || !areGLExtensionsSupported(\"GL_ARB_pixel_buffer_object \"\n                                     \"GL_EXT_framebuffer_object\")) {\n        printf(\"ERROR: Support for necessary OpenGL extensions missing.\");\n        fflush(stderr);\n        return false;\n    }\n\n#ifndef USE_TEXTURE_RGBA8UI\n    glClearColor(0.5, 0.5, 0.5, 1.0);\n#else\n    glClearColorIuiEXT(128, 128, 128, 255);\n#endif\n    glDisable(GL_DEPTH_TEST);\n    glViewport(0, 0, window_width, window_height);\n    glMatrixMode(GL_PROJECTION);\n    glLoadIdentity();\n    gluPerspective(60.0, (GLfloat)window_width / (GLfloat)window_height, 0.1f, 10.0f);\n\n    glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);\n\n    glEnable(GL_LIGHT0);\n    float red[]   = {1.0f, 0.1f, 0.1f, 1.0f};\n    float white[] = {1.0f, 1.0f, 1.0f, 1.0f};\n    glMaterialfv(GL_FRONT_AND_BACK, GL_DIFFUSE, red);\n    glMaterialfv(GL_FRONT_AND_BACK, GL_SPECULAR, white);\n    glMaterialf(GL_FRONT_AND_BACK, GL_SHININESS, 60.0f);\n\n    SDK_CHECK_ERROR_GL();\n\n    return true;\n}\n"}, "code_dirs": {"postProcessGL.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/postProcessGL", "main.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/postProcessGL"}}
{"kernel_name": "postProcessGL", "parallel_api": "ocl", "code": {"PostprocessGL.cl": "#define USE_LOCAL_MEM\n\n#define SMEM(X, Y) sdata[(Y)*tilew+(X)]\n\nint iclamp(int x, int a, int b)\n{\n    return max(a, min(b, x));\n}\n\n// convert floating point rgb color to 8-bit integer\nuint rgbToInt(float r, float g, float b)\n{\n  r = clamp(r, 0.0f, 255.0f);\n  g = clamp(g, 0.0f, 255.0f);\n  b = clamp(b, 0.0f, 255.0f);\n  return (convert_uint(b)<<16) + (convert_uint(g)<<8) + convert_uint(r);\n}\n\nuint getPixel(__global uint *data, int x, int y, int width, int height)\n{\n    x = iclamp(x, 0, width - 1);\n    y = iclamp(y, 0, height - 1);\n    return data[y * width + x];\n}\n\n__kernel void postprocess(__global uint* g_data, __global uint* g_odata, int imgw, int imgh, int tilew, int radius, float threshold, float highlight, __local uint* sdata)\n{\n    const int tx = get_local_id(0);\n    const int ty = get_local_id(1);\n    const int bw = get_local_size(0);\n    const int bh = get_local_size(1);\n    const int x = get_global_id(0);\n    const int y = get_global_id(1);\n\n    if( x >= imgw || y >= imgh ) return;\n\n#ifdef USE_LOCAL_MEM   \n\n    SMEM(radius + tx, radius + ty) = getPixel(g_data, x, y, imgw, imgh);\n\n    // borders\n    if (tx < radius) {\n        // left\n        SMEM(tx, radius + ty) = getPixel(g_data, x - radius, y, imgw, imgh);\n        // right\n        SMEM(radius + bw + tx, radius + ty) = getPixel(g_data, x + bw, y, imgw, imgh);\n    }\n    if (ty < radius) {\n        // top\n        SMEM(radius + tx, ty) = getPixel(g_data, x, y - radius, imgw, imgh);\n        // bottom\n        SMEM(radius + tx, radius + bh + ty) = getPixel(g_data, x, y + bh, imgw, imgh);\n    }\n\n    // load corners\n    if ((tx < radius) && (ty < radius)) {\n        // tl\n        SMEM(tx, ty) = getPixel(g_data, x - radius, y - radius, imgw, imgh);\n        // bl\n        SMEM(tx, radius + bh + ty) = getPixel(g_data, x - radius, y + bh, imgw, imgh);\n        // tr\n        SMEM(radius + bw + tx, ty) = getPixel(g_data, x + bh, y - radius, imgw, imgh);\n        // br\n        SMEM(radius + bw + tx, radius + bh + ty) = getPixel(g_data, x + bw, y + bh, imgw, imgh);\n    }\n\n    // wait for loads to complete\n    barrier(CLK_LOCAL_MEM_FENCE);\n#endif\n\n    // perform convolution\n    float rsum = 0.0f;\n    float gsum = 0.0f;\n    float bsum = 0.0f;\n    float samples = 0.0f;\n     \n    for(int dy=-radius; dy<=radius; dy++) \n    {\n        for(int dx=-radius; dx<=radius; dx++) \n        {\n\n#ifdef USE_LOCAL_MEM\n\t        uint pixel = SMEM(radius + tx + dx, radius + ty + dy);\n#else\n\t        uint pixel = getPixel(g_data, x + dx, y + dy, imgw, imgh);\n#endif\n\t \n            // only sum pixels within disc-shaped kernel\n            float l = dx*dx + dy*dy;\n\t        if (l <= radius*radius) \n            {\n                float r = convert_float(pixel&0x0ff);\n                float g = convert_float((pixel>>8)&0x0ff);\n                float b = convert_float((pixel>>16)&0x0ff);\n\n                // brighten highlights\n                float lum = (r + g + b) * 0.001307189542f;// /(255*3);\n                if (lum > threshold) \n                {\n                    r *= highlight;\n                    g *= highlight;\n\t                b *= highlight;\n                }\n\n\t            rsum += r;\n\t            gsum += g;\n\t            bsum += b;\n\t            samples += 1.0f;\n            }\n        }\n    }\n\n    rsum /= samples;\n    gsum /= samples;\n    bsum /= samples;\n\n    g_odata[y * imgw + x] = rgbToInt(rsum, gsum, bsum);\n}\n\n", "oclPostprocessGL.cpp": "#include <GL/glew.h>\n#if defined (_WIN32)\n    #include <GL/wglew.h>\n#endif\n\n#ifdef UNIX\n    #if defined(__APPLE__) || defined(MACOSX)\n       #include <OpenGL/OpenGL.h>\n       #include <GLUT/glut.h>\n    #else\n       #include <GL/freeglut.h>\n       #include <GL/glx.h>\n    #endif\n#else\n    #include <GL/freeglut.h>\n#endif\n\n#include <memory>\n#include <iostream>\n#include <cassert>\n\n#include <oclUtils.h>\n\n#include <shrQATest.h>\n\n#if defined (__APPLE__) || defined(MACOSX)\n   #define GL_SHARING_EXTENSION \"cl_APPLE_gl_sharing\"\n#else\n   #define GL_SHARING_EXTENSION \"cl_khr_gl_sharing\"\n#endif\n\n#define REFRESH_DELAY\t  10 //ms\n\nint *pArgc = NULL;\nchar **pArgv = NULL;\n\nint iGLUTWindowHandle;                      // handle to the GLUT window\nint iGLUTMenuHandle;                        // handle to the GLUT menu\nint iGraphicsWinWidth = 512;                // GL Window width\nint iGraphicsWinHeight = 512;               // GL Window height\ncl_int image_width = iGraphicsWinWidth;     // teapot image width\ncl_int image_height = iGraphicsWinHeight;   // teapot image height\nGLuint tex_screen;                          // (offscreen) render target\nfloat rotate[3];                            // var for teapot view rotation \n\nGLuint pbo_source;\nGLuint pbo_dest;\nunsigned int size_tex_data;\nunsigned int num_texels;\nunsigned int num_values;\n\ncl_context cxGPUContext;\ncl_command_queue cqCommandQueue;\ncl_device_id device;\ncl_uint uiNumDevsUsed = 1;          // Number of devices used in this sample \ncl_program cpProgram;\ncl_kernel ckKernel;\nsize_t szGlobalWorkSize[2];\nsize_t szLocalWorkSize[2];\ncl_mem cl_pbos[2] = {0,0};\ncl_int ciErrNum;\nconst char* clSourcefile = \"postprocessGL.cl\";\n\nint iFrameCount = 0;                // FPS count for averaging\nint iFrameTrigger = 90;             // FPS trigger for sampling\nint iFramesPerSec = 0;              // frames per second\nint iTestSets = 3;                  // # of loop set retriggers before auto exit when bNoPrompt = shrTrue\n\nconst char* cProcessor [] = {\"OpenCL GPU\", \"Host C++ CPU\"};\nint iProcFlag = 0;                  // 0 = GPU, 1 = CPU\nshrBOOL bNoPrompt = shrFALSE;\t\t// false = normal GL loop, true = Finite period of GL loop (a few seconds)\nshrBOOL bQATest = shrFALSE;\t\t\t// false = normal GL loop, true = run No-GL test sequence\nbool bPostprocess = shrTRUE;        // true = run blur filter processing on GPU or host, false = just do display of old data\nbool bAnimate = true;               // true = continue incrementing rotation of view with GL, false = stop rotation    \nint blur_radius = 4;                // radius of 2D convolution performed in post processing step\nbool bGLinterop = shrFALSE;\nconst char* cExecutableName = NULL;\n\nint initCL(int argc, const char** argv);\nvoid renderScene();\nvoid displayImage();\nvoid processImage();\nvoid postprocessHost(unsigned int* g_data, unsigned int* g_odata, int imgw, int imgh, int tilew, int radius, float threshold, float highlight);\n\nbool InitGL(int* argc, char** argv);\nvoid createPBO(GLuint* pbo);\nvoid deletePBO(GLuint* pbo);\nvoid createTexture(GLuint* tex_name, unsigned int size_x, unsigned int size_y);\nvoid deleteTexture(GLuint* tex);\nvoid dumpImage();\nvoid DisplayGL();\nvoid idle();\nvoid KeyboardGL(unsigned char key, int x, int y);\nvoid timerEvent(int value);\nvoid Reshape(int w, int h);\nvoid mainMenu(int i);\n\nvoid Cleanup(int iExitCode);\nvoid (*pCleanup)(int) = &Cleanup;\nvoid TestNoGL();\nvoid TriggerFPSUpdate();\n\nint main(int argc, char** argv) \n{\n    pArgc = &argc;\n    pArgv = argv;\n\n    shrQAStart(argc, argv);\n\ncExecutableName = argv[0];\n    shrSetLogFileName (\"oclPostProcessGL.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\nif (argc > 1) \n    {\n        bQATest   = shrCheckCmdLineFlag(argc, (const char**)argv, \"qatest\");\n        bNoPrompt = shrCheckCmdLineFlag(argc, (const char**)argv, \"noprompt\");\n    }\n    shrLog(\" Image Width = %d, Image Height = %d, Blur Radius = %d\\n\\n\", image_width, image_height, blur_radius);\n\nif(!bQATest) \n    {\n        InitGL(&argc, argv);\n\ncreatePBO(&pbo_source);\n        createPBO(&pbo_dest);\n\ncreateTexture(&tex_screen, image_width, image_height);        \n\n        bGLinterop = shrTRUE;\n    }\n\nif( initCL(argc, (const char**)argv) != 0 ) \n    {\n        return -1;\n    }\n\nshrDeltaT (1);\n\nshrLog(\"\\n%s...\\n\", bQATest ? \"No-GL test sequence\" : \"Standard GL Loop\"); \n\n    printf(\"\\n\"\n        \"\\tControls\\n\"\n\t\t\"\\t(right click mouse button for Menu)\\n\"\n\t\t\"\\t[   ] : Toggle Post-Processing (blur filter) ON/OFF\\n\"\n\t\t\"\\t[ p ] : Toggle Processing (between GPU or CPU)\\n\"\n\t\t\"\\t[ a ] : Toggle OpenGL Animation (rotation) ON/OFF\\n\"\n\t\t\"\\t[+/=] : Increase Blur Radius\\n\"\n\t\t\"\\t[-/_] : Decrease Blur Radius\\n\"\n\t\t\"\\t[Esc] - Quit\\n\\n\"\n        );\n\n    if(!bQATest) \n    {\n        glutMainLoop();\n    } \n    else \n    {\n        TestNoGL();\n    }\n    \n    Cleanup(EXIT_SUCCESS);\n}\n\nvoid dumpImage() \n{\n    unsigned char* h_dump = (unsigned char*) malloc(sizeof(unsigned int) * image_height * image_width);\n    \n    clEnqueueReadBuffer(cqCommandQueue, cl_pbos[1], CL_TRUE, 0, sizeof(unsigned int) * image_height * image_width, \n                        h_dump, 0, NULL, NULL);\n    \n    shrSavePPM4ub( \"dump.ppm\", h_dump, image_width, image_height);\n    free(h_dump);\n}\n\nvoid displayImage()\n{\n\n    glDisable(GL_DEPTH_TEST);\n    glDisable(GL_LIGHTING);\n    glEnable(GL_TEXTURE_2D);\n    glTexEnvf(GL_TEXTURE_ENV, GL_TEXTURE_ENV_MODE, GL_REPLACE);\n\n    glMatrixMode(GL_PROJECTION);\n    glPushMatrix();\n    glLoadIdentity();\n    glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0);\n\n    glMatrixMode( GL_MODELVIEW);\n    glLoadIdentity();\n\n    glViewport(0, 0, iGraphicsWinWidth, iGraphicsWinHeight);\n\n    glBegin(GL_QUADS);\n\n    glTexCoord2f(0.0, 0.0);\n    glVertex3f(-1.0, -1.0, 0.5);\n\n    glTexCoord2f(1.0, 0.0);\n    glVertex3f(1.0, -1.0, 0.5);\n\n    glTexCoord2f(1.0, 1.0);\n    glVertex3f(1.0, 1.0, 0.5);\n\n    glTexCoord2f(0.0, 1.0);\n    glVertex3f(-1.0, 1.0, 0.5);\n\n    glEnd();\n\n    glMatrixMode(GL_PROJECTION);\n    glPopMatrix();\n\n    glDisable(GL_TEXTURE_2D);\n    glBindBuffer(GL_PIXEL_PACK_BUFFER_ARB, 0);\n    glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n}\n\nvoid DisplayGL()\n{\n\n    renderScene();\n\ndouble dProcessingTime = 0.0;\n    if (iFrameCount >= iFrameTrigger)\n    {\n        shrDeltaT(0); \n    }\n\nprocessImage();\n\nif (iFrameCount >= iFrameTrigger)\n    {\n        dProcessingTime = shrDeltaT(0); \n    }\n\ndisplayImage();\n    glutSwapBuffers();\n    glutPostRedisplay();\n\nif (iFrameCount++ > iFrameTrigger) \n    {\n\n        char cFPS[256];\n        iFramesPerSec = (int)((double)iFrameCount/shrDeltaT(1));\n#ifdef GPU_PROFILING\n        if( bPostprocess ) \n        {\n            #ifdef _WIN32\n            sprintf_s(cFPS, 256, \"%s Postprocess ON  %ix%i | %i fps | Proc.t = %.3f s\",  \n                                      cProcessor[iProcFlag], iGraphicsWinWidth, iGraphicsWinHeight, \n                                      iFramesPerSec, dProcessingTime);\n            #else \n            sprintf(cFPS, \"%s Postprocess ON  %ix%i | %i fps | Proc.t = %.3f s\",  \n                               cProcessor[iProcFlag], iGraphicsWinWidth, iGraphicsWinHeight, \n                               iFramesPerSec, dProcessingTime);\n            #endif\n        } \n        else \n        {\n            #ifdef _WIN32\n            sprintf_s(cFPS, 256, \"Postprocess OFF  %ix%i | %i fps\",  iGraphicsWinWidth, iGraphicsWinHeight, iFramesPerSec);\n            #else \n            sprintf(cFPS, \"Postprocess OFF  %ix%i | %i fps\",  iGraphicsWinWidth, iGraphicsWinHeight, iFramesPerSec);\n            #endif\n        }\n#else \n        if(bPostprocess) \n        {\n            #ifdef _WIN32\n            sprintf_s(cFPS, 256, \"%s Postprocess ON  %ix%i\",  cProcessor[iProcFlag], iGraphicsWinWidth, iGraphicsWinHeight);\n            #else \n            sprintf(cFPS, \"%s Postprocess ON  %ix%i\",  cProcessor[iProcFlag], iGraphicsWinWidth, iGraphicsWinHeight);\n            #endif\n        } \n        else \n        {\n            #ifdef _WIN32\n            sprintf_s(cFPS, 256, \"%s Postprocess OFF  %ix%i\",  cProcessor[iProcFlag], iGraphicsWinWidth, iGraphicsWinHeight);\n            #else \n            sprintf(cFPS, \"%s Postprocess OFF  %ix%i\",  cProcessor[iProcFlag], iGraphicsWinWidth, iGraphicsWinHeight);\n            #endif\n        }\n#endif\n        glutSetWindowTitle(cFPS);\n\nshrLog(\" %s\\n\", cFPS); \n\nif ((bNoPrompt) && (!--iTestSets))\n        {\n\n            Cleanup(EXIT_SUCCESS);\n        }\n\niFrameCount = 0; \n        iFrameTrigger = (iFramesPerSec > 1) ? iFramesPerSec * 2 : 1;\n    }\n}\n\nvoid timerEvent(int value)\n{\n    if (bAnimate) {\n        rotate[0] += 0.2f; if( rotate[0] > 360.0f ) rotate[0] -= 360.0f;\n        rotate[1] += 0.6f; if( rotate[1] > 360.0f ) rotate[1] -= 360.0f;\n        rotate[2] += 1.0f; if( rotate[2] > 360.0f ) rotate[2] -= 360.0f;    \n    }\n    glutPostRedisplay();\n    glutTimerFunc(REFRESH_DELAY, timerEvent, 0);\n}\n\nvoid KeyboardGL(unsigned char key, int x, int y)\n{\n    switch(key) \n    {\n        case 'P':   // P toggles Processing between CPU and GPU\n        case 'p':   // p toggles Processing between CPU and GPU\n            if (iProcFlag == 0)\n            {\n                iProcFlag = 1;\n            }\n            else \n            {\n                iProcFlag = 0;\n            }\n            shrLog(\"\\n%s Processing...\\n\", cProcessor[iProcFlag]);\n            break;\n        case ' ':   // space bar toggles processing on and off\n            bPostprocess = !bPostprocess;\n            shrLog(\"\\nPostprocessing (Blur Filter) Toggled %s...\\n\", bPostprocess ? \"ON\" : \"OFF\");\n            break;\n        case 'A':   // 'A' toggles animation (spinning of teacup) on/off  \n        case 'a':   // 'a' toggles animation (spinning of teacup) on/off \n            bAnimate = !bAnimate;\n            shrLog(\"\\nGL Animation (Rotation) Toggled %s...\\n\", bAnimate ? \"ON\" : \"OFF\");\n            break;\n        case '=':\n        case '+':\n            if (blur_radius < 16) blur_radius++;\n            shrLog(\"\\nBlur radius = %d\\n\", blur_radius);\n            break;\n        case '-':\n        case '_':\n            if (blur_radius > 1) blur_radius--;\n            shrLog(\"\\nBlur radius = %d\\n\", blur_radius);\n            break;\n        case '\\033': // escape quits\n        case '\\015': // Enter quits    \n        case 'Q':    // Q quits\n        case 'q':    // q (or escape) quits\n\n            bNoPrompt = shrTRUE;\n            Cleanup(EXIT_SUCCESS);\n            break;\n    }\n\nTriggerFPSUpdate();\n    glutPostRedisplay();\n}\n\nvoid Reshape(int w, int h)\n{\t\t\n    w = MAX(w,1);\n    h = MAX(h,1);\n\n    iGraphicsWinWidth = w;\n    iGraphicsWinHeight = h;\n\n    glBindTexture(GL_TEXTURE_2D, tex_screen);\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, w, h, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);\n\n    image_width = w;\n    image_height = h;\n\n    num_texels = image_width * image_height;\n    num_values = num_texels * 4;\n    size_tex_data = sizeof(GLubyte) * num_values;\n\n    if( cl_pbos[0] != 0 ) {\n\n      glBindBuffer(GL_ARRAY_BUFFER, pbo_source);\n      glBufferData(GL_ARRAY_BUFFER, size_tex_data, NULL, GL_DYNAMIC_DRAW);\n\n      glBindBuffer(GL_ARRAY_BUFFER, pbo_dest);\n      glBufferData(GL_ARRAY_BUFFER, size_tex_data, NULL, GL_DYNAMIC_DRAW);\n\n      glBindBuffer(GL_ARRAY_BUFFER,0);\n\nclReleaseMemObject(cl_pbos[0]);\n\t  clReleaseMemObject(cl_pbos[1]);\n\nif( bGLinterop ) {\n\t\t  cl_pbos[0] = clCreateFromGLBuffer(cxGPUContext, CL_MEM_READ_ONLY, pbo_source, &ciErrNum);\n\t\t  cl_pbos[1] = clCreateFromGLBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, pbo_dest, &ciErrNum);\n\t  } else {\n\t\t  cl_pbos[0] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, 4 * image_width * image_height, NULL, &ciErrNum);\n\t\t  cl_pbos[1] = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, 4 * image_width * image_height, NULL, &ciErrNum);\n\t  }\n\nclSetKernelArg(ckKernel, 0, sizeof(cl_mem), (void *) &(cl_pbos[0]));\n\t  clSetKernelArg(ckKernel, 1, sizeof(cl_mem), (void *) &(cl_pbos[1]));\n      clSetKernelArg(ckKernel, 2, sizeof(cl_int), &image_width);\n      clSetKernelArg(ckKernel, 3, sizeof(cl_int), &image_height);\t\n    }\n\n    glutPostRedisplay();\n}\n\nvoid mainMenu(int i)\n{\n    KeyboardGL((unsigned char) i, 0, 0);\n}\n\nvoid deleteTexture(GLuint* tex)\n{\n    glDeleteTextures(1, tex);\n\n    *tex = 0;\n}\n\nvoid createTexture( GLuint* tex_name, unsigned int size_x, unsigned int size_y)\n{\n\n    glGenTextures(1, tex_name);\n    glBindTexture(GL_TEXTURE_2D, *tex_name);\n\nglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\nglTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA, size_x, size_y, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);\n}\n\nvoid pboRegister()\n{    \n\n    if( bGLinterop ) {\n\t\tglFlush();\n        clEnqueueAcquireGLObjects(cqCommandQueue,2, cl_pbos, 0, NULL, NULL);\n\t} else {\n\nglBindBufferARB(GL_PIXEL_PACK_BUFFER_ARB, pbo_source);    \n\n        GLubyte* ptr = (GLubyte*)glMapBufferARB(GL_PIXEL_PACK_BUFFER_ARB,\n                                            GL_READ_ONLY_ARB);\n\n        clEnqueueWriteBuffer(cqCommandQueue, cl_pbos[0], CL_TRUE, 0, \n                            sizeof(unsigned int) * image_height * image_width, ptr, 0, NULL, NULL);\n        glUnmapBufferARB(GL_PIXEL_PACK_BUFFER_ARB);\n        glBindBufferARB(GL_PIXEL_PACK_BUFFER_ARB, 0);\n\t}\n}\n\nvoid pboUnregister()\n{\n\n    if( bGLinterop ) {\n        clEnqueueReleaseGLObjects(cqCommandQueue,2, cl_pbos, 0, NULL, NULL);\n\t\tclFinish(cqCommandQueue);\n\t} else {\n\nglBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo_dest);    \n\nGLubyte* ptr = (GLubyte*)glMapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB,\n                                            GL_WRITE_ONLY_ARB);\n        clEnqueueReadBuffer(cqCommandQueue, cl_pbos[1], CL_TRUE, 0, \n                            sizeof(unsigned int) * image_height * image_width, ptr, 0, NULL, NULL);        \n        glUnmapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB); \n        glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n\t}\n}\n\nbool InitGL(int* argc, char **argv )\n{\n\n    glutInit(argc, argv);\n    glutInitDisplayMode(GLUT_RGBA | GLUT_ALPHA | GLUT_DOUBLE | GLUT_DEPTH);\n    glutInitWindowPosition (glutGet(GLUT_SCREEN_WIDTH)/2 - iGraphicsWinWidth/2, \n                            glutGet(GLUT_SCREEN_HEIGHT)/2 - iGraphicsWinHeight/2);\n    glutInitWindowSize(iGraphicsWinWidth, iGraphicsWinHeight);\n    iGLUTWindowHandle = glutCreateWindow(\"OpenCL/OpenGL post-processing\");\n#if !(defined (__APPLE__) || defined(MACOSX))\n    glutSetOption(GLUT_ACTION_ON_WINDOW_CLOSE, GLUT_ACTION_GLUTMAINLOOP_RETURNS);\n#endif\n\nglutDisplayFunc(DisplayGL);\n    glutKeyboardFunc(KeyboardGL);\n    glutReshapeFunc(Reshape);\n    glutTimerFunc(REFRESH_DELAY, timerEvent, 0);\n\niGLUTMenuHandle = glutCreateMenu(mainMenu);\n    glutAddMenuEntry(\"Toggle Post-processing (Blur filter) ON/OFF <spacebar>\", ' ');\n    glutAddMenuEntry(\"Toggle Processor between GPU and CPU [p]\", 'p');\n    glutAddMenuEntry(\"Toggle GL animation (rotation) ON/OFF [a]\", 'a');\n    glutAddMenuEntry(\"Increment blur radius [+ or =]\", '=');\n    glutAddMenuEntry(\"Decrement blur radius [- or _]\", '-');\n    glutAddMenuEntry(\"Quit <esc>\", '\\033');\n    glutAttachMenu(GLUT_RIGHT_BUTTON);\n\nglewInit();\n    GLboolean bGLEW = glewIsSupported(\"GL_VERSION_2_0 GL_ARB_pixel_buffer_object\"); \n    oclCheckErrorEX(bGLEW, shrTRUE, pCleanup);\n\nglClearColor(0.5, 0.5, 0.5, 1.0);\n    glDisable(GL_DEPTH_TEST);\n\nglViewport(0, 0, iGraphicsWinWidth, iGraphicsWinHeight);\n\nglMatrixMode(GL_PROJECTION);\n    glLoadIdentity();\n    gluPerspective(60.0, (GLfloat)iGraphicsWinWidth / (GLfloat) iGraphicsWinHeight, 0.1, 10.0);\n    glPolygonMode(GL_FRONT_AND_BACK, GL_FILL);\n    glEnable(GL_LIGHT0);\n    float red[] = { 1.0, 0.1, 0.1, 1.0 };\n    float white[] = { 1.0, 1.0, 1.0, 1.0 };\n    glMaterialfv(GL_FRONT_AND_BACK, GL_DIFFUSE, red);\n    glMaterialfv(GL_FRONT_AND_BACK, GL_SPECULAR, white);\n    glMaterialf(GL_FRONT_AND_BACK, GL_SHININESS, 60.0);\n\n    return true;\n}\n\nvoid createPBO(GLuint* pbo)\n{\n\n    num_texels = image_width * image_height;\n    num_values = num_texels * 4;\n    size_tex_data = sizeof(GLubyte) * num_values;\n\nglGenBuffers(1, pbo);\n    glBindBuffer(GL_ARRAY_BUFFER, *pbo);\n\nglBufferData(GL_ARRAY_BUFFER, size_tex_data, NULL, GL_DYNAMIC_DRAW);\n\n    glBindBuffer(GL_ARRAY_BUFFER, 0);\n}\n\nvoid deletePBO(GLuint* pbo)\n{\n    glBindBuffer(GL_ARRAY_BUFFER, *pbo);\n    glDeleteBuffers(1, pbo);\n\n    *pbo = 0;\n}\n\nvoid renderScene()\n{\n    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);\n\n    glMatrixMode(GL_PROJECTION);\n    glLoadIdentity();\n    gluPerspective(60.0, (GLfloat)iGraphicsWinWidth / (GLfloat) iGraphicsWinHeight, 0.1, 10.0);\n\n    glMatrixMode(GL_MODELVIEW);\n    glLoadIdentity();\n    glTranslatef(0.0, 0.0, -3.0);\n    glRotatef(rotate[0], 1.0, 0.0, 0.0);\n    glRotatef(rotate[1], 0.0, 1.0, 0.0);\n    glRotatef(rotate[2], 0.0, 0.0, 1.0);\n\n    glViewport(0, 0, iGraphicsWinWidth, iGraphicsWinHeight);\n\n    glEnable(GL_LIGHTING);\n    glEnable(GL_DEPTH_TEST);\n    glDepthFunc(GL_LESS);\n\n    glutSolidTeapot(1.0);\n}\n\nint initCL(int argc, const char** argv)\n{\n    cl_platform_id cpPlatform;\n    cl_uint uiDevCount;\n    cl_device_id *cdDevices;\n\nciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\nciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiDevCount);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\ncdDevices = new cl_device_id [uiDevCount];\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiDevCount, cdDevices, NULL);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\nunsigned int uiDeviceUsed = 0;\n    unsigned int uiEndDev = uiDevCount - 1;\n    if(shrGetCmdLineArgumentu(argc, argv, \"device\", &uiDeviceUsed))\n    {\n      uiDeviceUsed = CLAMP(uiDeviceUsed, 0, uiEndDev);\n      uiEndDev = uiDeviceUsed; \n    } \n\nif(bGLinterop && !bQATest)\n    {\n        bool bSharingSupported = false;\n        for(unsigned int i = uiDeviceUsed; (!bSharingSupported && (i <= uiEndDev)); ++i) \n        {\n            size_t extensionSize;\n            ciErrNum = clGetDeviceInfo(cdDevices[i], CL_DEVICE_EXTENSIONS, 0, NULL, &extensionSize );\n            oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n            if(extensionSize > 0) \n            {\n                char* extensions = (char*)malloc(extensionSize);\n                ciErrNum = clGetDeviceInfo(cdDevices[i], CL_DEVICE_EXTENSIONS, extensionSize, extensions, &extensionSize);\n                oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n                std::string stdDevString(extensions);\n                free(extensions);\n\n                size_t szOldPos = 0;\n                size_t szSpacePos = stdDevString.find(' ', szOldPos); // extensions string is space delimited\n                while (szSpacePos != stdDevString.npos)\n                {\n                    if( strcmp(GL_SHARING_EXTENSION, stdDevString.substr(szOldPos, szSpacePos - szOldPos).c_str()) == 0 ) \n                    {\n\n                        uiDeviceUsed = i;\n                        bSharingSupported = true;\n                        break;\n                    }\n                    do \n                    {\n                        szOldPos = szSpacePos + 1;\n                        szSpacePos = stdDevString.find(' ', szOldPos);\n                    } \n                    while (szSpacePos == szOldPos);\n                }\n            }\n        }\n       \n        shrLog(\"%s...\\n\\n\", bSharingSupported ? \"Using CL-GL Interop\" : \"No device found that supports CL/GL context sharing\");  \n        oclCheckErrorEX(bSharingSupported, true, pCleanup);\n\n#if defined (__APPLE__) || defined (MACOSX)\n            CGLContextObj kCGLContext = CGLGetCurrentContext();\n            CGLShareGroupObj kCGLShareGroup = CGLGetShareGroup(kCGLContext);\n            cl_context_properties props[] = \n            {\n                CL_CONTEXT_PROPERTY_USE_CGL_SHAREGROUP_APPLE, (cl_context_properties)kCGLShareGroup, \n                0 \n            };\n            cxGPUContext = clCreateContext(props, 0,0, NULL, NULL, &ciErrNum);\n        #else\n            #ifdef UNIX\n                cl_context_properties props[] = \n                {\n                    CL_GL_CONTEXT_KHR, (cl_context_properties)glXGetCurrentContext(), \n                    CL_GLX_DISPLAY_KHR, (cl_context_properties)glXGetCurrentDisplay(), \n                    CL_CONTEXT_PLATFORM, (cl_context_properties)cpPlatform, \n                    0\n                };\n                cxGPUContext = clCreateContext(props, 1, &cdDevices[uiDeviceUsed], NULL, NULL, &ciErrNum);\n            #else // Win32\n                cl_context_properties props[] = \n                {\n                    CL_GL_CONTEXT_KHR, (cl_context_properties)wglGetCurrentContext(), \n                    CL_WGL_HDC_KHR, (cl_context_properties)wglGetCurrentDC(), \n                    CL_CONTEXT_PLATFORM, (cl_context_properties)cpPlatform, \n                    0\n                };\n                cxGPUContext = clCreateContext(props, 1, &cdDevices[uiDeviceUsed], NULL, NULL, &ciErrNum);\n            #endif\n        #endif\n    }\n    else \n    {\n\n        cl_context_properties props[] = {CL_CONTEXT_PLATFORM, (cl_context_properties)cpPlatform, 0};\n        cxGPUContext = clCreateContext(props, 1, &cdDevices[uiDeviceUsed], NULL, NULL, &ciErrNum);\n\n\t\tbGLinterop = shrFALSE;\n    }\n\n    shrCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\nshrLog(\"Device # %u, \", uiDeviceUsed);\n    oclPrintDevName(LOGBOTH, cdDevices[uiDeviceUsed]);\n    shrLog(\"\\n\");\n\ncqCommandQueue = clCreateCommandQueue(cxGPUContext, cdDevices[uiDeviceUsed], 0, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\nif( bGLinterop ) {\n        cl_pbos[0] = clCreateFromGLBuffer(cxGPUContext, CL_MEM_READ_ONLY, pbo_source, &ciErrNum);\n        cl_pbos[1] = clCreateFromGLBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, pbo_dest, &ciErrNum);\n\t} else {\n        cl_pbos[0] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, 4 * image_width * image_height, NULL, &ciErrNum);\n        cl_pbos[1] = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, 4 * image_width * image_height, NULL, &ciErrNum);\n\t}\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\nsize_t program_length;\n    const char* source_path = shrFindFilePath(clSourcefile, argv[0]);\n    char *source = oclLoadProgSource(source_path, \"\", &program_length);\n    oclCheckErrorEX(source != NULL, shrTRUE, pCleanup);\n\ncpProgram = clCreateProgramWithSource(cxGPUContext, 1,(const char **) &source, &program_length, &ciErrNum);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    free(source);\n\nciErrNum = clBuildProgram(cpProgram, 0, NULL, \"-cl-fast-relaxed-math\", NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclPostProcessGL.ptx\");\n        Cleanup(EXIT_FAILURE); \n    }\n\nckKernel = clCreateKernel(cpProgram, \"postprocess\", &ciErrNum);\n\nciErrNum |= clSetKernelArg(ckKernel, 0, sizeof(cl_mem), (void *) &(cl_pbos[0]));\n    ciErrNum |= clSetKernelArg(ckKernel, 1, sizeof(cl_mem), (void *) &(cl_pbos[1]));\n    ciErrNum |= clSetKernelArg(ckKernel, 2, sizeof(image_width), &image_width);\n    ciErrNum |= clSetKernelArg(ckKernel, 3, sizeof(image_width), &image_height);\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n    \n    return 0;\n}\n\nint executeKernel(cl_int radius)\n{\n\nszLocalWorkSize[0] = 16;\n    szLocalWorkSize[1] = 16;\n    szGlobalWorkSize[0] = shrRoundUp((int)szLocalWorkSize[0], image_width);\n    szGlobalWorkSize[1] = shrRoundUp((int)szLocalWorkSize[1], image_height);\n\ncl_int tilew =  (cl_int)szLocalWorkSize[0]+(2*radius);\n    ciErrNum = clSetKernelArg(ckKernel, 4, sizeof(tilew), &tilew);\n    ciErrNum |= clSetKernelArg(ckKernel, 5, sizeof(radius), &radius);    \n    cl_float threshold = 0.8f;\n    ciErrNum |= clSetKernelArg(ckKernel, 6, sizeof(threshold), &threshold);        \n    cl_float highlight = 4.0f;\n    ciErrNum |= clSetKernelArg(ckKernel, 7, sizeof(highlight), &highlight);            \n\nciErrNum |= clSetKernelArg(ckKernel, 8, (szLocalWorkSize[0]+(2*16))*(szLocalWorkSize[1]+(2*16))*sizeof(int), NULL);\n\n#ifdef GPU_PROFILING\n    int nIter = 30;\n    for( int i=-1; i< nIter; ++i) {\n        if( i ==0 )\n            shrDeltaT(0);\n#endif        \n    ciErrNum |= clEnqueueNDRangeKernel(cqCommandQueue, ckKernel, 2, NULL,\n                                      szGlobalWorkSize, szLocalWorkSize, \n                                     0, NULL, NULL);\n#ifdef GPU_PROFILING\n    }\n    clFinish(cqCommandQueue);\n    double dSeconds = shrDeltaT(0)/(double)nIter;\n    double dNumTexels = (double)image_width * (double)image_height;\n    double mtexps = 1.0e-6 * dNumTexels/dSeconds;\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclPostprocessGL, Throughput = %.4f MTexels/s, Time = %.5f s, Size = %.0f Texels, NumDevsUsed = %u, Workgroup = %u\\n\", \n            mtexps, dSeconds, dNumTexels, uiNumDevsUsed, szLocalWorkSize[0] * szLocalWorkSize[1]);\n\n#endif\n\n    oclCheckErrorEX(ciErrNum, CL_SUCCESS, pCleanup);\n\n    return 0;\n}\n\nvoid processImage()\n{\n\n    glBindBuffer(GL_PIXEL_PACK_BUFFER_ARB, pbo_source);\n\nglReadPixels(0, 0, image_width, image_height, GL_BGRA, GL_UNSIGNED_BYTE, NULL); \n\n    if (bPostprocess)\n    {\n        if (iProcFlag == 0) \n        {\n            pboRegister();\n            executeKernel(blur_radius);\n            pboUnregister();\n        } \n        else \n        {\n\n            glBindBufferARB(GL_PIXEL_PACK_BUFFER_ARB, pbo_source);    \n            glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, pbo_dest);    \n            \n            unsigned int* source_ptr = (unsigned int*)glMapBufferARB(GL_PIXEL_PACK_BUFFER_ARB,\n                                                                     GL_READ_ONLY_ARB);\n            \n            unsigned int* dest_ptr = (unsigned int*)glMapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB,\n                                                                   GL_WRITE_ONLY_ARB);\n\npostprocessHost(source_ptr, dest_ptr, image_width, image_height, 0, blur_radius, 0.8f, 4.0f);\n\nglUnmapBufferARB(GL_PIXEL_PACK_BUFFER_ARB);\n            glBindBufferARB(GL_PIXEL_PACK_BUFFER_ARB, 0);\n            glUnmapBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB); \n            glBindBufferARB(GL_PIXEL_UNPACK_BUFFER_ARB, 0);\n        }\n\nglBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo_dest);\n        glBindTexture(GL_TEXTURE_2D, tex_screen);\n        glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, \n                        image_width, image_height, \n                        GL_BGRA, GL_UNSIGNED_BYTE, NULL);\n\n    } \n    else \n    {\n\n        glBindBuffer(GL_PIXEL_UNPACK_BUFFER_ARB, pbo_source);\n        glBindTexture(GL_TEXTURE_2D, tex_screen);\n        glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, \n                        image_width, image_height, \n                        GL_BGRA, GL_UNSIGNED_BYTE, NULL);\n        \n    }\n}\n\nvoid TriggerFPSUpdate()\n{\n    iFrameCount = 0; \n    shrDeltaT(1);\n    iFramesPerSec = 1;\n    iFrameTrigger = 2;\n}\n\nvoid TestNoGL()\n{\n\n    cl_pbos[0] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, 4 * image_width * image_height, NULL, &ciErrNum);\n    cl_pbos[1] = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, 4 * image_width * image_height, NULL, &ciErrNum);\n\nciErrNum |= clSetKernelArg(ckKernel, 0, sizeof(cl_mem), (void *) &(cl_pbos[0]));\n    ciErrNum |= clSetKernelArg(ckKernel, 1, sizeof(cl_mem), (void *) &(cl_pbos[1]));\n    ciErrNum |= clSetKernelArg(ckKernel, 2, sizeof(image_width), &image_width);\n    ciErrNum |= clSetKernelArg(ckKernel, 3, sizeof(image_width), &image_height);\n\nexecuteKernel(blur_radius);\n\nCleanup(EXIT_SUCCESS);\n}\n\nvoid Cleanup(int iExitCode)\n{\n\n    shrLog(\"\\nStarting Cleanup...\\n\\n\");\n    if(pbo_source)deletePBO(&pbo_source);\n    if(pbo_dest)deletePBO(&pbo_dest);\n    if(tex_screen)deleteTexture(&tex_screen);\n\tif(ckKernel)clReleaseKernel(ckKernel); \n    if(cpProgram)clReleaseProgram(cpProgram);\n    if(cl_pbos[0])clReleaseMemObject(cl_pbos[0]);\n    if(cl_pbos[1])clReleaseMemObject(cl_pbos[1]);    \n    if(cqCommandQueue)clReleaseCommandQueue(cqCommandQueue);\n    if(cxGPUContext)clReleaseContext(cxGPUContext);\n\n    shrLogEx(LOGBOTH | CLOSELOG, 0, \"%s Exiting...\\n\", cExecutableName);\n\nshrQAFinish2(bQATest, *pArgc, (const char **)pArgv, (iExitCode == 0) ? QA_PASSED : QA_FAILED);\n    exit (iExitCode);\n}\n"}, "code_dirs": {"PostprocessGL.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclPostprocessGL", "oclPostprocessGL.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclPostprocessGL"}}
{"kernel_name": "BandwidthTest", "parallel_api": "cuda", "code": {"p2pBandwidthLatencyTest.cu": "#include <cstdio>\n#include <helper_cuda.h>\n#include <helper_timer.h>\n#include <vector>\n\nusing namespace std;\n\nconst char *sSampleName = \"P2P (Peer-to-Peer) GPU Bandwidth Latency Test\";\n\ntypedef enum {\n    P2P_WRITE = 0,\n    P2P_READ  = 1,\n} P2PDataTransfer;\n\ntypedef enum {\n    CE = 0,\n    SM = 1,\n} P2PEngine;\n\nP2PEngine p2p_mechanism = CE;\n\n#define cudaCheckError()                                                                     \\\n    {                                                                                        \\\n        cudaError_t e = cudaGetLastError();                                                  \\\n        if (e != cudaSuccess) {                                                              \\\n            printf(\"Cuda failure %s:%d: '%s'\\n\", __FILE__, __LINE__, cudaGetErrorString(e)); \\\n            exit(EXIT_FAILURE);                                                              \\\n        }                                                                                    \\\n    }\n__global__ void delay(volatile int *flag, unsigned long long timeout_clocks = 10000000)\n{\n    long long int start_clock, sample_clock;\n    start_clock = clock64();\n\n    while (!*flag) {\n        sample_clock = clock64();\n\n        if (sample_clock - start_clock > timeout_clocks) {\n            break;\n        }\n    }\n}\n\n__global__ void copyp2p(int4 *__restrict__ dest, int4 const *__restrict__ src, size_t num_elems)\n{\n    size_t globalId = blockIdx.x * blockDim.x + threadIdx.x;\n    size_t gridSize = blockDim.x * gridDim.x;\n\n#pragma unroll(5)\n    for (size_t i = globalId; i < num_elems; i += gridSize) {\n        dest[i] = src[i];\n    }\n}\n\nvoid printHelp(void)\n{\n    printf(\"Usage:  p2pBandwidthLatencyTest [OPTION]...\\n\");\n    printf(\"Tests bandwidth/latency of GPU pairs using P2P and without P2P\\n\");\n    printf(\"\\n\");\n\n    printf(\"Options:\\n\");\n    printf(\"--help\\t\\tDisplay this help menu\\n\");\n    printf(\"--p2p_read\\tUse P2P reads for data transfers between GPU pairs and show \"\n           \"corresponding results.\\n \\t\\tDefault used is P2P write operation.\\n\");\n    printf(\"--sm_copy                      Use SM intiated p2p transfers instead of Copy Engine\\n\");\n    printf(\"--numElems=<NUM_OF_INT_ELEMS>  Number of integer elements to be used in p2p copy.\\n\");\n}\n\nvoid checkP2Paccess(int numGPUs)\n{\n    for (int i = 0; i < numGPUs; i++) {\n        cudaSetDevice(i);\n        cudaCheckError();\n\n        for (int j = 0; j < numGPUs; j++) {\n            int access;\n            if (i != j) {\n                cudaDeviceCanAccessPeer(&access, i, j);\n                cudaCheckError();\n                printf(\"Device=%d %s Access Peer Device=%d\\n\", i, access ? \"CAN\" : \"CANNOT\", j);\n            }\n        }\n    }\n    printf(\"\\n***NOTE: In case a device doesn't have P2P access to other one, it \"\n           \"falls back to normal memcopy procedure.\\nSo you can see lesser \"\n           \"Bandwidth (GB/s) and unstable Latency (us) in those cases.\\n\\n\");\n}\n\nvoid performP2PCopy(int         *dest,\n                    int          destDevice,\n                    int         *src,\n                    int          srcDevice,\n                    int          num_elems,\n                    int          repeat,\n                    bool         p2paccess,\n                    cudaStream_t streamToRun)\n{\n    int blockSize = 0;\n    int numBlocks = 0;\n\n    cudaOccupancyMaxPotentialBlockSize(&numBlocks, &blockSize, copyp2p);\n    cudaCheckError();\n\n    if (p2p_mechanism == SM && p2paccess) {\n        for (int r = 0; r < repeat; r++) {\n            copyp2p<<<numBlocks, blockSize, 0, streamToRun>>>((int4 *)dest, (int4 *)src, num_elems / 4);\n        }\n    }\n    else {\n        for (int r = 0; r < repeat; r++) {\n            cudaMemcpyPeerAsync(dest, destDevice, src, srcDevice, sizeof(int) * num_elems, streamToRun);\n        }\n    }\n}\n\nvoid outputBandwidthMatrix(int numElems, int numGPUs, bool p2p, P2PDataTransfer p2p_method)\n{\n    int                  repeat = 5;\n    volatile int        *flag   = NULL;\n    vector<int *>        buffers(numGPUs);\n    vector<int *>        buffersD2D(numGPUs); // buffer for D2D, that is, intra-GPU copy\n    vector<cudaEvent_t>  start(numGPUs);\n    vector<cudaEvent_t>  stop(numGPUs);\n    vector<cudaStream_t> stream(numGPUs);\n\n    cudaHostAlloc((void **)&flag, sizeof(*flag), cudaHostAllocPortable);\n    cudaCheckError();\n\n    for (int d = 0; d < numGPUs; d++) {\n        cudaSetDevice(d);\n        cudaStreamCreateWithFlags(&stream[d], cudaStreamNonBlocking);\n        cudaMalloc(&buffers[d], numElems * sizeof(int));\n        cudaCheckError();\n        cudaMemset(buffers[d], 0, numElems * sizeof(int));\n        cudaCheckError();\n        cudaMalloc(&buffersD2D[d], numElems * sizeof(int));\n        cudaCheckError();\n        cudaMemset(buffersD2D[d], 0, numElems * sizeof(int));\n        cudaCheckError();\n        cudaEventCreate(&start[d]);\n        cudaCheckError();\n        cudaEventCreate(&stop[d]);\n        cudaCheckError();\n    }\n\n    vector<double> bandwidthMatrix(numGPUs * numGPUs);\n\n    for (int i = 0; i < numGPUs; i++) {\n        cudaSetDevice(i);\n\n        for (int j = 0; j < numGPUs; j++) {\n            int access = 0;\n            if (p2p) {\n                cudaDeviceCanAccessPeer(&access, i, j);\n                if (access) {\n                    cudaDeviceEnablePeerAccess(j, 0);\n                    cudaCheckError();\n                    cudaSetDevice(j);\n                    cudaCheckError();\n                    cudaDeviceEnablePeerAccess(i, 0);\n                    cudaCheckError();\n                    cudaSetDevice(i);\n                    cudaCheckError();\n                }\n            }\n\n            cudaStreamSynchronize(stream[i]);\n            cudaCheckError();\n\n            *flag = 0;\n            delay<<<1, 1, 0, stream[i]>>>(flag);\n            cudaCheckError();\n            cudaEventRecord(start[i], stream[i]);\n            cudaCheckError();\n\n            if (i == j) {\n                // Perform intra-GPU, D2D copies\n                performP2PCopy(buffers[i], i, buffersD2D[i], i, numElems, repeat, access, stream[i]);\n            }\n            else {\n                if (p2p_method == P2P_WRITE) {\n                    performP2PCopy(buffers[j], j, buffers[i], i, numElems, repeat, access, stream[i]);\n                }\n                else {\n                    performP2PCopy(buffers[i], i, buffers[j], j, numElems, repeat, access, stream[i]);\n                }\n            }\n\n            cudaEventRecord(stop[i], stream[i]);\n            cudaCheckError();\n\n            *flag = 1;\n            cudaStreamSynchronize(stream[i]);\n            cudaCheckError();\n\n            float time_ms;\n            cudaEventElapsedTime(&time_ms, start[i], stop[i]);\n            double time_s = time_ms / 1e3;\n\n            double gb = numElems * sizeof(int) * repeat / (double)1e9;\n            if (i == j) {\n                gb *= 2;\n            }\n            bandwidthMatrix[i * numGPUs + j] = gb / time_s;\n            if (p2p && access) {\n                cudaDeviceDisablePeerAccess(j);\n                cudaSetDevice(j);\n                cudaDeviceDisablePeerAccess(i);\n                cudaSetDevice(i);\n                cudaCheckError();\n            }\n        }\n    }\n\n    printf(\"   D\\\\D\");\n\n    for (int j = 0; j < numGPUs; j++) {\n        printf(\"%6d \", j);\n    }\n\n    printf(\"\\n\");\n\n    for (int i = 0; i < numGPUs; i++) {\n        printf(\"%6d \", i);\n\n        for (int j = 0; j < numGPUs; j++) {\n            printf(\"%6.02f \", bandwidthMatrix[i * numGPUs + j]);\n        }\n\n        printf(\"\\n\");\n    }\n\n    for (int d = 0; d < numGPUs; d++) {\n        cudaSetDevice(d);\n        cudaFree(buffers[d]);\n        cudaFree(buffersD2D[d]);\n        cudaCheckError();\n        cudaEventDestroy(start[d]);\n        cudaCheckError();\n        cudaEventDestroy(stop[d]);\n        cudaCheckError();\n        cudaStreamDestroy(stream[d]);\n        cudaCheckError();\n    }\n\n    cudaFreeHost((void *)flag);\n    cudaCheckError();\n}\n\nvoid outputBidirectionalBandwidthMatrix(int numElems, int numGPUs, bool p2p)\n{\n    int                  repeat = 5;\n    volatile int        *flag   = NULL;\n    vector<int *>        buffers(numGPUs);\n    vector<int *>        buffersD2D(numGPUs);\n    vector<cudaEvent_t>  start(numGPUs);\n    vector<cudaEvent_t>  stop(numGPUs);\n    vector<cudaStream_t> stream0(numGPUs);\n    vector<cudaStream_t> stream1(numGPUs);\n\n    cudaHostAlloc((void **)&flag, sizeof(*flag), cudaHostAllocPortable);\n    cudaCheckError();\n\n    for (int d = 0; d < numGPUs; d++) {\n        cudaSetDevice(d);\n        cudaMalloc(&buffers[d], numElems * sizeof(int));\n        cudaMemset(buffers[d], 0, numElems * sizeof(int));\n        cudaMalloc(&buffersD2D[d], numElems * sizeof(int));\n        cudaMemset(buffersD2D[d], 0, numElems * sizeof(int));\n        cudaCheckError();\n        cudaEventCreate(&start[d]);\n        cudaCheckError();\n        cudaEventCreate(&stop[d]);\n        cudaCheckError();\n        cudaStreamCreateWithFlags(&stream0[d], cudaStreamNonBlocking);\n        cudaCheckError();\n        cudaStreamCreateWithFlags(&stream1[d], cudaStreamNonBlocking);\n        cudaCheckError();\n    }\n\n    vector<double> bandwidthMatrix(numGPUs * numGPUs);\n\n    for (int i = 0; i < numGPUs; i++) {\n        cudaSetDevice(i);\n\n        for (int j = 0; j < numGPUs; j++) {\n            int access = 0;\n            if (p2p) {\n                cudaDeviceCanAccessPeer(&access, i, j);\n                if (access) {\n                    cudaSetDevice(i);\n                    cudaDeviceEnablePeerAccess(j, 0);\n                    cudaCheckError();\n                    cudaSetDevice(j);\n                    cudaDeviceEnablePeerAccess(i, 0);\n                    cudaCheckError();\n                }\n            }\n\n            cudaSetDevice(i);\n            cudaStreamSynchronize(stream0[i]);\n            cudaStreamSynchronize(stream1[j]);\n            cudaCheckError();\n\n            *flag = 0;\n            cudaSetDevice(i);\n            delay<<<1, 1, 0, stream0[i]>>>(flag);\n            cudaCheckError();\n\n            cudaEventRecord(start[i], stream0[i]);\n            cudaStreamWaitEvent(stream1[j], start[i], 0);\n\n            if (i == j) {\n                performP2PCopy(buffers[i], i, buffersD2D[i], i, numElems, repeat, access, stream0[i]);\n                performP2PCopy(buffersD2D[i], i, buffers[i], i, numElems, repeat, access, stream1[i]);\n            }\n            else {\n                if (access && p2p_mechanism == SM) {\n                    cudaSetDevice(j);\n                }\n                performP2PCopy(buffers[i], i, buffers[j], j, numElems, repeat, access, stream1[j]);\n                if (access && p2p_mechanism == SM) {\n                    cudaSetDevice(i);\n                }\n                performP2PCopy(buffers[j], j, buffers[i], i, numElems, repeat, access, stream0[i]);\n            }\n\n            cudaEventRecord(stop[j], stream1[j]);\n            cudaStreamWaitEvent(stream0[i], stop[j], 0);\n            cudaEventRecord(stop[i], stream0[i]);\n\n            *flag = 1;\n            cudaStreamSynchronize(stream0[i]);\n            cudaStreamSynchronize(stream1[j]);\n            cudaCheckError();\n\n            float time_ms;\n            cudaEventElapsedTime(&time_ms, start[i], stop[i]);\n            double time_s = time_ms / 1e3;\n\n            double gb = 2.0 * numElems * sizeof(int) * repeat / (double)1e9;\n            if (i == j) {\n                gb *= 2;\n            }\n            bandwidthMatrix[i * numGPUs + j] = gb / time_s;\n            if (p2p && access) {\n                cudaSetDevice(i);\n                cudaDeviceDisablePeerAccess(j);\n                cudaSetDevice(j);\n                cudaDeviceDisablePeerAccess(i);\n            }\n        }\n    }\n\n    printf(\"   D\\\\D\");\n\n    for (int j = 0; j < numGPUs; j++) {\n        printf(\"%6d \", j);\n    }\n\n    printf(\"\\n\");\n\n    for (int i = 0; i < numGPUs; i++) {\n        printf(\"%6d \", i);\n\n        for (int j = 0; j < numGPUs; j++) {\n            printf(\"%6.02f \", bandwidthMatrix[i * numGPUs + j]);\n        }\n\n        printf(\"\\n\");\n    }\n\n    for (int d = 0; d < numGPUs; d++) {\n        cudaSetDevice(d);\n        cudaFree(buffers[d]);\n        cudaFree(buffersD2D[d]);\n        cudaCheckError();\n        cudaEventDestroy(start[d]);\n        cudaCheckError();\n        cudaEventDestroy(stop[d]);\n        cudaCheckError();\n        cudaStreamDestroy(stream0[d]);\n        cudaCheckError();\n        cudaStreamDestroy(stream1[d]);\n        cudaCheckError();\n    }\n\n    cudaFreeHost((void *)flag);\n    cudaCheckError();\n}\n\nvoid outputLatencyMatrix(int numGPUs, bool p2p, P2PDataTransfer p2p_method)\n{\n    int                  repeat    = 100;\n    int                  numElems  = 4;\n    volatile int        *flag      = NULL;\n    StopWatchInterface  *stopWatch = NULL;\n    vector<int *>        buffers(numGPUs);\n    vector<int *>        buffersD2D(numGPUs);\n    vector<cudaStream_t> stream(numGPUs);\n    vector<cudaEvent_t>  start(numGPUs);\n    vector<cudaEvent_t>  stop(numGPUs);\n\n    cudaHostAlloc((void **)&flag, sizeof(*flag), cudaHostAllocPortable);\n    cudaCheckError();\n\n    if (!sdkCreateTimer(&stopWatch)) {\n        printf(\"Failed to create stop watch\\n\");\n        exit(EXIT_FAILURE);\n    }\n    sdkStartTimer(&stopWatch);\n\n    for (int d = 0; d < numGPUs; d++) {\n        cudaSetDevice(d);\n        cudaStreamCreateWithFlags(&stream[d], cudaStreamNonBlocking);\n        cudaMalloc(&buffers[d], sizeof(int) * numElems);\n        cudaMemset(buffers[d], 0, sizeof(int) * numElems);\n        cudaMalloc(&buffersD2D[d], sizeof(int) * numElems);\n        cudaMemset(buffersD2D[d], 0, sizeof(int) * numElems);\n        cudaCheckError();\n        cudaEventCreate(&start[d]);\n        cudaCheckError();\n        cudaEventCreate(&stop[d]);\n        cudaCheckError();\n    }\n\n    vector<double> gpuLatencyMatrix(numGPUs * numGPUs);\n    vector<double> cpuLatencyMatrix(numGPUs * numGPUs);\n\n    for (int i = 0; i < numGPUs; i++) {\n        cudaSetDevice(i);\n\n        for (int j = 0; j < numGPUs; j++) {\n            int access = 0;\n            if (p2p) {\n                cudaDeviceCanAccessPeer(&access, i, j);\n                if (access) {\n                    cudaDeviceEnablePeerAccess(j, 0);\n                    cudaCheckError();\n                    cudaSetDevice(j);\n                    cudaDeviceEnablePeerAccess(i, 0);\n                    cudaSetDevice(i);\n                    cudaCheckError();\n                }\n            }\n            cudaStreamSynchronize(stream[i]);\n            cudaCheckError();\n\n            *flag = 0;\n            delay<<<1, 1, 0, stream[i]>>>(flag);\n            cudaCheckError();\n            cudaEventRecord(start[i], stream[i]);\n\n            sdkResetTimer(&stopWatch);\n            if (i == j) {\n                // Perform intra-GPU, D2D copies\n                performP2PCopy(buffers[i], i, buffersD2D[i], i, numElems, repeat, access, stream[i]);\n            }\n            else {\n                if (p2p_method == P2P_WRITE) {\n                    performP2PCopy(buffers[j], j, buffers[i], i, numElems, repeat, access, stream[i]);\n                }\n                else {\n                    performP2PCopy(buffers[i], i, buffers[j], j, numElems, repeat, access, stream[i]);\n                }\n            }\n            float cpu_time_ms = sdkGetTimerValue(&stopWatch);\n\n            cudaEventRecord(stop[i], stream[i]);\n            *flag = 1;\n            cudaStreamSynchronize(stream[i]);\n            cudaCheckError();\n\n            float gpu_time_ms;\n            cudaEventElapsedTime(&gpu_time_ms, start[i], stop[i]);\n\n            gpuLatencyMatrix[i * numGPUs + j] = gpu_time_ms * 1e3 / repeat;\n            cpuLatencyMatrix[i * numGPUs + j] = cpu_time_ms * 1e3 / repeat;\n            if (p2p && access) {\n                cudaDeviceDisablePeerAccess(j);\n                cudaSetDevice(j);\n                cudaDeviceDisablePeerAccess(i);\n                cudaSetDevice(i);\n                cudaCheckError();\n            }\n        }\n    }\n\n    printf(\"   GPU\");\n\n    for (int j = 0; j < numGPUs; j++) {\n        printf(\"%6d \", j);\n    }\n\n    printf(\"\\n\");\n\n    for (int i = 0; i < numGPUs; i++) {\n        printf(\"%6d \", i);\n\n        for (int j = 0; j < numGPUs; j++) {\n            printf(\"%6.02f \", gpuLatencyMatrix[i * numGPUs + j]);\n        }\n\n        printf(\"\\n\");\n    }\n\n    printf(\"\\n   CPU\");\n\n    for (int j = 0; j < numGPUs; j++) {\n        printf(\"%6d \", j);\n    }\n\n    printf(\"\\n\");\n\n    for (int i = 0; i < numGPUs; i++) {\n        printf(\"%6d \", i);\n\n        for (int j = 0; j < numGPUs; j++) {\n            printf(\"%6.02f \", cpuLatencyMatrix[i * numGPUs + j]);\n        }\n\n        printf(\"\\n\");\n    }\n\n    for (int d = 0; d < numGPUs; d++) {\n        cudaSetDevice(d);\n        cudaFree(buffers[d]);\n        cudaFree(buffersD2D[d]);\n        cudaCheckError();\n        cudaEventDestroy(start[d]);\n        cudaCheckError();\n        cudaEventDestroy(stop[d]);\n        cudaCheckError();\n        cudaStreamDestroy(stream[d]);\n        cudaCheckError();\n    }\n\n    sdkDeleteTimer(&stopWatch);\n\n    cudaFreeHost((void *)flag);\n    cudaCheckError();\n}\n\nint main(int argc, char **argv)\n{\n    int             numGPUs, numElems = 40000000;\n    P2PDataTransfer p2p_method = P2P_WRITE;\n\n    cudaGetDeviceCount(&numGPUs);\n    cudaCheckError();\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"help\")) {\n        printHelp();\n        return 0;\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"p2p_read\")) {\n        p2p_method = P2P_READ;\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"sm_copy\")) {\n        p2p_mechanism = SM;\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"numElems\")) {\n        numElems = getCmdLineArgumentInt(argc, (const char **)argv, \"numElems\");\n    }\n\n    printf(\"[%s]\\n\", sSampleName);\n\n    for (int i = 0; i < numGPUs; i++) {\n        cudaDeviceProp prop;\n        cudaGetDeviceProperties(&prop, i);\n        cudaCheckError();\n        printf(\"Device: %d, %s, pciBusID: %x, pciDeviceID: %x, pciDomainID:%x\\n\",\n               i,\n               prop.name,\n               prop.pciBusID,\n               prop.pciDeviceID,\n               prop.pciDomainID);\n    }\n\n    checkP2Paccess(numGPUs);\n\n    printf(\"P2P Connectivity Matrix\\n\");\n    printf(\"     D\\\\D\");\n\n    for (int j = 0; j < numGPUs; j++) {\n        printf(\"%6d\", j);\n    }\n    printf(\"\\n\");\n\n    for (int i = 0; i < numGPUs; i++) {\n        printf(\"%6d\\t\", i);\n        for (int j = 0; j < numGPUs; j++) {\n            if (i != j) {\n                int access;\n                cudaDeviceCanAccessPeer(&access, i, j);\n                cudaCheckError();\n                printf(\"%6d\", (access) ? 1 : 0);\n            }\n            else {\n                printf(\"%6d\", 1);\n            }\n        }\n        printf(\"\\n\");\n    }\n\n    printf(\"Unidirectional P2P=Disabled Bandwidth Matrix (GB/s)\\n\");\n    outputBandwidthMatrix(numElems, numGPUs, false, P2P_WRITE);\n    printf(\"Unidirectional P2P=Enabled Bandwidth (P2P Writes) Matrix (GB/s)\\n\");\n    outputBandwidthMatrix(numElems, numGPUs, true, P2P_WRITE);\n    if (p2p_method == P2P_READ) {\n        printf(\"Unidirectional P2P=Enabled Bandwidth (P2P Reads) Matrix (GB/s)\\n\");\n        outputBandwidthMatrix(numElems, numGPUs, true, p2p_method);\n    }\n    printf(\"Bidirectional P2P=Disabled Bandwidth Matrix (GB/s)\\n\");\n    outputBidirectionalBandwidthMatrix(numElems, numGPUs, false);\n    printf(\"Bidirectional P2P=Enabled Bandwidth Matrix (GB/s)\\n\");\n    outputBidirectionalBandwidthMatrix(numElems, numGPUs, true);\n\n    printf(\"P2P=Disabled Latency Matrix (us)\\n\");\n    outputLatencyMatrix(numGPUs, false, P2P_WRITE);\n    printf(\"P2P=Enabled Latency (P2P Writes) Matrix (us)\\n\");\n    outputLatencyMatrix(numGPUs, true, P2P_WRITE);\n    if (p2p_method == P2P_READ) {\n        printf(\"P2P=Enabled Latency (P2P Reads) Matrix (us)\\n\");\n        outputLatencyMatrix(numGPUs, true, p2p_method);\n    }\n\n    printf(\"\\nNOTE: The CUDA Samples are not meant for performance measurements. \"\n           \"Results may vary when GPU Boost is enabled.\\n\");\n\n    exit(EXIT_SUCCESS);\n}\n"}, "code_dirs": {"p2pBandwidthLatencyTest.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/5_Domain_Specific/p2pBandwidthLatencyTest"}}
{"kernel_name": "BandwidthTest", "parallel_api": "ocl", "code": {"oclBandwidthTest.cpp": "#include <oclUtils.h>\n#include <shrQATest.h>\n\n#include <memory>\n#include <iostream>\n#include <cassert>\n\n#define MEMCOPY_ITERATIONS  100\n#define DEFAULT_SIZE        ( 32 * ( 1 << 20 ) )\n#define DEFAULT_INCREMENT   (1 << 22)\n#define CACHE_CLEAR_SIZE    (1 << 24)\n\n#define SHMOO_MEMSIZE_MAX     (1 << 26)\n#define SHMOO_MEMSIZE_START   (1 << 10)\n#define SHMOO_INCREMENT_1KB   (1 << 10)\n#define SHMOO_INCREMENT_2KB   (1 << 11)\n#define SHMOO_INCREMENT_10KB  (10 * (1 << 10))\n#define SHMOO_INCREMENT_100KB (100 * (1 << 10))\n#define SHMOO_INCREMENT_1MB   (1 << 20)\n#define SHMOO_INCREMENT_2MB   (1 << 21)\n#define SHMOO_INCREMENT_4MB   (1 << 22)\n#define SHMOO_LIMIT_20KB      (20 * (1 << 10))\n#define SHMOO_LIMIT_50KB      (50 * (1 << 10))\n#define SHMOO_LIMIT_100KB     (100 * (1 << 10))\n#define SHMOO_LIMIT_1MB       (1 << 20)\n#define SHMOO_LIMIT_16MB      (1 << 24)\n#define SHMOO_LIMIT_32MB      (1 << 25)\n\nenum testMode { QUICK_MODE, RANGE_MODE, SHMOO_MODE };\nenum memcpyKind { DEVICE_TO_HOST, HOST_TO_DEVICE, DEVICE_TO_DEVICE };\nenum printMode { USER_READABLE, CSV };\nenum memoryMode { PAGEABLE, PINNED };\nenum accessMode { MAPPED, DIRECT };\n\ncl_context cxGPUContext;\ncl_command_queue cqCommandQueue;\ncl_device_id *devices;\n\n\nint runTest(const int argc, const char **argv);\nvoid createQueue(unsigned int device);\nvoid testBandwidth( unsigned int start, unsigned int end, unsigned int increment, \n                    testMode mode, memcpyKind kind, printMode printmode, accessMode accMode, memoryMode memMode, int startDevice, int endDevice);\nvoid testBandwidthQuick(unsigned int size, memcpyKind kind, printMode printmode, accessMode accMode, memoryMode memMode, int startDevice, int endDevice);\nvoid testBandwidthRange(unsigned int start, unsigned int end, unsigned int increment, \n                        memcpyKind kind, printMode printmode, accessMode accMode, memoryMode memMode, int startDevice, int endDevice);\nvoid testBandwidthShmoo(memcpyKind kind, printMode printmode,accessMode accMode,  memoryMode memMode, int startDevice, int endDevice);\ndouble testDeviceToHostTransfer(unsigned int memSize, accessMode accMode, memoryMode memMode);\ndouble testHostToDeviceTransfer(unsigned int memSize, accessMode accMode, memoryMode memMode);\ndouble testDeviceToDeviceTransfer(unsigned int memSize);\nvoid printResultsReadable(unsigned int *memSizes, double* bandwidths, unsigned int count, memcpyKind kind, accessMode accMode, memoryMode memMode, int iNumDevs);\nvoid printResultsCSV(unsigned int *memSizes, double* bandwidths, unsigned int count, memcpyKind kind, accessMode accMode, memoryMode memMode, int iNumDevs);\nvoid printHelp(void);\n\nint main(int argc, char** argv) \n{\n    shrQAStart(argc, argv);\n\n    shrSetLogFileName (\"oclBandwidthTest.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    int iRetVal = runTest(argc, (const char **)argv);\n\n    shrQAFinishExit(argc, (const char **)argv, (iRetVal == 0) ? QA_PASSED : QA_FAILED);\n}\n\nint runTest(const int argc, const char **argv)\n{\n    int start = DEFAULT_SIZE;\n    int end = DEFAULT_SIZE;\n    int startDevice = 0;\n    int endDevice = 0;\n    int increment = DEFAULT_INCREMENT;\n    testMode mode = QUICK_MODE;\n    bool htod = false;\n    bool dtoh = false;\n    bool dtod = false;\n    char *modeStr;\n    char *device = NULL;\n    printMode printmode = USER_READABLE;\n    char *memModeStr = NULL;\n    memoryMode memMode = PAGEABLE;\n    accessMode accMode = DIRECT;\n\n    if(shrCheckCmdLineFlag( argc, argv, \"help\"))\n    {\n        printHelp();\n        return 0;\n    }\n\n    if(shrCheckCmdLineFlag( argc, argv, \"csv\"))\n    {\n        printmode = CSV;\n    }\n\n    if(shrGetCmdLineArgumentstr(argc, argv, \"memory\", &memModeStr))\n    {\n        if(strcmp(memModeStr, \"pageable\") == 0 )\n        {\n            memMode = PAGEABLE;\n        }\n        else if(strcmp(memModeStr, \"pinned\") == 0)\n        {\n            memMode = PINNED;\n        }\n        else\n        {\n            shrLog(\"Invalid memory mode - valid modes are pageable or pinned\\n\");\n            shrLog(\"See --help for more information\\n\");\n            return -1000;\n        }\n    }\n    else\n    {\n        memMode = PAGEABLE;\n    }\n   \n    if(shrGetCmdLineArgumentstr(argc, argv, \"access\", &memModeStr))\n    {\n        if(strcmp(memModeStr, \"direct\") == 0)\n        {\n            accMode = DIRECT;\n        }\n        else if(strcmp(memModeStr, \"mapped\") == 0)\n        {\n            accMode = MAPPED;\n        }\n        else\n        {\n            shrLog(\"Invalid access mode - valid modes are direct or mapped\\n\");\n            shrLog(\"See --help for more information\\n\");\n            return -2000;\n        }\n    }\n    else\n    {\n        accMode = DIRECT;\n    }\n\n    cl_platform_id clSelectedPlatformID = NULL; \n    cl_int ciErrNum = oclGetPlatformID (&clSelectedPlatformID);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    cl_uint ciDeviceCount;\n    ciErrNum = clGetDeviceIDs (clSelectedPlatformID, CL_DEVICE_TYPE_GPU, 0, NULL, &ciDeviceCount);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        shrLog(\" Error %i in clGetDeviceIDs call !!!\\n\\n\", ciErrNum);\n        return ciErrNum;\n    }\n    else if (ciDeviceCount == 0)\n    {\n        shrLog(\" There are no devices supporting OpenCL (return code %i)\\n\\n\", ciErrNum);\n        return ciErrNum;\n    } \n\n    if(shrGetCmdLineArgumentstr(argc, argv, \"device\", &device))\n    {\n        if(strcmp (device, \"all\") == 0)\n        {\n            shrLog(\"\\n!!!Cumulative Bandwidth to be computed from all the devices !!!\\n\\n\");\n            startDevice = 0;\n            endDevice = (int)(ciDeviceCount-1);\n        }\n        else\n        {\n            startDevice = endDevice = atoi(device);\n            if(startDevice < 0 || ((size_t)startDevice) >= ciDeviceCount)\n            {\n                shrLog(\"\\n!!!Invalid GPU number %d given hence default gpu %d will be used !!!\\n\", startDevice,0);\n                startDevice = endDevice = 0;\n            }\n        }\n    }\n     \n    shrLog(\"Running on...\\n\\n\");\n    devices = (cl_device_id*) malloc(sizeof(cl_device_id) * ciDeviceCount);\n    ciErrNum = clGetDeviceIDs (clSelectedPlatformID, CL_DEVICE_TYPE_GPU, ciDeviceCount, devices, &ciDeviceCount);\n    for(int currentDevice = startDevice; currentDevice <= endDevice; currentDevice++)\n    {\n        oclPrintDevName(LOGBOTH, devices[currentDevice]);\n        shrLog(\"\\n\");\n    }\n    shrLog(\"\\n\");\n\n    if(shrGetCmdLineArgumentstr(argc, argv, \"mode\", &modeStr))\n    {\n        if(strcmp(modeStr, \"quick\") == 0)\n        {\n            shrLog(\"Quick Mode\\n\\n\");\n            mode = QUICK_MODE;\n        }\n        else if(strcmp(modeStr, \"shmoo\") == 0)\n        {\n            shrLog(\"Shmoo Mode\\n\\n\");\n            mode = SHMOO_MODE;\n        }\n        else if(strcmp(modeStr, \"range\") == 0)\n        {\n            shrLog(\"Range Mode\\n\\n\");\n            mode = RANGE_MODE;\n        }\n        else\n        {\n            shrLog(\"Invalid mode - valid modes are quick, range, or shmoo\\n\");\n            shrLog(\"See --help for more information\\n\\n\");\n            return -3000;\n        }\n    }\n    else\n    {\n        shrLog(\"Quick Mode\\n\\n\");\n        mode = QUICK_MODE;\n    }\n    \n    if(shrCheckCmdLineFlag(argc, argv, \"htod\"))\n        htod = true;\n    if(shrCheckCmdLineFlag(argc, argv, \"dtoh\"))\n        dtoh = true;\n    if(shrCheckCmdLineFlag(argc, argv, \"dtod\"))\n        dtod = true;\n\n    if(!htod && !dtoh && !dtod)\n    {\n        htod = true;\n        dtoh = true;\n        dtod = true;\n    }\n\n    if(RANGE_MODE == mode)\n    {\n        if(shrGetCmdLineArgumenti( argc, argv, \"start\", &start))\n        {\n            if( start <= 0 )\n            {\n                shrLog(\"Illegal argument - start must be greater than zero\\n\");\n                return -4000;\n            }   \n        }\n        else\n        {\n            shrLog(\"Must specify a starting size in range mode\\n\");\n            shrLog(\"See --help for more information\\n\");\n            return -5000;\n        }\n\n        if(shrGetCmdLineArgumenti( argc, argv, \"end\", &end))\n        {\n            if(end <= 0)\n            {\n                shrLog(\"Illegal argument - end must be greater than zero\\n\");\n                return -6000;\n            }\n\n            if(start > end)\n            {\n                shrLog(\"Illegal argument - start is greater than end\\n\");\n                return -7000;\n            }\n        }\n        else\n        {\n            shrLog(\"Must specify an end size in range mode.\\n\");\n            shrLog(\"See --help for more information\\n\");\n            return -8000;\n        }\n\n        if(shrGetCmdLineArgumenti( argc, argv, \"increment\", &increment))\n        {\n            if(increment <= 0)\n            {\n                shrLog(\"Illegal argument - increment must be greater than zero\\n\");\n                return -9000;\n            }\n        }\n        else\n        {\n            shrLog(\"Must specify an increment in user mode\\n\");\n            shrLog(\"See --help for more information\\n\");\n            return -10000;\n        }\n    }\n   \n    cxGPUContext = clCreateContext(0, ciDeviceCount, devices, NULL, NULL, NULL);\n    if (cxGPUContext == (cl_context)0) \n    {\n        shrLog(\"Failed to create OpenCL context!\\n\");\n        return -11000;    \n    }\n\n    if(htod)\n    {\n        testBandwidth((unsigned int)start, (unsigned int)end, (unsigned int)increment, \n                      mode, HOST_TO_DEVICE, printmode, accMode, memMode, startDevice, endDevice);\n    }                       \n    if(dtoh)\n    {\n        testBandwidth((unsigned int)start, (unsigned int)end, (unsigned int)increment,\n                      mode, DEVICE_TO_HOST, printmode, accMode, memMode, startDevice, endDevice);\n    }                       \n    if(dtod)\n    {\n        testBandwidth((unsigned int)start, (unsigned int)end, (unsigned int)increment,\n                      mode, DEVICE_TO_DEVICE, printmode, accMode, memMode, startDevice, endDevice);\n    }                       \n\n    free(memModeStr); \n    if(cqCommandQueue)clReleaseCommandQueue(cqCommandQueue);\n    if(cxGPUContext)clReleaseContext(cxGPUContext);\n    if(devices)free(devices);\n    \n    return 0;\n}\n\nvoid\ncreateQueue(unsigned int device)\n{\n    if(cqCommandQueue) \n    {\n        clReleaseCommandQueue(cqCommandQueue);\n    }\n  \n    cqCommandQueue = clCreateCommandQueue(cxGPUContext, devices[device], CL_QUEUE_PROFILING_ENABLE, NULL);\n}\n  \nvoid\ntestBandwidth(unsigned int start, unsigned int end, unsigned int increment, \n              testMode mode, memcpyKind kind, printMode printmode, accessMode accMode, \n              memoryMode memMode, int startDevice, int endDevice)\n{\n    switch(mode)\n    {\n    case QUICK_MODE:\n        testBandwidthQuick( DEFAULT_SIZE, kind, printmode, accMode, memMode, startDevice, endDevice);\n        break;\n    case RANGE_MODE:\n        testBandwidthRange(start, end, increment, kind, printmode, accMode, memMode, startDevice, endDevice);\n        break;\n    case SHMOO_MODE: \n        testBandwidthShmoo(kind, printmode, accMode, memMode, startDevice, endDevice);\n        break;\n    default:  \n        break;\n    }\n\n}\n\nvoid\ntestBandwidthQuick(unsigned int size, memcpyKind kind, printMode printmode, accessMode accMode, \n                   memoryMode memMode, int startDevice, int endDevice)\n{\n    testBandwidthRange(size, size, DEFAULT_INCREMENT, kind, printmode, accMode, memMode, startDevice, endDevice);\n}\n\nvoid\ntestBandwidthRange(unsigned int start, unsigned int end, unsigned int increment, \n                   memcpyKind kind, printMode printmode, accessMode accMode, memoryMode memMode, int startDevice, int endDevice)\n{\n    unsigned int count = 1 + ((end - start) / increment);\n    \n    unsigned int * memSizes = (unsigned int *)malloc(count * sizeof( unsigned int ));\n    double* bandwidths = (double*)malloc(count * sizeof(double));\n\n    for (unsigned int i = 0; i < count; i++)\n        bandwidths[i] = 0.0;\n\n    for (int currentDevice = startDevice; currentDevice <= endDevice; currentDevice++)\n    {\n        createQueue(currentDevice);\n\n        for(unsigned int i = 0; i < count; i++)\n        {\n            memSizes[i] = start + i * increment;\n            switch(kind)\n            {\n            case DEVICE_TO_HOST:    bandwidths[i] += testDeviceToHostTransfer(memSizes[i], accMode, memMode);\n                break;\n            case HOST_TO_DEVICE:    bandwidths[i] += testHostToDeviceTransfer(memSizes[i], accMode, memMode);\n                break;\n            case DEVICE_TO_DEVICE:  bandwidths[i] += testDeviceToDeviceTransfer(memSizes[i]);\n                break;\n            }\n        }\n    }\n\n    if(printmode == CSV)\n    {\n        printResultsCSV(memSizes, bandwidths, count, kind, accMode, memMode, (1 + endDevice - startDevice));\n    }\n    else\n    {\n        printResultsReadable(memSizes, bandwidths, count, kind, accMode, memMode, (1 + endDevice - startDevice));\n    }\n\n    free(memSizes);\n    free(bandwidths);\n}\n\nvoid testBandwidthShmoo(memcpyKind kind, printMode printmode, accessMode accMode, \n                   memoryMode memMode, int startDevice, int endDevice)\n{\n    unsigned int count = 1 + (SHMOO_LIMIT_20KB  / SHMOO_INCREMENT_1KB)\n        + ((SHMOO_LIMIT_50KB - SHMOO_LIMIT_20KB) / SHMOO_INCREMENT_2KB)\n        + ((SHMOO_LIMIT_100KB - SHMOO_LIMIT_50KB) / SHMOO_INCREMENT_10KB)\n        + ((SHMOO_LIMIT_1MB - SHMOO_LIMIT_100KB) / SHMOO_INCREMENT_100KB)\n        + ((SHMOO_LIMIT_16MB - SHMOO_LIMIT_1MB) / SHMOO_INCREMENT_1MB)\n        + ((SHMOO_LIMIT_32MB - SHMOO_LIMIT_16MB) / SHMOO_INCREMENT_2MB)\n        + ((SHMOO_MEMSIZE_MAX - SHMOO_LIMIT_32MB) / SHMOO_INCREMENT_4MB);\n\n    unsigned int *memSizes = (unsigned int *)malloc(count * sizeof(unsigned int));\n    double* bandwidths = (double*)malloc(count * sizeof(double));\n\n    for (unsigned int i = 0; i < count; i++)\n        bandwidths[i] = 0.0;\n   \n    for (int currentDevice = startDevice; currentDevice <= endDevice; currentDevice++)\n    {\n        createQueue(currentDevice);\n\n        int iteration = 0;\n        unsigned int memSize = 0;\n        while(memSize <= SHMOO_MEMSIZE_MAX )\n        {\n            if(memSize < SHMOO_LIMIT_20KB )\n            {\n                memSize += SHMOO_INCREMENT_1KB;\n            }\n            else if( memSize < SHMOO_LIMIT_50KB)\n            {\n                memSize += SHMOO_INCREMENT_2KB;\n            }\n            else if( memSize < SHMOO_LIMIT_100KB)\n            {\n                memSize += SHMOO_INCREMENT_10KB;\n            }\n            else if( memSize < SHMOO_LIMIT_1MB)\n            {\n                memSize += SHMOO_INCREMENT_100KB;\n            }\n            else if( memSize < SHMOO_LIMIT_16MB)\n            {\n                memSize += SHMOO_INCREMENT_1MB;\n            }\n            else if( memSize < SHMOO_LIMIT_32MB)\n            {\n                memSize += SHMOO_INCREMENT_2MB;\n            }\n            else \n            {\n                memSize += SHMOO_INCREMENT_4MB;\n            }\n\n            memSizes[iteration] = memSize;\n            switch(kind)\n            {\n            case DEVICE_TO_HOST:    bandwidths[iteration] += testDeviceToHostTransfer(memSizes[iteration], accMode, memMode);\n                break;\n            case HOST_TO_DEVICE:    bandwidths[iteration] += testHostToDeviceTransfer(memSizes[iteration], accMode, memMode);\n                break;\n            case DEVICE_TO_DEVICE:  bandwidths[iteration] += testDeviceToDeviceTransfer(memSizes[iteration]);\n                break;\n            }\n            iteration++;\n            shrLog(\".\");\n        }\n    }\n\n    shrLog(\"\\n\");\n    if( CSV == printmode)\n    {\n        printResultsCSV(memSizes, bandwidths, count,  kind, accMode, memMode, (endDevice - startDevice));\n    }\n    else\n    {\n        printResultsReadable(memSizes, bandwidths, count, kind, accMode, memMode, (endDevice - startDevice));\n    }\n\n    free(memSizes);\n    free(bandwidths);\n}\n\ndouble testDeviceToHostTransfer(unsigned int memSize, accessMode accMode, memoryMode memMode)\n{\n    double elapsedTimeInSec = 0.0;\n    double bandwidthInMBs = 0.0;\n    unsigned char *h_data = NULL;\n    cl_mem cmPinnedData = NULL;\n    cl_mem cmDevData = NULL;\n    cl_int ciErrNum = CL_SUCCESS;\n\n    if(memMode == PINNED)\n    {\n        cmPinnedData = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE | CL_MEM_ALLOC_HOST_PTR, memSize, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        h_data = (unsigned char*)clEnqueueMapBuffer(cqCommandQueue, cmPinnedData, CL_TRUE, CL_MAP_WRITE, 0, memSize, 0, NULL, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        for(unsigned int i = 0; i < memSize/sizeof(unsigned char); i++)\n        {\n            h_data[i] = (unsigned char)(i & 0xff);\n        }\n\n        ciErrNum = clEnqueueUnmapMemObject(cqCommandQueue, cmPinnedData, (void*)h_data, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }\n    else \n    {\n        h_data = (unsigned char *)malloc(memSize);\n\n        for(unsigned int i = 0; i < memSize/sizeof(unsigned char); i++)\n        {\n            h_data[i] = (unsigned char)(i & 0xff);\n        }\n    }\n\n    cmDevData = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, memSize, NULL, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    if(memMode == PINNED)\n    {\n\t    // Get a mapped pointer\n        h_data = (unsigned char*)clEnqueueMapBuffer(cqCommandQueue, cmPinnedData, CL_TRUE, CL_MAP_WRITE, 0, memSize, 0, NULL, NULL, &ciErrNum);\t        \n\n        ciErrNum = clEnqueueWriteBuffer(cqCommandQueue, cmDevData, CL_FALSE, 0, memSize, h_data, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }\n    else\n    {\n        ciErrNum = clEnqueueWriteBuffer(cqCommandQueue, cmDevData, CL_FALSE, 0, memSize, h_data, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    ciErrNum = clFinish(cqCommandQueue);\n    shrDeltaT(0);\n    if(accMode == DIRECT)\n    { \n        for(unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++)\n        {\n            ciErrNum = clEnqueueReadBuffer(cqCommandQueue, cmDevData, CL_FALSE, 0, memSize, h_data, 0, NULL, NULL);\n            oclCheckError(ciErrNum, CL_SUCCESS);\n        }\n        ciErrNum = clFinish(cqCommandQueue);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    } \n    else \n    {\n        void* dm_idata = clEnqueueMapBuffer(cqCommandQueue, cmDevData, CL_TRUE, CL_MAP_WRITE, 0, memSize, 0, NULL, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        for(unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++)\n        {\n            memcpy(h_data, dm_idata, memSize);\n        }\n        ciErrNum = clEnqueueUnmapMemObject(cqCommandQueue, cmDevData, dm_idata, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }\n    \n    elapsedTimeInSec = shrDeltaT(0);\n    \n    bandwidthInMBs = ((double)memSize * (double)MEMCOPY_ITERATIONS) / (elapsedTimeInSec * (double)(1 << 20));\n\n    if(cmDevData)clReleaseMemObject(cmDevData);\n    if(cmPinnedData) \n    {\n\t    clEnqueueUnmapMemObject(cqCommandQueue, cmPinnedData, (void*)h_data, 0, NULL, NULL);\t\n\t    clReleaseMemObject(cmPinnedData);\t\n    }\n    h_data = NULL;\n\n    return bandwidthInMBs;\n}\n\ndouble testHostToDeviceTransfer(unsigned int memSize, accessMode accMode, memoryMode memMode)\n{\n    double elapsedTimeInSec = 0.0;\n    double bandwidthInMBs = 0.0;\n    unsigned char* h_data = NULL;\n    cl_mem cmPinnedData = NULL;\n    cl_mem cmDevData = NULL;\n    cl_int ciErrNum = CL_SUCCESS;\n\n    if(memMode == PINNED)\n   { \n        cmPinnedData = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE | CL_MEM_ALLOC_HOST_PTR, memSize, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        h_data = (unsigned char*)clEnqueueMapBuffer(cqCommandQueue, cmPinnedData, CL_TRUE, CL_MAP_WRITE, 0, memSize, 0, NULL, NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        for(unsigned int i = 0; i < memSize/sizeof(unsigned char); i++)\n        {\n            h_data[i] = (unsigned char)(i & 0xff);\n        }\n\t\n        ciErrNum = clEnqueueUnmapMemObject(cqCommandQueue, cmPinnedData, (void*)h_data, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\t\th_data = NULL;  // buffer is unmapped\n    }\n    else \n    {\n        h_data = (unsigned char *)malloc(memSize);\n\n        for(unsigned int i = 0; i < memSize/sizeof(unsigned char); i++)\n        {\n            h_data[i] = (unsigned char)(i & 0xff);\n        }\n    }\n\n    cmDevData = clCreateBuffer(cxGPUContext, CL_MEM_READ_WRITE, memSize, NULL, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    clFinish(cqCommandQueue);\n    shrDeltaT(0);\n    if(accMode == DIRECT)\n    { \n\t    if(memMode == PINNED) \n        {\n            h_data = (unsigned char*)clEnqueueMapBuffer(cqCommandQueue, cmPinnedData, CL_TRUE, CL_MAP_READ, 0, memSize, 0, NULL, NULL, &ciErrNum);\n            oclCheckError(ciErrNum, CL_SUCCESS);\n\t    }\n\n        for(unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++)\n        {\n                ciErrNum = clEnqueueWriteBuffer(cqCommandQueue, cmDevData, CL_FALSE, 0, memSize, h_data, 0, NULL, NULL);\n                oclCheckError(ciErrNum, CL_SUCCESS);\n        }\n        ciErrNum = clFinish(cqCommandQueue);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    } \n    else \n    {\n        void* dm_idata = clEnqueueMapBuffer(cqCommandQueue, cmDevData, CL_TRUE, CL_MAP_WRITE, 0, memSize, 0, NULL, NULL, &ciErrNum);\n\t\toclCheckError(ciErrNum, CL_SUCCESS);\n\t\tif(memMode == PINNED ) \n\t\t{\n\t\t\th_data = (unsigned char*)clEnqueueMapBuffer(cqCommandQueue, cmPinnedData, CL_TRUE, CL_MAP_READ, 0, memSize, 0, NULL, NULL, &ciErrNum); \n            oclCheckError(ciErrNum, CL_SUCCESS); \n        } \n        for(unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++)\n        {\n            memcpy(dm_idata, h_data, memSize);\n        }\n        ciErrNum = clEnqueueUnmapMemObject(cqCommandQueue, cmDevData, dm_idata, 0, NULL, NULL);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }\n    \n    elapsedTimeInSec = shrDeltaT(0);\n    \n    bandwidthInMBs = ((double)memSize * (double)MEMCOPY_ITERATIONS)/(elapsedTimeInSec * (double)(1 << 20));\n\n    if(cmDevData)clReleaseMemObject(cmDevData);\n    if(cmPinnedData) \n    {\n\t    clEnqueueUnmapMemObject(cqCommandQueue, cmPinnedData, (void*)h_data, 0, NULL, NULL);\n\t    clReleaseMemObject(cmPinnedData);\n    }\n    h_data = NULL;\n\n    return bandwidthInMBs;\n}\n\ndouble testDeviceToDeviceTransfer(unsigned int memSize)\n{\n    double elapsedTimeInSec = 0.0;\n    double bandwidthInMBs = 0.0;\n    unsigned char* h_idata = NULL;\n    cl_int ciErrNum = CL_SUCCESS;\n    \n    h_idata = (unsigned char *)malloc( memSize );\n        \n    for(unsigned int i = 0; i < memSize/sizeof(unsigned char); i++)\n    {\n        h_idata[i] = (unsigned char) (i & 0xff);\n    }\n\n    cl_mem d_idata = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY, memSize, NULL, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    cl_mem d_odata = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY, memSize, NULL, &ciErrNum);         \n    oclCheckError(ciErrNum, CL_SUCCESS);\n    ciErrNum = clEnqueueWriteBuffer(cqCommandQueue, d_idata, CL_TRUE, 0, memSize, h_idata, 0, NULL, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    clFinish(cqCommandQueue);\n    shrDeltaT(0);\n    for(unsigned int i = 0; i < MEMCOPY_ITERATIONS; i++)\n    {\n        ciErrNum = clEnqueueCopyBuffer(cqCommandQueue, d_idata, d_odata, 0, 0, memSize, 0, NULL, NULL);                \n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }    \n\n    clFinish(cqCommandQueue);\n    \n    elapsedTimeInSec = shrDeltaT(0);\n    \n    bandwidthInMBs = 2.0 * ((double)memSize * (double)MEMCOPY_ITERATIONS)/(elapsedTimeInSec * (double)(1 << 20));\n\n    free(h_idata);\n    clReleaseMemObject(d_idata);\n    clReleaseMemObject(d_odata);\n\n    return bandwidthInMBs;\n}\n\nvoid printResultsReadable(unsigned int *memSizes, double* bandwidths, unsigned int count, memcpyKind kind, accessMode accMode, memoryMode memMode, int iNumDevs)\n{\n    if (kind == DEVICE_TO_DEVICE)\n    {\n        shrLog(\"Device to Device Bandwidth, %i Device(s)\\n\", iNumDevs);\n    }\n    else \n    {\n        if (kind == DEVICE_TO_HOST)\n        {\n            shrLog(\"Device to Host Bandwidth, %i Device(s), \", iNumDevs);\n        }\n        else if (kind == HOST_TO_DEVICE)\n        {\n            shrLog(\"Host to Device Bandwidth, %i Device(s), \", iNumDevs);\n        }\n        if(memMode == PAGEABLE)\n        {\n            shrLog(\"Paged memory\");\n        }\n        else if (memMode == PINNED)\n        {\n            shrLog(\"Pinned memory\");\n        }\n        if(accMode == DIRECT)\n        {\n            shrLog(\", direct access\\n\");\n        }\n        else if (accMode == MAPPED)\n        {\n            shrLog(\", mapped access\\n\");\n        }\n    }\n\n    shrLog(\"   Transfer Size (Bytes)\\tBandwidth(MB/s)\\n\");\n    unsigned int i; \n    for(i = 0; i < (count - 1); i++)\n    {\n        shrLog(\"   %u\\t\\t\\t%s%.1f\\n\", memSizes[i], (memSizes[i] < 10000)? \"\\t\" : \"\", bandwidths[i]);\n    }\n    shrLog(\"   %u\\t\\t\\t%s%.1f\\n\\n\", memSizes[i], (memSizes[i] < 10000)? \"\\t\" : \"\", bandwidths[i]);\n}\n\nvoid printResultsCSV(unsigned int *memSizes, double* bandwidths, unsigned int count, memcpyKind kind, accessMode accMode, memoryMode memMode, int iNumDevs)\n{\n    unsigned int i; \n    double dSeconds = 0.0;\n    std::string sConfig;\n        \n    if (kind == DEVICE_TO_DEVICE)\n    {\n        sConfig += \"D2D\";\n    }\n    else \n    {\n        if (kind == DEVICE_TO_HOST)\n        {\n            sConfig += \"D2H\";\n        }\n        else if (kind == HOST_TO_DEVICE)\n        {\n            sConfig += \"H2D\";\n        }\n\n        if(memMode == PAGEABLE)\n        {\n            sConfig += \"-Paged\";\n        }\n        else if (memMode == PINNED)\n        {\n            sConfig += \"-Pinned\";\n        }\n\n        if(accMode == DIRECT)\n        {\n            sConfig += \"-Direct\";            \n        }\n        else if (accMode == MAPPED)\n        {\n            sConfig += \"-Mapped\";            \n        }\n    }\n\n\n    for(i = 0; i < count; i++)\n    {\n        dSeconds = (double)memSizes[i] / (bandwidths[i] * (double)(1<<20));\n        shrLogEx(LOGBOTH | MASTER, 0, \"oclBandwidthTest-%s, Bandwidth = %.1f MB/s, Time = %.5f s, Size = %u Bytes, NumDevsUsed = %i\\n\", sConfig.c_str(), bandwidths[i], dSeconds, memSizes[i], iNumDevs);\n    }\n}\n\nvoid printHelp(void)\n{\n    shrLog(\"Usage:  oclBandwidthTest [OPTION]...\\n\");\n    shrLog(\"Test the bandwidth for device to host, host to device, and device to device transfers\\n\");\n    shrLog(\"\\n\");\n    shrLog(\"Example:  measure the bandwidth of device to host pinned memory copies in the range 1024 Bytes to 102400 Bytes in 1024 Byte increments\\n\");\n    shrLog(\"./oclBandwidthTest --memory=pinned --mode=range --start=1024 --end=102400 --increment=1024 --dtoh\\n\");\n\n    shrLog(\"\\n\");\n    shrLog(\"Options:\\n\");\n    shrLog(\"--help\\tDisplay this help menu\\n\");\n    shrLog(\"--csv\\tPrint results as a CSV\\n\");\n    shrLog(\"--device=[device_number]\\tSpecify the device device to be used\\n\");\n    shrLog(\"  all - compute cumulative bandwidth on all the devices\\n\");\n    shrLog(\"  0,1,2,...,n - Specify a GPU device to be used to run this test\\n\");\n    shrLog(\"--access=[ACCESSMODE]\\tSpecify which memory access mode to use\\n\");\n    shrLog(\"  direct   - direct device memory\\n\");\n    shrLog(\"  mapped   - mapped device memory\\n\");\n    shrLog(\"--memory=[MEMMODE]\\tSpecify which memory mode to use\\n\");\n    shrLog(\"  pageable  - pageable system memory\\n\");\n    shrLog(\"  pinned    - pinned system memory\\n\");\n    shrLog(\"--mode=[MODE]\\tSpecify the mode to use\\n\");\n    shrLog(\"  quick - performs a quick measurement\\n\");\n    shrLog(\"  range - measures a user-specified range of values\\n\");\n    shrLog(\"  shmoo - performs an intense shmoo of a large range of values\\n\");\n\n    shrLog(\"--htod\\tMeasure host to device transfers\\n\");   \n    shrLog(\"--dtoh\\tMeasure device to host transfers\\n\");\n    shrLog(\"--dtod\\tMeasure device to device transfers\\n\");\n    \n    shrLog(\"Range mode options\\n\");\n    shrLog(\"--start=[SIZE]\\tStarting transfer size in bytes\\n\");\n    shrLog(\"--end=[SIZE]\\tEnding transfer size in bytes\\n\");\n    shrLog(\"--increment=[SIZE]\\tIncrement size in bytes\\n\");\n}\n"}, "code_dirs": {"oclBandwidthTest.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclBandwidthTest"}}
{"kernel_name": "transpose", "parallel_api": "cuda", "code": {"transpose.cu": "#include <cooperative_groups.h>\n\nnamespace cg = cooperative_groups;\n#include <helper_cuda.h>\n#include <helper_image.h>\n#include <helper_string.h>\n\nconst char *sSDKsample = \"Transpose\";\n\n#define TILE_DIM   32\n#define BLOCK_ROWS 16\n\nint MATRIX_SIZE_X = 1024;\nint MATRIX_SIZE_Y = 1024;\nint MUL_FACTOR    = TILE_DIM;\n\n#define FLOOR(a, b) (a - (a % b))\n\nint MAX_TILES = (FLOOR(MATRIX_SIZE_X, 512) * FLOOR(MATRIX_SIZE_Y, 512)) / (TILE_DIM * TILE_DIM);\n\n#define NUM_REPS 100\n\n__global__ void copy(float *odata, float *idata, int width, int height)\n{\n    int xIndex = blockIdx.x * TILE_DIM + threadIdx.x;\n    int yIndex = blockIdx.y * TILE_DIM + threadIdx.y;\n\n    int index = xIndex + width * yIndex;\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        odata[index + i * width] = idata[index + i * width];\n    }\n}\n\n__global__ void copySharedMem(float *odata, float *idata, int width, int height)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ float tile[TILE_DIM][TILE_DIM];\n\n    int xIndex = blockIdx.x * TILE_DIM + threadIdx.x;\n    int yIndex = blockIdx.y * TILE_DIM + threadIdx.y;\n\n    int index = xIndex + width * yIndex;\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        if (xIndex < width && yIndex < height) {\n            tile[threadIdx.y + i][threadIdx.x] = idata[index + i * width];\n        }\n    }\n\n    cg::sync(cta);\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        if (xIndex < height && yIndex < width) {\n            odata[index + i * width] = tile[threadIdx.y + i][threadIdx.x];\n        }\n    }\n}\n\n__global__ void transposeNaive(float *odata, float *idata, int width, int height)\n{\n    int xIndex = blockIdx.x * TILE_DIM + threadIdx.x;\n    int yIndex = blockIdx.y * TILE_DIM + threadIdx.y;\n\n    int index_in  = xIndex + width * yIndex;\n    int index_out = yIndex + height * xIndex;\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        odata[index_out + i] = idata[index_in + i * width];\n    }\n}\n\n__global__ void transposeCoalesced(float *odata, float *idata, int width, int height)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ float tile[TILE_DIM][TILE_DIM];\n\n    int xIndex   = blockIdx.x * TILE_DIM + threadIdx.x;\n    int yIndex   = blockIdx.y * TILE_DIM + threadIdx.y;\n    int index_in = xIndex + (yIndex)*width;\n\n    xIndex        = blockIdx.y * TILE_DIM + threadIdx.x;\n    yIndex        = blockIdx.x * TILE_DIM + threadIdx.y;\n    int index_out = xIndex + (yIndex)*height;\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        tile[threadIdx.y + i][threadIdx.x] = idata[index_in + i * width];\n    }\n\n    cg::sync(cta);\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        odata[index_out + i * height] = tile[threadIdx.x][threadIdx.y + i];\n    }\n}\n\n__global__ void transposeNoBankConflicts(float *odata, float *idata, int width, int height)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ float tile[TILE_DIM][TILE_DIM + 1];\n\n    int xIndex   = blockIdx.x * TILE_DIM + threadIdx.x;\n    int yIndex   = blockIdx.y * TILE_DIM + threadIdx.y;\n    int index_in = xIndex + (yIndex)*width;\n\n    xIndex        = blockIdx.y * TILE_DIM + threadIdx.x;\n    yIndex        = blockIdx.x * TILE_DIM + threadIdx.y;\n    int index_out = xIndex + (yIndex)*height;\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        tile[threadIdx.y + i][threadIdx.x] = idata[index_in + i * width];\n    }\n\n    cg::sync(cta);\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        odata[index_out + i * height] = tile[threadIdx.x][threadIdx.y + i];\n    }\n}\n\n__global__ void transposeDiagonal(float *odata, float *idata, int width, int height)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ float tile[TILE_DIM][TILE_DIM + 1];\n\n    int blockIdx_x, blockIdx_y;\n\n    if (width == height) {\n        blockIdx_y = blockIdx.x;\n        blockIdx_x = (blockIdx.x + blockIdx.y) % gridDim.x;\n    }\n    else {\n        int bid    = blockIdx.x + gridDim.x * blockIdx.y;\n        blockIdx_y = bid % gridDim.y;\n        blockIdx_x = ((bid / gridDim.y) + blockIdx_y) % gridDim.x;\n    }\n\n    int xIndex   = blockIdx_x * TILE_DIM + threadIdx.x;\n    int yIndex   = blockIdx_y * TILE_DIM + threadIdx.y;\n    int index_in = xIndex + (yIndex)*width;\n\n    xIndex        = blockIdx_y * TILE_DIM + threadIdx.x;\n    yIndex        = blockIdx_x * TILE_DIM + threadIdx.y;\n    int index_out = xIndex + (yIndex)*height;\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        tile[threadIdx.y + i][threadIdx.x] = idata[index_in + i * width];\n    }\n\n    cg::sync(cta);\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        odata[index_out + i * height] = tile[threadIdx.x][threadIdx.y + i];\n    }\n}\n\n__global__ void transposeFineGrained(float *odata, float *idata, int width, int height)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ float block[TILE_DIM][TILE_DIM + 1];\n\n    int xIndex = blockIdx.x * TILE_DIM + threadIdx.x;\n    int yIndex = blockIdx.y * TILE_DIM + threadIdx.y;\n    int index  = xIndex + (yIndex)*width;\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        block[threadIdx.y + i][threadIdx.x] = idata[index + i * width];\n    }\n\n    cg::sync(cta);\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        odata[index + i * height] = block[threadIdx.x][threadIdx.y + i];\n    }\n}\n\n__global__ void transposeCoarseGrained(float *odata, float *idata, int width, int height)\n{\n    cg::thread_block cta = cg::this_thread_block();\n    __shared__ float block[TILE_DIM][TILE_DIM + 1];\n\n    int xIndex   = blockIdx.x * TILE_DIM + threadIdx.x;\n    int yIndex   = blockIdx.y * TILE_DIM + threadIdx.y;\n    int index_in = xIndex + (yIndex)*width;\n\n    xIndex        = blockIdx.y * TILE_DIM + threadIdx.x;\n    yIndex        = blockIdx.x * TILE_DIM + threadIdx.y;\n    int index_out = xIndex + (yIndex)*height;\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        block[threadIdx.y + i][threadIdx.x] = idata[index_in + i * width];\n    }\n\n    cg::sync(cta);\n\n    for (int i = 0; i < TILE_DIM; i += BLOCK_ROWS) {\n        odata[index_out + i * height] = block[threadIdx.y + i][threadIdx.x];\n    }\n}\n\nvoid computeTransposeGold(float *gold, float *idata, const int size_x, const int size_y)\n{\n    for (int y = 0; y < size_y; ++y) {\n        for (int x = 0; x < size_x; ++x) {\n            gold[(x * size_y) + y] = idata[(y * size_x) + x];\n        }\n    }\n}\n\nvoid getParams(int argc, char **argv, cudaDeviceProp &deviceProp, int &size_x, int &size_y, int max_tile_dim)\n{\n    if (checkCmdLineFlag(argc, (const char **)argv, \"dimX\")) {\n        size_x = getCmdLineArgumentInt(argc, (const char **)argv, \"dimX\");\n\n        if (size_x > max_tile_dim) {\n            printf(\"> MatrixSize X = %d is greater than the recommended size = %d\\n\", size_x, max_tile_dim);\n        }\n        else {\n            printf(\"> MatrixSize X = %d\\n\", size_x);\n        }\n    }\n    else {\n        size_x = max_tile_dim;\n        size_x = FLOOR(size_x, 512);\n    }\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"dimY\")) {\n        size_y = getCmdLineArgumentInt(argc, (const char **)argv, \"dimY\");\n\n        if (size_y > max_tile_dim) {\n            printf(\"> MatrixSize Y = %d is greater than the recommended size = %d\\n\", size_y, max_tile_dim);\n        }\n        else {\n            printf(\"> MatrixSize Y = %d\\n\", size_y);\n        }\n    }\n    else {\n        size_y = max_tile_dim;\n        size_y = FLOOR(size_y, 512);\n    }\n}\n\nvoid showHelp()\n{\n    printf(\"\\n%s : Command line options\\n\", sSDKsample);\n    printf(\"\\t-device=n          (where n=0,1,2.... for the GPU device)\\n\\n\");\n    printf(\"> The default matrix size can be overridden with these parameters\\n\");\n    printf(\"\\t-dimX=row_dim_size (matrix row    dimensions)\\n\");\n    printf(\"\\t-dimY=col_dim_size (matrix column dimensions)\\n\");\n}\n\nint main(int argc, char **argv)\n{\n    printf(\"%s Starting...\\n\\n\", sSDKsample);\n\n    if (checkCmdLineFlag(argc, (const char **)argv, \"help\")) {\n        showHelp();\n        return 0;\n    }\n\n    int            devID = findCudaDevice(argc, (const char **)argv);\n    cudaDeviceProp deviceProp;\n\n    checkCudaErrors(cudaGetDevice(&devID));\n    checkCudaErrors(cudaGetDeviceProperties(&deviceProp, devID));\n\n    float scale_factor, total_tiles;\n    scale_factor = max(\n        (192.0f / (_ConvertSMVer2Cores(deviceProp.major, deviceProp.minor) * (float)deviceProp.multiProcessorCount)),\n        1.0f);\n\n    printf(\"> Device %d: \\\"%s\\\"\\n\", devID, deviceProp.name);\n    printf(\"> SM Capability %d.%d detected:\\n\", deviceProp.major, deviceProp.minor);\n\n    int size_x, size_y, max_matrix_dim, matrix_size_test;\n\n    matrix_size_test = 512;\n    total_tiles      = (float)MAX_TILES / scale_factor;\n\n    max_matrix_dim = FLOOR((int)(floor(sqrt(total_tiles)) * TILE_DIM), matrix_size_test);\n\n    if (max_matrix_dim == 0) {\n        max_matrix_dim = matrix_size_test;\n    }\n\n    printf(\"> [%s] has %d MP(s) x %d (Cores/MP) = %d (Cores)\\n\",\n           deviceProp.name,\n           deviceProp.multiProcessorCount,\n           _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor),\n           _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor) * deviceProp.multiProcessorCount);\n\n    printf(\"> Compute performance scaling factor = %4.2f\\n\", scale_factor);\n\n    getParams(argc, argv, deviceProp, size_x, size_y, max_matrix_dim);\n\n    if (size_x != size_y) {\n        printf(\"\\n[%s] does not support non-square matrices (row_dim_size(%d) != \"\n               \"col_dim_size(%d))\\nExiting...\\n\\n\",\n               sSDKsample,\n               size_x,\n               size_y);\n        exit(EXIT_FAILURE);\n    }\n\n    if (size_x % TILE_DIM != 0 || size_y % TILE_DIM != 0) {\n        printf(\"[%s] Matrix size must be integral multiple of tile \"\n               \"size\\nExiting...\\n\\n\",\n               sSDKsample);\n        exit(EXIT_FAILURE);\n    }\n\n    void (*kernel)(float *, float *, int, int);\n    const char *kernelName;\n\n    dim3 grid(size_x / TILE_DIM, size_y / TILE_DIM), threads(TILE_DIM, BLOCK_ROWS);\n\n    if (grid.x < 1 || grid.y < 1) {\n        printf(\"[%s] grid size computation incorrect in test \\nExiting...\\n\\n\", sSDKsample);\n        exit(EXIT_FAILURE);\n    }\n\n    cudaEvent_t start, stop;\n\n    size_t mem_size = static_cast<size_t>(sizeof(float) * size_x * size_y);\n\n    if (2 * mem_size > deviceProp.totalGlobalMem) {\n        printf(\"Input matrix size is larger than the available device memory!\\n\");\n        printf(\"Please choose a smaller size matrix\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    float *h_idata       = (float *)malloc(mem_size);\n    float *h_odata       = (float *)malloc(mem_size);\n    float *transposeGold = (float *)malloc(mem_size);\n    float *gold;\n\n    float *d_idata, *d_odata;\n    checkCudaErrors(cudaMalloc((void **)&d_idata, mem_size));\n    checkCudaErrors(cudaMalloc((void **)&d_odata, mem_size));\n\n    for (int i = 0; i < (size_x * size_y); ++i) {\n        h_idata[i] = (float)i;\n    }\n\n    checkCudaErrors(cudaMemcpy(d_idata, h_idata, mem_size, cudaMemcpyHostToDevice));\n\n    computeTransposeGold(transposeGold, h_idata, size_x, size_y);\n\n    printf(\"\\nMatrix size: %dx%d (%dx%d tiles), tile size: %dx%d, block size: \"\n           \"%dx%d\\n\\n\",\n           size_x,\n           size_y,\n           size_x / TILE_DIM,\n           size_y / TILE_DIM,\n           TILE_DIM,\n           TILE_DIM,\n           TILE_DIM,\n           BLOCK_ROWS);\n\n    checkCudaErrors(cudaEventCreate(&start));\n    checkCudaErrors(cudaEventCreate(&stop));\n\n    bool success = true;\n\n    for (int k = 0; k < 8; k++) {\n        switch (k) {\n        case 0:\n            kernel     = &copy;\n            kernelName = \"simple copy       \";\n            break;\n\n        case 1:\n            kernel     = &copySharedMem;\n            kernelName = \"shared memory copy\";\n            break;\n\n        case 2:\n            kernel     = &transposeNaive;\n            kernelName = \"naive             \";\n            break;\n\n        case 3:\n            kernel     = &transposeCoalesced;\n            kernelName = \"coalesced         \";\n            break;\n\n        case 4:\n            kernel     = &transposeNoBankConflicts;\n            kernelName = \"optimized         \";\n            break;\n\n        case 5:\n            kernel     = &transposeCoarseGrained;\n            kernelName = \"coarse-grained    \";\n            break;\n\n        case 6:\n            kernel     = &transposeFineGrained;\n            kernelName = \"fine-grained      \";\n            break;\n\n        case 7:\n            kernel     = &transposeDiagonal;\n            kernelName = \"diagonal          \";\n            break;\n        }\n\n        if (kernel == &copy || kernel == &copySharedMem) {\n            gold = h_idata;\n        }\n        else if (kernel == &transposeCoarseGrained || kernel == &transposeFineGrained) {\n            gold = h_odata;\n        }\n        else {\n            gold = transposeGold;\n        }\n\n        checkCudaErrors(cudaGetLastError());\n\n        kernel<<<grid, threads>>>(d_odata, d_idata, size_x, size_y);\n\n        checkCudaErrors(cudaEventRecord(start, 0));\n\n        for (int i = 0; i < NUM_REPS; i++) {\n            kernel<<<grid, threads>>>(d_odata, d_idata, size_x, size_y);\n            checkCudaErrors(cudaGetLastError());\n        }\n\n        checkCudaErrors(cudaEventRecord(stop, 0));\n        checkCudaErrors(cudaEventSynchronize(stop));\n        float kernelTime;\n        checkCudaErrors(cudaEventElapsedTime(&kernelTime, start, stop));\n\n        checkCudaErrors(cudaMemcpy(h_odata, d_odata, mem_size, cudaMemcpyDeviceToHost));\n        bool res = compareData(gold, h_odata, size_x * size_y, 0.01f, 0.0f);\n\n        if (res == false) {\n            printf(\"*** %s kernel FAILED ***\\n\", kernelName);\n            success = false;\n        }\n\n        checkCudaErrors(cudaMemcpy(h_odata, d_odata, mem_size, cudaMemcpyDeviceToHost));\n        res = compareData(gold, h_odata, size_x * size_y, 0.01f, 0.0f);\n\n        if (res == false) {\n            printf(\"*** %s kernel FAILED ***\\n\", kernelName);\n            success = false;\n        }\n\n        float kernelBandwidth = 2.0f * 1000.0f * mem_size / (1024 * 1024 * 1024) / (kernelTime / NUM_REPS);\n        printf(\"transpose %s, Throughput = %.4f GB/s, Time = %.5f ms, Size = %u fp32 \"\n               \"elements, NumDevsUsed = %u, Workgroup = %u\\n\",\n               kernelName,\n               kernelBandwidth,\n               kernelTime / NUM_REPS,\n               (size_x * size_y),\n               1,\n               TILE_DIM * BLOCK_ROWS);\n\n        for (int i = 0; i < (size_x * size_y); ++i) {\n            h_odata[i] = 0;\n        }\n\n        checkCudaErrors(cudaMemcpy(d_odata, h_odata, mem_size, cudaMemcpyHostToDevice));\n    }\n\n    free(h_idata);\n    free(h_odata);\n    free(transposeGold);\n    cudaFree(d_idata);\n    cudaFree(d_odata);\n\n    checkCudaErrors(cudaEventDestroy(start));\n    checkCudaErrors(cudaEventDestroy(stop));\n\n    if (!success) {\n        printf(\"Test failed!\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    printf(\"Test passed\\n\");\n    exit(EXIT_SUCCESS);\n}\n"}, "code_dirs": {"transpose.cu": "/home/erel.kaplan/atca_proj/data/nvidia_samples/cuda/Samples/6_Performance/transpose"}}
{"kernel_name": "transpose", "parallel_api": "ocl", "code": {"transpose.cl": "#define BLOCK_DIM 16\n\n__kernel void transpose(__global float *odata, __global float *idata, int offset, int width, int height, __local float* block)\n{\n\t// read the matrix tile into shared memory\n\tunsigned int xIndex = get_global_id(0);\n\tunsigned int yIndex = get_global_id(1);\n\n\tif((xIndex + offset < width) && (yIndex < height))\n\t{\n\t\tunsigned int index_in = yIndex * width + xIndex + offset;\n\t\tblock[get_local_id(1)*(BLOCK_DIM+1)+get_local_id(0)] = idata[index_in];\n\t}\n\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\t// write the transposed matrix tile to global memory\n\txIndex = get_group_id(1) * BLOCK_DIM + get_local_id(0);\n\tyIndex = get_group_id(0) * BLOCK_DIM + get_local_id(1);\n\tif((xIndex < height) && (yIndex + offset < width))\n    {\n\t\tunsigned int index_out = yIndex * height + xIndex;\n\t\todata[index_out] = block[get_local_id(0)*(BLOCK_DIM+1)+get_local_id(1)];\n\t}\n}\n\n__kernel void transpose_naive(__global float *odata, __global float* idata, int offset, int width, int height)\n{\n    unsigned int xIndex = get_global_id(0);\n    unsigned int yIndex = get_global_id(1);\n    \n    if (xIndex + offset < width && yIndex < height)\n    {\n        unsigned int index_in  = xIndex + offset + width * yIndex;\n        unsigned int index_out = yIndex + height * xIndex;\n        odata[index_out] = idata[index_in]; \n    }\n}\n\n\n__kernel void simple_copy(__global float *odata, __global float* idata, int offset, int width, int height)\n{\n    unsigned int xIndex = get_global_id(0);\n    unsigned int yIndex = get_global_id(1);\n    \n    if (xIndex + offset < width && yIndex < height)\n    {\n        unsigned int index_in  = xIndex + offset + width * yIndex;\n        odata[index_in] = idata[index_in]; \n    }\n}\n\n__kernel void shared_copy(__global float *odata, __global float *idata, int offset, int width, int height, __local float* block)\n{\n\t// read the matrix tile into shared memory\n\tunsigned int xIndex = get_global_id(0);\n\tunsigned int yIndex = get_global_id(1);\n\n    unsigned int index_in = yIndex * width + xIndex + offset;\n\tif((xIndex + offset< width) && (yIndex < height))\n\t{\n\t\tblock[get_local_id(1)*(BLOCK_DIM+1)+get_local_id(0)] = idata[index_in];\n\t}\n\n\tbarrier(CLK_LOCAL_MEM_FENCE);\n\n\tif((xIndex < height) && (yIndex+ offset < width))\n    {\n\t\todata[index_in] = block[get_local_id(1)*(BLOCK_DIM+1)+get_local_id(0)];\n\t}\n}\n\n\n__kernel void uncoalesced_copy(__global float *odata, __global float* idata, int offset, int width, int height)\n{\n    unsigned int xIndex = get_global_id(0);\n    unsigned int yIndex = get_global_id(1);\n    \n    if (xIndex + offset < width && yIndex < height)\n    {\n        unsigned int index_in  = yIndex + height * (xIndex+ offset);\n        odata[index_in] = idata[index_in]; \n    }\n}\n", "oclTranspose.cpp": "\n#include <oclUtils.h>\n#include <shrQATest.h>\n\n#define BLOCK_DIM 16\n\n// max GPU's to manage for multi-GPU parallel compute\nconst unsigned int MAX_GPU_COUNT = 8;\n\n// global variables\ncl_platform_id cpPlatform;\ncl_uint uiNumDevices;\ncl_device_id* cdDevices;\ncl_context cxGPUContext;\ncl_kernel ckKernel[MAX_GPU_COUNT];\ncl_command_queue commandQueue[MAX_GPU_COUNT];\ncl_program cpProgram;\n\nint runTest( int argc, const char** argv);\nextern \"C\" void computeGold( float* reference, float* idata, \n                         const unsigned int size_x, const unsigned int size_y );\n\nint main( int argc, const char** argv) \n{    \n    shrQAStart(argc, (char **)argv);\n\n    // set logfile name and start logs\n    shrSetLogFileName (\"oclTranspose.txt\");\n    shrLog(\"%s Starting...\\n\\n\", argv[0]); \n\n    // run the main test\n    int result = runTest(argc, argv);\n    oclCheckError(result, 0);\n}\n\ndouble transposeGPU(const char* kernelName, bool useLocalMem,  cl_uint ciDeviceCount, float* h_idata, float* h_odata, unsigned int size_x, unsigned int size_y)\n{\n    cl_mem d_odata[MAX_GPU_COUNT];\n    cl_mem d_idata[MAX_GPU_COUNT];\n    cl_kernel ckKernel[MAX_GPU_COUNT];\n\n    size_t szGlobalWorkSize[2];\n    size_t szLocalWorkSize[2];\n    cl_int ciErrNum;\n\n    size_t sizePerGPU = shrRoundUp(BLOCK_DIM, (size_x+ciDeviceCount-1) / ciDeviceCount);\n    \n    // size of memory required to store the matrix\n    const size_t mem_size = sizeof(float) * size_x * size_y;\n\n    for(unsigned int i = 0; i < ciDeviceCount; ++i){\n        // allocate device memory and copy host to device memory\n        d_idata[i] = clCreateBuffer(cxGPUContext, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR,\n                                    mem_size, h_idata, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        // create buffer to store output\n        d_odata[i] = clCreateBuffer(cxGPUContext, CL_MEM_WRITE_ONLY ,\n                                    sizePerGPU*size_y*sizeof(float), NULL, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n\n        // create the naive transpose kernel\n        ckKernel[i] = clCreateKernel(cpProgram, kernelName, &ciErrNum);\n        oclCheckError(ciErrNum, CL_SUCCESS);\n        \n        // set the args values for the naive kernel\n        size_t offset = i * sizePerGPU;\n        ciErrNum  = clSetKernelArg(ckKernel[i], 0, sizeof(cl_mem), (void *) &d_odata[i]);\n        ciErrNum |= clSetKernelArg(ckKernel[i], 1, sizeof(cl_mem), (void *) &d_idata[0]);\n        ciErrNum |= clSetKernelArg(ckKernel[i], 2, sizeof(int), &offset);\n        ciErrNum |= clSetKernelArg(ckKernel[i], 3, sizeof(int), &size_x);\n        ciErrNum |= clSetKernelArg(ckKernel[i], 4, sizeof(int), &size_y);\n        if(useLocalMem)\n        {\n            ciErrNum |= clSetKernelArg(ckKernel[i], 5, (BLOCK_DIM + 1) * BLOCK_DIM * sizeof(float), 0 );\n        }\n    }\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // set up execution configuration\n    szLocalWorkSize[0] = BLOCK_DIM;\n    szLocalWorkSize[1] = BLOCK_DIM;\n    szGlobalWorkSize[0] = sizePerGPU;\n    szGlobalWorkSize[1] = shrRoundUp(BLOCK_DIM, size_y);\n    \n    // execute the kernel numIterations times\n    int numIterations = 100;\n    shrLog(\"\\nProcessing a %d by %d matrix of floats...\\n\\n\", size_x, size_y);\n    for (int i = -1; i < numIterations; ++i)\n    {\n        // Start time measurement after warmup\n        if( i == 0 ) shrDeltaT(0);\n\n        for(unsigned int k=0; k < ciDeviceCount; ++k){\n            ciErrNum |= clEnqueueNDRangeKernel(commandQueue[k], ckKernel[k], 2, NULL,                                           \n                                szGlobalWorkSize, szLocalWorkSize, 0, NULL, NULL);\n        }\n        oclCheckError(ciErrNum, CL_SUCCESS);\n    }    \n\n    // Block CPU till GPU is done\n    for(unsigned int k=0; k < ciDeviceCount; ++k){ \n        ciErrNum |= clFinish(commandQueue[k]);\n    }\n    double time = shrDeltaT(0)/(double)numIterations;\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // Copy back to host\n    for(unsigned int i = 0; i < ciDeviceCount; ++i){\n        size_t offset = i * sizePerGPU;\n        size_t size = MIN(size_x - i * sizePerGPU, sizePerGPU);\n\n        ciErrNum |= clEnqueueReadBuffer(commandQueue[i], d_odata[i], CL_TRUE, 0,\n                                size * size_y * sizeof(float), &h_odata[offset * size_y], \n                                0, NULL, NULL);\n    }\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    for(unsigned int i = 0; i < ciDeviceCount; ++i){\n        ciErrNum |= clReleaseMemObject(d_idata[i]);\n        ciErrNum |= clReleaseMemObject(d_odata[i]);\n        ciErrNum |= clReleaseKernel(ckKernel[i]);\n    }\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    return time;\n}\n\nint runTest( const int argc, const char** argv) \n{\n    cl_int ciErrNum;\n    cl_uint ciDeviceCount;\n    unsigned int size_x = 2048;\n    unsigned int size_y = 2048;\n\n    int temp;\n    if( shrGetCmdLineArgumenti( argc, argv,\"width\", &temp) ){\n        size_x = temp;\n    }\n\n    if( shrGetCmdLineArgumenti( argc, argv,\"height\", &temp) ){\n        size_y = temp;\n    }\n\n    // size of memory required to store the matrix\n    const size_t mem_size = sizeof(float) * size_x * size_y;\n\n    //Get the NVIDIA platform\n    ciErrNum = oclGetPlatformID(&cpPlatform);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    //Get the devices\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, 0, NULL, &uiNumDevices);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    cdDevices = (cl_device_id *)malloc(uiNumDevices * sizeof(cl_device_id) );\n    ciErrNum = clGetDeviceIDs(cpPlatform, CL_DEVICE_TYPE_GPU, uiNumDevices, cdDevices, NULL);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    //Create the context\n    cxGPUContext = clCreateContext(0, uiNumDevices, cdDevices, NULL, NULL, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n  \n    if(shrCheckCmdLineFlag(argc, (const char**)argv, \"device\"))\n    {\n        ciDeviceCount = 0;\n        // User specified GPUs\n        char* deviceList;\n        char* deviceStr;\n\n        shrGetCmdLineArgumentstr(argc, (const char**)argv, \"device\", &deviceList);\n\n        #ifdef WIN32\n            char* next_token;\n            deviceStr = strtok_s (deviceList,\" ,.-\", &next_token);\n        #else\n            deviceStr = strtok (deviceList,\" ,.-\");\n        #endif   \n        ciDeviceCount = 0;\n        while(deviceStr != NULL) \n        {\n            // get and print the device for this queue\n            cl_device_id device = oclGetDev(cxGPUContext, atoi(deviceStr));\n\t    if( device == (cl_device_id)-1 ) {\n                shrLog(\" Invalid Device: %s\\n\\n\", deviceStr);\n                return -1;\n\t    }\t\n\n            shrLog(\"Device %d: \", atoi(deviceStr));\n            oclPrintDevName(LOGBOTH, device);            \n            shrLog(\"\\n\");\n           \n            // create command queue\n            commandQueue[ciDeviceCount] = clCreateCommandQueue(cxGPUContext, device, CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n            if (ciErrNum != CL_SUCCESS)\n            {\n                shrLog(\" Error %i in clCreateCommandQueue call !!!\\n\\n\", ciErrNum);\n                return ciErrNum;\n            }\n\n            ++ciDeviceCount;\n\n            #ifdef WIN32\n                deviceStr = strtok_s (NULL,\" ,.-\", &next_token);\n            #else            \n                deviceStr = strtok (NULL,\" ,.-\");\n            #endif\n        }\n\n        free(deviceList);\n    } \n    else \n    {\n        // Find out how many GPU's to compute on all available GPUs\n        size_t nDeviceBytes;\n        ciErrNum |= clGetContextInfo(cxGPUContext, CL_CONTEXT_DEVICES, 0, NULL, &nDeviceBytes);\n        ciDeviceCount = (cl_uint)nDeviceBytes/sizeof(cl_device_id);\n\n        if (ciErrNum != CL_SUCCESS)\n        {\n            shrLog(\" Error %i in clGetDeviceIDs call !!!\\n\\n\", ciErrNum);\n            return ciErrNum;\n        }\n        else if (ciDeviceCount == 0)\n        {\n            shrLog(\" There are no devices supporting OpenCL (return code %i)\\n\\n\", ciErrNum);\n            return -1;\n        } \n\n        // create command-queues\n        for(unsigned int i = 0; i < ciDeviceCount; ++i) \n        {\n            // get and print the device for this queue\n            cl_device_id device = oclGetDev(cxGPUContext, i);\n            shrLog(\"Device %d: \", i);\n            oclPrintDevName(LOGBOTH, device);            \n            shrLog(\"\\n\");\n\n            // create command queue\n            commandQueue[i] = clCreateCommandQueue(cxGPUContext, device, CL_QUEUE_PROFILING_ENABLE, &ciErrNum);\n            if (ciErrNum != CL_SUCCESS)\n            {\n                shrLog(\" Error %i in clCreateCommandQueue call !!!\\n\\n\", ciErrNum);\n                return ciErrNum;\n            }\n        }\n    }\n \n    // allocate and initalize host memory\n    float* h_idata = (float*)malloc(mem_size);\n    float* h_odata = (float*) malloc(mem_size);\n    srand(15235911);\n    shrFillArray(h_idata, (size_x * size_y));\n\n    // Program Setup\n    size_t program_length;\n    char* source_path = shrFindFilePath(\"transpose.cl\", argv[0]);\n    oclCheckError(source_path != NULL, shrTRUE);\n    char *source = oclLoadProgSource(source_path, \"\", &program_length);\n    oclCheckError(source != NULL, shrTRUE);\n\n    // create the program\n    cpProgram = clCreateProgramWithSource(cxGPUContext, 1,\n                      (const char **)&source, &program_length, &ciErrNum);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n    \n    // build the program\n    ciErrNum = clBuildProgram(cpProgram, 0, NULL, \"-cl-fast-relaxed-math\", NULL, NULL);\n    if (ciErrNum != CL_SUCCESS)\n    {\n        // write out standard error, Build Log and PTX, then return error\n        shrLogEx(LOGBOTH | ERRORMSG, ciErrNum, STDERROR);\n        oclLogBuildInfo(cpProgram, oclGetFirstDev(cxGPUContext));\n        oclLogPtx(cpProgram, oclGetFirstDev(cxGPUContext), \"oclTranspose.ptx\");\n        return(EXIT_FAILURE); \n    }\n    \n    // Run Naive Kernel\n#ifdef GPU_PROFILING\n    // Matrix Copy kernel runs to measure reference performance.\n    double uncoalescedCopyTime = transposeGPU(\"uncoalesced_copy\", false, ciDeviceCount, h_idata, h_odata, size_x, size_y);\n    double simpleCopyTime = transposeGPU(\"simple_copy\", false, ciDeviceCount, h_idata, h_odata, size_x, size_y);\n    double sharedCopyTime = transposeGPU(\"shared_copy\", true, ciDeviceCount, h_idata, h_odata, size_x, size_y);\n#endif\n\n    double naiveTime = transposeGPU(\"transpose_naive\", false, ciDeviceCount, h_idata, h_odata, size_x, size_y);\n    double optimizedTime = transposeGPU(\"transpose\", true, ciDeviceCount, h_idata, h_odata, size_x, size_y);\n\n#ifdef GPU_PROFILING\n    // log times\n\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclTranspose-Outer-simple copy, Throughput = %.4f GB/s, Time = %.5f s, Size = %u fp32 elements, NumDevsUsed = %u, Workgroup = %u\\n\", \n           (1.0e-9 * double(size_x * size_y * sizeof(float))/simpleCopyTime), simpleCopyTime, (size_x * size_y), ciDeviceCount, BLOCK_DIM * BLOCK_DIM); \n\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclTranspose-Outer-shared memory copy, Throughput = %.4f GB/s, Time = %.5f s, Size = %u fp32 elements, NumDevsUsed = %u, Workgroup = %u\\n\", \n           (1.0e-9 * double(size_x * size_y * sizeof(float))/sharedCopyTime), sharedCopyTime, (size_x * size_y), ciDeviceCount, BLOCK_DIM * BLOCK_DIM); \n\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclTranspose-Outer-uncoalesced copy, Throughput = %.4f GB/s, Time = %.5f s, Size = %u fp32 elements, NumDevsUsed = %u, Workgroup = %u\\n\", \n           (1.0e-9 * double(size_x * size_y * sizeof(float))/uncoalescedCopyTime), uncoalescedCopyTime, (size_x * size_y), ciDeviceCount, BLOCK_DIM * BLOCK_DIM); \n\n    shrLogEx(LOGBOTH | MASTER, 0, \"oclTranspose-Outer-naive, Throughput = %.4f GB/s, Time = %.5f s, Size = %u fp32 elements, NumDevsUsed = %u, Workgroup = %u\\n\", \n           (1.0e-9 * double(size_x * size_y * sizeof(float))/naiveTime), naiveTime, (size_x * size_y), ciDeviceCount, BLOCK_DIM * BLOCK_DIM); \n    \n    shrLogEx(LOGBOTH | MASTER, 0, \"oclTranspose-Outer-optimized, Throughput = %.4f GB/s, Time = %.5f s, Size = %u fp32 elements, NumDevsUsed = %u, Workgroup = %u\\n\", \n          (1.0e-9 * double(size_x * size_y * sizeof(float))/optimizedTime), optimizedTime, (size_x * size_y), ciDeviceCount, BLOCK_DIM * BLOCK_DIM); \n\n#endif\n  \n    // compute reference solution and cross check results\n    float* reference = (float*)malloc( mem_size);\n    computeGold( reference, h_idata, size_x, size_y);\n    shrLog(\"\\nComparing results with CPU computation... \\n\\n\");\n    shrBOOL res = shrComparef( reference, h_odata, size_x * size_y);\n\n    // cleanup memory\n    free(h_idata);\n    free(h_odata);\n    free(reference);\n    free(source);\n    free(source_path);\n\n    // cleanup OpenCL\n    ciErrNum = clReleaseProgram(cpProgram);    \n    for(unsigned int i = 0; i < ciDeviceCount; ++i) \n    {\n        ciErrNum |= clReleaseCommandQueue(commandQueue[i]);\n    }    \n    ciErrNum |= clReleaseContext(cxGPUContext);\n    oclCheckError(ciErrNum, CL_SUCCESS);\n\n    // pass or fail (cumulative... all tests in the loop)\n    shrQAFinishExit(argc, (const char **)argv, (1 == res) ? QA_PASSED : QA_FAILED);\n\n    return 0;\n}\n"}, "code_dirs": {"transpose.cl": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclTranspose", "oclTranspose.cpp": "/home/erel.kaplan/atca_proj/data/nvidia_samples/opencl/OpenCL/src/oclTranspose"}}
